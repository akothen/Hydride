; ModuleID = 'softmax'
source_filename = "/home/muchenx2/Hydride/frontends/halide/src/runtime/posix_allocator.cpp"
target datalayout = "e-m:o-i64:64-i128:128-n32:64-S128"
target triple = "arm64-apple-macosx"

%struct.mach_timebase_info = type { i32, i32 }
%"struct.Halide::Runtime::Internal::Synchronization::hash_table" = type { [1024 x %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"] }
%"struct.Halide::Runtime::Internal::Synchronization::hash_bucket" = type { %"class.Halide::Runtime::Internal::Synchronization::word_lock", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* }
%"class.Halide::Runtime::Internal::Synchronization::word_lock" = type { i64 }
%"struct.Halide::Runtime::Internal::Synchronization::queue_data" = type { %"struct.Halide::Runtime::Internal::Synchronization::thread_parker", i64, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, i64 }
%"struct.Halide::Runtime::Internal::Synchronization::thread_parker" = type <{ %struct.pthread_mutex_t, %struct.pthread_mutex_t, i8, [7 x i8] }>
%struct.pthread_mutex_t = type { [8 x i64] }
%"struct.Halide::Runtime::Internal::work_queue_t" = type { %struct.halide_mutex, i32, i32, %"struct.Halide::Runtime::Internal::work"*, i32, i32, i32, [4 x i8], %struct.halide_mutex, %struct.halide_mutex, %struct.halide_mutex, i32, i32, [256 x %struct.halide_thread*], i8, i8, i32 }
%"struct.Halide::Runtime::Internal::work" = type { %struct.halide_parallel_task_t, i32 (i8*, i32, i8*)*, %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"*, i32, %"struct.Halide::Runtime::Internal::work"*, i32, i8*, i32, i32, i32, i8 }
%struct.halide_parallel_task_t = type { i32 (i8*, i32, i32, i8*, i8*)*, i8*, i8*, %struct.halide_semaphore_acquire_t*, i32, i32, i32, i32, i8, [7 x i8] }
%struct.halide_semaphore_acquire_t = type { %struct.halide_semaphore_t*, i32, [4 x i8] }
%struct.halide_semaphore_t = type { [2 x i64] }
%struct.halide_mutex = type { [1 x i64] }
%struct.halide_thread = type opaque
%"class.Halide::Runtime::Internal::TraceBuffer" = type { %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock", i32, i32, [1048576 x i8] }
%"class.Halide::Runtime::Internal::SharedExclusiveSpinLock" = type { i32 }
%struct.halide_trace_event_t = type <{ i8*, i8*, i32*, i8*, %struct.halide_type_t, i32, i32, i32, i32, [4 x i8] }>
%struct.halide_type_t = type { i8, i8, i16 }
%"struct.Halide::Runtime::Internal::CacheEntry" = type { %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"*, i8*, i64, i8*, i32, i32, i32, i32, %struct.halide_dimension_t*, %struct.halide_buffer_t*, i64, i8, [7 x i8] }
%struct.halide_dimension_t = type { i32, i32, i32, i32 }
%struct.halide_buffer_t = type { i64, %struct.halide_device_interface_t*, i8*, i64, %struct.halide_type_t, i32, %struct.halide_dimension_t*, i8* }
%struct.halide_device_interface_t = type { i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, void (i8*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i64, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, i32*, i32*)*, %struct.halide_device_interface_impl_t* }
%struct.halide_device_interface_impl_t = type { void ()*, void ()*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i64)*, i32 (i8*, %struct.halide_buffer_t*)* }
%struct.halide_device_allocation_pool = type { i32 (i8*)*, %struct.halide_device_allocation_pool* }
%struct.halide_profiler_state = type { %struct.halide_mutex, i32, i32, i32, i32, %struct.halide_profiler_pipeline_stats*, void (i32*, i32*)*, %struct.halide_thread* }
%struct.halide_profiler_pipeline_stats = type { i64, i64, i64, i64, i64, i64, i8*, %struct.halide_profiler_func_stats*, i8*, i32, i32, i32, i32, i32, [4 x i8] }
%struct.halide_profiler_func_stats = type { i64, i64, i64, i64, i64, i64, i64, i8*, i32, [4 x i8] }
%struct.halide_filter_argument_t = type { i8*, i32, i32, %struct.halide_type_t, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, i64** }
%struct.halide_scalar_value_t = type { %union.anon.28 }
%union.anon.28 = type { double }
%struct.halide_filter_metadata_t = type { i32, i32, %struct.halide_filter_argument_t*, i8*, i8* }
%"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control" = type { %"struct.Halide::Runtime::Internal::Synchronization::parking_control", i64* }
%"struct.Halide::Runtime::Internal::Synchronization::parking_control" = type { i32 (...)** }
%"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data" = type { %"struct.Halide::Runtime::Internal::Synchronization::thread_parker", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* }
%"struct.Halide::Runtime::Internal::Synchronization::validate_action" = type { i8, [7 x i8], i64 }
%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control" = type { %"struct.Halide::Runtime::Internal::Synchronization::parking_control", i64*, %"class.Halide::Runtime::Internal::Synchronization::word_lock"* }
%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair" = type { %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"*, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* }
%"struct.Halide::Runtime::Internal::spawned_thread" = type { void (i8*)*, i8*, i64 }
%struct.halide_mutex_array = type { %struct.halide_mutex* }
%"struct.Halide::Runtime::Internal::halide_tiff_header" = type <{ i16, i16, i32, i16, [15 x %"struct.Halide::Runtime::Internal::tiff_tag"], i32, [2 x i32], [2 x i32] }>
%"struct.Halide::Runtime::Internal::tiff_tag" = type { i16, i16, i32, %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock" }
%"struct.Halide::Runtime::Internal::CacheBlockHeader" = type { %"struct.Halide::Runtime::Internal::CacheEntry"*, i32, [4 x i8] }
%"struct.Halide::Runtime::Internal::device_copy" = type { i64, i64, i64, [16 x i64], [16 x i64], [16 x i64], i64 }
%"struct.Halide::Runtime::Internal::CpuFeatures" = type { [2 x i64], [2 x i64] }

@_ZN6Halide7Runtime8Internal13custom_mallocE = linkonce local_unnamed_addr global i8* (i8*, i64)* @halide_default_malloc, align 8
@_ZN6Halide7Runtime8Internal11custom_freeE = linkonce local_unnamed_addr global void (i8*, i8*)* @halide_default_free, align 8
@_ZN6Halide7Runtime8Internal13error_handlerE = linkonce local_unnamed_addr global void (i8*, i8*)* @halide_default_error, align 8
@.str = private unnamed_addr constant [8 x i8] c"Error: \00", align 1
@_ZN6Halide7Runtime8Internal12custom_printE = linkonce local_unnamed_addr global void (i8*, i8*)* @halide_default_print, align 8
@_ZN6Halide7Runtime8Internal29halide_reference_clock_initedE = linkonce local_unnamed_addr global i8 0, align 1
@_ZN6Halide7Runtime8Internal22halide_reference_clockE = linkonce local_unnamed_addr global i64 0, align 8
@_ZN6Halide7Runtime8Internal20halide_timebase_infoE = linkonce global %struct.mach_timebase_info zeroinitializer, align 4
@_ZN6Halide7Runtime8Internal15Synchronization5tableE = linkonce global %"struct.Halide::Runtime::Internal::Synchronization::hash_table" zeroinitializer, align 8
@_ZN6Halide7Runtime8Internal10work_queueE = linkonce global %"struct.Halide::Runtime::Internal::work_queue_t" { %struct.halide_mutex zeroinitializer, i32 0, i32 0, %"struct.Halide::Runtime::Internal::work"* null, i32 0, i32 0, i32 0, [4 x i8] undef, %struct.halide_mutex zeroinitializer, %struct.halide_mutex zeroinitializer, %struct.halide_mutex zeroinitializer, i32 0, i32 0, [256 x %struct.halide_thread*] zeroinitializer, i8 0, i8 0, i32 0 }, align 8
@_ZN6Halide7Runtime8Internal14custom_do_taskE = linkonce local_unnamed_addr global i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* @halide_default_do_task, align 8
@_ZN6Halide7Runtime8Internal19custom_do_loop_taskE = linkonce local_unnamed_addr global i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)* @halide_default_do_loop_task, align 8
@_ZN6Halide7Runtime8Internal17custom_do_par_forE = linkonce local_unnamed_addr global i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* @halide_default_do_par_for, align 8
@_ZTVN6Halide7Runtime8Internal15Synchronization21mutex_parking_controlE = linkonce_odr unnamed_addr constant { [6 x i8*] } { [6 x i8*] [i8* null, i8* null, i8* bitcast (i1 (%"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)* @_ZN6Halide7Runtime8Internal15Synchronization21mutex_parking_control8validateERNS2_15validate_actionE to i8*), i8* bitcast (void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)* @_ZN6Halide7Runtime8Internal15Synchronization15parking_control12before_sleepEv to i8*), i8* bitcast (i64 (%"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"*, i32, i1)* @_ZN6Halide7Runtime8Internal15Synchronization21mutex_parking_control6unparkEib to i8*), i8* bitcast (void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)* @_ZN6Halide7Runtime8Internal15Synchronization15parking_control16requeue_callbackERKNS2_15validate_actionEbb to i8*)] }, align 8
@.str.5 = private unnamed_addr constant [130 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/synchronization_common.h:386 halide_abort_if_false() failed: next != nullptr\0A\00", align 1
@_ZTVN6Halide7Runtime8Internal15Synchronization20wait_parking_controlE = linkonce_odr unnamed_addr constant { [6 x i8*] } { [6 x i8*] [i8* null, i8* null, i8* bitcast (i1 (%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)* @_ZN6Halide7Runtime8Internal15Synchronization20wait_parking_control8validateERNS2_15validate_actionE to i8*), i8* bitcast (void (%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"*)* @_ZN6Halide7Runtime8Internal15Synchronization20wait_parking_control12before_sleepEv to i8*), i8* bitcast (i64 (%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"*, i32, i1)* @_ZN6Halide7Runtime8Internal15Synchronization20wait_parking_control6unparkEib to i8*), i8* bitcast (void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)* @_ZN6Halide7Runtime8Internal15Synchronization15parking_control16requeue_callbackERKNS2_15validate_actionEbb to i8*)] }, align 8
@.str.5.6 = private unnamed_addr constant [124 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/synchronization_common.h:994 halide_abort_if_false() failed: val & 0x1\0A\00", align 1
@_ZTVN6Halide7Runtime8Internal15Synchronization25broadcast_parking_controlE = linkonce_odr unnamed_addr constant { [6 x i8*] } { [6 x i8*] [i8* null, i8* null, i8* bitcast (i1 (%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)* @_ZN6Halide7Runtime8Internal15Synchronization25broadcast_parking_control8validateERNS2_15validate_actionE to i8*), i8* bitcast (void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)* @_ZN6Halide7Runtime8Internal15Synchronization15parking_control12before_sleepEv to i8*), i8* bitcast (i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)* @_ZN6Halide7Runtime8Internal15Synchronization15parking_control6unparkEib to i8*), i8* bitcast (void (%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)* @_ZN6Halide7Runtime8Internal15Synchronization25broadcast_parking_control16requeue_callbackERKNS2_15validate_actionEbb to i8*)] }, align 8
@.str.6 = private unnamed_addr constant [186 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/thread_pool_common.h:155 halide_abort_if_false() failed: bytes == limit && \22Logic error in thread pool work queue initialization.\\n\22\0A\00", align 1
@.str.3 = private unnamed_addr constant [263 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/thread_pool_common.h:527 halide_abort_if_false() failed: (min_threads <= ((task_parent->task.min_threads * task_parent->active_workers) - task_parent->threads_reserved)) && \22Logic error: thread over commit.\\n\22\0A\00", align 1
@.str.1 = private unnamed_addr constant [15 x i8] c"HL_NUM_THREADS\00", align 1
@.str.2 = private unnamed_addr constant [14 x i8] c"HL_NUMTHREADS\00", align 1
@_ZN6Halide7Runtime8Internal24custom_do_parallel_tasksE = linkonce local_unnamed_addr global i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)* @halide_default_do_parallel_tasks, align 8
@_ZN6Halide7Runtime8Internal21custom_semaphore_initE = linkonce local_unnamed_addr global i32 (%struct.halide_semaphore_t*, i32)* @halide_default_semaphore_init, align 8
@_ZN6Halide7Runtime8Internal28custom_semaphore_try_acquireE = linkonce local_unnamed_addr global i1 (%struct.halide_semaphore_t*, i32)* @halide_default_semaphore_try_acquire, align 8
@_ZN6Halide7Runtime8Internal24custom_semaphore_releaseE = linkonce local_unnamed_addr global i32 (%struct.halide_semaphore_t*, i32)* @halide_default_semaphore_release, align 8
@llvm.global_dtors = appending global [4 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 65535, void ()* @halide_thread_pool_cleanup, i8* null }, { i32, void ()*, i8* } { i32 65535, void ()* @halide_trace_cleanup, i8* null }, { i32, void ()*, i8* } { i32 65535, void ()* @halide_cache_cleanup, i8* null }, { i32, void ()*, i8* } { i32 65535, void ()* @halide_profiler_shutdown, i8* null }]
@_ZTVN6Halide7Runtime8Internal15Synchronization22signal_parking_controlE = linkonce_odr unnamed_addr constant { [6 x i8*] } { [6 x i8*] [i8* null, i8* null, i8* bitcast (i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)* @_ZN6Halide7Runtime8Internal15Synchronization15parking_control8validateERNS2_15validate_actionE to i8*), i8* bitcast (void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)* @_ZN6Halide7Runtime8Internal15Synchronization15parking_control12before_sleepEv to i8*), i8* bitcast (i64 (%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"*, i32, i1)* @_ZN6Halide7Runtime8Internal15Synchronization22signal_parking_control6unparkEib to i8*), i8* bitcast (void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)* @_ZN6Halide7Runtime8Internal15Synchronization15parking_control16requeue_callbackERKNS2_15validate_actionEbb to i8*)] }, align 8
@.str.4 = private unnamed_addr constant [38 x i8] c"halide_set_num_threads: must be >= 0.\00", align 1
@_ZN6Halide7Runtime8Internal17custom_get_symbolE = linkonce local_unnamed_addr global i8* (i8*)* @halide_default_get_symbol, align 8
@_ZN6Halide7Runtime8Internal19custom_load_libraryE = linkonce local_unnamed_addr global i8* (i8*)* @halide_default_load_library, align 8
@_ZN6Halide7Runtime8Internal25custom_get_library_symbolE = linkonce local_unnamed_addr global i8* (i8*, i8*)* @halide_default_get_library_symbol, align 8
@_ZN6Halide7Runtime8Internal17halide_gpu_deviceE = linkonce local_unnamed_addr global i32 0, align 4
@_ZN6Halide7Runtime8Internal22halide_gpu_device_lockE = linkonce global i8 0, align 1
@_ZN6Halide7Runtime8Internal29halide_gpu_device_initializedE = linkonce local_unnamed_addr global i8 0, align 1
@.str.8 = private unnamed_addr constant [14 x i8] c"HL_GPU_DEVICE\00", align 1
@_ZN6Halide7Runtime8Internal19halide_trace_bufferE = linkonce local_unnamed_addr global %"class.Halide::Runtime::Internal::TraceBuffer"* null, align 8
@_ZN6Halide7Runtime8Internal17halide_trace_fileE = linkonce local_unnamed_addr global i32 -1, align 4
@_ZN6Halide7Runtime8Internal22halide_trace_file_lockE = linkonce global i8 0, align 1
@_ZN6Halide7Runtime8Internal29halide_trace_file_initializedE = linkonce local_unnamed_addr global i8 0, align 1
@_ZN6Halide7Runtime8Internal35halide_trace_file_internally_openedE = linkonce local_unnamed_addr global i8* null, align 8
@_ZN6Halide7Runtime8Internal19halide_custom_traceE = linkonce local_unnamed_addr global i32 (i8*, %struct.halide_trace_event_t*)* @halide_default_trace, align 8
@_ZZ20halide_default_traceE3ids = internal global i32 1, align 4
@.str.32 = private unnamed_addr constant [144 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/tracing.cpp:115 halide_abort_if_false() failed: success && \22Could not write to trace file\22\0A\00", align 1
@.str.31 = private unnamed_addr constant [120 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/tracing.cpp:87 halide_abort_if_false() failed: size <= buffer_size\0A\00", align 1
@.str.1.10 = private unnamed_addr constant [1 x i8] zeroinitializer, align 1
@.str.2.11 = private unnamed_addr constant [140 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/tracing.cpp:218 halide_abort_if_false() failed: print_bits <= 64 && \22Tracing bad type\22\0A\00", align 1
@__const.halide_default_trace.event_types = private unnamed_addr constant [11 x i8*] [i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.3.12, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.4.13, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.5.14, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.6.15, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.7, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.8.16, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.9.17, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.10, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.11, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.12, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.13, i32 0, i32 0)], align 8
@.str.17 = private unnamed_addr constant [2 x i8] c"<\00", align 1
@.str.20 = private unnamed_addr constant [3 x i8] c">)\00", align 1
@.str.18 = private unnamed_addr constant [5 x i8] c">, <\00", align 1
@.str.22 = private unnamed_addr constant [5 x i8] c" = <\00", align 1
@.str.23 = private unnamed_addr constant [4 x i8] c" = \00", align 1
@.str.24 = private unnamed_addr constant [142 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/tracing.cpp:287 halide_abort_if_false() failed: print_bits >= 16 && \22Tracing a bad type\22\0A\00", align 1
@.str.25 = private unnamed_addr constant [2 x i8] c">\00", align 1
@.str.26 = private unnamed_addr constant [9 x i8] c" tag = \22\00", align 1
@.str.27 = private unnamed_addr constant [2 x i8] c"\22\00", align 1
@.str.3.12 = private unnamed_addr constant [5 x i8] c"Load\00", align 1
@.str.4.13 = private unnamed_addr constant [6 x i8] c"Store\00", align 1
@.str.5.14 = private unnamed_addr constant [18 x i8] c"Begin realization\00", align 1
@.str.6.15 = private unnamed_addr constant [16 x i8] c"End realization\00", align 1
@.str.7 = private unnamed_addr constant [8 x i8] c"Produce\00", align 1
@.str.8.16 = private unnamed_addr constant [12 x i8] c"End produce\00", align 1
@.str.9.17 = private unnamed_addr constant [8 x i8] c"Consume\00", align 1
@.str.10 = private unnamed_addr constant [12 x i8] c"End consume\00", align 1
@.str.11 = private unnamed_addr constant [15 x i8] c"Begin pipeline\00", align 1
@.str.12 = private unnamed_addr constant [13 x i8] c"End pipeline\00", align 1
@.str.13 = private unnamed_addr constant [4 x i8] c"Tag\00", align 1
@.str.28 = private unnamed_addr constant [14 x i8] c"HL_TRACE_FILE\00", align 1
@.str.29 = private unnamed_addr constant [3 x i8] c"ab\00", align 1
@.str.30 = private unnamed_addr constant [139 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/tracing.cpp:351 halide_abort_if_false() failed: file && \22Failed to open trace file\\n\22\0A\00", align 1
@_ZN6Halide7Runtime8Internal30pixel_type_to_tiff_sample_typeE = linkonce local_unnamed_addr global [10 x i16] [i16 3, i16 3, i16 1, i16 2, i16 1, i16 2, i16 1, i16 2, i16 1, i16 2], align 2
@_ZN6Halide7Runtime8Internal31pixel_type_to_matlab_class_codeE = linkonce local_unnamed_addr global [10 x i8] c"\07\06\09\08\0B\0A\0D\0C\0F\0E", align 1
@_ZN6Halide7Runtime8Internal30pixel_type_to_matlab_type_codeE = linkonce local_unnamed_addr global [10 x i8] c"\07\09\02\01\04\03\06\05\0D\0C", align 1
@.str.34 = private unnamed_addr constant [51 x i8] c"Bounds query buffer passed to halide_debug_to_file\00", align 1
@.str.1.35 = private unnamed_addr constant [59 x i8] c"Can't debug_to_file a Func with more than four dimensions\0A\00", align 1
@.str.2.36 = private unnamed_addr constant [3 x i8] c"wb\00", align 1
@.str.3.37 = private unnamed_addr constant [6 x i8] c".tiff\00", align 1
@.str.4.38 = private unnamed_addr constant [5 x i8] c".tif\00", align 1
@.str.5.39 = private unnamed_addr constant [5 x i8] c".mat\00", align 1
@__const.halide_debug_to_file.header = private unnamed_addr constant [129 x i8] c"MATLAB 5.0 MAT-file, produced by Halide                                                                                     \00\01IM\00", align 1
@.str.6.40 = private unnamed_addr constant [53 x i8] c"Can't debug_to_file to a .mat file greater than 4GB\0A\00", align 1
@_ZN6Halide7Runtime8Internal16memoization_lockE = linkonce global %struct.halide_mutex zeroinitializer, align 8
@_ZN6Halide7Runtime8Internal13cache_entriesE = linkonce global [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*] zeroinitializer, align 8
@_ZN6Halide7Runtime8Internal18most_recently_usedE = linkonce local_unnamed_addr global %"struct.Halide::Runtime::Internal::CacheEntry"* null, align 8
@_ZN6Halide7Runtime8Internal19least_recently_usedE = linkonce local_unnamed_addr global %"struct.Halide::Runtime::Internal::CacheEntry"* null, align 8
@_ZN6Halide7Runtime8Internal14max_cache_sizeE = linkonce local_unnamed_addr global i64 1048576, align 8
@_ZN6Halide7Runtime8Internal18current_cache_sizeE = linkonce local_unnamed_addr global i64 0, align 8
@.str.2.42 = private unnamed_addr constant [126 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/cache.cpp:284 halide_abort_if_false() failed: prev_hash_entry != nullptr\0A\00", align 1
@.str.3.43 = private unnamed_addr constant [129 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/cache.cpp:373 halide_abort_if_false() failed: entry->more_recent != nullptr\0A\00", align 1
@.str.4.44 = private unnamed_addr constant [128 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/cache.cpp:377 halide_abort_if_false() failed: least_recently_used == entry\0A\00", align 1
@.str.5.45 = private unnamed_addr constant [129 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/cache.cpp:380 halide_abort_if_false() failed: entry->more_recent != nullptr\0A\00", align 1
@.str.9.46 = private unnamed_addr constant [122 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/cache.cpp:472 halide_abort_if_false() failed: no_host_pointers_equal\0A\00", align 1
@.str.12.47 = private unnamed_addr constant [123 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/cache.cpp:550 halide_abort_if_false() failed: entry->in_use_count > 0\0A\00", align 1
@.str.50 = private unnamed_addr constant [10 x i8] c"<nullptr>\00", align 1
@.str.1.57 = private unnamed_addr constant [5 x i8] c"-nan\00", align 1
@.str.2.58 = private unnamed_addr constant [4 x i8] c"nan\00", align 1
@.str.3.59 = private unnamed_addr constant [5 x i8] c"-inf\00", align 1
@.str.4.60 = private unnamed_addr constant [4 x i8] c"inf\00", align 1
@.str.5.61 = private unnamed_addr constant [14 x i8] c"-0.000000e+00\00", align 1
@.str.6.62 = private unnamed_addr constant [13 x i8] c"0.000000e+00\00", align 1
@.str.7.63 = private unnamed_addr constant [10 x i8] c"-0.000000\00", align 1
@.str.8.64 = private unnamed_addr constant [9 x i8] c"0.000000\00", align 1
@.str.9.65 = private unnamed_addr constant [2 x i8] c"-\00", align 1
@.str.11.67 = private unnamed_addr constant [3 x i8] c"e+\00", align 1
@.str.12.68 = private unnamed_addr constant [3 x i8] c"e-\00", align 1
@.str.13.71 = private unnamed_addr constant [17 x i8] c"0123456789abcdef\00", align 1
@.str.18.72 = private unnamed_addr constant [14 x i8] c"bad_type_code\00", align 1
@.str.17.73 = private unnamed_addr constant [7 x i8] c"handle\00", align 1
@.str.16.74 = private unnamed_addr constant [6 x i8] c"float\00", align 1
@.str.15.75 = private unnamed_addr constant [5 x i8] c"uint\00", align 1
@.str.14.76 = private unnamed_addr constant [4 x i8] c"int\00", align 1
@.str.19.77 = private unnamed_addr constant [2 x i8] c"x\00", align 1
@.str.20.78 = private unnamed_addr constant [8 x i8] c"nullptr\00", align 1
@.str.21.79 = private unnamed_addr constant [8 x i8] c"buffer(\00", align 1
@.str.23.82 = private unnamed_addr constant [4 x i8] c", {\00", align 1
@.str.24.83 = private unnamed_addr constant [2 x i8] c"}\00", align 1
@_ZN6Halide7Runtime8Internal36halide_reuse_device_allocations_flagE = linkonce local_unnamed_addr global i8 1, align 1
@_ZN6Halide7Runtime8Internal21allocation_pools_lockE = linkonce global %struct.halide_mutex zeroinitializer, align 8
@_ZN6Halide7Runtime8Internal23device_allocation_poolsE = linkonce local_unnamed_addr global %struct.halide_device_allocation_pool* null, align 8
@_ZN6Halide7Runtime8Internal17device_copy_mutexE = linkonce global %struct.halide_mutex zeroinitializer, align 8
@.str.6.88 = private unnamed_addr constant [20 x i8] c"halide_copy_to_host\00", align 1
@.str.7.89 = private unnamed_addr constant [22 x i8] c"halide_copy_to_device\00", align 1
@.str.9.90 = private unnamed_addr constant [61 x i8] c"halide_copy_to_device does not support switching interfaces\0A\00", align 1
@.str.17.91 = private unnamed_addr constant [21 x i8] c"halide_device_malloc\00", align 1
@.str.20.92 = private unnamed_addr constant [59 x i8] c"halide_device_malloc doesn't support switching interfaces\0A\00", align 1
@.str.16.93 = private unnamed_addr constant [19 x i8] c"halide_device_sync\00", align 1
@.str.21.96 = private unnamed_addr constant [19 x i8] c"halide_device_free\00", align 1
@.str.22.97 = private unnamed_addr constant [127 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/device_interface.cpp:252 halide_abort_if_false() failed: buf->device == 0\0A\00", align 1
@.str.23.98 = private unnamed_addr constant [30 x i8] c"halide_device_and_host_malloc\00", align 1
@.str.25.99 = private unnamed_addr constant [68 x i8] c"halide_device_and_host_malloc doesn't support switching interfaces\0A\00", align 1
@.str.26.100 = private unnamed_addr constant [42 x i8] c"allocating host and device memory failed\0A\00", align 1
@.str.27.101 = private unnamed_addr constant [28 x i8] c"halide_device_and_host_free\00", align 1
@.str.28.102 = private unnamed_addr constant [127 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/device_interface.cpp:317 halide_abort_if_false() failed: buf->device == 0\0A\00", align 1
@.str.29.103 = private unnamed_addr constant [38 x i8] c"halide_default_device_and_host_malloc\00", align 1
@.str.30.104 = private unnamed_addr constant [36 x i8] c"halide_default_device_and_host_free\00", align 1
@.str.31.105 = private unnamed_addr constant [26 x i8] c"halide_device_wrap_native\00", align 1
@.str.32.106 = private unnamed_addr constant [64 x i8] c"halide_device_wrap_native doesn't support switching interfaces\0A\00", align 1
@.str.33.107 = private unnamed_addr constant [28 x i8] c"halide_device_detach_native\00", align 1
@.str.34.108 = private unnamed_addr constant [127 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/device_interface.cpp:403 halide_abort_if_false() failed: buf->device == 0\0A\00", align 1
@.str.35 = private unnamed_addr constant [36 x i8] c"halide_default_device_detach_native\00", align 1
@.str.41 = private unnamed_addr constant [64 x i8] c"halide_buffer_copy does not support switching device interfaces\00", align 1
@.str.58 = private unnamed_addr constant [44 x i8] c"device_interface does not support cropping\0A\00", align 1
@.str.59 = private unnamed_addr constant [43 x i8] c"device_interface does not support slicing\0A\00", align 1
@.str.60 = private unnamed_addr constant [52 x i8] c"destination buffer already has a device allocation\0A\00", align 1
@.str.61 = private unnamed_addr constant [48 x i8] c"src and dst must have identical dimensionality\0A\00", align 1
@.str.64 = private unnamed_addr constant [52 x i8] c"dst must have exactly one fewer dimension than src\0A\00", align 1
@.str.111 = private unnamed_addr constant [41 x i8] c"Bounds inference call to external stage \00", align 1
@.str.1.112 = private unnamed_addr constant [27 x i8] c" returned non-zero value: \00", align 1
@.str.2.113 = private unnamed_addr constant [24 x i8] c"Call to external stage \00", align 1
@.str.3.114 = private unnamed_addr constant [18 x i8] c"Bounds given for \00", align 1
@.str.4.115 = private unnamed_addr constant [5 x i8] c" in \00", align 1
@.str.5.116 = private unnamed_addr constant [8 x i8] c" (from \00", align 1
@.str.6.117 = private unnamed_addr constant [5 x i8] c" to \00", align 1
@.str.7.118 = private unnamed_addr constant [38 x i8] c") do not cover required region (from \00", align 1
@.str.8.119 = private unnamed_addr constant [2 x i8] c")\00", align 1
@.str.9.120 = private unnamed_addr constant [11 x i8] c" has type \00", align 1
@.str.10.121 = private unnamed_addr constant [38 x i8] c" but type of the buffer passed in is \00", align 1
@.str.11.122 = private unnamed_addr constant [31 x i8] c" requires a buffer of exactly \00", align 1
@.str.12.123 = private unnamed_addr constant [43 x i8] c" dimensions, but the buffer passed in has \00", align 1
@.str.13.124 = private unnamed_addr constant [12 x i8] c" dimensions\00", align 1
@.str.14.125 = private unnamed_addr constant [17 x i8] c" is accessed at \00", align 1
@.str.15.126 = private unnamed_addr constant [28 x i8] c", which is before the min (\00", align 1
@.str.16.127 = private unnamed_addr constant [16 x i8] c") in dimension \00", align 1
@.str.17.128 = private unnamed_addr constant [28 x i8] c", which is beyond the max (\00", align 1
@.str.18.129 = private unnamed_addr constant [29 x i8] c"Total allocation for buffer \00", align 1
@.str.19.130 = private unnamed_addr constant [5 x i8] c" is \00", align 1
@.str.20.131 = private unnamed_addr constant [37 x i8] c", which exceeds the maximum size of \00", align 1
@.str.21.132 = private unnamed_addr constant [24 x i8] c"The extents for buffer \00", align 1
@.str.22.133 = private unnamed_addr constant [12 x i8] c" dimension \00", align 1
@.str.23.134 = private unnamed_addr constant [15 x i8] c" is negative (\00", align 1
@.str.24.135 = private unnamed_addr constant [31 x i8] c"Product of extents for buffer \00", align 1
@.str.25.136 = private unnamed_addr constant [29 x i8] c"Applying the constraints on \00", align 1
@.str.26.137 = private unnamed_addr constant [54 x i8] c" to the required region made it smaller in dimension \00", align 1
@.str.27.138 = private unnamed_addr constant [3 x i8] c". \00", align 1
@.str.28.139 = private unnamed_addr constant [16 x i8] c"Required size: \00", align 1
@.str.29.140 = private unnamed_addr constant [19 x i8] c"Constrained size: \00", align 1
@.str.30.141 = private unnamed_addr constant [2 x i8] c".\00", align 1
@.str.31.142 = private unnamed_addr constant [22 x i8] c"Constraint violated: \00", align 1
@.str.32.143 = private unnamed_addr constant [3 x i8] c" (\00", align 1
@.str.33.144 = private unnamed_addr constant [6 x i8] c") == \00", align 1
@.str.34.145 = private unnamed_addr constant [11 x i8] c"Parameter \00", align 1
@.str.35.146 = private unnamed_addr constant [23 x i8] c" but must be at least \00", align 1
@.str.36 = private unnamed_addr constant [22 x i8] c" but must be at most \00", align 1
@.str.37 = private unnamed_addr constant [47 x i8] c"Out of memory (halide_malloc returned nullptr)\00", align 1
@.str.38 = private unnamed_addr constant [17 x i8] c"Buffer argument \00", align 1
@.str.39 = private unnamed_addr constant [12 x i8] c" is nullptr\00", align 1
@.str.40 = private unnamed_addr constant [25 x i8] c"Failed to dump function \00", align 1
@.str.41.147 = private unnamed_addr constant [10 x i8] c" to file \00", align 1
@.str.42 = private unnamed_addr constant [13 x i8] c" with error \00", align 1
@.str.43 = private unnamed_addr constant [21 x i8] c"The host pointer of \00", align 1
@.str.44 = private unnamed_addr constant [22 x i8] c" is not aligned to a \00", align 1
@.str.45 = private unnamed_addr constant [17 x i8] c" bytes boundary.\00", align 1
@.str.46 = private unnamed_addr constant [12 x i8] c"The buffer \00", align 1
@.str.47 = private unnamed_addr constant [53 x i8] c" is dirty on device, but this pipeline was compiled \00", align 1
@.str.48 = private unnamed_addr constant [43 x i8] c"with no support for device to host copies.\00", align 1
@.str.49 = private unnamed_addr constant [55 x i8] c" is null, but the pipeline will access it on the host.\00", align 1
@.str.50.148 = private unnamed_addr constant [30 x i8] c"The folded storage dimension \00", align 1
@.str.51 = private unnamed_addr constant [5 x i8] c" of \00", align 1
@.str.52 = private unnamed_addr constant [36 x i8] c" was accessed out of order by loop \00", align 1
@.str.53 = private unnamed_addr constant [23 x i8] c"Cannot fold dimension \00", align 1
@.str.54 = private unnamed_addr constant [36 x i8] c" because an extern stage accesses [\00", align 1
@.str.55 = private unnamed_addr constant [3 x i8] c", \00", align 1
@.str.56 = private unnamed_addr constant [3 x i8] c"],\00", align 1
@.str.57 = private unnamed_addr constant [47 x i8] c" which is outside the range currently valid: [\00", align 1
@.str.58.149 = private unnamed_addr constant [3 x i8] c"].\00", align 1
@.str.59.150 = private unnamed_addr constant [47 x i8] c" which wraps around the boundary of the fold, \00", align 1
@.str.60.151 = private unnamed_addr constant [30 x i8] c"which occurs at multiples of \00", align 1
@.str.61.152 = private unnamed_addr constant [18 x i8] c"The fold factor (\00", align 1
@.str.62 = private unnamed_addr constant [16 x i8] c") of dimension \00", align 1
@.str.63 = private unnamed_addr constant [61 x i8] c" is too small to store the required region accessed by loop \00", align 1
@.str.64.153 = private unnamed_addr constant [3 x i8] c").\00", align 1
@.str.65 = private unnamed_addr constant [22 x i8] c"Requirement Failed: (\00", align 1
@.str.66 = private unnamed_addr constant [3 x i8] c") \00", align 1
@.str.67 = private unnamed_addr constant [59 x i8] c"A schedule specialized with specialize_fail() was chosen: \00", align 1
@.str.68 = private unnamed_addr constant [55 x i8] c"Buffer has a non-zero device but no device interface.\0A\00", align 1
@.str.69 = private unnamed_addr constant [57 x i8] c"Buffer has a non-null device_interface but device is 0.\0A\00", align 1
@.str.70 = private unnamed_addr constant [49 x i8] c"Buffer has both host and device dirty bits set.\0A\00", align 1
@.str.71 = private unnamed_addr constant [26 x i8] c"Buffer pointer passed to \00", align 1
@.str.72 = private unnamed_addr constant [11 x i8] c" is null.\0A\00", align 1
@.str.73 = private unnamed_addr constant [32 x i8] c"The explicit allocation bound (\00", align 1
@.str.74 = private unnamed_addr constant [45 x i8] c" is too small to store the required region (\00", align 1
@.str.75 = private unnamed_addr constant [77 x i8] c"Buffer could not be cropped (runtime error or unimplemented device option).\0A\00", align 1
@.str.29.163 = private unnamed_addr constant [35 x i8] c"Printer buffer allocation failed.\0A\00", align 1
@.str.7.164 = private unnamed_addr constant [2 x i8] c"\0A\00", align 1
@.str.8.165 = private unnamed_addr constant [14 x i8] c" total time: \00", align 1
@.str.9.166 = private unnamed_addr constant [4 x i8] c" ms\00", align 1
@.str.10.167 = private unnamed_addr constant [12 x i8] c"  samples: \00", align 1
@.str.11.168 = private unnamed_addr constant [9 x i8] c"  runs: \00", align 1
@.str.12.169 = private unnamed_addr constant [13 x i8] c"  time/run: \00", align 1
@.str.13.170 = private unnamed_addr constant [5 x i8] c" ms\0A\00", align 1
@.str.14.171 = private unnamed_addr constant [24 x i8] c" average threads used: \00", align 1
@.str.15.172 = private unnamed_addr constant [20 x i8] c" heap allocations: \00", align 1
@.str.16.173 = private unnamed_addr constant [20 x i8] c"  peak heap usage: \00", align 1
@.str.17.174 = private unnamed_addr constant [8 x i8] c" bytes\0A\00", align 1
@.str.18.175 = private unnamed_addr constant [3 x i8] c"  \00", align 1
@.str.19.176 = private unnamed_addr constant [3 x i8] c": \00", align 1
@.str.20.177 = private unnamed_addr constant [2 x i8] c" \00", align 1
@.str.21.178 = private unnamed_addr constant [3 x i8] c"ms\00", align 1
@.str.22.179 = private unnamed_addr constant [2 x i8] c"(\00", align 1
@.str.23.180 = private unnamed_addr constant [3 x i8] c"%)\00", align 1
@.str.24.181 = private unnamed_addr constant [10 x i8] c"threads: \00", align 1
@.str.25.182 = private unnamed_addr constant [8 x i8] c" peak: \00", align 1
@.str.26.183 = private unnamed_addr constant [7 x i8] c" num: \00", align 1
@.str.27.184 = private unnamed_addr constant [7 x i8] c" avg: \00", align 1
@.str.28.185 = private unnamed_addr constant [9 x i8] c" stack: \00", align 1
@_ZZ25halide_profiler_get_stateE1s = internal global %struct.halide_profiler_state { %struct.halide_mutex zeroinitializer, i32 1, i32 0, i32 0, i32 0, %struct.halide_profiler_pipeline_stats* null, void (i32*, i32*)* null, %struct.halide_thread* null }, align 8
@.str.186 = private unnamed_addr constant [128 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/profiler_common.cpp:246 halide_abort_if_false() failed: p_stats != nullptr\0A\00", align 1
@.str.1.187 = private unnamed_addr constant [128 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/profiler_common.cpp:273 halide_abort_if_false() failed: p_stats != nullptr\0A\00", align 1
@.str.2.188 = private unnamed_addr constant [122 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/profiler_common.cpp:274 halide_abort_if_false() failed: func_id >= 0\0A\00", align 1
@.str.3.189 = private unnamed_addr constant [138 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/profiler_common.cpp:275 halide_abort_if_false() failed: func_id < p_stats->num_funcs\0A\00", align 1
@.str.4.190 = private unnamed_addr constant [128 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/profiler_common.cpp:309 halide_abort_if_false() failed: p_stats != nullptr\0A\00", align 1
@.str.5.191 = private unnamed_addr constant [122 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/profiler_common.cpp:310 halide_abort_if_false() failed: func_id >= 0\0A\00", align 1
@.str.6.192 = private unnamed_addr constant [138 x i8] c"/home/muchenx2/Hydride/frontends/halide/src/runtime/profiler_common.cpp:311 halide_abort_if_false() failed: func_id < p_stats->num_funcs\0A\00", align 1
@_ZN6Halide7Runtime8Internal30custom_can_use_target_featuresE = linkonce local_unnamed_addr global i32 (i32, i64*)* @halide_default_can_use_target_features, align 8
@_ZN6Halide7Runtime8Internal36halide_cpu_features_initialized_lockE = linkonce global %struct.halide_mutex zeroinitializer, align 8
@_ZN6Halide7Runtime8Internal31halide_cpu_features_initializedE = linkonce local_unnamed_addr global i8 0, align 1
@_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE = linkonce global [4 x i64] zeroinitializer, align 8
@.str.197 = private unnamed_addr constant [81 x i8] c"Internal error: wrong structure size passed to halide_can_use_target_features()\0A\00", align 1
@0 = private constant [4 x i64*] zeroinitializer
@str = private constant [6 x i8] c"input\00", align 32
@str.200 = private constant [16 x i8] c"beta_multiplier\00", align 32
@str.201 = private constant [11 x i8] c"beta_shift\00", align 32
@str.202 = private constant [12 x i8] c"output_zero\00", align 32
@str.203 = private constant [18 x i8] c"output_multiplier\00", align 32
@str.204 = private constant [13 x i8] c"output_shift\00", align 32
@1 = private constant [4 x i64*] zeroinitializer
@str.205 = private constant [7 x i8] c"output\00", align 32
@2 = private constant [7 x %struct.halide_filter_argument_t] [%struct.halide_filter_argument_t { i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str, i32 0, i32 0), i32 1, i32 2, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** getelementptr inbounds ([4 x i64*], [4 x i64*]* @0, i32 0, i32 0) }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @str.200, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 0, i8 16, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([11 x i8], [11 x i8]* @str.201, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 1, i8 16, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([12 x i8], [12 x i8]* @str.202, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([18 x i8], [18 x i8]* @str.203, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 0, i8 16, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([13 x i8], [13 x i8]* @str.204, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 1, i8 16, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str.205, i32 0, i32 0), i32 2, i32 2, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** getelementptr inbounds ([4 x i64*], [4 x i64*]* @1, i32 0, i32 0) }]
@str.206 = private constant [38 x i8] c"arm-64-osx-no_asserts-no_bounds_query\00", align 32
@str.207 = private constant [8 x i8] c"softmax\00", align 32
@softmax_metadata_storage = private constant %struct.halide_filter_metadata_t { i32 1, i32 7, %struct.halide_filter_argument_t* getelementptr inbounds ([7 x %struct.halide_filter_argument_t], [7 x %struct.halide_filter_argument_t]* @2, i32 0, i32 0), i8* getelementptr inbounds ([38 x i8], [38 x i8]* @str.206, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str.207, i32 0, i32 0) }
@switch.table.halide_type_to_string = private unnamed_addr constant [4 x i8*] [i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.14.76, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.15.75, i64 0, i64 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.16.74, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.17.73, i64 0, i64 0)], align 8

; Function Attrs: nounwind mustprogress
define weak i8* @halide_default_malloc(i8* %user_context, i64 %x) #0 {
entry:
  %add = add i64 %x, 32
  %call1 = tail call i8* @malloc(i64 %add) #14
  %cmp = icmp eq i8* %call1, null
  br i1 %cmp, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %0 = ptrtoint i8* %call1 to i64
  %sub = add i64 %0, 39
  %and = and i64 %sub, -32
  %1 = inttoptr i64 %and to i8*
  %2 = inttoptr i64 %and to i8**
  %arrayidx = getelementptr inbounds i8*, i8** %2, i64 -1
  store i8* %call1, i8** %arrayidx, align 8, !tbaa !14
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i8* [ %1, %if.end ], [ null, %entry ]
  ret i8* %retval.0
}

declare i8* @malloc(i64) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void @halide_default_free(i8* %user_context, i8* %ptr) #0 {
entry:
  %arrayidx = getelementptr inbounds i8, i8* %ptr, i64 -8
  %0 = bitcast i8* %arrayidx to i8**
  %1 = load i8*, i8** %0, align 8, !tbaa !14
  tail call void @free(i8* %1) #14
  ret void
}

declare void @free(i8*) local_unnamed_addr #1

; Function Attrs: nounwind willreturn mustprogress
define weak i8* (i8*, i64)* @halide_set_custom_malloc(i8* (i8*, i64)* %user_malloc) local_unnamed_addr #2 {
entry:
  %0 = load i8* (i8*, i64)*, i8* (i8*, i64)** @_ZN6Halide7Runtime8Internal13custom_mallocE, align 8, !tbaa !14
  store i8* (i8*, i64)* %user_malloc, i8* (i8*, i64)** @_ZN6Halide7Runtime8Internal13custom_mallocE, align 8, !tbaa !14
  ret i8* (i8*, i64)* %0
}

; Function Attrs: nounwind willreturn mustprogress
define weak void (i8*, i8*)* @halide_set_custom_free(void (i8*, i8*)* %user_free) local_unnamed_addr #2 {
entry:
  %0 = load void (i8*, i8*)*, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal11custom_freeE, align 8, !tbaa !14
  store void (i8*, i8*)* %user_free, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal11custom_freeE, align 8, !tbaa !14
  ret void (i8*, i8*)* %0
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_malloc(i8* %user_context, i64 %x) local_unnamed_addr #0 {
entry:
  %0 = load i8* (i8*, i64)*, i8* (i8*, i64)** @_ZN6Halide7Runtime8Internal13custom_mallocE, align 8, !tbaa !14
  %call = tail call i8* %0(i8* %user_context, i64 %x) #14
  ret i8* %call
}

; Function Attrs: nounwind mustprogress
define weak void @halide_free(i8* %user_context, i8* %ptr) local_unnamed_addr #0 {
entry:
  %0 = load void (i8*, i8*)*, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal11custom_freeE, align 8, !tbaa !14
  tail call void %0(i8* %user_context, i8* %ptr) #14
  ret void
}

; Function Attrs: nounwind mustprogress
define weak void @halide_default_error(i8* %user_context, i8* %msg) #0 {
entry:
  %buf = alloca [4096 x i8], align 1
  %0 = getelementptr inbounds [4096 x i8], [4096 x i8]* %buf, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 4096, i8* nonnull %0) #15
  %add.ptr = getelementptr inbounds [4096 x i8], [4096 x i8]* %buf, i64 0, i64 4094
  %call = call i8* @halide_string_to_string(i8* nonnull %0, i8* nonnull %add.ptr, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str, i64 0, i64 0)) #14
  %add.ptr2 = getelementptr inbounds i8, i8* %call, i64 4094
  %call3 = call i8* @halide_string_to_string(i8* %call, i8* nonnull %add.ptr2, i8* %msg) #14
  %arrayidx = getelementptr inbounds i8, i8* %call3, i64 -1
  %1 = load i8, i8* %arrayidx, align 1, !tbaa !18
  %cmp.not = icmp eq i8 %1, 10
  br i1 %cmp.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  store i8 10, i8* %call3, align 1, !tbaa !18
  %arrayidx5 = getelementptr inbounds i8, i8* %call3, i64 1
  store i8 0, i8* %arrayidx5, align 1, !tbaa !18
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %dst.0 = phi i8* [ %arrayidx5, %if.then ], [ %call3, %entry ]
  %sub.ptr.lhs.cast = ptrtoint i8* %dst.0 to i64
  %sub.ptr.rhs.cast = ptrtoint [4096 x i8]* %buf to i64
  %sub.ptr.sub = sub i64 1, %sub.ptr.rhs.cast
  %add = add i64 %sub.ptr.sub, %sub.ptr.lhs.cast
  %call9 = call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %0, i64 %add) #14
  call void @halide_print(i8* %user_context, i8* nonnull %0) #14
  call void @abort() #14
  call void @llvm.lifetime.end.p0i8(i64 4096, i8* nonnull %0) #15
  ret void
}

; Function Attrs: argmemonly nofree nosync nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #3

declare void @abort() local_unnamed_addr #1

; Function Attrs: argmemonly nofree nosync nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #3

; Function Attrs: nounwind mustprogress
define weak void @halide_error(i8* %user_context, i8* %msg) local_unnamed_addr #0 {
entry:
  %0 = load void (i8*, i8*)*, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal13error_handlerE, align 8, !tbaa !14
  tail call void %0(i8* %user_context, i8* %msg) #14
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void (i8*, i8*)* @halide_set_error_handler(void (i8*, i8*)* %handler) local_unnamed_addr #2 {
entry:
  %0 = load void (i8*, i8*)*, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal13error_handlerE, align 8, !tbaa !14
  store void (i8*, i8*)* %handler, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal13error_handlerE, align 8, !tbaa !14
  ret void (i8*, i8*)* %0
}

; Function Attrs: nounwind mustprogress
define weak void @halide_print(i8* %user_context, i8* %msg) local_unnamed_addr #0 {
entry:
  %0 = load void (i8*, i8*)*, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal12custom_printE, align 8, !tbaa !14
  tail call void %0(i8* %user_context, i8* %msg) #14
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void (i8*, i8*)* @halide_set_custom_print(void (i8*, i8*)* %print) local_unnamed_addr #2 {
entry:
  %0 = load void (i8*, i8*)*, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal12custom_printE, align 8, !tbaa !14
  store void (i8*, i8*)* %print, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal12custom_printE, align 8, !tbaa !14
  ret void (i8*, i8*)* %0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_start_clock(i8* %user_context) local_unnamed_addr #0 {
entry:
  %0 = load i8, i8* @_ZN6Halide7Runtime8Internal29halide_reference_clock_initedE, align 1, !tbaa !19, !range !21
  %tobool.not = icmp eq i8 %0, 0
  br i1 %tobool.not, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %call = tail call i32 @mach_timebase_info(%struct.mach_timebase_info* nonnull @_ZN6Halide7Runtime8Internal20halide_timebase_infoE) #14
  %call1 = tail call i64 @mach_absolute_time() #14
  store i64 %call1, i64* @_ZN6Halide7Runtime8Internal22halide_reference_clockE, align 8, !tbaa !22
  store i8 1, i8* @_ZN6Halide7Runtime8Internal29halide_reference_clock_initedE, align 1, !tbaa !19
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  ret i32 0
}

declare i32 @mach_timebase_info(%struct.mach_timebase_info*) local_unnamed_addr #1

declare i64 @mach_absolute_time() local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak i64 @halide_current_time_ns(i8* %user_context) local_unnamed_addr #0 {
entry:
  %call = tail call i64 @mach_absolute_time() #14
  %0 = load i64, i64* @_ZN6Halide7Runtime8Internal22halide_reference_clockE, align 8, !tbaa !22
  %sub = sub i64 %call, %0
  %1 = load i32, i32* getelementptr inbounds (%struct.mach_timebase_info, %struct.mach_timebase_info* @_ZN6Halide7Runtime8Internal20halide_timebase_infoE, i64 0, i32 0), align 4, !tbaa !24
  %conv = zext i32 %1 to i64
  %mul = mul i64 %sub, %conv
  %2 = load i32, i32* getelementptr inbounds (%struct.mach_timebase_info, %struct.mach_timebase_info* @_ZN6Halide7Runtime8Internal20halide_timebase_infoE, i64 0, i32 1), align 4, !tbaa !27
  %conv1 = zext i32 %2 to i64
  %div = udiv i64 %mul, %conv1
  ret i64 %div
}

; Function Attrs: nounwind mustprogress
define weak void @halide_sleep_ms(i8* %user_context, i32 %ms) local_unnamed_addr #0 {
entry:
  %mul = mul nsw i32 %ms, 1000
  %call = tail call i32 @usleep(i32 %mul) #14
  ret void
}

declare i32 @usleep(i32) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void @halide_default_print(i8* %user_context, i8* %str) #0 {
entry:
  %call = tail call i64 @strlen(i8* %str) #14
  %call1 = tail call i64 @write(i32 1, i8* %str, i64 %call) #14
  ret void
}

declare i64 @strlen(i8*) local_unnamed_addr #1

declare i64 @write(i32, i8*, i64) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak i32 @halide_host_cpu_count() local_unnamed_addr #0 {
entry:
  %call = tail call i64 @sysconf(i32 58) #14
  %conv = trunc i64 %call to i32
  ret i32 %conv
}

declare i64 @sysconf(i32) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void @halide_thread_yield() local_unnamed_addr #0 {
entry:
  %call = tail call i32 @swtch_pri(i32 0) #14
  ret void
}

declare i32 @swtch_pri(i32) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_do_task(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %idx, i8* %closure) #0 {
entry:
  %call = tail call i32 %f(i8* %user_context, i32 %idx, i8* %closure) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_do_loop_task(i8* %user_context, i32 (i8*, i32, i32, i8*, i8*)* %f, i32 %min, i32 %extent, i8* %closure, i8* %task_parent) #0 {
entry:
  %call = tail call i32 %f(i8* %user_context, i32 %min, i32 %extent, i8* %closure, i8* %task_parent) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_do_par_for(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %min, i32 %size, i8* %closure) #0 {
entry:
  %job = alloca %"struct.Halide::Runtime::Internal::work", align 8
  %cmp = icmp slt i32 %size, 1
  br i1 %cmp, label %return, label %if.end

if.end:                                           ; preds = %entry
  %0 = bitcast %"struct.Halide::Runtime::Internal::work"* %job to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %0) #15
  %fn = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 0
  store i32 (i8*, i32, i32, i8*, i8*)* null, i32 (i8*, i32, i32, i8*, i8*)** %fn, align 8, !tbaa !28
  %min2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 5
  store i32 %min, i32* %min2, align 4, !tbaa !31
  %extent = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 6
  store i32 %size, i32* %extent, align 8, !tbaa !32
  %serial = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 8
  store i8 0, i8* %serial, align 8, !tbaa !33
  %semaphores = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 3
  store %struct.halide_semaphore_acquire_t* null, %struct.halide_semaphore_acquire_t** %semaphores, align 8, !tbaa !34
  %num_semaphores = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 4
  store i32 0, i32* %num_semaphores, align 8, !tbaa !35
  %closure8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 1
  store i8* %closure, i8** %closure8, align 8, !tbaa !36
  %min_threads = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 7
  store i32 0, i32* %min_threads, align 4, !tbaa !37
  %name = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 0, i32 2
  store i8* null, i8** %name, align 8, !tbaa !38
  %task_fn = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 1
  store i32 (i8*, i32, i8*)* %f, i32 (i8*, i32, i8*)** %task_fn, align 8, !tbaa !39
  %user_context11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 7
  store i8* %user_context, i8** %user_context11, align 8, !tbaa !40
  %exit_status = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 9
  %active_workers = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 8
  %1 = bitcast i32* %active_workers to <2 x i32>*
  store <2 x i32> zeroinitializer, <2 x i32>* %1, align 8, !tbaa !41
  %next_semaphore = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 10
  store i32 0, i32* %next_semaphore, align 8, !tbaa !42
  %owner_is_sleeping = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 11
  store i8 0, i8* %owner_is_sleeping, align 4, !tbaa !43
  %siblings = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 3
  store %"struct.Halide::Runtime::Internal::work"* %job, %"struct.Halide::Runtime::Internal::work"** %siblings, align 8, !tbaa !44
  %sibling_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 4
  store i32 0, i32* %sibling_count, align 8, !tbaa !45
  %parent_job = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job, i64 0, i32 5
  store %"struct.Halide::Runtime::Internal::work"* null, %"struct.Halide::Runtime::Internal::work"** %parent_job, align 8, !tbaa !46
  call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  call void @_ZN6Halide7Runtime8Internal27enqueue_work_already_lockedEiPNS1_4workES3_(i32 1, %"struct.Halide::Runtime::Internal::work"* nonnull %job, %"struct.Halide::Runtime::Internal::work"* null) #16
  call void @_ZN6Halide7Runtime8Internal28worker_thread_already_lockedEPNS1_4workE(%"struct.Halide::Runtime::Internal::work"* nonnull %job) #16
  call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %2 = load i32, i32* %exit_status, align 4, !tbaa !47
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %0) #15
  br label %return

return:                                           ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %2, %if.end ], [ 0, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind
define weak void @halide_mutex_lock(%struct.halide_mutex* %mutex) local_unnamed_addr #4 {
entry:
  %control.i.i = alloca %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", align 8
  %state.i = getelementptr %struct.halide_mutex, %struct.halide_mutex* %mutex, i64 0, i32 0, i64 0
  %0 = cmpxchg weak i64* %state.i, i64 0, i64 1 acquire monotonic
  %1 = extractvalue { i64, i1 } %0, 1
  br i1 %1, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex4lockEv.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  %2 = load atomic i64, i64* %state.i monotonic, align 8
  %3 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i to i8*
  %4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 0, i32 0
  %lock_state2.i.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 1
  %5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 0
  %6 = ptrtoint %struct.halide_mutex* %mutex to i64
  br label %while.cond.outer.i.i

while.cond.outer.i.i:                             ; preds = %while.cond.outer.i.i.backedge, %if.then.i
  %expected.0.ph.i.i = phi i64 [ %2, %if.then.i ], [ %expected.0.ph.i.i.be, %while.cond.outer.i.i.backedge ]
  %spinner.sroa.0.0.ph.i.i = phi i32 [ 40, %if.then.i ], [ %spinner.sroa.0.0.ph.i.i.be, %while.cond.outer.i.i.backedge ]
  %and55.i.i = and i64 %expected.0.ph.i.i, 1
  %tobool.not56.i.i = icmp eq i64 %and55.i.i, 0
  br i1 %tobool.not56.i.i, label %if.then.i.i, label %if.end4.i.i

if.then.i.i:                                      ; preds = %while.cond.outer.i.i, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i
  %expected.057.i.i = phi i64 [ %9, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i ], [ %expected.0.ph.i.i, %while.cond.outer.i.i ]
  %or.i.i = or i64 %expected.057.i.i, 1
  %7 = cmpxchg weak i64* %state.i, i64 %expected.057.i.i, i64 %or.i.i acquire monotonic
  %8 = extractvalue { i64, i1 } %7, 1
  br i1 %8, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex4lockEv.exit, label %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i

_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i: ; preds = %if.then.i.i
  %9 = extractvalue { i64, i1 } %7, 0
  %and.i.i = and i64 %9, 1
  %tobool.not.i.i = icmp eq i64 %and.i.i, 0
  br i1 %tobool.not.i.i, label %if.then.i.i, label %if.end4.i.i.loopexit

if.end4.i.i.loopexit:                             ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i
  %10 = extractvalue { i64, i1 } %7, 0
  br label %if.end4.i.i

if.end4.i.i:                                      ; preds = %if.end4.i.i.loopexit, %while.cond.outer.i.i
  %expected.0.lcssa.i.i = phi i64 [ %expected.0.ph.i.i, %while.cond.outer.i.i ], [ %10, %if.end4.i.i.loopexit ]
  %cmp.i.i.i = icmp sgt i32 %spinner.sroa.0.0.ph.i.i, 0
  br i1 %cmp.i.i.i, label %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i, label %if.end8.i.i

_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i: ; preds = %if.end4.i.i
  %cmp4.i.not.i.i = icmp eq i32 %spinner.sroa.0.0.ph.i.i, 1
  br i1 %cmp4.i.not.i.i, label %if.end8.i.i, label %if.then6.i.i

if.then6.i.i:                                     ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i
  %dec.i.i.i = add nsw i32 %spinner.sroa.0.0.ph.i.i, -1
  call void @halide_thread_yield() #14
  %11 = load atomic i64, i64* %state.i monotonic, align 8
  br label %while.cond.outer.i.i.backedge

if.end8.i.i:                                      ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i, %if.end4.i.i
  %spinner.sroa.0.152.i.i = phi i32 [ 0, %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i ], [ %spinner.sroa.0.0.ph.i.i, %if.end4.i.i ]
  %and9.i.i = and i64 %expected.0.lcssa.i.i, 2
  %cmp.i.i = icmp eq i64 %and9.i.i, 0
  br i1 %cmp.i.i, label %if.then10.i.i, label %if.end19.i.i

if.then10.i.i:                                    ; preds = %if.end8.i.i
  %or12.i.i = or i64 %expected.0.lcssa.i.i, 2
  %12 = cmpxchg weak i64* %state.i, i64 %expected.0.lcssa.i.i, i64 %or12.i.i monotonic monotonic
  %13 = extractvalue { i64, i1 } %12, 1
  br i1 %13, label %if.end19.i.i, label %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i

_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i: ; preds = %if.then10.i.i
  %14 = extractvalue { i64, i1 } %12, 0
  br label %while.cond.outer.i.i.backedge

if.end19.i.i:                                     ; preds = %if.then10.i.i, %if.end8.i.i
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %3) #15
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN6Halide7Runtime8Internal15Synchronization21mutex_parking_controlE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8, !tbaa !48
  store i64* %state.i, i64** %lock_state2.i.i.i, align 8, !tbaa !50
  %call21.i.i = call i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control4parkEy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %5, i64 %6) #14
  %cmp22.i.i = icmp eq i64 %call21.i.i, %6
  br i1 %cmp22.i.i, label %cleanup30.critedge.i.i, label %if.end24.i.i

if.end24.i.i:                                     ; preds = %if.end19.i.i
  %15 = load atomic i64, i64* %state.i monotonic, align 8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %3) #15
  br label %while.cond.outer.i.i.backedge

while.cond.outer.i.i.backedge:                    ; preds = %if.end24.i.i, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i, %if.then6.i.i
  %expected.0.ph.i.i.be = phi i64 [ %14, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i ], [ %15, %if.end24.i.i ], [ %11, %if.then6.i.i ]
  %spinner.sroa.0.0.ph.i.i.be = phi i32 [ %spinner.sroa.0.152.i.i, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i ], [ 40, %if.end24.i.i ], [ %dec.i.i.i, %if.then6.i.i ]
  br label %while.cond.outer.i.i

cleanup30.critedge.i.i:                           ; preds = %if.end19.i.i
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %3) #15
  br label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex4lockEv.exit

_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex4lockEv.exit: ; preds = %if.then.i.i, %cleanup30.critedge.i.i, %entry
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal27enqueue_work_already_lockedEiPNS1_4workES3_(i32 %num_jobs, %"struct.Halide::Runtime::Internal::work"* %jobs, %"struct.Halide::Runtime::Internal::work"* %task_parent) local_unnamed_addr #0 {
entry:
  %0 = load i8, i8* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 15), align 1, !tbaa !52, !range !21
  %tobool.not = icmp eq i8 %0, 0
  br i1 %tobool.not, label %land.rhs.i, label %if.end4

land.rhs.i:                                       ; preds = %entry, %while.body.i
  %bytes.011.i = phi i8* [ %incdec.ptr.i, %while.body.i ], [ bitcast (i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 2) to i8*), %entry ]
  %1 = load i8, i8* %bytes.011.i, align 1, !tbaa !18
  %cmp2.i = icmp eq i8 %1, 0
  br i1 %cmp2.i, label %while.body.i, label %do.body.i

while.body.i:                                     ; preds = %land.rhs.i
  %incdec.ptr.i = getelementptr inbounds i8, i8* %bytes.011.i, i64 1
  %exitcond.not.i = icmp eq i8* %incdec.ptr.i, bitcast (%"struct.Halide::Runtime::Internal::work_queue_t"* select (i1 icmp ugt (i8* bitcast (%"struct.Halide::Runtime::Internal::work_queue_t"* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 1) to i8*), i8* getelementptr (i8, i8* bitcast (i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 2) to i8*), i64 1)), %"struct.Halide::Runtime::Internal::work_queue_t"* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 1), %"struct.Halide::Runtime::Internal::work_queue_t"* bitcast (i8* getelementptr (i8, i8* bitcast (i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 2) to i8*), i64 1) to %"struct.Halide::Runtime::Internal::work_queue_t"*)) to i8*)
  br i1 %exitcond.not.i, label %do.body.i, label %land.rhs.i, !llvm.loop !56

do.body.i:                                        ; preds = %while.body.i, %land.rhs.i
  %bytes.0.lcssa.i = phi i8* [ %bytes.011.i, %land.rhs.i ], [ bitcast (%"struct.Halide::Runtime::Internal::work_queue_t"* select (i1 icmp ugt (i8* bitcast (%"struct.Halide::Runtime::Internal::work_queue_t"* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 1) to i8*), i8* getelementptr (i8, i8* bitcast (i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 2) to i8*), i64 1)), %"struct.Halide::Runtime::Internal::work_queue_t"* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 1), %"struct.Halide::Runtime::Internal::work_queue_t"* bitcast (i8* getelementptr (i8, i8* bitcast (i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 2) to i8*), i64 1) to %"struct.Halide::Runtime::Internal::work_queue_t"*)) to i8*), %while.body.i ]
  %cmp3.i = icmp eq i8* %bytes.0.lcssa.i, bitcast (%"struct.Halide::Runtime::Internal::work_queue_t"* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 1) to i8*)
  br i1 %cmp3.i, label %_ZNK6Halide7Runtime8Internal12work_queue_t13assert_zeroedEv.exit, label %if.then.i

if.then.i:                                        ; preds = %do.body.i
  tail call void @halide_print(i8* null, i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.6, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %_ZNK6Halide7Runtime8Internal12work_queue_t13assert_zeroedEv.exit

_ZNK6Halide7Runtime8Internal12work_queue_t13assert_zeroedEv.exit: ; preds = %if.then.i, %do.body.i
  %2 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 1), align 8, !tbaa !58
  %tobool1.not = icmp eq i32 %2, 0
  br i1 %tobool1.not, label %if.then2, label %if.end

if.then2:                                         ; preds = %_ZNK6Halide7Runtime8Internal12work_queue_t13assert_zeroedEv.exit
  %call = tail call i32 @_ZN6Halide7Runtime8Internal27default_desired_num_threadsEv() #16
  br label %if.end

if.end:                                           ; preds = %if.then2, %_ZNK6Halide7Runtime8Internal12work_queue_t13assert_zeroedEv.exit
  %3 = phi i32 [ %call, %if.then2 ], [ %2, %_ZNK6Halide7Runtime8Internal12work_queue_t13assert_zeroedEv.exit ]
  %4 = icmp sgt i32 %3, 1
  %spec.select.i = select i1 %4, i32 %3, i32 1
  %5 = icmp slt i32 %spec.select.i, 256
  %call3176 = select i1 %5, i32 %spec.select.i, i32 256
  store i32 %call3176, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 1), align 8, !tbaa !58
  store i8 1, i8* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 15), align 1, !tbaa !52
  br label %if.end4

if.end4:                                          ; preds = %if.end, %entry
  %cmp181 = icmp sgt i32 %num_jobs, 0
  br i1 %cmp181, label %for.body.preheader, label %for.cond.cleanup

for.body.preheader:                               ; preds = %if.end4
  %wide.trip.count = zext i32 %num_jobs to i64
  br label %for.body

for.cond.cleanup.loopexit:                        ; preds = %for.inc
  %phi.bo = and i8 %stealable_jobs.1, 1
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit, %if.end4
  %workers_to_wake.0.lcssa = phi i32 [ -1, %if.end4 ], [ %workers_to_wake.1, %for.cond.cleanup.loopexit ]
  %stealable_jobs.0.lcssa = phi i8 [ 0, %if.end4 ], [ %phi.bo, %for.cond.cleanup.loopexit ]
  %job_has_acquires.0.lcssa = phi i8 [ 0, %if.end4 ], [ %spec.select, %for.cond.cleanup.loopexit ]
  %job_may_block.0.lcssa = phi i8 [ 0, %if.end4 ], [ %job_may_block.1, %for.cond.cleanup.loopexit ]
  %min_threads.0.lcssa = phi i32 [ 0, %if.end4 ], [ %add, %for.cond.cleanup.loopexit ]
  %cmp31 = icmp eq %"struct.Halide::Runtime::Internal::work"* %task_parent, null
  br i1 %cmp31, label %if.then32, label %do.body61

for.body:                                         ; preds = %for.inc, %for.body.preheader
  %indvars.iv193 = phi i64 [ 0, %for.body.preheader ], [ %indvars.iv.next194, %for.inc ]
  %min_threads.0187 = phi i32 [ 0, %for.body.preheader ], [ %add, %for.inc ]
  %job_may_block.0185 = phi i8 [ 0, %for.body.preheader ], [ %job_may_block.1, %for.inc ]
  %job_has_acquires.0184 = phi i8 [ 0, %for.body.preheader ], [ %spec.select, %for.inc ]
  %stealable_jobs.0183 = phi i8 [ 0, %for.body.preheader ], [ %stealable_jobs.1, %for.inc ]
  %workers_to_wake.0182 = phi i32 [ -1, %for.body.preheader ], [ %workers_to_wake.1, %for.inc ]
  %min_threads5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv193, i32 0, i32 7
  %6 = load i32, i32* %min_threads5, align 4, !tbaa !37
  %cmp6 = icmp eq i32 %6, 0
  %add = add i32 %6, %min_threads.0187
  %stealable_jobs.1 = select i1 %cmp6, i8 1, i8 %stealable_jobs.0183
  %job_may_block.1 = select i1 %cmp6, i8 %job_may_block.0185, i8 1
  %num_semaphores = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv193, i32 0, i32 4
  %7 = load i32, i32* %num_semaphores, align 8, !tbaa !35
  %cmp16.not = icmp eq i32 %7, 0
  %spec.select = select i1 %cmp16.not, i8 %job_has_acquires.0184, i8 1
  %serial = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv193, i32 0, i32 8
  %8 = load i8, i8* %serial, align 8, !tbaa !33, !range !21
  %tobool22.not = icmp eq i8 %8, 0
  br i1 %tobool22.not, label %if.else24, label %if.then23

if.then23:                                        ; preds = %for.body
  %inc = add nsw i32 %workers_to_wake.0182, 1
  br label %for.inc

if.else24:                                        ; preds = %for.body
  %extent = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv193, i32 0, i32 6
  %9 = load i32, i32* %extent, align 8, !tbaa !32
  %add28 = add nsw i32 %9, %workers_to_wake.0182
  br label %for.inc

for.inc:                                          ; preds = %if.else24, %if.then23
  %workers_to_wake.1 = phi i32 [ %inc, %if.then23 ], [ %add28, %if.else24 ]
  %indvars.iv.next194 = add nuw nsw i64 %indvars.iv193, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next194, %wide.trip.count
  br i1 %exitcond.not, label %for.cond.cleanup.loopexit, label %for.body, !llvm.loop !59

if.then32:                                        ; preds = %for.cond.cleanup
  %10 = or i8 %job_may_block.0.lcssa, %job_has_acquires.0.lcssa
  %11 = and i8 %10, 1
  %12 = icmp eq i8 %11, 0
  %not. = xor i1 %12, true
  %add36 = zext i1 %not. to i32
  %min_threads.2 = add nsw i32 %min_threads.0.lcssa, %add36
  %13 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 4), align 8, !tbaa !60
  %cmp38180 = icmp slt i32 %13, 256
  br i1 %cmp38180, label %land.rhs, label %do.end50

land.rhs:                                         ; preds = %if.then32, %while.body
  %14 = phi i32 [ %inc45, %while.body ], [ %13, %if.then32 ]
  %15 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 1), align 8, !tbaa !58
  %sub = add nsw i32 %15, -1
  %cmp39 = icmp slt i32 %14, %sub
  br i1 %cmp39, label %while.body, label %lor.rhs

lor.rhs:                                          ; preds = %land.rhs
  %add40 = add nsw i32 %14, 1
  %16 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  %sub41 = sub i32 %add40, %16
  %cmp42 = icmp slt i32 %sub41, %min_threads.2
  br i1 %cmp42, label %while.body, label %do.end50

while.body:                                       ; preds = %lor.rhs, %land.rhs
  %17 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 5), align 4, !tbaa !62
  %inc43 = add nsw i32 %17, 1
  store i32 %inc43, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 5), align 4, !tbaa !62
  %call44 = tail call %struct.halide_thread* @halide_spawn_thread(void (i8*)* nonnull @_ZN6Halide7Runtime8Internal13worker_threadEPv, i8* null) #16
  %18 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 4), align 8, !tbaa !60
  %inc45 = add nsw i32 %18, 1
  store i32 %inc45, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 4), align 8, !tbaa !60
  %idxprom46 = sext i32 %18 to i64
  %arrayidx47 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 13, i64 %idxprom46
  store %struct.halide_thread* %call44, %struct.halide_thread** %arrayidx47, align 8, !tbaa !14
  %cmp38 = icmp slt i32 %18, 255
  br i1 %cmp38, label %land.rhs, label %do.end50, !llvm.loop !63

do.end50:                                         ; preds = %while.body, %lor.rhs, %if.then32
  br i1 %12, label %if.end77, label %if.then54

if.then54:                                        ; preds = %do.end50
  %19 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  %inc55 = add nsw i32 %19, 1
  store i32 %inc55, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  br label %if.end77

do.body61:                                        ; preds = %for.cond.cleanup
  %min_threads63 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %task_parent, i64 0, i32 0, i32 7
  %20 = load i32, i32* %min_threads63, align 4, !tbaa !37
  %active_workers = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %task_parent, i64 0, i32 8
  %21 = load i32, i32* %active_workers, align 8, !tbaa !64
  %mul = mul nsw i32 %21, %20
  %threads_reserved = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %task_parent, i64 0, i32 6
  %22 = load i32, i32* %threads_reserved, align 8, !tbaa !65
  %sub64 = sub nsw i32 %mul, %22
  %cmp65.not = icmp sgt i32 %min_threads.0.lcssa, %sub64
  br i1 %cmp65.not, label %if.then66, label %do.end69

if.then66:                                        ; preds = %do.body61
  tail call void @halide_print(i8* null, i8* getelementptr inbounds ([263 x i8], [263 x i8]* @.str.3, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end69

do.end69:                                         ; preds = %if.then66, %do.body61
  %23 = or i8 %job_may_block.0.lcssa, %job_has_acquires.0.lcssa
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  br i1 %25, label %if.end77, label %if.then73

if.then73:                                        ; preds = %do.end69
  %26 = load i32, i32* %threads_reserved, align 8, !tbaa !65
  %inc75 = add nsw i32 %26, 1
  store i32 %inc75, i32* %threads_reserved, align 8, !tbaa !65
  br label %if.end77

if.end77:                                         ; preds = %if.then73, %do.end69, %if.then54, %do.end50
  br i1 %cmp181, label %for.body83.lr.ph, label %for.cond.cleanup82

for.body83.lr.ph:                                 ; preds = %if.end77
  %.promoted = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), align 8, !tbaa !66
  %27 = zext i32 %num_jobs to i64
  %min.iters.check = icmp eq i32 %num_jobs, 1
  br i1 %min.iters.check, label %for.body83.preheader, label %vector.ph

vector.ph:                                        ; preds = %for.body83.lr.ph
  %n.vec = and i64 %27, 4294967294
  %ind.end = and i64 %27, 1
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vector.recur = phi %"struct.Halide::Runtime::Internal::work"* [ %.promoted, %vector.ph ], [ %31, %vector.body ]
  %offset.idx = sub i64 %27, %index
  %28 = add nsw i64 %offset.idx, -1
  %29 = add i64 %offset.idx, -2
  %30 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %28
  %31 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %29
  %32 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %28, i32 2
  %33 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %29, i32 2
  store %"struct.Halide::Runtime::Internal::work"* %vector.recur, %"struct.Halide::Runtime::Internal::work"** %32, align 8, !tbaa !67
  store %"struct.Halide::Runtime::Internal::work"* %30, %"struct.Halide::Runtime::Internal::work"** %33, align 8, !tbaa !67
  %34 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %28, i32 3
  %35 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %29, i32 3
  store %"struct.Halide::Runtime::Internal::work"* %jobs, %"struct.Halide::Runtime::Internal::work"** %34, align 8, !tbaa !44
  store %"struct.Halide::Runtime::Internal::work"* %jobs, %"struct.Halide::Runtime::Internal::work"** %35, align 8, !tbaa !44
  %36 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %28, i32 4
  %37 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %29, i32 4
  store i32 %num_jobs, i32* %36, align 8, !tbaa !45
  store i32 %num_jobs, i32* %37, align 8, !tbaa !45
  %38 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %28, i32 6
  %39 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %29, i32 6
  store i32 0, i32* %38, align 8, !tbaa !65
  store i32 0, i32* %39, align 8, !tbaa !65
  %index.next = add i64 %index, 2
  %40 = icmp eq i64 %index.next, %n.vec
  br i1 %40, label %middle.block, label %vector.body, !llvm.loop !68

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %n.vec, %27
  br i1 %cmp.n, label %for.cond80.for.cond.cleanup82_crit_edge, label %for.body83.preheader

for.body83.preheader:                             ; preds = %for.body83.lr.ph, %middle.block
  %indvars.iv.ph = phi i64 [ %ind.end, %middle.block ], [ %27, %for.body83.lr.ph ]
  %scalar.recur.ph = phi %"struct.Halide::Runtime::Internal::work"* [ %31, %middle.block ], [ %.promoted, %for.body83.lr.ph ]
  br label %for.body83

for.cond80.for.cond.cleanup82_crit_edge:          ; preds = %for.body83, %middle.block
  store %"struct.Halide::Runtime::Internal::work"* %jobs, %"struct.Halide::Runtime::Internal::work"** getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), align 8, !tbaa !66
  br label %for.cond.cleanup82

for.cond.cleanup82:                               ; preds = %for.cond80.for.cond.cleanup82_crit_edge, %if.end77
  %41 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 12), align 4, !tbaa !70
  %tobool96 = icmp ne i32 %41, 0
  %42 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 11), align 8
  %43 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 4), align 8
  %cmp98 = icmp slt i32 %42, %43
  %44 = or i1 %tobool96, %cmp98
  %cmp102 = icmp sgt i32 %workers_to_wake.0.lcssa, %42
  %or.cond174 = or i1 %cmp102, %44
  %storemerge = select i1 %or.cond174, i32 %43, i32 %workers_to_wake.0.lcssa
  store i32 %storemerge, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 6), align 8, !tbaa !71
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 8)) #16
  %45 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 6), align 8, !tbaa !71
  %46 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 5), align 4, !tbaa !62
  %cmp106 = icmp sgt i32 %45, %46
  br i1 %cmp106, label %if.then107, label %if.end111

for.body83:                                       ; preds = %for.body83.preheader, %for.body83
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body83 ], [ %indvars.iv.ph, %for.body83.preheader ]
  %scalar.recur = phi %"struct.Halide::Runtime::Internal::work"* [ %arrayidx85, %for.body83 ], [ %scalar.recur.ph, %for.body83.preheader ]
  %indvars.iv.next = add nsw i64 %indvars.iv, -1
  %arrayidx85 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv.next
  %next_job = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv.next, i32 2
  store %"struct.Halide::Runtime::Internal::work"* %scalar.recur, %"struct.Halide::Runtime::Internal::work"** %next_job, align 8, !tbaa !67
  %siblings = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv.next, i32 3
  store %"struct.Halide::Runtime::Internal::work"* %jobs, %"struct.Halide::Runtime::Internal::work"** %siblings, align 8, !tbaa !44
  %sibling_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv.next, i32 4
  store i32 %num_jobs, i32* %sibling_count, align 8, !tbaa !45
  %threads_reserved93 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %jobs, i64 %indvars.iv.next, i32 6
  store i32 0, i32* %threads_reserved93, align 8, !tbaa !65
  %cmp81 = icmp sgt i64 %indvars.iv, 1
  br i1 %cmp81, label %for.body83, label %for.cond80.for.cond.cleanup82_crit_edge, !llvm.loop !72

if.then107:                                       ; preds = %for.cond.cleanup82
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 9)) #16
  %tobool108.not = icmp eq i8 %stealable_jobs.0.lcssa, 0
  br i1 %tobool108.not, label %if.end111, label %if.then109

if.then109:                                       ; preds = %if.then107
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 10)) #16
  br label %if.end111

if.end111:                                        ; preds = %if.then109, %if.then107, %for.cond.cleanup82
  %47 = or i8 %job_may_block.0.lcssa, %job_has_acquires.0.lcssa
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  br i1 %49, label %if.end123, label %if.then115

if.then115:                                       ; preds = %if.end111
  br i1 %cmp31, label %if.else120, label %if.then117

if.then117:                                       ; preds = %if.then115
  %threads_reserved118 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %task_parent, i64 0, i32 6
  %50 = load i32, i32* %threads_reserved118, align 8, !tbaa !65
  %dec119 = add nsw i32 %50, -1
  store i32 %dec119, i32* %threads_reserved118, align 8, !tbaa !65
  br label %if.end123

if.else120:                                       ; preds = %if.then115
  %51 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  %dec121 = add nsw i32 %51, -1
  store i32 %dec121, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  br label %if.end123

if.end123:                                        ; preds = %if.else120, %if.then117, %if.end111
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal28worker_thread_already_lockedEPNS1_4workE(%"struct.Halide::Runtime::Internal::work"* %owned_job) local_unnamed_addr #0 {
entry:
  %active_workers.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %owned_job, i64 0, i32 8
  %tobool.not = icmp eq %"struct.Halide::Runtime::Internal::work"* %owned_job, null
  %extent.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %owned_job, i64 0, i32 0, i32 6
  %exit_status = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %owned_job, i64 0, i32 9
  %parent_job = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %owned_job, i64 0, i32 5
  %siblings56 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %owned_job, i64 0, i32 3
  %owner_is_sleeping = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %owned_job, i64 0, i32 11
  %next_job10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %owned_job, i64 0, i32 2
  br label %while.cond

while.cond:                                       ; preds = %while.cond.backedge, %entry
  %spin_count.0 = phi i32 [ 0, %entry ], [ %spin_count.0.be, %while.cond.backedge ]
  br i1 %tobool.not, label %cond.false, label %cond.true

cond.true:                                        ; preds = %while.cond
  %0 = load i32, i32* %extent.i, align 8, !tbaa !32
  %tobool.not.i = icmp eq i32 %0, 0
  br i1 %tobool.not.i, label %cond.end, label %if.then

cond.false:                                       ; preds = %while.cond
  %1 = load i8, i8* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 14), align 8, !tbaa !73, !range !21
  %tobool1.not = icmp eq i8 %1, 0
  br i1 %tobool1.not, label %do.end.thread, label %while.end316

cond.end:                                         ; preds = %cond.true
  %2 = load i32, i32* %active_workers.i, align 8, !tbaa !64
  %tobool2.i.not = icmp eq i32 %2, 0
  br i1 %tobool2.i.not, label %while.end316, label %if.then

if.then:                                          ; preds = %cond.end, %cond.true
  %3 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), align 8, !tbaa !66
  %4 = load i32, i32* %exit_status, align 4, !tbaa !47
  %cmp.not = icmp eq i32 %4, 0
  br i1 %cmp.not, label %if.else, label %if.then3

if.then3:                                         ; preds = %if.then
  %5 = load i32, i32* %active_workers.i, align 8, !tbaa !64
  %cmp4 = icmp eq i32 %5, 0
  br i1 %cmp4, label %while.cond6.preheader, label %do.end

while.cond6.preheader:                            ; preds = %if.then3
  %cmp7.not524 = icmp eq %"struct.Halide::Runtime::Internal::work"* %3, %owned_job
  br i1 %cmp7.not524, label %while.end, label %while.body8

while.body8:                                      ; preds = %while.cond6.preheader, %while.body8
  %job.0525 = phi %"struct.Halide::Runtime::Internal::work"* [ %6, %while.body8 ], [ %3, %while.cond6.preheader ]
  %next_job = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.0525, i64 0, i32 2
  %6 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %next_job, align 8, !tbaa !67
  %cmp7.not = icmp eq %"struct.Halide::Runtime::Internal::work"* %6, %owned_job
  br i1 %cmp7.not, label %while.end.loopexit, label %while.body8, !llvm.loop !74

while.end.loopexit:                               ; preds = %while.body8
  %next_job.le = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.0525, i64 0, i32 2
  br label %while.end

while.end:                                        ; preds = %while.end.loopexit, %while.cond6.preheader
  %prev_ptr.0.lcssa = phi %"struct.Halide::Runtime::Internal::work"** [ getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), %while.cond6.preheader ], [ %next_job.le, %while.end.loopexit ]
  %7 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %next_job10, align 8, !tbaa !67
  store %"struct.Halide::Runtime::Internal::work"* %7, %"struct.Halide::Runtime::Internal::work"** %prev_ptr.0.lcssa, align 8, !tbaa !14
  store i32 0, i32* %extent.i, align 8, !tbaa !32
  br label %while.cond.backedge

if.else:                                          ; preds = %if.then
  %8 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %parent_job, align 8, !tbaa !46
  %tobool11.not = icmp eq %"struct.Halide::Runtime::Internal::work"* %8, null
  br i1 %tobool11.not, label %do.end, label %land.lhs.true

land.lhs.true:                                    ; preds = %if.else
  %exit_status13 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %8, i64 0, i32 9
  %9 = load i32, i32* %exit_status13, align 4, !tbaa !47
  %cmp14.not = icmp eq i32 %9, 0
  br i1 %cmp14.not, label %do.end, label %if.then15

if.then15:                                        ; preds = %land.lhs.true
  store i32 %9, i32* %exit_status, align 4, !tbaa !47
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 10)) #16
  br label %while.cond.backedge

do.end:                                           ; preds = %land.lhs.true, %if.else, %if.then3
  %tobool23.not527 = icmp eq %"struct.Halide::Runtime::Internal::work"* %3, null
  br i1 %tobool23.not527, label %if.then105, label %do.end27

do.end.thread:                                    ; preds = %cond.false
  %10 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), align 8, !tbaa !66
  %tobool23.not527563 = icmp eq %"struct.Halide::Runtime::Internal::work"* %10, null
  br i1 %tobool23.not527563, label %if.else112, label %do.end27.us

do.end27.us:                                      ; preds = %do.end.thread, %cleanup.us
  %job.1529.us = phi %"struct.Halide::Runtime::Internal::work"* [ %29, %cleanup.us ], [ %10, %do.end.thread ]
  %prev_ptr.1528.us = phi %"struct.Halide::Runtime::Internal::work"** [ %next_job95.us, %cleanup.us ], [ getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), %do.end.thread ]
  %parent_job29.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529.us, i64 0, i32 5
  %11 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %parent_job29.us, align 8, !tbaa !46
  %cmp30.us = icmp eq %"struct.Halide::Runtime::Internal::work"* %11, null
  br i1 %cmp30.us, label %if.then31.us, label %if.else32.us

if.else32.us:                                     ; preds = %do.end27.us
  %active_workers33.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %11, i64 0, i32 8
  %12 = load i32, i32* %active_workers33.us, align 8, !tbaa !64
  %cmp34.us = icmp eq i32 %12, 0
  %min_threads.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %11, i64 0, i32 0, i32 7
  %13 = load i32, i32* %min_threads.us, align 4, !tbaa !37
  br i1 %cmp34.us, label %if.then35.us, label %if.else38.us

if.else38.us:                                     ; preds = %if.else32.us
  %mul.us = mul nsw i32 %13, %12
  %threads_reserved42.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %11, i64 0, i32 6
  %14 = load i32, i32* %threads_reserved42.us, align 8, !tbaa !65
  %sub43.us = sub nsw i32 %mul.us, %14
  br label %if.end45.us

if.then35.us:                                     ; preds = %if.else32.us
  %threads_reserved.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %11, i64 0, i32 6
  %15 = load i32, i32* %threads_reserved.us, align 8, !tbaa !65
  %sub37.us = sub nsw i32 %13, %15
  br label %if.end45.us

if.then31.us:                                     ; preds = %do.end27.us
  %16 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 4), align 8, !tbaa !60
  %add.us = add nsw i32 %16, 1
  %17 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  %sub.us = sub i32 %add.us, %17
  br label %if.end45.us

if.end45.us:                                      ; preds = %if.then31.us, %if.then35.us, %if.else38.us
  %threads_available.0.us = phi i32 [ %sub.us, %if.then31.us ], [ %sub37.us, %if.then35.us ], [ %sub43.us, %if.else38.us ]
  %min_threads47.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529.us, i64 0, i32 0, i32 7
  %18 = load i32, i32* %min_threads47.us, align 4, !tbaa !37
  %cmp48.not.us = icmp sge i32 %threads_available.0.us, %18
  %serial.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529.us, i64 0, i32 0, i32 8
  %19 = load i8, i8* %serial.us, align 8, !tbaa !33, !range !21
  %tobool69.not.us = icmp eq i8 %19, 0
  br i1 %tobool69.not.us, label %if.end45.us.lor.end73.us_crit_edge, label %lor.rhs70.us

if.end45.us.lor.end73.us_crit_edge:               ; preds = %if.end45.us
  %.0 = and i1 %cmp48.not.us, true
  br label %lor.end73.us

lor.rhs70.us:                                     ; preds = %if.end45.us
  %active_workers71.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529.us, i64 0, i32 8
  %20 = load i32, i32* %active_workers71.us, align 8, !tbaa !64
  %cmp72.us = icmp eq i32 %20, 0
  %.1 = and i1 %cmp48.not.us, %cmp72.us
  br label %lor.end73.us

lor.end73.us:                                     ; preds = %if.end45.us.lor.end73.us_crit_edge, %lor.rhs70.us
  %.phi = phi i1 [ %.0, %if.end45.us.lor.end73.us_crit_edge ], [ %.1, %lor.rhs70.us ]
  br i1 %.phi, label %if.then86.us, label %cleanup.us

if.then86.us:                                     ; preds = %lor.end73.us
  %next_semaphore.i.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529.us, i64 0, i32 10
  %21 = load i32, i32* %next_semaphore.i.us, align 8, !tbaa !42
  %num_semaphores.i.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529.us, i64 0, i32 0, i32 4
  %22 = load i32, i32* %num_semaphores.i.us, align 8, !tbaa !35
  %cmp14.i.us = icmp slt i32 %21, %22
  br i1 %cmp14.i.us, label %for.body.lr.ph.i.us, label %if.else127

for.body.lr.ph.i.us:                              ; preds = %if.then86.us
  %semaphores.i.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529.us, i64 0, i32 0, i32 3
  br label %for.body.i.us

for.body.i.us:                                    ; preds = %for.inc.i.us, %for.body.lr.ph.i.us
  %23 = phi i32 [ %21, %for.body.lr.ph.i.us ], [ %inc.i.us, %for.inc.i.us ]
  %24 = load %struct.halide_semaphore_acquire_t*, %struct.halide_semaphore_acquire_t** %semaphores.i.us, align 8, !tbaa !34
  %idxprom.i.us = sext i32 %23 to i64
  %semaphore.i.us = getelementptr inbounds %struct.halide_semaphore_acquire_t, %struct.halide_semaphore_acquire_t* %24, i64 %idxprom.i.us, i32 0
  %25 = load %struct.halide_semaphore_t*, %struct.halide_semaphore_t** %semaphore.i.us, align 8, !tbaa !75
  %count.i.us = getelementptr inbounds %struct.halide_semaphore_acquire_t, %struct.halide_semaphore_acquire_t* %24, i64 %idxprom.i.us, i32 1
  %26 = load i32, i32* %count.i.us, align 8, !tbaa !77
  %call.i.us = tail call zeroext i1 @halide_default_semaphore_try_acquire(%struct.halide_semaphore_t* %25, i32 %26) #14
  br i1 %call.i.us, label %for.inc.i.us, label %cleanup.us

for.inc.i.us:                                     ; preds = %for.body.i.us
  %27 = load i32, i32* %next_semaphore.i.us, align 8, !tbaa !42
  %inc.i.us = add nsw i32 %27, 1
  store i32 %inc.i.us, i32* %next_semaphore.i.us, align 8, !tbaa !42
  %28 = load i32, i32* %num_semaphores.i.us, align 8, !tbaa !35
  %cmp.i.us = icmp slt i32 %inc.i.us, %28
  br i1 %cmp.i.us, label %for.body.i.us, label %if.else127, !llvm.loop !78

cleanup.us:                                       ; preds = %for.body.i.us, %lor.end73.us
  %next_job95.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529.us, i64 0, i32 2
  %29 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %next_job95.us, align 8, !tbaa !67
  %tobool23.not.us = icmp eq %"struct.Halide::Runtime::Internal::work"* %29, null
  br i1 %tobool23.not.us, label %if.then103, label %do.end27.us

do.end27:                                         ; preds = %do.end, %cleanup
  %job.1529 = phi %"struct.Halide::Runtime::Internal::work"* [ %50, %cleanup ], [ %3, %do.end ]
  %prev_ptr.1528 = phi %"struct.Halide::Runtime::Internal::work"** [ %next_job95, %cleanup ], [ getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), %do.end ]
  %parent_job29 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 5
  %30 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %parent_job29, align 8, !tbaa !46
  %cmp30 = icmp eq %"struct.Halide::Runtime::Internal::work"* %30, null
  br i1 %cmp30, label %if.then31, label %if.else32

if.then31:                                        ; preds = %do.end27
  %31 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 4), align 8, !tbaa !60
  %add = add nsw i32 %31, 1
  %32 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  %sub = sub i32 %add, %32
  br label %if.end45

if.else32:                                        ; preds = %do.end27
  %active_workers33 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %30, i64 0, i32 8
  %33 = load i32, i32* %active_workers33, align 8, !tbaa !64
  %cmp34 = icmp eq i32 %33, 0
  %min_threads = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %30, i64 0, i32 0, i32 7
  %34 = load i32, i32* %min_threads, align 4, !tbaa !37
  br i1 %cmp34, label %if.then35, label %if.else38

if.then35:                                        ; preds = %if.else32
  %threads_reserved = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %30, i64 0, i32 6
  %35 = load i32, i32* %threads_reserved, align 8, !tbaa !65
  %sub37 = sub nsw i32 %34, %35
  br label %if.end45

if.else38:                                        ; preds = %if.else32
  %mul = mul nsw i32 %34, %33
  %threads_reserved42 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %30, i64 0, i32 6
  %36 = load i32, i32* %threads_reserved42, align 8, !tbaa !65
  %sub43 = sub nsw i32 %mul, %36
  br label %if.end45

if.end45:                                         ; preds = %if.else38, %if.then35, %if.then31
  %threads_available.0 = phi i32 [ %sub, %if.then31 ], [ %sub37, %if.then35 ], [ %sub43, %if.else38 ]
  %min_threads47 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 0, i32 7
  %37 = load i32, i32* %min_threads47, align 4, !tbaa !37
  %cmp48.not = icmp slt i32 %threads_available.0, %37
  %siblings = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 3
  %38 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %siblings, align 8, !tbaa !44
  %39 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %siblings56, align 8, !tbaa !44
  %cmp57 = icmp ne %"struct.Halide::Runtime::Internal::work"* %38, %39
  %cmp60 = icmp ne i32 %37, 0
  %serial = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 0, i32 8
  %40 = load i8, i8* %serial, align 8, !tbaa !33, !range !21
  %tobool69.not = icmp eq i8 %40, 0
  br i1 %tobool69.not, label %if.end45.lor.end73_crit_edge, label %lor.rhs70

if.end45.lor.end73_crit_edge:                     ; preds = %if.end45
  %.not472.0 = xor i1 true, true
  br label %lor.end73

lor.rhs70:                                        ; preds = %if.end45
  %active_workers71 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 8
  %41 = load i32, i32* %active_workers71, align 8, !tbaa !64
  %cmp72 = icmp eq i32 %41, 0
  %.not472.1 = xor i1 %cmp72, true
  br label %lor.end73

lor.end73:                                        ; preds = %if.end45.lor.end73_crit_edge, %lor.rhs70
  %.not472.phi = phi i1 [ %.not472.0, %if.end45.lor.end73_crit_edge ], [ %.not472.1, %lor.rhs70 ]
  %.not = and i1 %cmp60, %cmp57
  %brmerge = or i1 %cmp48.not, %.not
  %brmerge473 = or i1 %brmerge, %.not472.phi
  br i1 %brmerge473, label %cleanup, label %if.then86

if.then86:                                        ; preds = %lor.end73
  %next_semaphore.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 10
  %42 = load i32, i32* %next_semaphore.i, align 8, !tbaa !42
  %num_semaphores.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 0, i32 4
  %43 = load i32, i32* %num_semaphores.i, align 8, !tbaa !35
  %cmp14.i = icmp slt i32 %42, %43
  br i1 %cmp14.i, label %for.body.lr.ph.i, label %if.else127

for.body.lr.ph.i:                                 ; preds = %if.then86
  %semaphores.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 0, i32 3
  br label %for.body.i

for.body.i:                                       ; preds = %for.inc.i, %for.body.lr.ph.i
  %44 = phi i32 [ %42, %for.body.lr.ph.i ], [ %inc.i, %for.inc.i ]
  %45 = load %struct.halide_semaphore_acquire_t*, %struct.halide_semaphore_acquire_t** %semaphores.i, align 8, !tbaa !34
  %idxprom.i = sext i32 %44 to i64
  %semaphore.i = getelementptr inbounds %struct.halide_semaphore_acquire_t, %struct.halide_semaphore_acquire_t* %45, i64 %idxprom.i, i32 0
  %46 = load %struct.halide_semaphore_t*, %struct.halide_semaphore_t** %semaphore.i, align 8, !tbaa !75
  %count.i = getelementptr inbounds %struct.halide_semaphore_acquire_t, %struct.halide_semaphore_acquire_t* %45, i64 %idxprom.i, i32 1
  %47 = load i32, i32* %count.i, align 8, !tbaa !77
  %call.i = tail call zeroext i1 @halide_default_semaphore_try_acquire(%struct.halide_semaphore_t* %46, i32 %47) #14
  br i1 %call.i, label %for.inc.i, label %cleanup

for.inc.i:                                        ; preds = %for.body.i
  %48 = load i32, i32* %next_semaphore.i, align 8, !tbaa !42
  %inc.i = add nsw i32 %48, 1
  store i32 %inc.i, i32* %next_semaphore.i, align 8, !tbaa !42
  %49 = load i32, i32* %num_semaphores.i, align 8, !tbaa !35
  %cmp.i = icmp slt i32 %inc.i, %49
  br i1 %cmp.i, label %for.body.i, label %if.else127, !llvm.loop !78

cleanup:                                          ; preds = %for.body.i, %lor.end73
  %next_job95 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1529, i64 0, i32 2
  %50 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %next_job95, align 8, !tbaa !67
  %tobool23.not = icmp eq %"struct.Halide::Runtime::Internal::work"* %50, null
  br i1 %tobool23.not, label %if.then103, label %do.end27

if.then103:                                       ; preds = %cleanup, %cleanup.us
  br i1 %tobool.not, label %if.else112, label %if.then105

if.then105:                                       ; preds = %do.end, %if.then103
  %inc = add nsw i32 %spin_count.0, 1
  %cmp106 = icmp slt i32 %spin_count.0, 40
  br i1 %cmp106, label %if.then107, label %if.else108

if.then107:                                       ; preds = %if.then105
  tail call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  tail call void @halide_thread_yield() #14
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  br label %while.cond.backedge

if.else108:                                       ; preds = %if.then105
  %51 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 12), align 4, !tbaa !70
  %inc109 = add nsw i32 %51, 1
  store i32 %inc109, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 12), align 4, !tbaa !70
  store i8 1, i8* %owner_is_sleeping, align 4, !tbaa !43
  tail call void @halide_cond_wait(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 10), %struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  store i8 0, i8* %owner_is_sleeping, align 4, !tbaa !43
  %52 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 12), align 4, !tbaa !70
  %dec = add nsw i32 %52, -1
  store i32 %dec, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 12), align 4, !tbaa !70
  br label %while.cond.backedge

if.else112:                                       ; preds = %if.then103, %do.end.thread
  %53 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 11), align 8, !tbaa !79
  %inc113 = add nsw i32 %53, 1
  store i32 %inc113, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 11), align 8, !tbaa !79
  %54 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 5), align 4, !tbaa !62
  %55 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 6), align 8, !tbaa !71
  %cmp114 = icmp sgt i32 %54, %55
  br i1 %cmp114, label %if.then115, label %if.else118

if.then115:                                       ; preds = %if.else112
  %dec116 = add nsw i32 %54, -1
  store i32 %dec116, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 5), align 4, !tbaa !62
  tail call void @halide_cond_wait(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 9), %struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %56 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 5), align 4, !tbaa !62
  %inc117 = add nsw i32 %56, 1
  store i32 %inc117, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 5), align 4, !tbaa !62
  br label %if.end124

if.else118:                                       ; preds = %if.else112
  %inc119 = add nsw i32 %spin_count.0, 1
  %cmp120 = icmp slt i32 %spin_count.0, 40
  br i1 %cmp120, label %if.then121, label %if.else122

if.then121:                                       ; preds = %if.else118
  tail call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  tail call void @halide_thread_yield() #14
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  br label %if.end124

if.else122:                                       ; preds = %if.else118
  tail call void @halide_cond_wait(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 8), %struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  br label %if.end124

if.end124:                                        ; preds = %if.else122, %if.then121, %if.then115
  %spin_count.1 = phi i32 [ %spin_count.0, %if.then115 ], [ %inc119, %if.then121 ], [ %inc119, %if.else122 ]
  %57 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 11), align 8, !tbaa !79
  %dec125 = add nsw i32 %57, -1
  store i32 %dec125, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 11), align 8, !tbaa !79
  br label %while.cond.backedge

if.else127:                                       ; preds = %if.then86, %if.then86.us, %for.inc.i, %for.inc.i.us
  %next_semaphore.i521 = phi i32* [ %next_semaphore.i.us, %for.inc.i.us ], [ %next_semaphore.i, %for.inc.i ], [ %next_semaphore.i.us, %if.then86.us ], [ %next_semaphore.i, %if.then86 ]
  %prev_ptr.1519 = phi %"struct.Halide::Runtime::Internal::work"** [ %prev_ptr.1528.us, %for.inc.i.us ], [ %prev_ptr.1528, %for.inc.i ], [ %prev_ptr.1528.us, %if.then86.us ], [ %prev_ptr.1528, %if.then86 ]
  %job.1515 = phi %"struct.Halide::Runtime::Internal::work"* [ %job.1529.us, %for.inc.i.us ], [ %job.1529, %for.inc.i ], [ %job.1529.us, %if.then86.us ], [ %job.1529, %if.then86 ]
  store i32 0, i32* %next_semaphore.i521, align 8, !tbaa !42
  %active_workers132 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 8
  %58 = load i32, i32* %active_workers132, align 8, !tbaa !64
  %inc133 = add nsw i32 %58, 1
  store i32 %inc133, i32* %active_workers132, align 8, !tbaa !64
  %parent_job134 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 5
  %59 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %parent_job134, align 8, !tbaa !46
  %cmp135 = icmp eq %"struct.Halide::Runtime::Internal::work"* %59, null
  %min_threads138 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 7
  %60 = load i32, i32* %min_threads138, align 4, !tbaa !37
  br i1 %cmp135, label %if.then136, label %if.else143

if.then136:                                       ; preds = %if.else127
  %61 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  %add139 = add nsw i32 %61, %60
  store i32 %add139, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  br label %if.end152

if.else143:                                       ; preds = %if.else127
  %threads_reserved147 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %59, i64 0, i32 6
  %62 = load i32, i32* %threads_reserved147, align 8, !tbaa !65
  %add148 = add nsw i32 %62, %60
  store i32 %add148, i32* %threads_reserved147, align 8, !tbaa !65
  br label %if.end152

if.end152:                                        ; preds = %if.else143, %if.then136
  %serial154 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 8
  %63 = load i8, i8* %serial154, align 8, !tbaa !33, !range !21
  %tobool155.not = icmp eq i8 %63, 0
  br i1 %tobool155.not, label %if.else198, label %if.then156

if.then156:                                       ; preds = %if.end152
  %next_job157 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 2
  %64 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %next_job157, align 8, !tbaa !67
  store %"struct.Halide::Runtime::Internal::work"* %64, %"struct.Halide::Runtime::Internal::work"** %prev_ptr.1519, align 8, !tbaa !14
  tail call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %extent163 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 6
  %next_semaphore.i474 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 10
  %num_semaphores.i475 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 4
  %semaphores.i477 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 3
  %user_context = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 7
  %fn = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 0
  %min = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 5
  %closure = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 1
  %65 = bitcast %"struct.Halide::Runtime::Internal::work"* %job.1515 to i8*
  br label %while.cond161.preheader

while.cond161.preheader:                          ; preds = %if.end172, %if.then156
  %iters.0538 = phi i32 [ 1, %if.then156 ], [ 0, %if.end172 ]
  %total_iters.0537 = phi i32 [ 0, %if.then156 ], [ %add178, %if.end172 ]
  %66 = load i32, i32* %extent163, align 8, !tbaa !32
  %sub164531 = sub nsw i32 %66, %total_iters.0537
  %cmp165532 = icmp sgt i32 %sub164531, %iters.0538
  br i1 %cmp165532, label %land.rhs.preheader, label %while.end169

land.rhs.preheader:                               ; preds = %while.cond161.preheader
  %.pre = load i32, i32* %next_semaphore.i474, align 8, !tbaa !42
  %.pre560 = load i32, i32* %num_semaphores.i475, align 8, !tbaa !35
  br label %land.rhs

land.rhs:                                         ; preds = %while.body167, %land.rhs.preheader
  %67 = phi i32 [ %76, %while.body167 ], [ %66, %land.rhs.preheader ]
  %68 = phi i32 [ %77, %while.body167 ], [ %.pre560, %land.rhs.preheader ]
  %69 = phi i32 [ 0, %while.body167 ], [ %.pre, %land.rhs.preheader ]
  %iters.1533 = phi i32 [ %inc168, %while.body167 ], [ %iters.0538, %land.rhs.preheader ]
  %cmp14.i476 = icmp slt i32 %69, %68
  br i1 %cmp14.i476, label %for.body.i483, label %while.body167

for.body.i483:                                    ; preds = %land.rhs, %for.inc.i486
  %70 = phi i32 [ %inc.i484, %for.inc.i486 ], [ %69, %land.rhs ]
  %71 = load %struct.halide_semaphore_acquire_t*, %struct.halide_semaphore_acquire_t** %semaphores.i477, align 8, !tbaa !34
  %idxprom.i479 = sext i32 %70 to i64
  %semaphore.i480 = getelementptr inbounds %struct.halide_semaphore_acquire_t, %struct.halide_semaphore_acquire_t* %71, i64 %idxprom.i479, i32 0
  %72 = load %struct.halide_semaphore_t*, %struct.halide_semaphore_t** %semaphore.i480, align 8, !tbaa !75
  %count.i481 = getelementptr inbounds %struct.halide_semaphore_acquire_t, %struct.halide_semaphore_acquire_t* %71, i64 %idxprom.i479, i32 1
  %73 = load i32, i32* %count.i481, align 8, !tbaa !77
  %call.i482 = tail call zeroext i1 @halide_default_semaphore_try_acquire(%struct.halide_semaphore_t* %72, i32 %73) #14
  br i1 %call.i482, label %for.inc.i486, label %while.end169

for.inc.i486:                                     ; preds = %for.body.i483
  %74 = load i32, i32* %next_semaphore.i474, align 8, !tbaa !42
  %inc.i484 = add nsw i32 %74, 1
  store i32 %inc.i484, i32* %next_semaphore.i474, align 8, !tbaa !42
  %75 = load i32, i32* %num_semaphores.i475, align 8, !tbaa !35
  %cmp.i485 = icmp slt i32 %inc.i484, %75
  br i1 %cmp.i485, label %for.body.i483, label %while.body167.loopexit, !llvm.loop !78

while.body167.loopexit:                           ; preds = %for.inc.i486
  %.pre561 = load i32, i32* %extent163, align 8, !tbaa !32
  br label %while.body167

while.body167:                                    ; preds = %while.body167.loopexit, %land.rhs
  %76 = phi i32 [ %.pre561, %while.body167.loopexit ], [ %67, %land.rhs ]
  %77 = phi i32 [ %75, %while.body167.loopexit ], [ %68, %land.rhs ]
  store i32 0, i32* %next_semaphore.i474, align 8, !tbaa !42
  %inc168 = add nuw nsw i32 %iters.1533, 1
  %sub164 = sub nsw i32 %76, %total_iters.0537
  %cmp165 = icmp sgt i32 %sub164, %inc168
  br i1 %cmp165, label %land.rhs, label %if.end172, !llvm.loop !80

while.end169:                                     ; preds = %for.body.i483, %while.cond161.preheader
  %iters.1523 = phi i32 [ %iters.0538, %while.cond161.preheader ], [ %iters.1533, %for.body.i483 ]
  %cmp170 = icmp eq i32 %iters.1523, 0
  br i1 %cmp170, label %while.end179, label %if.end172

if.end172:                                        ; preds = %while.body167, %while.end169
  %iters.1523566 = phi i32 [ %iters.1523, %while.end169 ], [ %inc168, %while.body167 ]
  %78 = load i8*, i8** %user_context, align 8, !tbaa !40
  %79 = load i32 (i8*, i32, i32, i8*, i8*)*, i32 (i8*, i32, i32, i8*, i8*)** %fn, align 8, !tbaa !28
  %80 = load i32, i32* %min, align 4, !tbaa !31
  %add175 = add nsw i32 %80, %total_iters.0537
  %81 = load i8*, i8** %closure, align 8, !tbaa !36
  %call177 = tail call i32 @halide_do_loop_task(i8* %78, i32 (i8*, i32, i32, i8*, i8*)* %79, i32 %add175, i32 %iters.1523566, i8* %81, i8* nonnull %65) #16
  %add178 = add nuw nsw i32 %iters.1523566, %total_iters.0537
  %cmp159 = icmp eq i32 %call177, 0
  br i1 %cmp159, label %while.cond161.preheader, label %while.end179, !llvm.loop !81

while.end179:                                     ; preds = %if.end172, %while.end169
  %cmp170568 = phi i1 [ true, %while.end169 ], [ false, %if.end172 ]
  %result.0.lcssa = phi i32 [ 0, %while.end169 ], [ %call177, %if.end172 ]
  %total_iters.0.lcssa = phi i32 [ %total_iters.0537, %while.end169 ], [ %add178, %if.end172 ]
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %82 = load i32, i32* %min, align 4, !tbaa !31
  %add182 = add nsw i32 %82, %total_iters.0.lcssa
  store i32 %add182, i32* %min, align 4, !tbaa !31
  %83 = load i32, i32* %extent163, align 8, !tbaa !32
  %sub185 = sub nsw i32 %83, %total_iters.0.lcssa
  store i32 %sub185, i32* %extent163, align 8, !tbaa !32
  br i1 %cmp170568, label %if.else190, label %if.end230.thread505

if.end230.thread505:                              ; preds = %while.end179
  store i32 0, i32* %extent163, align 8, !tbaa !32
  br label %if.then238

if.else190:                                       ; preds = %while.end179
  %cmp193 = icmp sgt i32 %sub185, 0
  br i1 %cmp193, label %if.then194, label %if.end271

if.then194:                                       ; preds = %if.else190
  %84 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), align 8, !tbaa !66
  store %"struct.Halide::Runtime::Internal::work"* %84, %"struct.Halide::Runtime::Internal::work"** %next_job157, align 8, !tbaa !67
  store %"struct.Halide::Runtime::Internal::work"* %job.1515, %"struct.Halide::Runtime::Internal::work"** getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 3), align 8, !tbaa !66
  br label %if.end271

if.else198:                                       ; preds = %if.end152
  %myjob.sroa.0.0..sroa_idx = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 0
  %myjob.sroa.0.0.copyload = load i32 (i8*, i32, i32, i8*, i8*)*, i32 (i8*, i32, i32, i8*, i8*)** %myjob.sroa.0.0..sroa_idx, align 8, !tbaa.struct !82
  %myjob.sroa.4.0..sroa_idx327 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 1
  %myjob.sroa.4.0.copyload = load i8*, i8** %myjob.sroa.4.0..sroa_idx327, align 8, !tbaa.struct !83
  %myjob.sroa.6333.0..sroa_idx334 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 5
  %myjob.sroa.6333.0.copyload = load i32, i32* %myjob.sroa.6333.0..sroa_idx334, align 4
  %myjob.sroa.8340.0..sroa_idx341 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 1
  %myjob.sroa.8340.0.copyload = load i32 (i8*, i32, i8*)*, i32 (i8*, i32, i8*)** %myjob.sroa.8340.0..sroa_idx341, align 8, !tbaa.struct !84
  %myjob.sroa.10347.0..sroa_idx348 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 7
  %myjob.sroa.10347.0.copyload = load i8*, i8** %myjob.sroa.10347.0..sroa_idx348, align 8, !tbaa.struct !85
  %inc201 = add nsw i32 %myjob.sroa.6333.0.copyload, 1
  store i32 %inc201, i32* %myjob.sroa.6333.0..sroa_idx334, align 4, !tbaa !31
  %extent203 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 6
  %85 = load i32, i32* %extent203, align 8, !tbaa !32
  %dec204 = add nsw i32 %85, -1
  store i32 %dec204, i32* %extent203, align 8, !tbaa !32
  %cmp207 = icmp eq i32 %dec204, 0
  br i1 %cmp207, label %if.then208, label %if.end210

if.then208:                                       ; preds = %if.else198
  %next_job209 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 2
  %86 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %next_job209, align 8, !tbaa !67
  store %"struct.Halide::Runtime::Internal::work"* %86, %"struct.Halide::Runtime::Internal::work"** %prev_ptr.1519, align 8, !tbaa !14
  br label %if.end210

if.end210:                                        ; preds = %if.then208, %if.else198
  tail call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %tobool211.not = icmp eq i32 (i8*, i32, i8*)* %myjob.sroa.8340.0.copyload, null
  br i1 %tobool211.not, label %if.else220, label %if.then212

if.then212:                                       ; preds = %if.end210
  %call219 = tail call i32 @halide_do_task(i8* %myjob.sroa.10347.0.copyload, i32 (i8*, i32, i8*)* nonnull %myjob.sroa.8340.0.copyload, i32 %myjob.sroa.6333.0.copyload, i8* %myjob.sroa.4.0.copyload) #16
  br label %if.end230

if.else220:                                       ; preds = %if.end210
  %87 = bitcast %"struct.Halide::Runtime::Internal::work"* %job.1515 to i8*
  %call228 = tail call i32 @halide_do_loop_task(i8* %myjob.sroa.10347.0.copyload, i32 (i8*, i32, i32, i8*, i8*)* %myjob.sroa.0.0.copyload, i32 %myjob.sroa.6333.0.copyload, i32 1, i8* %myjob.sroa.4.0.copyload, i8* %87) #16
  br label %if.end230

if.end230:                                        ; preds = %if.else220, %if.then212
  %result.1 = phi i32 [ %call219, %if.then212 ], [ %call228, %if.else220 ]
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %cmp237.not = icmp eq i32 %result.1, 0
  br i1 %cmp237.not, label %if.end271, label %if.then238

if.then238:                                       ; preds = %if.end230, %if.end230.thread505
  %result.2510 = phi i32 [ %result.0.lcssa, %if.end230.thread505 ], [ %result.1, %if.end230 ]
  %exit_status239 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 9
  store i32 %result.2510, i32* %exit_status239, align 4, !tbaa !47
  %sibling_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 4
  %88 = load i32, i32* %sibling_count, align 8, !tbaa !45
  %cmp240540 = icmp sgt i32 %88, 0
  br i1 %cmp240540, label %do.end243.lr.ph, label %if.end271

do.end243.lr.ph:                                  ; preds = %if.then238
  %siblings244 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 3
  %89 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %siblings244, align 8, !tbaa !44
  %wide.trip.count = zext i32 %88 to i64
  br label %do.end243

do.end243:                                        ; preds = %for.inc, %do.end243.lr.ph
  %indvars.iv = phi i64 [ 0, %do.end243.lr.ph ], [ %indvars.iv.next, %for.inc ]
  %wake_owners.0541 = phi i8 [ 0, %do.end243.lr.ph ], [ %wake_owners.1, %for.inc ]
  %exit_status245 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %89, i64 %indvars.iv, i32 9
  %90 = load i32, i32* %exit_status245, align 4, !tbaa !47
  %cmp246 = icmp eq i32 %90, 0
  br i1 %cmp246, label %if.then247, label %for.inc

if.then247:                                       ; preds = %do.end243
  store i32 %result.2510, i32* %exit_status245, align 4, !tbaa !47
  %91 = load i32, i32* %active_workers132, align 8, !tbaa !64
  %cmp253 = icmp eq i32 %91, 0
  br i1 %cmp253, label %land.rhs254, label %land.end260

land.rhs254:                                      ; preds = %if.then247
  %owner_is_sleeping258 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %89, i64 %indvars.iv, i32 11
  %92 = load i8, i8* %owner_is_sleeping258, align 4, !tbaa !43, !range !21
  br label %land.end260

land.end260:                                      ; preds = %land.rhs254, %if.then247
  %93 = phi i8 [ 0, %if.then247 ], [ %92, %land.rhs254 ]
  %94 = and i8 %wake_owners.0541, 1
  %or = or i8 %93, %94
  br label %for.inc

for.inc:                                          ; preds = %land.end260, %do.end243
  %wake_owners.1 = phi i8 [ %or, %land.end260 ], [ %wake_owners.0541, %do.end243 ]
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond.not, label %if.end271, label %do.end243, !llvm.loop !86

if.end271:                                        ; preds = %for.inc, %if.then238, %if.end230, %if.then194, %if.else190
  %wake_owners.2 = phi i8 [ 0, %if.end230 ], [ 0, %if.else190 ], [ 0, %if.then194 ], [ 0, %if.then238 ], [ %wake_owners.1, %for.inc ]
  %95 = load %"struct.Halide::Runtime::Internal::work"*, %"struct.Halide::Runtime::Internal::work"** %parent_job134, align 8, !tbaa !46
  %cmp273 = icmp eq %"struct.Halide::Runtime::Internal::work"* %95, null
  %96 = load i32, i32* %min_threads138, align 4, !tbaa !37
  br i1 %cmp273, label %if.then274, label %if.else281

if.then274:                                       ; preds = %if.end271
  %97 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  %sub277 = sub nsw i32 %97, %96
  store i32 %sub277, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 16), align 4, !tbaa !61
  br label %if.end290

if.else281:                                       ; preds = %if.end271
  %threads_reserved285 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %95, i64 0, i32 6
  %98 = load i32, i32* %threads_reserved285, align 8, !tbaa !65
  %sub286 = sub nsw i32 %98, %96
  store i32 %sub286, i32* %threads_reserved285, align 8, !tbaa !65
  br label %if.end290

if.end290:                                        ; preds = %if.else281, %if.then274
  %99 = load i32, i32* %active_workers132, align 8, !tbaa !64
  %dec292 = add nsw i32 %99, -1
  store i32 %dec292, i32* %active_workers132, align 8, !tbaa !64
  %100 = and i8 %wake_owners.2, 1
  %tobool296.not = icmp eq i8 %100, 0
  br i1 %tobool296.not, label %lor.lhs.false297, label %if.then310

lor.lhs.false297:                                 ; preds = %if.end290
  %cmp299 = icmp eq i32 %dec292, 0
  br i1 %cmp299, label %land.lhs.true300, label %while.cond.backedge

land.lhs.true300:                                 ; preds = %lor.lhs.false297
  %extent302 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 0, i32 6
  %101 = load i32, i32* %extent302, align 8, !tbaa !32
  %cmp303 = icmp eq i32 %101, 0
  br i1 %cmp303, label %land.lhs.true307, label %lor.lhs.false304

lor.lhs.false304:                                 ; preds = %land.lhs.true300
  %exit_status305 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 9
  %102 = load i32, i32* %exit_status305, align 4, !tbaa !47
  %cmp306.not = icmp eq i32 %102, 0
  br i1 %cmp306.not, label %while.cond.backedge, label %land.lhs.true307

land.lhs.true307:                                 ; preds = %lor.lhs.false304, %land.lhs.true300
  %owner_is_sleeping308 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %job.1515, i64 0, i32 11
  %103 = load i8, i8* %owner_is_sleeping308, align 4, !tbaa !43, !range !21
  %tobool309.not = icmp eq i8 %103, 0
  br i1 %tobool309.not, label %while.cond.backedge, label %if.then310

if.then310:                                       ; preds = %land.lhs.true307, %if.end290
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 10)) #16
  br label %while.cond.backedge

while.cond.backedge:                              ; preds = %if.then310, %land.lhs.true307, %lor.lhs.false304, %lor.lhs.false297, %if.end124, %if.else108, %if.then107, %if.then15, %while.end
  %spin_count.0.be = phi i32 [ %spin_count.0, %while.end ], [ %spin_count.0, %if.then15 ], [ %inc, %if.then107 ], [ %inc, %if.else108 ], [ %spin_count.1, %if.end124 ], [ 0, %if.then310 ], [ 0, %land.lhs.true307 ], [ 0, %lor.lhs.false304 ], [ 0, %lor.lhs.false297 ]
  br label %while.cond, !llvm.loop !87

while.end316:                                     ; preds = %cond.end, %cond.false
  ret void
}

; Function Attrs: nounwind
define weak void @halide_mutex_unlock(%struct.halide_mutex* %mutex) local_unnamed_addr #4 {
entry:
  %control.i.i = alloca %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", align 8
  %state.i = getelementptr %struct.halide_mutex, %struct.halide_mutex* %mutex, i64 0, i32 0, i64 0
  %0 = cmpxchg weak i64* %state.i, i64 1, i64 0 release monotonic
  %1 = extractvalue { i64, i1 } %0, 1
  br i1 %1, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex6unlockEv.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  %2 = cmpxchg i64* %state.i, i64 1, i64 0 release monotonic
  %3 = extractvalue { i64, i1 } %2, 1
  br i1 %3, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex6unlockEv.exit, label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i
  %4 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %4) #15
  %5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN6Halide7Runtime8Internal15Synchronization21mutex_parking_controlE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8, !tbaa !48
  %lock_state2.i.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 1
  store i64* %state.i, i64** %lock_state2.i.i.i, align 8, !tbaa !50
  %6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 0
  %7 = ptrtoint %struct.halide_mutex* %mutex to i64
  %call3.i.i = call i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control10unpark_oneEy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %6, i64 %7) #14
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %4) #15
  br label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex6unlockEv.exit

_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex6unlockEv.exit: ; preds = %if.end.i.i, %if.then.i, %entry
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control10unpark_oneEy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, i64 %addr) local_unnamed_addr #0 align 2 {
entry:
  %call = tail call nonnull align 8 dereferenceable(24) %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* @_ZN6Halide7Runtime8Internal15Synchronization11lock_bucketEy(i64 %addr) #16
  %head = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 1
  %0 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %head, align 8, !tbaa !14
  %tail = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 2
  %1 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::parking_control"* %this to i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)***
  %state.i60 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 0, i32 0
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 0
  br label %while.cond

while.cond:                                       ; preds = %cleanup, %entry
  %data_location.0 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** [ %head, %entry ], [ %data_location.1, %cleanup ]
  %prev.0 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ null, %entry ], [ %prev.1, %cleanup ]
  %data.0 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %0, %entry ], [ %data.1, %cleanup ]
  %retval.0 = phi i64 [ undef, %entry ], [ %retval.1, %cleanup ]
  %cmp.not = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.0, null
  br i1 %cmp.not, label %while.end22, label %while.body

while.body:                                       ; preds = %while.cond
  %sleep_address = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.0, i64 0, i32 1
  %2 = load atomic i64, i64* %sleep_address monotonic, align 8
  %cmp2 = icmp eq i64 %2, %addr
  %next3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.0, i64 0, i32 2
  %3 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next3, align 8, !tbaa !88
  br i1 %cmp2, label %if.then, label %cleanup

if.then:                                          ; preds = %while.body
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %3, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %data_location.0, align 8, !tbaa !14
  %4 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %tail, align 8, !tbaa !93
  %cmp4 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %4, %data.0
  br i1 %cmp4, label %if.then5, label %while.cond7.preheader

while.cond7.preheader:                            ; preds = %if.then
  %cmp872.not = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %3, null
  br i1 %cmp872.not, label %if.end, label %while.body9

if.then5:                                         ; preds = %if.then
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %prev.0, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %tail, align 8, !tbaa !93
  br label %if.end

while.body9:                                      ; preds = %while.cond7.preheader, %while.body9
  %data2.073 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %6, %while.body9 ], [ %3, %while.cond7.preheader ]
  %sleep_address10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data2.073, i64 0, i32 1
  %5 = load atomic i64, i64* %sleep_address10 monotonic, align 8
  %cmp11 = icmp eq i64 %5, %addr
  %next12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data2.073, i64 0, i32 2
  %6 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next12, align 8, !tbaa !88
  %cmp8 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %6, null
  %7 = or i1 %cmp11, %cmp8
  br i1 %7, label %if.end.loopexit, label %while.body9, !llvm.loop !96

if.end.loopexit:                                  ; preds = %while.body9
  %frombool = zext i1 %cmp11 to i8
  br label %if.end

if.end:                                           ; preds = %if.end.loopexit, %if.then5, %while.cond7.preheader
  %more_waiters.1 = phi i8 [ 0, %if.then5 ], [ 0, %while.cond7.preheader ], [ %frombool, %if.end.loopexit ]
  %tobool13 = icmp ne i8 %more_waiters.1, 0
  %vtable = load i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)**, i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)*** %1, align 8, !tbaa !48
  %vfn = getelementptr inbounds i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)*, i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)** %vtable, i64 2
  %8 = load i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)*, i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)** %vfn, align 8
  %call14 = tail call i64 %8(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, i32 1, i1 zeroext %tobool13) #14
  %unpark_info = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.0, i64 0, i32 3
  store i64 %call14, i64* %unpark_info, align 8, !tbaa !97
  %mutex.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.0, i64 0, i32 0, i32 0
  %call.i = tail call i32 @pthread_mutex_lock(%struct.pthread_mutex_t* nonnull %mutex.i) #14
  %9 = atomicrmw and i64* %state.i60, i64 -2 release
  %and.i61 = and i64 %9, 2
  %cmp.i62 = icmp ne i64 %and.i61, 0
  %cmp3.not.i63 = icmp ult i64 %9, 4
  %or.cond.i64 = or i1 %cmp3.not.i63, %cmp.i62
  br i1 %or.cond.i64, label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit66, label %if.then.i65

if.then.i65:                                      ; preds = %if.end
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex) #14
  br label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit66

_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit66: ; preds = %if.then.i65, %if.end
  %should_park.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.0, i64 0, i32 0, i32 2
  store i8 0, i8* %should_park.i, align 8, !tbaa !98
  %condvar.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.0, i64 0, i32 0, i32 1
  %call.i67 = tail call i32 @pthread_cond_signal(%struct.pthread_mutex_t* nonnull %condvar.i) #14
  %call.i69 = tail call i32 @pthread_mutex_unlock(%struct.pthread_mutex_t* nonnull %mutex.i) #14
  %10 = zext i8 %more_waiters.1 to i64
  br label %cleanup

cleanup:                                          ; preds = %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit66, %while.body
  %data_location.1 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** [ %data_location.0, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit66 ], [ %next3, %while.body ]
  %prev.1 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %prev.0, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit66 ], [ %data.0, %while.body ]
  %data.1 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %data.0, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit66 ], [ %3, %while.body ]
  %retval.1 = phi i64 [ %10, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit66 ], [ %retval.0, %while.body ]
  br i1 %cmp2, label %cleanup27, label %while.cond, !llvm.loop !99

while.end22:                                      ; preds = %while.cond
  %vtable23 = load i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)**, i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)*** %1, align 8, !tbaa !48
  %vfn24 = getelementptr inbounds i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)*, i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)** %vtable23, i64 2
  %11 = load i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)*, i64 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, i32, i1)** %vfn24, align 8
  %call25 = tail call i64 %11(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, i32 0, i1 zeroext false) #14
  %12 = atomicrmw and i64* %state.i60, i64 -2 release
  %and.i = and i64 %12, 2
  %cmp.i = icmp ne i64 %and.i, 0
  %cmp3.not.i = icmp ult i64 %12, 4
  %or.cond.i = or i1 %cmp3.not.i, %cmp.i
  br i1 %or.cond.i, label %cleanup27, label %if.then.i

if.then.i:                                        ; preds = %while.end22
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex) #14
  br label %cleanup27

cleanup27:                                        ; preds = %cleanup, %if.then.i, %while.end22
  %retval.2 = phi i64 [ 0, %while.end22 ], [ 0, %if.then.i ], [ %retval.1, %cleanup ]
  ret i64 %retval.2
}

; Function Attrs: nounwind mustprogress
define linkonce nonnull align 8 dereferenceable(24) %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* @_ZN6Halide7Runtime8Internal15Synchronization11lock_bucketEy(i64 %addr) local_unnamed_addr #0 {
entry:
  %mul.i = mul i64 %addr, -7046029254386353131
  %shr.i = lshr i64 %mul.i, 54
  %arrayidx = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_table", %"struct.Halide::Runtime::Internal::Synchronization::hash_table"* @_ZN6Halide7Runtime8Internal15Synchronization5tableE, i64 0, i32 0, i64 %shr.i
  %state.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx, i64 0, i32 0, i32 0
  %0 = cmpxchg weak i64* %state.i, i64 0, i64 1 acquire monotonic
  %1 = extractvalue { i64, i1 } %0, 1
  br i1 %1, label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock9lock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex) #14
  br label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit

_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit: ; preds = %if.then.i, %entry
  ret %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx
}

declare i32 @pthread_mutex_lock(%struct.pthread_mutex_t*) local_unnamed_addr #1

; Function Attrs: nounwind
define linkonce void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %this) local_unnamed_addr #4 align 2 {
entry:
  %state = getelementptr inbounds %"class.Halide::Runtime::Internal::Synchronization::word_lock", %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %this, i64 0, i32 0
  %0 = load atomic i64, i64* %state monotonic, align 8
  br label %while.cond

while.cond:                                       ; preds = %if.end, %entry
  %expected.0 = phi i64 [ %0, %entry ], [ %3, %if.end ]
  %and = and i64 %expected.0, 2
  %tobool.not = icmp ne i64 %and, 0
  %cmp = icmp ult i64 %expected.0, 4
  %or.cond = or i1 %cmp, %tobool.not
  br i1 %or.cond, label %cleanup75, label %if.end

if.end:                                           ; preds = %while.cond
  %or = or i64 %expected.0, 2
  %1 = cmpxchg weak i64* %state, i64 %expected.0, i64 %or acquire monotonic
  %2 = extractvalue { i64, i1 } %1, 1
  %3 = extractvalue { i64, i1 } %1, 0
  br i1 %2, label %while.cond11, label %while.cond

while.cond11:                                     ; preds = %if.end, %cleanup70
  %.pn.pn = phi { i64, i1 } [ %.pn, %cleanup70 ], [ %1, %if.end ]
  %expected.3 = extractvalue { i64, i1 } %.pn.pn, 0
  %and13 = and i64 %expected.3, -4
  %4 = inttoptr i64 %and13 to %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*
  %tail14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %4, i64 0, i32 3
  %tail.0143 = load %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %tail14, align 8, !tbaa !100
  %cmp16144 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %tail.0143, null
  br i1 %cmp16144, label %while.body17, label %while.end23

while.body17:                                     ; preds = %while.cond11, %do.end
  %current.0145 = phi %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* [ %5, %do.end ], [ %4, %while.cond11 ]
  %next18 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %current.0145, i64 0, i32 1
  %5 = load %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %next18, align 8, !tbaa !102
  %cmp19.not = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %5, null
  br i1 %cmp19.not, label %if.then20, label %do.end

if.then20:                                        ; preds = %while.body17
  tail call void @halide_print(i8* null, i8* getelementptr inbounds ([130 x i8], [130 x i8]* @.str.5, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then20, %while.body17
  %prev = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %5, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %current.0145, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %prev, align 8, !tbaa !103
  %tail22 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %5, i64 0, i32 3
  %tail.0 = load %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %tail22, align 8, !tbaa !100
  %cmp16 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %tail.0, null
  br i1 %cmp16, label %while.body17, label %while.end23, !llvm.loop !104

while.end23:                                      ; preds = %do.end, %while.cond11
  %tail.0.lcssa = phi %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* [ %tail.0143, %while.cond11 ], [ %tail.0, %do.end ]
  store %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %tail.0.lcssa, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %tail14, align 8, !tbaa !100
  %and25 = and i64 %expected.3, 1
  %tobool26.not = icmp eq i64 %and25, 0
  br i1 %tobool26.not, label %if.end35, label %if.then27

if.then27:                                        ; preds = %while.end23
  %and29 = and i64 %expected.3, -3
  %6 = cmpxchg weak i64* %state, i64 %expected.3, i64 %and29 acq_rel monotonic
  %7 = extractvalue { i64, i1 } %6, 1
  br i1 %7, label %cleanup75, label %cleanup70

if.end35:                                         ; preds = %while.end23
  %prev36 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %tail.0.lcssa, i64 0, i32 2
  %8 = load %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %prev36, align 8, !tbaa !103
  %cmp37 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %8, null
  br i1 %cmp37, label %while.body41, label %if.else62

while.body41:                                     ; preds = %if.end35, %if.end47
  %expected.5146 = phi i64 [ %11, %if.end47 ], [ %expected.3, %if.end35 ]
  %and43 = and i64 %expected.5146, 1
  %9 = cmpxchg weak i64* %state, i64 %expected.5146, i64 %and43 acq_rel monotonic
  %10 = extractvalue { i64, i1 } %9, 1
  br i1 %10, label %if.end66, label %if.end47

if.end47:                                         ; preds = %while.body41
  %11 = extractvalue { i64, i1 } %9, 0
  %cmp49 = icmp ult i64 %11, 4
  br i1 %cmp49, label %while.body41, label %cleanup70, !llvm.loop !105

if.else62:                                        ; preds = %if.end35
  store %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %8, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %tail14, align 8, !tbaa !100
  %12 = atomicrmw and i64* %state, i64 -3 release
  br label %if.end66

if.end66:                                         ; preds = %while.body41, %if.else62
  %mutex.i103 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %tail.0.lcssa, i64 0, i32 0, i32 0
  %call.i104 = tail call i32 @pthread_mutex_lock(%struct.pthread_mutex_t* nonnull %mutex.i103) #14
  %should_park.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %tail.0.lcssa, i64 0, i32 0, i32 2
  store i8 0, i8* %should_park.i, align 8, !tbaa !98
  %condvar.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %tail.0.lcssa, i64 0, i32 0, i32 1
  %call.i101 = tail call i32 @pthread_cond_signal(%struct.pthread_mutex_t* nonnull %condvar.i) #14
  %call.i = tail call i32 @pthread_mutex_unlock(%struct.pthread_mutex_t* nonnull %mutex.i103) #14
  br label %cleanup75

cleanup70:                                        ; preds = %if.end47, %if.then27
  %.pn = phi { i64, i1 } [ %6, %if.then27 ], [ %9, %if.end47 ]
  fence acquire
  br label %while.cond11

cleanup75:                                        ; preds = %while.cond, %if.then27, %if.end66
  ret void
}

declare i32 @pthread_cond_signal(%struct.pthread_mutex_t*) local_unnamed_addr #1

declare i32 @pthread_mutex_unlock(%struct.pthread_mutex_t*) local_unnamed_addr #1

; Function Attrs: nounwind
define linkonce void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock9lock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %this) local_unnamed_addr #4 align 2 {
entry:
  %node = alloca %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", align 8
  %state = getelementptr inbounds %"class.Halide::Runtime::Internal::Synchronization::word_lock", %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %this, i64 0, i32 0
  %0 = load atomic i64, i64* %state monotonic, align 8
  %1 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %node to i8*
  %should_park.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %node, i64 0, i32 0, i32 2
  %mutex2.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %node, i64 0, i32 0, i32 0
  %condvar3.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %node, i64 0, i32 0, i32 1
  %next.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %node, i64 0, i32 1
  %tail.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data", %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %node, i64 0, i32 3
  %2 = ptrtoint %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %node to i64
  %3 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %next.i to <2 x %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*>*
  br label %while.cond.outer

while.cond.outer:                                 ; preds = %while.cond.outer.backedge, %entry
  %expected.0.ph = phi i64 [ %0, %entry ], [ %expected.0.ph.be, %while.cond.outer.backedge ]
  %spinner.sroa.0.0.ph = phi i32 [ 40, %entry ], [ %spinner.sroa.0.0.ph.be, %while.cond.outer.backedge ]
  %and46 = and i64 %expected.0.ph, 1
  %tobool.not47 = icmp eq i64 %and46, 0
  br i1 %tobool.not47, label %if.then, label %if.end4

if.then:                                          ; preds = %while.cond.outer, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit
  %expected.048 = phi i64 [ %6, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit ], [ %expected.0.ph, %while.cond.outer ]
  %or = or i64 %expected.048, 1
  %4 = cmpxchg weak i64* %state, i64 %expected.048, i64 %or acquire monotonic
  %5 = extractvalue { i64, i1 } %4, 1
  br i1 %5, label %cleanup23, label %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit

_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit: ; preds = %if.then
  %6 = extractvalue { i64, i1 } %4, 0
  %and = and i64 %6, 1
  %tobool.not = icmp eq i64 %and, 0
  br i1 %tobool.not, label %if.then, label %if.end4.loopexit

if.end4.loopexit:                                 ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit
  %7 = extractvalue { i64, i1 } %4, 0
  br label %if.end4

if.end4:                                          ; preds = %if.end4.loopexit, %while.cond.outer
  %expected.0.lcssa = phi i64 [ %expected.0.ph, %while.cond.outer ], [ %7, %if.end4.loopexit ]
  %cmp.not = icmp ugt i64 %expected.0.lcssa, 3
  %cmp.i = icmp sgt i32 %spinner.sroa.0.0.ph, 0
  %or.cond = and i1 %cmp.i, %cmp.not
  br i1 %or.cond, label %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit, label %if.end9

_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit: ; preds = %if.end4
  %cmp4.i = icmp sgt i32 %spinner.sroa.0.0.ph, 1
  br i1 %cmp4.i, label %if.then7, label %if.end9

if.then7:                                         ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit
  %dec.i = add nsw i32 %spinner.sroa.0.0.ph, -1
  call void @halide_thread_yield() #14
  %8 = load atomic i64, i64* %state monotonic, align 8
  br label %while.cond.outer.backedge

if.end9:                                          ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit, %if.end4
  %spinner.sroa.0.2 = phi i32 [ %spinner.sroa.0.0.ph, %if.end4 ], [ 0, %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit ]
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %1) #15
  store i8 0, i8* %should_park.i.i, align 8, !tbaa !98
  %call.i.i29 = call i32 @pthread_mutex_init(%struct.pthread_mutex_t* nonnull %mutex2.i.i, i8* null) #14
  %call4.i.i = call i32 @pthread_cond_init(%struct.pthread_mutex_t* nonnull %condvar3.i.i, i8* null) #14
  store <2 x %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*> zeroinitializer, <2 x %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*>* %3, align 8, !tbaa !14
  store %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* null, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %tail.i, align 8, !tbaa !100
  store i8 1, i8* %should_park.i.i, align 8, !tbaa !98
  %and10 = and i64 %expected.0.lcssa, -4
  %cmp11 = icmp eq i64 %and10, 0
  br i1 %cmp11, label %if.then12, label %if.else

if.then12:                                        ; preds = %if.end9
  store %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %node, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %tail.i, align 8, !tbaa !100
  br label %if.end13

if.else:                                          ; preds = %if.end9
  %9 = inttoptr i64 %and10 to %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"*
  store %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"* %9, %"struct.Halide::Runtime::Internal::Synchronization::word_lock_queue_data"** %next.i, align 8, !tbaa !102
  br label %if.end13

if.end13:                                         ; preds = %if.else, %if.then12
  %and15 = and i64 %expected.0.lcssa, 3
  %or16 = or i64 %and15, %2
  %10 = cmpxchg weak i64* %state, i64 %expected.0.lcssa, i64 %or16 release monotonic
  %11 = extractvalue { i64, i1 } %10, 1
  br i1 %11, label %if.then19, label %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_release_relaxedEPyS4_S4_.exit

_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_release_relaxedEPyS4_S4_.exit: ; preds = %if.end13
  %12 = extractvalue { i64, i1 } %10, 0
  br label %if.end22

if.then19:                                        ; preds = %if.end13
  %call.i = call i32 @pthread_mutex_lock(%struct.pthread_mutex_t* nonnull %mutex2.i.i) #14
  %13 = load i8, i8* %should_park.i.i, align 8, !tbaa !98, !range !21
  %tobool.not6.i = icmp eq i8 %13, 0
  br i1 %tobool.not6.i, label %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit, label %while.body.i

while.body.i:                                     ; preds = %if.then19, %while.body.i
  %call3.i = call i32 @pthread_cond_wait(%struct.pthread_mutex_t* nonnull %condvar3.i.i, %struct.pthread_mutex_t* nonnull %mutex2.i.i) #14
  %14 = load i8, i8* %should_park.i.i, align 8, !tbaa !98, !range !21
  %tobool.not.i = icmp eq i8 %14, 0
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit, label %while.body.i, !llvm.loop !106

_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit: ; preds = %while.body.i, %if.then19
  %call5.i = call i32 @pthread_mutex_unlock(%struct.pthread_mutex_t* nonnull %mutex2.i.i) #14
  %15 = load atomic i64, i64* %state monotonic, align 8
  br label %if.end22

if.end22:                                         ; preds = %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_release_relaxedEPyS4_S4_.exit
  %expected.3 = phi i64 [ %15, %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit ], [ %12, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_release_relaxedEPyS4_S4_.exit ]
  %spinner.sroa.0.3 = phi i32 [ 40, %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit ], [ %spinner.sroa.0.2, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_release_relaxedEPyS4_S4_.exit ]
  %call.i.i = call i32 @pthread_cond_destroy(%struct.pthread_mutex_t* nonnull %condvar3.i.i) #14
  %call2.i.i = call i32 @pthread_mutex_destroy(%struct.pthread_mutex_t* nonnull %mutex2.i.i) #14
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %1) #15
  br label %while.cond.outer.backedge

while.cond.outer.backedge:                        ; preds = %if.end22, %if.then7
  %expected.0.ph.be = phi i64 [ %8, %if.then7 ], [ %expected.3, %if.end22 ]
  %spinner.sroa.0.0.ph.be = phi i32 [ %dec.i, %if.then7 ], [ %spinner.sroa.0.3, %if.end22 ]
  br label %while.cond.outer

cleanup23:                                        ; preds = %if.then
  ret void
}

declare i32 @pthread_mutex_init(%struct.pthread_mutex_t*, i8*) local_unnamed_addr #1

declare i32 @pthread_cond_init(%struct.pthread_mutex_t*, i8*) local_unnamed_addr #1

declare i32 @pthread_cond_wait(%struct.pthread_mutex_t*, %struct.pthread_mutex_t*) local_unnamed_addr #1

declare i32 @pthread_cond_destroy(%struct.pthread_mutex_t*) local_unnamed_addr #1

declare i32 @pthread_mutex_destroy(%struct.pthread_mutex_t*) local_unnamed_addr #1

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr zeroext i1 @_ZN6Halide7Runtime8Internal15Synchronization21mutex_parking_control8validateERNS2_15validate_actionE(%"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* nonnull dereferenceable(16) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action) unnamed_addr #2 align 2 {
entry:
  %lock_state = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %this, i64 0, i32 1
  %0 = load i64*, i64** %lock_state, align 8, !tbaa !50
  %1 = load atomic i64, i64* %0 monotonic, align 8
  %cmp = icmp eq i64 %1, 3
  ret i1 %cmp
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr void @_ZN6Halide7Runtime8Internal15Synchronization15parking_control12before_sleepEv(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this) unnamed_addr #2 align 2 {
entry:
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr i64 @_ZN6Halide7Runtime8Internal15Synchronization21mutex_parking_control6unparkEib(%"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* nonnull dereferenceable(16) %this, i32 %unparked, i1 zeroext %more_waiters) unnamed_addr #2 align 2 {
entry:
  %0 = select i1 %more_waiters, i64 2, i64 0
  %lock_state = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %this, i64 0, i32 1
  %1 = load i64*, i64** %lock_state, align 8, !tbaa !50
  store atomic i64 %0, i64* %1 release, align 8
  ret i64 0
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr void @_ZN6Halide7Runtime8Internal15Synchronization15parking_control16requeue_callbackERKNS2_15validate_actionEbb(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action, i1 zeroext %one_to_wake, i1 zeroext %some_requeued) unnamed_addr #2 align 2 {
entry:
  ret void
}

; Function Attrs: nounwind
define weak void @halide_cond_broadcast(%struct.halide_mutex* %cond) local_unnamed_addr #4 {
entry:
  %control.i = alloca %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", align 8
  %state.i = getelementptr %struct.halide_mutex, %struct.halide_mutex* %cond, i64 0, i32 0, i64 0
  %0 = load atomic i64, i64* %state.i monotonic, align 8
  %cmp.i = icmp eq i64 %0, 0
  br i1 %cmp.i, label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond9broadcastEv.exit, label %if.end.i

if.end.i:                                         ; preds = %entry
  %1 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %1) #15
  %2 = inttoptr i64 %0 to %"class.Halide::Runtime::Internal::Synchronization::word_lock"*
  %3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN6Halide7Runtime8Internal15Synchronization25broadcast_parking_controlE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %3, align 8, !tbaa !48
  %cond_state2.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 1
  store i64* %state.i, i64** %cond_state2.i.i, align 8, !tbaa !107
  %mutex3.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 2
  store %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %2, %"class.Halide::Runtime::Internal::Synchronization::word_lock"** %mutex3.i.i, align 8, !tbaa !109
  %4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 0
  %5 = ptrtoint %struct.halide_mutex* %cond to i64
  %call.i = call i32 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control14unpark_requeueEyyy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %4, i64 %5, i64 %0, i64 0) #14
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %1) #15
  br label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond9broadcastEv.exit

_ZN6Halide7Runtime8Internal15Synchronization9fast_cond9broadcastEv.exit: ; preds = %if.end.i, %entry
  ret void
}

; Function Attrs: nounwind mustprogress
define weak zeroext i1 @halide_default_semaphore_try_acquire(%struct.halide_semaphore_t* %s, i32 %n) #0 {
entry:
  %cmp = icmp eq i32 %n, 0
  br i1 %cmp, label %return, label %if.end

if.end:                                           ; preds = %entry
  %value = bitcast %struct.halide_semaphore_t* %s to i32*
  %0 = load atomic i32, i32* %value acquire, align 4
  %sub12 = sub nsw i32 %0, %n
  %cmp113 = icmp sgt i32 %sub12, -1
  br i1 %cmp113, label %land.rhs, label %return

land.rhs:                                         ; preds = %if.end, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_130atomic_cas_weak_relacq_relaxedIiEEbPT_S6_S6_.exit
  %sub15 = phi i32 [ %sub, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_130atomic_cas_weak_relacq_relaxedIiEEbPT_S6_S6_.exit ], [ %sub12, %if.end ]
  %expected.014 = phi i32 [ %3, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_130atomic_cas_weak_relacq_relaxedIiEEbPT_S6_S6_.exit ], [ %0, %if.end ]
  %1 = cmpxchg weak i32* %value, i32 %expected.014, i32 %sub15 acq_rel monotonic
  %2 = extractvalue { i32, i1 } %1, 1
  br i1 %2, label %return.loopexit, label %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_130atomic_cas_weak_relacq_relaxedIiEEbPT_S6_S6_.exit

_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_130atomic_cas_weak_relacq_relaxedIiEEbPT_S6_S6_.exit: ; preds = %land.rhs
  %3 = extractvalue { i32, i1 } %1, 0
  %sub = sub nsw i32 %3, %n
  %cmp1 = icmp sgt i32 %sub, -1
  br i1 %cmp1, label %land.rhs, label %return.loopexit

return.loopexit:                                  ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_130atomic_cas_weak_relacq_relaxedIiEEbPT_S6_S6_.exit, %land.rhs
  %4 = extractvalue { i32, i1 } %1, 1
  br label %return

return:                                           ; preds = %return.loopexit, %if.end, %entry
  %retval.0 = phi i1 [ true, %entry ], [ false, %if.end ], [ %4, %return.loopexit ]
  ret i1 %retval.0
}

; Function Attrs: nounwind
define weak void @halide_cond_wait(%struct.halide_mutex* %cond, %struct.halide_mutex* %mutex) local_unnamed_addr #4 {
entry:
  %control.i.i.i = alloca %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", align 8
  %control.i = alloca %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", align 8
  %0 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %0) #15
  %state.i = getelementptr %struct.halide_mutex, %struct.halide_mutex* %cond, i64 0, i32 0, i64 0
  %1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN6Halide7Runtime8Internal15Synchronization20wait_parking_controlE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %1, align 8, !tbaa !48
  %cond_state2.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 1
  store i64* %state.i, i64** %cond_state2.i.i, align 8, !tbaa !110
  %mutex3.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 2
  %2 = bitcast %"class.Halide::Runtime::Internal::Synchronization::word_lock"** %mutex3.i.i to %struct.halide_mutex**
  store %struct.halide_mutex* %mutex, %struct.halide_mutex** %2, align 8, !tbaa !112
  %3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 0
  %4 = ptrtoint %struct.halide_mutex* %cond to i64
  %call.i = call i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control4parkEy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %3, i64 %4) #14
  %5 = ptrtoint %struct.halide_mutex* %mutex to i64
  %cmp.not.i = icmp eq i64 %call.i, %5
  %6 = getelementptr %struct.halide_mutex, %struct.halide_mutex* %mutex, i64 0, i32 0, i64 0
  br i1 %cmp.not.i, label %if.else.i, label %if.then.i

if.then.i:                                        ; preds = %entry
  %7 = cmpxchg weak i64* %6, i64 0, i64 1 acquire monotonic
  %8 = extractvalue { i64, i1 } %7, 1
  br i1 %8, label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond4waitEPNS2_10fast_mutexE.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.then.i
  %9 = load atomic i64, i64* %6 monotonic, align 8
  %10 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i.i to i8*
  %11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i.i, i64 0, i32 0, i32 0
  %lock_state2.i.i.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i.i, i64 0, i32 1
  %12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i.i, i64 0, i32 0
  br label %while.cond.outer.i.i.i

while.cond.outer.i.i.i:                           ; preds = %while.cond.outer.i.i.i.backedge, %if.then.i.i
  %expected.0.ph.i.i.i = phi i64 [ %9, %if.then.i.i ], [ %expected.0.ph.i.i.i.be, %while.cond.outer.i.i.i.backedge ]
  %spinner.sroa.0.0.ph.i.i.i = phi i32 [ 40, %if.then.i.i ], [ %spinner.sroa.0.0.ph.i.i.i.be, %while.cond.outer.i.i.i.backedge ]
  %and55.i.i.i = and i64 %expected.0.ph.i.i.i, 1
  %tobool.not56.i.i.i = icmp eq i64 %and55.i.i.i, 0
  br i1 %tobool.not56.i.i.i, label %if.then.i.i.i, label %if.end4.i.i.i

if.then.i.i.i:                                    ; preds = %while.cond.outer.i.i.i, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i.i
  %expected.057.i.i.i = phi i64 [ %15, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i.i ], [ %expected.0.ph.i.i.i, %while.cond.outer.i.i.i ]
  %or.i.i.i = or i64 %expected.057.i.i.i, 1
  %13 = cmpxchg weak i64* %6, i64 %expected.057.i.i.i, i64 %or.i.i.i acquire monotonic
  %14 = extractvalue { i64, i1 } %13, 1
  br i1 %14, label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond4waitEPNS2_10fast_mutexE.exit, label %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i.i

_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i.i: ; preds = %if.then.i.i.i
  %15 = extractvalue { i64, i1 } %13, 0
  %and.i.i.i = and i64 %15, 1
  %tobool.not.i.i.i = icmp eq i64 %and.i.i.i, 0
  br i1 %tobool.not.i.i.i, label %if.then.i.i.i, label %if.end4.i.i.i.loopexit

if.end4.i.i.i.loopexit:                           ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_acquire_relaxedEPyS4_S4_.exit.i.i.i
  %16 = extractvalue { i64, i1 } %13, 0
  br label %if.end4.i.i.i

if.end4.i.i.i:                                    ; preds = %if.end4.i.i.i.loopexit, %while.cond.outer.i.i.i
  %expected.0.lcssa.i.i.i = phi i64 [ %expected.0.ph.i.i.i, %while.cond.outer.i.i.i ], [ %16, %if.end4.i.i.i.loopexit ]
  %cmp.i.i.i.i = icmp sgt i32 %spinner.sroa.0.0.ph.i.i.i, 0
  br i1 %cmp.i.i.i.i, label %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i.i, label %if.end8.i.i.i

_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i.i: ; preds = %if.end4.i.i.i
  %cmp4.i.not.i.i.i = icmp eq i32 %spinner.sroa.0.0.ph.i.i.i, 1
  br i1 %cmp4.i.not.i.i.i, label %if.end8.i.i.i, label %if.then6.i.i.i

if.then6.i.i.i:                                   ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i.i
  %dec.i.i.i.i = add nsw i32 %spinner.sroa.0.0.ph.i.i.i, -1
  call void @halide_thread_yield() #14
  %17 = load atomic i64, i64* %6 monotonic, align 8
  br label %while.cond.outer.i.i.i.backedge

if.end8.i.i.i:                                    ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i.i, %if.end4.i.i.i
  %spinner.sroa.0.152.i.i.i = phi i32 [ 0, %_ZN6Halide7Runtime8Internal15Synchronization12spin_control11should_spinEv.exit.i.i.i ], [ %spinner.sroa.0.0.ph.i.i.i, %if.end4.i.i.i ]
  %and9.i.i.i = and i64 %expected.0.lcssa.i.i.i, 2
  %cmp.i.i.i = icmp eq i64 %and9.i.i.i, 0
  br i1 %cmp.i.i.i, label %if.then10.i.i.i, label %if.end19.i.i.i

if.then10.i.i.i:                                  ; preds = %if.end8.i.i.i
  %or12.i.i.i = or i64 %expected.0.lcssa.i.i.i, 2
  %18 = cmpxchg weak i64* %6, i64 %expected.0.lcssa.i.i.i, i64 %or12.i.i.i monotonic monotonic
  %19 = extractvalue { i64, i1 } %18, 1
  br i1 %19, label %if.end19.i.i.i, label %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i.i

_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i.i: ; preds = %if.then10.i.i.i
  %20 = extractvalue { i64, i1 } %18, 0
  br label %while.cond.outer.i.i.i.backedge

if.end19.i.i.i:                                   ; preds = %if.then10.i.i.i, %if.end8.i.i.i
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %10) #15
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN6Halide7Runtime8Internal15Synchronization21mutex_parking_controlE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %11, align 8, !tbaa !48
  store i64* %6, i64** %lock_state2.i.i.i.i, align 8, !tbaa !50
  %call21.i.i.i = call i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control4parkEy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %12, i64 %5) #14
  %cmp22.i.i.i = icmp eq i64 %call21.i.i.i, %5
  br i1 %cmp22.i.i.i, label %cleanup30.critedge.i.i.i, label %if.end24.i.i.i

if.end24.i.i.i:                                   ; preds = %if.end19.i.i.i
  %21 = load atomic i64, i64* %6 monotonic, align 8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %10) #15
  br label %while.cond.outer.i.i.i.backedge

while.cond.outer.i.i.i.backedge:                  ; preds = %if.end24.i.i.i, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i.i, %if.then6.i.i.i
  %expected.0.ph.i.i.i.be = phi i64 [ %20, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i.i ], [ %21, %if.end24.i.i.i ], [ %17, %if.then6.i.i.i ]
  %spinner.sroa.0.0.ph.i.i.i.be = phi i32 [ %spinner.sroa.0.152.i.i.i, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i.i.i ], [ 40, %if.end24.i.i.i ], [ %dec.i.i.i.i, %if.then6.i.i.i ]
  br label %while.cond.outer.i.i.i

cleanup30.critedge.i.i.i:                         ; preds = %if.end19.i.i.i
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %10) #15
  br label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond4waitEPNS2_10fast_mutexE.exit

if.else.i:                                        ; preds = %entry
  %22 = load atomic i64, i64* %6 monotonic, align 8
  %and.i = and i64 %22, 1
  %tobool.not.i = icmp eq i64 %and.i, 0
  br i1 %tobool.not.i, label %if.then2.i, label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond4waitEPNS2_10fast_mutexE.exit

if.then2.i:                                       ; preds = %if.else.i
  call void @halide_print(i8* null, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @.str.5.6, i64 0, i64 0)) #14
  call void @abort() #14
  br label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond4waitEPNS2_10fast_mutexE.exit

_ZN6Halide7Runtime8Internal15Synchronization9fast_cond4waitEPNS2_10fast_mutexE.exit: ; preds = %if.then.i.i.i, %if.then2.i, %if.else.i, %cleanup30.critedge.i.i.i, %if.then.i
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %0) #15
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_do_loop_task(i8* %user_context, i32 (i8*, i32, i32, i8*, i8*)* %f, i32 %min, i32 %size, i8* %closure, i8* %task_parent) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)*, i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)** @_ZN6Halide7Runtime8Internal19custom_do_loop_taskE, align 8, !tbaa !14
  %call = tail call i32 %0(i8* %user_context, i32 (i8*, i32, i32, i8*, i8*)* %f, i32 %min, i32 %size, i8* %closure, i8* %task_parent) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_do_task(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %idx, i8* %closure) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)*, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)** @_ZN6Halide7Runtime8Internal14custom_do_taskE, align 8, !tbaa !14
  %call = tail call i32 %0(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %idx, i8* %closure) #14
  ret i32 %call
}

; Function Attrs: nounwind
define linkonce i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control4parkEy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, i64 %addr) local_unnamed_addr #4 align 2 {
entry:
  %queue_data = alloca %"struct.Halide::Runtime::Internal::Synchronization::queue_data", align 8
  %action = alloca %"struct.Halide::Runtime::Internal::Synchronization::validate_action", align 8
  %0 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data to i8*
  call void @llvm.lifetime.start.p0i8(i64 160, i8* nonnull %0) #15
  %should_park.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data, i64 0, i32 0, i32 2
  store i8 0, i8* %should_park.i.i, align 8, !tbaa !98
  %mutex2.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data, i64 0, i32 0, i32 0
  %call.i.i = call i32 @pthread_mutex_init(%struct.pthread_mutex_t* nonnull %mutex2.i.i, i8* null) #14
  %condvar3.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data, i64 0, i32 0, i32 1
  %call4.i.i = call i32 @pthread_cond_init(%struct.pthread_mutex_t* nonnull %condvar3.i.i, i8* null) #14
  %sleep_address.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data, i64 0, i32 1
  store i64 0, i64* %sleep_address.i, align 8, !tbaa !113
  %next.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* null, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next.i, align 8, !tbaa !88
  %unpark_info.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data, i64 0, i32 3
  store i64 0, i64* %unpark_info.i, align 8, !tbaa !97
  %call = call nonnull align 8 dereferenceable(24) %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* @_ZN6Halide7Runtime8Internal15Synchronization11lock_bucketEy(i64 %addr) #16
  %1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::validate_action", %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* %action, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1) #15
  store i8 0, i8* %1, align 8, !tbaa !114
  %invalid_unpark_info.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::validate_action", %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* %action, i64 0, i32 2
  store i64 0, i64* %invalid_unpark_info.i, align 8, !tbaa !116
  %2 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::parking_control"* %this to i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)***
  %vtable = load i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)**, i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)*** %2, align 8, !tbaa !48
  %3 = load i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)*, i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)** %vtable, align 8
  %call2 = call zeroext i1 %3(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action) #14
  br i1 %call2, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %state.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 0, i32 0
  %4 = atomicrmw and i64* %state.i, i64 -2 release
  %and.i = and i64 %4, 2
  %cmp.i = icmp ne i64 %and.i, 0
  %cmp3.not.i = icmp ult i64 %4, 4
  %or.cond.i = or i1 %cmp3.not.i, %cmp.i
  br i1 %or.cond.i, label %cleanup, label %if.then.i

if.then.i:                                        ; preds = %if.then
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 0
  call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex) #14
  br label %cleanup

if.end:                                           ; preds = %entry
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* null, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next.i, align 8, !tbaa !88
  store i64 %addr, i64* %sleep_address.i, align 8, !tbaa !113
  store i8 1, i8* %should_park.i.i, align 8, !tbaa !98
  %head = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 1
  %5 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %head, align 8, !tbaa !117
  %cmp.not = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %5, null
  %tail = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 2
  %6 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %tail, align 8
  %next4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %6, i64 0, i32 2
  %head.sink = select i1 %cmp.not, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %head, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next4
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %head.sink, align 8, !tbaa !14
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %queue_data, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %tail, align 8, !tbaa !93
  %state.i23 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 0, i32 0
  %7 = atomicrmw and i64* %state.i23, i64 -2 release
  %and.i24 = and i64 %7, 2
  %cmp.i25 = icmp ne i64 %and.i24, 0
  %cmp3.not.i26 = icmp ult i64 %7, 4
  %or.cond.i27 = or i1 %cmp3.not.i26, %cmp.i25
  br i1 %or.cond.i27, label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit29, label %if.then.i28

if.then.i28:                                      ; preds = %if.end
  %mutex8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %call, i64 0, i32 0
  call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex8) #14
  br label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit29

_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit29: ; preds = %if.then.i28, %if.end
  %8 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::parking_control"* %this to void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)***
  %vtable9 = load void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)**, void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)*** %8, align 8, !tbaa !48
  %vfn10 = getelementptr inbounds void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)*, void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)** %vtable9, i64 1
  %9 = load void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)*, void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*)** %vfn10, align 8
  call void %9(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this) #14
  %call.i = call i32 @pthread_mutex_lock(%struct.pthread_mutex_t* nonnull %mutex2.i.i) #14
  %10 = load i8, i8* %should_park.i.i, align 8, !tbaa !98, !range !21
  %tobool.not6.i = icmp eq i8 %10, 0
  br i1 %tobool.not6.i, label %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit, label %while.body.i

while.body.i:                                     ; preds = %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit29, %while.body.i
  %call3.i = call i32 @pthread_cond_wait(%struct.pthread_mutex_t* nonnull %condvar3.i.i, %struct.pthread_mutex_t* nonnull %mutex2.i.i) #14
  %11 = load i8, i8* %should_park.i.i, align 8, !tbaa !98, !range !21
  %tobool.not.i = icmp eq i8 %11, 0
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit, label %while.body.i, !llvm.loop !106

_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit: ; preds = %while.body.i, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit29
  %call5.i = call i32 @pthread_mutex_unlock(%struct.pthread_mutex_t* nonnull %mutex2.i.i) #14
  br label %cleanup

cleanup:                                          ; preds = %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit, %if.then.i, %if.then
  %unpark_info.i.sink = phi i64* [ %unpark_info.i, %_ZN6Halide7Runtime8Internal15Synchronization13thread_parker4parkEv.exit ], [ %invalid_unpark_info.i, %if.then ], [ %invalid_unpark_info.i, %if.then.i ]
  %12 = load i64, i64* %unpark_info.i.sink, align 8, !tbaa !22
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1) #15
  %call.i.i22 = call i32 @pthread_cond_destroy(%struct.pthread_mutex_t* nonnull %condvar3.i.i) #14
  %call2.i.i = call i32 @pthread_mutex_destroy(%struct.pthread_mutex_t* nonnull %mutex2.i.i) #14
  call void @llvm.lifetime.end.p0i8(i64 160, i8* nonnull %0) #15
  ret i64 %12
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr zeroext i1 @_ZN6Halide7Runtime8Internal15Synchronization20wait_parking_control8validateERNS2_15validate_actionE(%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* nonnull dereferenceable(24) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action) unnamed_addr #2 align 2 {
entry:
  %cond_state = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %this, i64 0, i32 1
  %0 = load i64*, i64** %cond_state, align 8, !tbaa !110
  %1 = load atomic i64, i64* %0 monotonic, align 8
  %cmp = icmp eq i64 %1, 0
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %this, i64 0, i32 2
  %2 = load %"class.Halide::Runtime::Internal::Synchronization::word_lock"*, %"class.Halide::Runtime::Internal::Synchronization::word_lock"** %mutex, align 8, !tbaa !112
  %3 = ptrtoint %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %2 to i64
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  store atomic i64 %3, i64* %0 monotonic, align 8
  br label %cleanup

if.else:                                          ; preds = %entry
  %cmp4.not = icmp eq i64 %1, %3
  br i1 %cmp4.not, label %cleanup, label %if.then5

if.then5:                                         ; preds = %if.else
  %invalid_unpark_info = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::validate_action", %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* %action, i64 0, i32 2
  store i64 %3, i64* %invalid_unpark_info, align 8, !tbaa !116
  br label %cleanup

cleanup:                                          ; preds = %if.then5, %if.else, %if.then
  %retval.0 = phi i1 [ false, %if.then5 ], [ true, %if.else ], [ true, %if.then ]
  ret i1 %retval.0
}

; Function Attrs: nounwind
define linkonce_odr void @_ZN6Halide7Runtime8Internal15Synchronization20wait_parking_control12before_sleepEv(%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* nonnull dereferenceable(24) %this) unnamed_addr #4 align 2 {
entry:
  %control.i.i = alloca %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", align 8
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %this, i64 0, i32 2
  %0 = load %"class.Halide::Runtime::Internal::Synchronization::word_lock"*, %"class.Halide::Runtime::Internal::Synchronization::word_lock"** %mutex, align 8, !tbaa !112
  %state.i = getelementptr inbounds %"class.Halide::Runtime::Internal::Synchronization::word_lock", %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %0, i64 0, i32 0
  %1 = cmpxchg weak i64* %state.i, i64 1, i64 0 release monotonic
  %2 = extractvalue { i64, i1 } %1, 1
  br i1 %2, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex6unlockEv.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  %3 = cmpxchg i64* %state.i, i64 1, i64 0 release monotonic
  %4 = extractvalue { i64, i1 } %3, 1
  br i1 %4, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex6unlockEv.exit, label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i
  %5 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %5) #15
  %6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN6Halide7Runtime8Internal15Synchronization21mutex_parking_controlE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8, !tbaa !48
  %lock_state2.i.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 1
  store i64* %state.i, i64** %lock_state2.i.i.i, align 8, !tbaa !50
  %7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::mutex_parking_control"* %control.i.i, i64 0, i32 0
  %8 = ptrtoint %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %0 to i64
  %call3.i.i = call i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control10unpark_oneEy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %7, i64 %8) #14
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %5) #15
  br label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex6unlockEv.exit

_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex6unlockEv.exit: ; preds = %if.end.i.i, %if.then.i, %entry
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr i64 @_ZN6Halide7Runtime8Internal15Synchronization20wait_parking_control6unparkEib(%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* nonnull dereferenceable(24) %this, i32 %unparked, i1 zeroext %more_waiters) unnamed_addr #2 align 2 {
entry:
  br i1 %more_waiters, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %cond_state = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %this, i64 0, i32 1
  %0 = load i64*, i64** %cond_state, align 8, !tbaa !110
  store atomic i64 0, i64* %0 monotonic, align 8
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  ret i64 0
}

; Function Attrs: nounwind
define linkonce i32 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control14unpark_requeueEyyy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, i64 %addr_from, i64 %addr_to, i64 %unpark_info) local_unnamed_addr #4 align 2 {
entry:
  %buckets = alloca %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair", align 8
  %action = alloca %"struct.Halide::Runtime::Internal::Synchronization::validate_action", align 8
  %0 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* %buckets to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %0) #15
  call void @_ZN6Halide7Runtime8Internal15Synchronization16lock_bucket_pairEyy(%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* nonnull sret(%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair") align 8 %buckets, i64 %addr_from, i64 %addr_to) #16
  %1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::validate_action", %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* %action, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1) #15
  store i8 0, i8* %1, align 8, !tbaa !114
  %invalid_unpark_info.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::validate_action", %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* %action, i64 0, i32 2
  store i64 0, i64* %invalid_unpark_info.i, align 8, !tbaa !116
  %2 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::parking_control"* %this to i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)***
  %vtable = load i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)**, i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)*** %2, align 8, !tbaa !48
  %3 = load i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)*, i1 (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*)** %vtable, align 8
  %call = call zeroext i1 %3(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action) #14
  br i1 %call, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  call void @_ZN6Halide7Runtime8Internal15Synchronization18unlock_bucket_pairERNS2_11bucket_pairE(%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* nonnull align 8 dereferenceable(16) %buckets) #16
  br label %cleanup

if.end:                                           ; preds = %entry
  %from = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair", %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* %buckets, i64 0, i32 0
  %4 = load %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"*, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %from, align 8, !tbaa !118
  %head = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %4, i64 0, i32 1
  %5 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %head, align 8, !tbaa !14
  %cmp.not92 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %5, null
  br i1 %cmp.not92, label %if.end38, label %while.body

while.body:                                       ; preds = %if.end, %if.end22
  %wakeup.098 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %wakeup.2, %if.end22 ], [ null, %if.end ]
  %requeue_tail.097 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %requeue_tail.2, %if.end22 ], [ null, %if.end ]
  %requeue.096 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %requeue.3, %if.end22 ], [ null, %if.end ]
  %data.095 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %7, %if.end22 ], [ %5, %if.end ]
  %prev.094 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %prev.1, %if.end22 ], [ null, %if.end ]
  %data_location.093 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** [ %data_location.1, %if.end22 ], [ %head, %if.end ]
  %sleep_address = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.095, i64 0, i32 1
  %6 = load atomic i64, i64* %sleep_address monotonic, align 8
  %next2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.095, i64 0, i32 2
  %7 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next2, align 8, !tbaa !88
  %cmp3 = icmp eq i64 %6, %addr_from
  br i1 %cmp3, label %if.then4, label %if.end22

if.then4:                                         ; preds = %while.body
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %7, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %data_location.093, align 8, !tbaa !14
  %8 = load %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"*, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %from, align 8, !tbaa !118
  %tail = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %8, i64 0, i32 2
  %9 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %tail, align 8, !tbaa !93
  %cmp6 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %9, %data.095
  br i1 %cmp6, label %if.then7, label %if.end10

if.then7:                                         ; preds = %if.then4
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %prev.094, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %tail, align 8, !tbaa !93
  br label %if.end10

if.end10:                                         ; preds = %if.then7, %if.then4
  %10 = load i8, i8* %1, align 8, !tbaa !114, !range !21
  %tobool = icmp ne i8 %10, 0
  %cmp11 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %wakeup.098, null
  %or.cond = and i1 %cmp11, %tobool
  br i1 %or.cond, label %if.end22, label %if.else

if.else:                                          ; preds = %if.end10
  %cmp13 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %requeue.096, null
  br i1 %cmp13, label %if.end17, label %if.else15

if.else15:                                        ; preds = %if.else
  %next16 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %requeue_tail.097, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %data.095, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next16, align 8, !tbaa !88
  br label %if.end17

if.end17:                                         ; preds = %if.else15, %if.else
  %requeue.1 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %requeue.096, %if.else15 ], [ %data.095, %if.else ]
  store atomic i64 %addr_to, i64* %sleep_address monotonic, align 8
  br label %if.end22

if.end22:                                         ; preds = %if.end17, %if.end10, %while.body
  %data_location.1 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** [ %data_location.093, %if.end10 ], [ %data_location.093, %if.end17 ], [ %next2, %while.body ]
  %prev.1 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %prev.094, %if.end10 ], [ %prev.094, %if.end17 ], [ %data.095, %while.body ]
  %requeue.3 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %requeue.096, %if.end10 ], [ %requeue.1, %if.end17 ], [ %requeue.096, %while.body ]
  %requeue_tail.2 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %requeue_tail.097, %if.end10 ], [ %data.095, %if.end17 ], [ %requeue_tail.097, %while.body ]
  %wakeup.2 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %data.095, %if.end10 ], [ %wakeup.098, %if.end17 ], [ %wakeup.098, %while.body ]
  %cmp.not = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %7, null
  br i1 %cmp.not, label %while.end, label %while.body, !llvm.loop !120

while.end:                                        ; preds = %if.end22
  %cmp23.not = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %requeue.3, null
  br i1 %cmp23.not, label %if.end38, label %if.then24

if.then24:                                        ; preds = %while.end
  %next25 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %requeue_tail.2, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* null, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next25, align 8, !tbaa !88
  %to = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair", %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* %buckets, i64 0, i32 1
  %11 = load %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"*, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %to, align 8, !tbaa !121
  %head26 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %11, i64 0, i32 1
  %12 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %head26, align 8, !tbaa !117
  %cmp27 = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %12, null
  br i1 %cmp27, label %if.end35, label %if.else31

if.else31:                                        ; preds = %if.then24
  %tail33 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %11, i64 0, i32 2
  %13 = load %"struct.Halide::Runtime::Internal::Synchronization::queue_data"*, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %tail33, align 8, !tbaa !93
  %next34 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %13, i64 0, i32 2
  br label %if.end35

if.end35:                                         ; preds = %if.else31, %if.then24
  %next34.sink = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** [ %next34, %if.else31 ], [ %head26, %if.then24 ]
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %requeue.3, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %next34.sink, align 8, !tbaa !14
  %tail37 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %11, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %requeue_tail.2, %"struct.Halide::Runtime::Internal::Synchronization::queue_data"** %tail37, align 8, !tbaa !93
  br label %if.end38

if.end38:                                         ; preds = %if.end35, %while.end, %if.end
  %cmp23106 = phi i1 [ true, %if.end35 ], [ false, %while.end ], [ false, %if.end ]
  %wakeup.0.lcssa105 = phi %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* [ %wakeup.2, %if.end35 ], [ %wakeup.2, %while.end ], [ null, %if.end ]
  %cmp39 = icmp ne %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %wakeup.0.lcssa105, null
  %14 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::parking_control"* %this to void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)***
  %vtable41 = load void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)**, void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)*** %14, align 8, !tbaa !48
  %vfn42 = getelementptr inbounds void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)*, void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)** %vtable41, i64 3
  %15 = load void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)*, void (%"struct.Halide::Runtime::Internal::Synchronization::parking_control"*, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"*, i1, i1)** %vfn42, align 8
  call void %15(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action, i1 zeroext %cmp39, i1 zeroext %cmp23106) #14
  br i1 %cmp39, label %if.then44, label %if.else48

if.then44:                                        ; preds = %if.end38
  %unpark_info45 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %wakeup.0.lcssa105, i64 0, i32 3
  store i64 %unpark_info, i64* %unpark_info45, align 8, !tbaa !97
  %mutex.i89 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %wakeup.0.lcssa105, i64 0, i32 0, i32 0
  %call.i90 = call i32 @pthread_mutex_lock(%struct.pthread_mutex_t* nonnull %mutex.i89) #14
  call void @_ZN6Halide7Runtime8Internal15Synchronization18unlock_bucket_pairERNS2_11bucket_pairE(%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* nonnull align 8 dereferenceable(16) %buckets) #16
  %should_park.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %wakeup.0.lcssa105, i64 0, i32 0, i32 2
  store i8 0, i8* %should_park.i, align 8, !tbaa !98
  %condvar.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::queue_data", %"struct.Halide::Runtime::Internal::Synchronization::queue_data"* %wakeup.0.lcssa105, i64 0, i32 0, i32 1
  %call.i88 = call i32 @pthread_cond_signal(%struct.pthread_mutex_t* nonnull %condvar.i) #14
  %call.i = call i32 @pthread_mutex_unlock(%struct.pthread_mutex_t* nonnull %mutex.i89) #14
  br label %if.end49

if.else48:                                        ; preds = %if.end38
  call void @_ZN6Halide7Runtime8Internal15Synchronization18unlock_bucket_pairERNS2_11bucket_pairE(%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* nonnull align 8 dereferenceable(16) %buckets) #16
  br label %if.end49

if.end49:                                         ; preds = %if.else48, %if.then44
  %16 = load i8, i8* %1, align 8
  %17 = and i8 %16, 1
  %tobool52 = icmp ne i8 %17, 0
  %18 = and i1 %cmp39, %tobool52
  %conv = zext i1 %18 to i32
  br label %cleanup

cleanup:                                          ; preds = %if.end49, %if.then
  %retval.0 = phi i32 [ %conv, %if.end49 ], [ 0, %if.then ]
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1) #15
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %0) #15
  ret i32 %retval.0
}

; Function Attrs: nounwind
define linkonce void @_ZN6Halide7Runtime8Internal15Synchronization16lock_bucket_pairEyy(%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* noalias sret(%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair") align 8 %agg.result, i64 %addr_from, i64 %addr_to) local_unnamed_addr #4 {
entry:
  %mul.i = mul i64 %addr_from, -7046029254386353131
  %shr.i = lshr i64 %mul.i, 54
  %mul.i37 = mul i64 %addr_to, -7046029254386353131
  %shr.i38 = lshr i64 %mul.i37, 54
  %cmp = icmp eq i64 %shr.i, %shr.i38
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %arrayidx = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_table", %"struct.Halide::Runtime::Internal::Synchronization::hash_table"* @_ZN6Halide7Runtime8Internal15Synchronization5tableE, i64 0, i32 0, i64 %shr.i
  %state.i42 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx, i64 0, i32 0, i32 0
  %0 = cmpxchg weak i64* %state.i42, i64 0, i64 1 acquire monotonic
  %1 = extractvalue { i64, i1 } %0, 1
  br i1 %1, label %cleanup, label %if.then.i43

if.then.i43:                                      ; preds = %if.then
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock9lock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex) #14
  br label %cleanup

if.else:                                          ; preds = %entry
  %cmp2 = icmp ult i64 %shr.i, %shr.i38
  br i1 %cmp2, label %if.then3, label %if.else9

if.then3:                                         ; preds = %if.else
  %arrayidx5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_table", %"struct.Halide::Runtime::Internal::Synchronization::hash_table"* @_ZN6Halide7Runtime8Internal15Synchronization5tableE, i64 0, i32 0, i64 %shr.i
  %arrayidx6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_table", %"struct.Halide::Runtime::Internal::Synchronization::hash_table"* @_ZN6Halide7Runtime8Internal15Synchronization5tableE, i64 0, i32 0, i64 %shr.i38
  %state.i52 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx5, i64 0, i32 0, i32 0
  %2 = cmpxchg weak i64* %state.i52, i64 0, i64 1 acquire monotonic
  %3 = extractvalue { i64, i1 } %2, 1
  br i1 %3, label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit54, label %if.then.i53

if.then.i53:                                      ; preds = %if.then3
  %mutex7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx5, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock9lock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex7) #14
  br label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit54

_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit54: ; preds = %if.then.i53, %if.then3
  %state.i49 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx6, i64 0, i32 0, i32 0
  %4 = cmpxchg weak i64* %state.i49, i64 0, i64 1 acquire monotonic
  %5 = extractvalue { i64, i1 } %4, 1
  br i1 %5, label %cleanup, label %if.then.i50

if.then.i50:                                      ; preds = %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit54
  %mutex8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx6, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock9lock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex8) #14
  br label %cleanup

if.else9:                                         ; preds = %if.else
  %arrayidx11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_table", %"struct.Halide::Runtime::Internal::Synchronization::hash_table"* @_ZN6Halide7Runtime8Internal15Synchronization5tableE, i64 0, i32 0, i64 %shr.i38
  %arrayidx13 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_table", %"struct.Halide::Runtime::Internal::Synchronization::hash_table"* @_ZN6Halide7Runtime8Internal15Synchronization5tableE, i64 0, i32 0, i64 %shr.i
  %state.i39 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx11, i64 0, i32 0, i32 0
  %6 = cmpxchg weak i64* %state.i39, i64 0, i64 1 acquire monotonic
  %7 = extractvalue { i64, i1 } %6, 1
  br i1 %7, label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit41, label %if.then.i40

if.then.i40:                                      ; preds = %if.else9
  %mutex14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx11, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock9lock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex14) #14
  br label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit41

_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit41: ; preds = %if.then.i40, %if.else9
  %state.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx13, i64 0, i32 0, i32 0
  %8 = cmpxchg weak i64* %state.i, i64 0, i64 1 acquire monotonic
  %9 = extractvalue { i64, i1 } %8, 1
  br i1 %9, label %cleanup, label %if.then.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit41
  %mutex15 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx13, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock9lock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex15) #14
  br label %cleanup

cleanup:                                          ; preds = %if.then.i, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit41, %if.then.i50, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit54, %if.then.i43, %if.then
  %arrayidx13.sink = phi %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* [ %arrayidx, %if.then ], [ %arrayidx, %if.then.i43 ], [ %arrayidx5, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit54 ], [ %arrayidx5, %if.then.i50 ], [ %arrayidx13, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit41 ], [ %arrayidx13, %if.then.i ]
  %arrayidx11.sink = phi %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* [ %arrayidx, %if.then ], [ %arrayidx, %if.then.i43 ], [ %arrayidx6, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit54 ], [ %arrayidx6, %if.then.i50 ], [ %arrayidx11, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock4lockEv.exit41 ], [ %arrayidx11, %if.then.i ]
  %from2.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair", %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* %agg.result, i64 0, i32 0
  store %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx13.sink, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %from2.i, align 8, !tbaa !14
  %to3.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair", %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* %agg.result, i64 0, i32 1
  store %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %arrayidx11.sink, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %to3.i, align 8, !tbaa !14
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal15Synchronization18unlock_bucket_pairERNS2_11bucket_pairE(%"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* nonnull align 8 dereferenceable(16) %buckets) local_unnamed_addr #0 {
entry:
  %from = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair", %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* %buckets, i64 0, i32 0
  %0 = load %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"*, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %from, align 8, !tbaa !118
  %to = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair", %"struct.Halide::Runtime::Internal::Synchronization::bucket_pair"* %buckets, i64 0, i32 1
  %1 = load %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"*, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %to, align 8, !tbaa !121
  %cmp = icmp eq %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %0, %1
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %state.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %0, i64 0, i32 0, i32 0
  %2 = atomicrmw and i64* %state.i, i64 -2 release
  %and.i = and i64 %2, 2
  %cmp.i = icmp ne i64 %and.i, 0
  %cmp3.not.i = icmp ult i64 %2, 4
  %or.cond.i = or i1 %cmp3.not.i, %cmp.i
  br i1 %or.cond.i, label %if.end15, label %if.then.i

if.then.i:                                        ; preds = %if.then
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %0, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex) #14
  br label %if.end15

if.else:                                          ; preds = %entry
  %cmp4 = icmp ugt %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %0, %1
  br i1 %cmp4, label %if.then5, label %if.else10

if.then5:                                         ; preds = %if.else
  %state.i25 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %0, i64 0, i32 0, i32 0
  %3 = atomicrmw and i64* %state.i25, i64 -2 release
  %and.i26 = and i64 %3, 2
  %cmp.i27 = icmp ne i64 %and.i26, 0
  %cmp3.not.i28 = icmp ult i64 %3, 4
  %or.cond.i29 = or i1 %cmp3.not.i28, %cmp.i27
  br i1 %or.cond.i29, label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit31, label %if.then.i30

if.then.i30:                                      ; preds = %if.then5
  %mutex7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %0, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex7) #14
  br label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit31

_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit31: ; preds = %if.then.i30, %if.then5
  %4 = load %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"*, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %to, align 8, !tbaa !121
  %state.i32 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %4, i64 0, i32 0, i32 0
  %5 = atomicrmw and i64* %state.i32, i64 -2 release
  %and.i33 = and i64 %5, 2
  %cmp.i34 = icmp ne i64 %and.i33, 0
  %cmp3.not.i35 = icmp ult i64 %5, 4
  %or.cond.i36 = or i1 %cmp3.not.i35, %cmp.i34
  br i1 %or.cond.i36, label %if.end15, label %if.then.i37

if.then.i37:                                      ; preds = %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit31
  %mutex9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %4, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex9) #14
  br label %if.end15

if.else10:                                        ; preds = %if.else
  %state.i39 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %1, i64 0, i32 0, i32 0
  %6 = atomicrmw and i64* %state.i39, i64 -2 release
  %and.i40 = and i64 %6, 2
  %cmp.i41 = icmp ne i64 %and.i40, 0
  %cmp3.not.i42 = icmp ult i64 %6, 4
  %or.cond.i43 = or i1 %cmp3.not.i42, %cmp.i41
  br i1 %or.cond.i43, label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit45, label %if.then.i44

if.then.i44:                                      ; preds = %if.else10
  %mutex12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %1, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex12) #14
  br label %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit45

_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit45: ; preds = %if.then.i44, %if.else10
  %7 = load %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"*, %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"** %from, align 8, !tbaa !118
  %state.i46 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %7, i64 0, i32 0, i32 0
  %8 = atomicrmw and i64* %state.i46, i64 -2 release
  %and.i47 = and i64 %8, 2
  %cmp.i48 = icmp ne i64 %and.i47, 0
  %cmp3.not.i49 = icmp ult i64 %8, 4
  %or.cond.i50 = or i1 %cmp3.not.i49, %cmp.i48
  br i1 %or.cond.i50, label %if.end15, label %if.then.i51

if.then.i51:                                      ; preds = %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit45
  %mutex14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket", %"struct.Halide::Runtime::Internal::Synchronization::hash_bucket"* %7, i64 0, i32 0
  tail call void @_ZN6Halide7Runtime8Internal15Synchronization9word_lock11unlock_fullEv(%"class.Halide::Runtime::Internal::Synchronization::word_lock"* nonnull dereferenceable(8) %mutex14) #14
  br label %if.end15

if.end15:                                         ; preds = %if.then.i51, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit45, %if.then.i37, %_ZN6Halide7Runtime8Internal15Synchronization9word_lock6unlockEv.exit31, %if.then.i, %if.then
  ret void
}

; Function Attrs: nounwind
define linkonce_odr zeroext i1 @_ZN6Halide7Runtime8Internal15Synchronization25broadcast_parking_control8validateERNS2_15validate_actionE(%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* nonnull dereferenceable(24) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action) unnamed_addr #4 align 2 {
entry:
  %cond_state = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %this, i64 0, i32 1
  %0 = load i64*, i64** %cond_state, align 8, !tbaa !107
  %1 = load atomic i64, i64* %0 monotonic, align 8
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %this, i64 0, i32 2
  %2 = load %"class.Halide::Runtime::Internal::Synchronization::word_lock"*, %"class.Halide::Runtime::Internal::Synchronization::word_lock"** %mutex, align 8, !tbaa !109
  %3 = ptrtoint %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %2 to i64
  %cmp.not = icmp eq i64 %1, %3
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  store atomic i64 0, i64* %0 monotonic, align 8
  %4 = load %"class.Halide::Runtime::Internal::Synchronization::word_lock"*, %"class.Halide::Runtime::Internal::Synchronization::word_lock"** %mutex, align 8, !tbaa !109
  %state.i = getelementptr inbounds %"class.Halide::Runtime::Internal::Synchronization::word_lock", %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %4, i64 0, i32 0
  %5 = load atomic i64, i64* %state.i monotonic, align 8
  %and11.i = and i64 %5, 1
  %tobool.not12.i = icmp eq i64 %and11.i, 0
  br i1 %tobool.not12.i, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex21make_parked_if_lockedEv.exit, label %if.end.i

if.end.i:                                         ; preds = %if.end, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i
  %val.013.i = phi i64 [ %8, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i ], [ %5, %if.end ]
  %or.i = or i64 %val.013.i, 2
  %6 = cmpxchg weak i64* %state.i, i64 %val.013.i, i64 %or.i monotonic monotonic
  %7 = extractvalue { i64, i1 } %6, 1
  br i1 %7, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex21make_parked_if_lockedEv.exit, label %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i

_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i: ; preds = %if.end.i
  %8 = extractvalue { i64, i1 } %6, 0
  %and.i = and i64 %8, 1
  %tobool.not.i = icmp eq i64 %and.i, 0
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex21make_parked_if_lockedEv.exit, label %if.end.i

_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex21make_parked_if_lockedEv.exit: ; preds = %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i, %if.end.i, %if.end
  %tobool.not.lcssa.i = phi i8 [ 1, %if.end ], [ 1, %_ZN6Halide7Runtime8Internal15Synchronization12_GLOBAL__N_131atomic_cas_weak_relaxed_relaxedEPyS4_S4_.exit.i ], [ 0, %if.end.i ]
  %unpark_one = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::validate_action", %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* %action, i64 0, i32 0
  store i8 %tobool.not.lcssa.i, i8* %unpark_one, align 8, !tbaa !114
  br label %cleanup

cleanup:                                          ; preds = %_ZN6Halide7Runtime8Internal15Synchronization10fast_mutex21make_parked_if_lockedEv.exit, %entry
  ret i1 %cmp.not
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control6unparkEib(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, i32 %unparked, i1 zeroext %more_waiters) unnamed_addr #2 align 2 {
entry:
  ret i64 0
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr void @_ZN6Halide7Runtime8Internal15Synchronization25broadcast_parking_control16requeue_callbackERKNS2_15validate_actionEbb(%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* nonnull dereferenceable(24) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action, i1 zeroext %one_to_wake, i1 zeroext %some_requeued) unnamed_addr #2 align 2 {
entry:
  %unpark_one = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::validate_action", %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* %action, i64 0, i32 0
  %0 = load i8, i8* %unpark_one, align 8, !tbaa !114, !range !21
  %tobool.not = icmp ne i8 %0, 0
  %1 = and i1 %tobool.not, %some_requeued
  br i1 %1, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %mutex = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %this, i64 0, i32 2
  %2 = load %"class.Halide::Runtime::Internal::Synchronization::word_lock"*, %"class.Halide::Runtime::Internal::Synchronization::word_lock"** %mutex, align 8, !tbaa !109
  %state.i = getelementptr inbounds %"class.Halide::Runtime::Internal::Synchronization::word_lock", %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %2, i64 0, i32 0
  %3 = atomicrmw or i64* %state.i, i64 2 monotonic
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce i32 @_ZN6Halide7Runtime8Internal27default_desired_num_threadsEv() local_unnamed_addr #0 {
entry:
  %call = tail call i8* @getenv(i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.1, i64 0, i64 0)) #14
  %tobool.not = icmp eq i8* %call, null
  br i1 %tobool.not, label %if.end, label %cond.true

if.end:                                           ; preds = %entry
  %call1 = tail call i8* @getenv(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.2, i64 0, i64 0)) #14
  %tobool2.not = icmp eq i8* %call1, null
  br i1 %tobool2.not, label %cond.false, label %cond.true

cond.true:                                        ; preds = %if.end, %entry
  %threads_str.010 = phi i8* [ %call1, %if.end ], [ %call, %entry ]
  %call3 = tail call i32 @atoi(i8* nonnull %threads_str.010) #14
  br label %cond.end

cond.false:                                       ; preds = %if.end
  %call4 = tail call i32 @halide_host_cpu_count() #14
  br label %cond.end

cond.end:                                         ; preds = %cond.false, %cond.true
  %cond = phi i32 [ %call3, %cond.true ], [ %call4, %cond.false ]
  ret i32 %cond
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal13worker_threadEPv(i8* %arg) #0 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %0 = bitcast i8* %arg to %"struct.Halide::Runtime::Internal::work"*
  tail call void @_ZN6Halide7Runtime8Internal28worker_thread_already_lockedEPNS1_4workE(%"struct.Halide::Runtime::Internal::work"* %0) #16
  tail call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  ret void
}

; Function Attrs: nounwind mustprogress
define weak %struct.halide_thread* @halide_spawn_thread(void (i8*)* %f, i8* %closure) local_unnamed_addr #0 {
entry:
  %call = tail call i8* @malloc(i64 24) #14
  %f1 = bitcast i8* %call to void (i8*)**
  store void (i8*)* %f, void (i8*)** %f1, align 8, !tbaa !122
  %closure2 = getelementptr inbounds i8, i8* %call, i64 8
  %0 = bitcast i8* %closure2 to i8**
  store i8* %closure, i8** %0, align 8, !tbaa !125
  %handle = getelementptr inbounds i8, i8* %call, i64 16
  %1 = bitcast i8* %handle to i64*
  store i64 0, i64* %1, align 8, !tbaa !126
  %call4 = tail call i32 @pthread_create(i64* nonnull %1, i8* null, i8* (i8*)* nonnull @_ZN6Halide7Runtime8Internal19spawn_thread_helperEPv, i8* %call) #14
  %2 = bitcast i8* %call to %struct.halide_thread*
  ret %struct.halide_thread* %2
}

; Function Attrs: nounwind mustprogress
define linkonce i8* @_ZN6Halide7Runtime8Internal19spawn_thread_helperEPv(i8* %arg) #0 {
entry:
  %f = bitcast i8* %arg to void (i8*)**
  %0 = load void (i8*)*, void (i8*)** %f, align 8, !tbaa !122
  %closure = getelementptr inbounds i8, i8* %arg, i64 8
  %1 = bitcast i8* %closure to i8**
  %2 = load i8*, i8** %1, align 8, !tbaa !125
  tail call void %0(i8* %2) #14
  ret i8* null
}

declare i32 @pthread_create(i64*, i8*, i8* (i8*)*, i8*) local_unnamed_addr #1

declare i8* @getenv(i8*) local_unnamed_addr #1

declare i32 @atoi(i8*) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_do_parallel_tasks(i8* %user_context, i32 %num_tasks, %struct.halide_parallel_task_t* %tasks, i8* %task_parent) #0 {
entry:
  %conv = sext i32 %num_tasks to i64
  %0 = alloca %"struct.Halide::Runtime::Internal::work", i64 %conv, align 8
  %cmp76 = icmp sgt i32 %num_tasks, 0
  br i1 %cmp76, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.inc, %entry
  %num_tasks.addr.0.lcssa = phi i32 [ %num_tasks, %entry ], [ %num_tasks.addr.1, %for.inc ]
  %cmp17 = icmp eq i32 %num_tasks.addr.0.lcssa, 0
  br i1 %cmp17, label %cleanup, label %if.end19

for.body:                                         ; preds = %entry, %for.inc
  %indvars.iv82 = phi i64 [ %indvars.iv.next83, %for.inc ], [ 0, %entry ]
  %num_tasks.addr.078 = phi i32 [ %num_tasks.addr.1, %for.inc ], [ %num_tasks, %entry ]
  %tasks.addr.077 = phi %struct.halide_parallel_task_t* [ %tasks.addr.1, %for.inc ], [ %tasks, %entry ]
  %extent = getelementptr inbounds %struct.halide_parallel_task_t, %struct.halide_parallel_task_t* %tasks.addr.077, i64 0, i32 6
  %1 = load i32, i32* %extent, align 8, !tbaa !127
  %cmp1 = icmp slt i32 %1, 1
  br i1 %cmp1, label %if.then, label %if.end

if.then:                                          ; preds = %for.body
  %dec = add nsw i32 %num_tasks.addr.078, -1
  br label %for.inc

if.end:                                           ; preds = %for.body
  %incdec.ptr = getelementptr inbounds %struct.halide_parallel_task_t, %struct.halide_parallel_task_t* %tasks.addr.077, i64 1
  %arrayidx = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv82
  %2 = bitcast %"struct.Halide::Runtime::Internal::work"* %arrayidx to i8*
  %3 = bitcast %struct.halide_parallel_task_t* %tasks.addr.077 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(56) %2, i8* nonnull align 8 dereferenceable(56) %3, i64 56, i1 false), !tbaa.struct !128
  %task_fn = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv82, i32 1
  store i32 (i8*, i32, i8*)* null, i32 (i8*, i32, i8*)** %task_fn, align 8, !tbaa !39
  %user_context6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv82, i32 7
  store i8* %user_context, i8** %user_context6, align 8, !tbaa !40
  %active_workers = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv82, i32 8
  %4 = bitcast i32* %active_workers to <2 x i32>*
  store <2 x i32> zeroinitializer, <2 x i32>* %4, align 8, !tbaa !41
  %next_semaphore = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv82, i32 10
  store i32 0, i32* %next_semaphore, align 8, !tbaa !42
  %owner_is_sleeping = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv82, i32 11
  store i8 0, i8* %owner_is_sleeping, align 4, !tbaa !43
  %parent_job = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv82, i32 5
  %5 = bitcast %"struct.Halide::Runtime::Internal::work"** %parent_job to i8**
  store i8* %task_parent, i8** %5, align 8, !tbaa !46
  br label %for.inc

for.inc:                                          ; preds = %if.end, %if.then
  %tasks.addr.1 = phi %struct.halide_parallel_task_t* [ %tasks.addr.077, %if.then ], [ %incdec.ptr, %if.end ]
  %num_tasks.addr.1 = phi i32 [ %dec, %if.then ], [ %num_tasks.addr.078, %if.end ]
  %indvars.iv.next83 = add nuw nsw i64 %indvars.iv82, 1
  %6 = sext i32 %num_tasks.addr.1 to i64
  %cmp = icmp slt i64 %indvars.iv.next83, %6
  br i1 %cmp, label %for.body, label %for.cond.cleanup, !llvm.loop !129

if.end19:                                         ; preds = %for.cond.cleanup
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %7 = bitcast i8* %task_parent to %"struct.Halide::Runtime::Internal::work"*
  call void @_ZN6Halide7Runtime8Internal27enqueue_work_already_lockedEiPNS1_4workES3_(i32 %num_tasks.addr.0.lcssa, %"struct.Halide::Runtime::Internal::work"* nonnull %0, %"struct.Halide::Runtime::Internal::work"* %7) #16
  %cmp2373 = icmp sgt i32 %num_tasks.addr.0.lcssa, 0
  br i1 %cmp2373, label %for.body25.preheader, label %for.cond.cleanup24

for.body25.preheader:                             ; preds = %if.end19
  %wide.trip.count = zext i32 %num_tasks.addr.0.lcssa to i64
  br label %for.body25

for.cond.cleanup24:                               ; preds = %for.body25, %if.end19
  %exit_status20.0.lcssa = phi i32 [ 0, %if.end19 ], [ %spec.select, %for.body25 ]
  call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  br label %cleanup

for.body25:                                       ; preds = %for.body25, %for.body25.preheader
  %indvars.iv = phi i64 [ 0, %for.body25.preheader ], [ %indvars.iv.next, %for.body25 ]
  %exit_status20.074 = phi i32 [ 0, %for.body25.preheader ], [ %spec.select, %for.body25 ]
  %add.ptr = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv
  call void @_ZN6Halide7Runtime8Internal28worker_thread_already_lockedEPNS1_4workE(%"struct.Halide::Runtime::Internal::work"* nonnull %add.ptr) #16
  %exit_status28 = getelementptr inbounds %"struct.Halide::Runtime::Internal::work", %"struct.Halide::Runtime::Internal::work"* %0, i64 %indvars.iv, i32 9
  %8 = load i32, i32* %exit_status28, align 4, !tbaa !47
  %cmp29.not = icmp eq i32 %8, 0
  %spec.select = select i1 %cmp29.not, i32 %exit_status20.074, i32 %8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond.not, label %for.cond.cleanup24, label %for.body25, !llvm.loop !130

cleanup:                                          ; preds = %for.cond.cleanup24, %for.cond.cleanup
  %retval.0 = phi i32 [ %exit_status20.0.lcssa, %for.cond.cleanup24 ], [ 0, %for.cond.cleanup ]
  ret i32 %retval.0
}

; Function Attrs: argmemonly nofree nosync nounwind willreturn
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* noalias nocapture writeonly, i8* noalias nocapture readonly, i64, i1 immarg) #3

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_default_semaphore_init(%struct.halide_semaphore_t* %s, i32 %n) #2 {
entry:
  %value = bitcast %struct.halide_semaphore_t* %s to i32*
  store atomic i32 %n, i32* %value release, align 4
  ret i32 %n
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_semaphore_release(%struct.halide_semaphore_t* %s, i32 %n) #0 {
entry:
  %value = bitcast %struct.halide_semaphore_t* %s to i32*
  %0 = atomicrmw add i32* %value, i32 %n acq_rel
  %cmp = icmp eq i32 %0, 0
  %cmp1 = icmp ne i32 %n, 0
  %or.cond = and i1 %cmp1, %cmp
  br i1 %or.cond, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 8)) #16
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 10)) #16
  tail call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %add = add nsw i32 %0, %n
  ret i32 %add
}

; Function Attrs: nounwind mustprogress
define weak void @halide_thread_pool_cleanup() #0 {
entry:
  tail call void @halide_shutdown_thread_pool() #16
  ret void
}

; Function Attrs: nounwind mustprogress
define weak void @halide_shutdown_thread_pool() local_unnamed_addr #0 {
entry:
  %0 = load i8, i8* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 15), align 1, !tbaa !52, !range !21
  %tobool.not = icmp eq i8 %0, 0
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  store i8 1, i8* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 14), align 8, !tbaa !73
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 10)) #16
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 8)) #16
  tail call void @halide_cond_broadcast(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 9)) #16
  tail call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %1 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 4), align 8, !tbaa !60
  %cmp4 = icmp sgt i32 %1, 0
  br i1 %cmp4, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.body, %if.then
  %call.i = tail call i8* @memset(i8* nonnull bitcast (i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 2) to i8*), i32 0, i64 2116) #14
  br label %if.end

for.body:                                         ; preds = %if.then, %for.body
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 0, %if.then ]
  %arrayidx = getelementptr inbounds %"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 13, i64 %indvars.iv
  %2 = load %struct.halide_thread*, %struct.halide_thread** %arrayidx, align 8, !tbaa !14
  tail call void @halide_join_thread(%struct.halide_thread* %2) #16
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %3 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 4), align 8, !tbaa !60
  %4 = sext i32 %3 to i64
  %cmp = icmp slt i64 %indvars.iv.next, %4
  br i1 %cmp, label %for.body, label %for.cond.cleanup, !llvm.loop !131

if.end:                                           ; preds = %for.cond.cleanup, %entry
  ret void
}

declare i8* @memset(i8*, i32, i64) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void @halide_join_thread(%struct.halide_thread* %thread_arg) local_unnamed_addr #0 {
entry:
  %ret = alloca i8*, align 8
  %0 = bitcast %struct.halide_thread* %thread_arg to %"struct.Halide::Runtime::Internal::spawned_thread"*
  %1 = bitcast i8** %ret to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1) #15
  store i8* null, i8** %ret, align 8, !tbaa !14
  %handle = getelementptr inbounds %"struct.Halide::Runtime::Internal::spawned_thread", %"struct.Halide::Runtime::Internal::spawned_thread"* %0, i64 0, i32 2
  %2 = load i64, i64* %handle, align 8, !tbaa !126
  %call = call i32 @pthread_join(i64 %2, i8** nonnull %ret) #14
  %3 = bitcast %struct.halide_thread* %thread_arg to i8*
  call void @free(i8* %3) #14
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1) #15
  ret void
}

declare i32 @pthread_join(i64, i8**) local_unnamed_addr #1

; Function Attrs: nounwind
define weak void @halide_cond_signal(%struct.halide_mutex* %cond) local_unnamed_addr #4 {
entry:
  %control.i = alloca %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", align 8
  %state.i = getelementptr %struct.halide_mutex, %struct.halide_mutex* %cond, i64 0, i32 0, i64 0
  %0 = load atomic i64, i64* %state.i monotonic, align 8
  %cmp.i = icmp eq i64 %0, 0
  br i1 %cmp.i, label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond6signalEv.exit, label %if.end.i

if.end.i:                                         ; preds = %entry
  %1 = bitcast %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %1) #15
  %2 = inttoptr i64 %0 to %"class.Halide::Runtime::Internal::Synchronization::word_lock"*
  %3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN6Halide7Runtime8Internal15Synchronization22signal_parking_controlE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %3, align 8, !tbaa !48
  %cond_state2.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 1
  store i64* %state.i, i64** %cond_state2.i.i, align 8, !tbaa !132
  %mutex3.i.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 2
  store %"class.Halide::Runtime::Internal::Synchronization::word_lock"* %2, %"class.Halide::Runtime::Internal::Synchronization::word_lock"** %mutex3.i.i, align 8, !tbaa !134
  %4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %control.i, i64 0, i32 0
  %5 = ptrtoint %struct.halide_mutex* %cond to i64
  %call.i = call i64 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control10unpark_oneEy(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %4, i64 %5) #14
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %1) #15
  br label %_ZN6Halide7Runtime8Internal15Synchronization9fast_cond6signalEv.exit

_ZN6Halide7Runtime8Internal15Synchronization9fast_cond6signalEv.exit: ; preds = %if.end.i, %entry
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr zeroext i1 @_ZN6Halide7Runtime8Internal15Synchronization15parking_control8validateERNS2_15validate_actionE(%"struct.Halide::Runtime::Internal::Synchronization::parking_control"* nonnull dereferenceable(8) %this, %"struct.Halide::Runtime::Internal::Synchronization::validate_action"* nonnull align 8 dereferenceable(16) %action) unnamed_addr #2 align 2 {
entry:
  ret i1 true
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce_odr i64 @_ZN6Halide7Runtime8Internal15Synchronization22signal_parking_control6unparkEib(%"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* nonnull dereferenceable(24) %this, i32 %unparked, i1 zeroext %more_waiters) unnamed_addr #2 align 2 {
entry:
  br i1 %more_waiters, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %cond_state = getelementptr inbounds %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control", %"struct.Halide::Runtime::Internal::Synchronization::wait_parking_control"* %this, i64 0, i32 1
  %0 = load i64*, i64** %cond_state, align 8, !tbaa !132
  store atomic i64 0, i64* %0 monotonic, align 8
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  ret i64 0
}

; Function Attrs: nounwind mustprogress
define weak %struct.halide_mutex_array* @halide_mutex_array_create(i32 %sz) local_unnamed_addr #0 {
entry:
  %call = tail call i8* @halide_malloc(i8* null, i64 8) #14
  %0 = bitcast i8* %call to %struct.halide_mutex_array*
  %cmp = icmp eq i8* %call, null
  br i1 %cmp, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %conv = sext i32 %sz to i64
  %mul = shl nsw i64 %conv, 3
  %call1 = tail call i8* @halide_malloc(i8* null, i64 %mul) #14
  %1 = bitcast i8* %call to i8**
  store i8* %call1, i8** %1, align 8, !tbaa !135
  %cmp4 = icmp eq i8* %call1, null
  br i1 %cmp4, label %if.then5, label %if.end6

if.then5:                                         ; preds = %if.end
  tail call void @halide_free(i8* null, i8* nonnull %call) #14
  br label %cleanup

if.end6:                                          ; preds = %if.end
  %call10 = tail call i8* @memset(i8* nonnull %call1, i32 0, i64 %mul) #14
  br label %cleanup

cleanup:                                          ; preds = %if.end6, %if.then5, %entry
  %retval.0 = phi %struct.halide_mutex_array* [ null, %if.then5 ], [ %0, %if.end6 ], [ null, %entry ]
  ret %struct.halide_mutex_array* %retval.0
}

; Function Attrs: nounwind mustprogress
define weak void @halide_mutex_array_destroy(i8* %user_context, i8* %array) local_unnamed_addr #0 {
entry:
  %0 = bitcast i8* %array to i8**
  %1 = load i8*, i8** %0, align 8, !tbaa !135
  tail call void @halide_free(i8* %user_context, i8* %1) #14
  tail call void @halide_free(i8* %user_context, i8* %array) #14
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_mutex_array_lock(%struct.halide_mutex_array* %array, i32 %entry1) local_unnamed_addr #0 {
entry:
  %array2 = getelementptr inbounds %struct.halide_mutex_array, %struct.halide_mutex_array* %array, i64 0, i32 0
  %0 = load %struct.halide_mutex*, %struct.halide_mutex** %array2, align 8, !tbaa !135
  %idxprom = sext i32 %entry1 to i64
  %arrayidx = getelementptr inbounds %struct.halide_mutex, %struct.halide_mutex* %0, i64 %idxprom
  tail call void @halide_mutex_lock(%struct.halide_mutex* %arrayidx) #16
  ret i32 0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_mutex_array_unlock(%struct.halide_mutex_array* %array, i32 %entry1) local_unnamed_addr #0 {
entry:
  %array2 = getelementptr inbounds %struct.halide_mutex_array, %struct.halide_mutex_array* %array, i64 0, i32 0
  %0 = load %struct.halide_mutex*, %struct.halide_mutex** %array2, align 8, !tbaa !135
  %idxprom = sext i32 %entry1 to i64
  %arrayidx = getelementptr inbounds %struct.halide_mutex, %struct.halide_mutex* %0, i64 %idxprom
  tail call void @halide_mutex_unlock(%struct.halide_mutex* %arrayidx) #16
  ret i32 0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_set_num_threads(i32 %n) local_unnamed_addr #0 {
entry:
  %cmp = icmp slt i32 %n, 0
  br i1 %cmp, label %if.end3.thread, label %if.end

if.end3.thread:                                   ; preds = %entry
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.4, i64 0, i64 0)) #14
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %0 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 1), align 8, !tbaa !58
  br label %if.else.i

if.end:                                           ; preds = %entry
  tail call void @halide_mutex_lock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  %cmp1 = icmp eq i32 %n, 0
  br i1 %cmp1, label %if.then2, label %if.end3

if.then2:                                         ; preds = %if.end
  %call = tail call i32 @_ZN6Halide7Runtime8Internal27default_desired_num_threadsEv() #16
  br label %if.end3

if.end3:                                          ; preds = %if.then2, %if.end
  %n.addr.0 = phi i32 [ %call, %if.then2 ], [ %n, %if.end ]
  %1 = load i32, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 1), align 8, !tbaa !58
  %cmp.i = icmp sgt i32 %n.addr.0, 256
  br i1 %cmp.i, label %_ZN6Halide7Runtime8Internal17clamp_num_threadsEi.exit, label %if.else.i

if.else.i:                                        ; preds = %if.end3, %if.end3.thread
  %2 = phi i32 [ %0, %if.end3.thread ], [ %1, %if.end3 ]
  %n.addr.012 = phi i32 [ %n, %if.end3.thread ], [ %n.addr.0, %if.end3 ]
  %3 = icmp sgt i32 %n.addr.012, 1
  %spec.select.i = select i1 %3, i32 %n.addr.012, i32 1
  br label %_ZN6Halide7Runtime8Internal17clamp_num_threadsEi.exit

_ZN6Halide7Runtime8Internal17clamp_num_threadsEi.exit: ; preds = %if.else.i, %if.end3
  %4 = phi i32 [ %2, %if.else.i ], [ %1, %if.end3 ]
  %call48 = phi i32 [ %spec.select.i, %if.else.i ], [ 256, %if.end3 ]
  store i32 %call48, i32* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 1), align 8, !tbaa !58
  tail call void @halide_mutex_unlock(%struct.halide_mutex* getelementptr inbounds (%"struct.Halide::Runtime::Internal::work_queue_t", %"struct.Halide::Runtime::Internal::work_queue_t"* @_ZN6Halide7Runtime8Internal10work_queueE, i64 0, i32 0)) #16
  ret i32 %4
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* @halide_set_custom_do_task(i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* %f) local_unnamed_addr #2 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)*, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)** @_ZN6Halide7Runtime8Internal14custom_do_taskE, align 8, !tbaa !14
  store i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* %f, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)** @_ZN6Halide7Runtime8Internal14custom_do_taskE, align 8, !tbaa !14
  ret i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* %0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)* @halide_set_custom_do_loop_task(i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)* %f) local_unnamed_addr #2 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)*, i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)** @_ZN6Halide7Runtime8Internal19custom_do_loop_taskE, align 8, !tbaa !14
  store i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)* %f, i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)** @_ZN6Halide7Runtime8Internal19custom_do_loop_taskE, align 8, !tbaa !14
  ret i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)* %0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* @halide_set_custom_do_par_for(i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* %f) local_unnamed_addr #2 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)*, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)** @_ZN6Halide7Runtime8Internal17custom_do_par_forE, align 8, !tbaa !14
  store i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* %f, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)** @_ZN6Halide7Runtime8Internal17custom_do_par_forE, align 8, !tbaa !14
  ret i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* %0
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_set_custom_parallel_runtime(i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* %do_par_for, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* %do_task, i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)* %do_loop_task, i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)* %do_parallel_tasks, i32 (%struct.halide_semaphore_t*, i32)* %semaphore_init, i1 (%struct.halide_semaphore_t*, i32)* %semaphore_try_acquire, i32 (%struct.halide_semaphore_t*, i32)* %semaphore_release) local_unnamed_addr #2 {
entry:
  store i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* %do_par_for, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)** @_ZN6Halide7Runtime8Internal17custom_do_par_forE, align 8, !tbaa !14
  store i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* %do_task, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)** @_ZN6Halide7Runtime8Internal14custom_do_taskE, align 8, !tbaa !14
  store i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)* %do_loop_task, i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)** @_ZN6Halide7Runtime8Internal19custom_do_loop_taskE, align 8, !tbaa !14
  store i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)* %do_parallel_tasks, i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)** @_ZN6Halide7Runtime8Internal24custom_do_parallel_tasksE, align 8, !tbaa !14
  store i32 (%struct.halide_semaphore_t*, i32)* %semaphore_init, i32 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal21custom_semaphore_initE, align 8, !tbaa !14
  store i1 (%struct.halide_semaphore_t*, i32)* %semaphore_try_acquire, i1 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal28custom_semaphore_try_acquireE, align 8, !tbaa !14
  store i32 (%struct.halide_semaphore_t*, i32)* %semaphore_release, i32 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal24custom_semaphore_releaseE, align 8, !tbaa !14
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_do_par_for(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %min, i32 %size, i8* %closure) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)*, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)** @_ZN6Halide7Runtime8Internal17custom_do_par_forE, align 8, !tbaa !14
  %call = tail call i32 %0(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %min, i32 %size, i8* %closure) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_do_parallel_tasks(i8* %user_context, i32 %num_tasks, %struct.halide_parallel_task_t* %tasks, i8* %task_parent) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)*, i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)** @_ZN6Halide7Runtime8Internal24custom_do_parallel_tasksE, align 8, !tbaa !14
  %call = tail call i32 %0(i8* %user_context, i32 %num_tasks, %struct.halide_parallel_task_t* %tasks, i8* %task_parent) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_semaphore_init(%struct.halide_semaphore_t* %sema, i32 %count) local_unnamed_addr #0 {
entry:
  %0 = load i32 (%struct.halide_semaphore_t*, i32)*, i32 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal21custom_semaphore_initE, align 8, !tbaa !14
  %call = tail call i32 %0(%struct.halide_semaphore_t* %sema, i32 %count) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_semaphore_release(%struct.halide_semaphore_t* %sema, i32 %count) local_unnamed_addr #0 {
entry:
  %0 = load i32 (%struct.halide_semaphore_t*, i32)*, i32 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal24custom_semaphore_releaseE, align 8, !tbaa !14
  %call = tail call i32 %0(%struct.halide_semaphore_t* %sema, i32 %count) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak zeroext i1 @halide_semaphore_try_acquire(%struct.halide_semaphore_t* %sema, i32 %count) local_unnamed_addr #0 {
entry:
  %0 = load i1 (%struct.halide_semaphore_t*, i32)*, i1 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal28custom_semaphore_try_acquireE, align 8, !tbaa !14
  %call = tail call zeroext i1 %0(%struct.halide_semaphore_t* %sema, i32 %count) #14
  ret i1 %call
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_default_get_symbol(i8* %name) #0 {
entry:
  %call = tail call i8* @dlsym(i8* nonnull inttoptr (i64 -2 to i8*), i8* %name) #14
  ret i8* %call
}

declare i8* @dlsym(i8*, i8*) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak i8* @halide_default_load_library(i8* %name) #0 {
entry:
  %call = tail call i8* @dlopen(i8* %name, i32 5) #14
  ret i8* %call
}

declare i8* @dlopen(i8*, i32) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak i8* @halide_default_get_library_symbol(i8* %lib, i8* %name) #0 {
entry:
  %cmp = icmp eq i8* %lib, null
  %spec.select = select i1 %cmp, i8* inttoptr (i64 -2 to i8*), i8* %lib
  %call = tail call i8* @dlsym(i8* %spec.select, i8* %name) #14
  ret i8* %call
}

; Function Attrs: nounwind willreturn mustprogress
define weak i8* (i8*)* @halide_set_custom_get_symbol(i8* (i8*)* %f) local_unnamed_addr #2 {
entry:
  %0 = load i8* (i8*)*, i8* (i8*)** @_ZN6Halide7Runtime8Internal17custom_get_symbolE, align 8, !tbaa !14
  store i8* (i8*)* %f, i8* (i8*)** @_ZN6Halide7Runtime8Internal17custom_get_symbolE, align 8, !tbaa !14
  ret i8* (i8*)* %0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i8* (i8*)* @halide_set_custom_load_library(i8* (i8*)* %f) local_unnamed_addr #2 {
entry:
  %0 = load i8* (i8*)*, i8* (i8*)** @_ZN6Halide7Runtime8Internal19custom_load_libraryE, align 8, !tbaa !14
  store i8* (i8*)* %f, i8* (i8*)** @_ZN6Halide7Runtime8Internal19custom_load_libraryE, align 8, !tbaa !14
  ret i8* (i8*)* %0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i8* (i8*, i8*)* @halide_set_custom_get_library_symbol(i8* (i8*, i8*)* %f) local_unnamed_addr #2 {
entry:
  %0 = load i8* (i8*, i8*)*, i8* (i8*, i8*)** @_ZN6Halide7Runtime8Internal25custom_get_library_symbolE, align 8, !tbaa !14
  store i8* (i8*, i8*)* %f, i8* (i8*, i8*)** @_ZN6Halide7Runtime8Internal25custom_get_library_symbolE, align 8, !tbaa !14
  ret i8* (i8*, i8*)* %0
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_get_symbol(i8* %name) local_unnamed_addr #0 {
entry:
  %0 = load i8* (i8*)*, i8* (i8*)** @_ZN6Halide7Runtime8Internal17custom_get_symbolE, align 8, !tbaa !14
  %call = tail call i8* %0(i8* %name) #14
  ret i8* %call
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_load_library(i8* %name) local_unnamed_addr #0 {
entry:
  %0 = load i8* (i8*)*, i8* (i8*)** @_ZN6Halide7Runtime8Internal19custom_load_libraryE, align 8, !tbaa !14
  %call = tail call i8* %0(i8* %name) #14
  ret i8* %call
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_get_library_symbol(i8* %lib, i8* %name) local_unnamed_addr #0 {
entry:
  %0 = load i8* (i8*, i8*)*, i8* (i8*, i8*)** @_ZN6Halide7Runtime8Internal25custom_get_library_symbolE, align 8, !tbaa !14
  %call = tail call i8* %0(i8* %lib, i8* %name) #14
  ret i8* %call
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_set_gpu_device(i32 %d) local_unnamed_addr #2 {
entry:
  store i32 %d, i32* @_ZN6Halide7Runtime8Internal17halide_gpu_deviceE, align 4, !tbaa !41
  store i8 1, i8* @_ZN6Halide7Runtime8Internal29halide_gpu_device_initializedE, align 1, !tbaa !19
  ret void
}

; Function Attrs: nounwind
define weak i32 @halide_get_gpu_device(i8* %user_context) local_unnamed_addr #4 {
entry:
  br label %while.cond.i

while.cond.i:                                     ; preds = %while.cond.i, %entry
  %0 = atomicrmw volatile xchg i8* @_ZN6Halide7Runtime8Internal22halide_gpu_device_lockE, i8 1 acquire
  %tobool.not.i = icmp eq i8 %0, 0
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit, label %while.cond.i, !llvm.loop !137

_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit: ; preds = %while.cond.i
  %1 = load i8, i8* @_ZN6Halide7Runtime8Internal29halide_gpu_device_initializedE, align 1, !tbaa !19, !range !21
  %tobool.not = icmp eq i8 %1, 0
  br i1 %tobool.not, label %if.then, label %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit.if.end4_crit_edge

_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit.if.end4_crit_edge: ; preds = %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit
  %.pre = load i32, i32* @_ZN6Halide7Runtime8Internal17halide_gpu_deviceE, align 4, !tbaa !41
  br label %if.end4

if.then:                                          ; preds = %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit
  %call = tail call i8* @getenv(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.8, i64 0, i64 0)) #14
  %tobool1.not = icmp eq i8* %call, null
  br i1 %tobool1.not, label %if.end, label %if.then2

if.then2:                                         ; preds = %if.then
  %call3 = tail call i32 @atoi(i8* nonnull %call) #14
  br label %if.end

if.end:                                           ; preds = %if.then2, %if.then
  %storemerge = phi i32 [ %call3, %if.then2 ], [ -1, %if.then ]
  store i32 %storemerge, i32* @_ZN6Halide7Runtime8Internal17halide_gpu_deviceE, align 4, !tbaa !41
  store i8 1, i8* @_ZN6Halide7Runtime8Internal29halide_gpu_device_initializedE, align 1, !tbaa !19
  br label %if.end4

if.end4:                                          ; preds = %if.end, %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit.if.end4_crit_edge
  %2 = phi i32 [ %.pre, %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit.if.end4_crit_edge ], [ %storemerge, %if.end ]
  store atomic volatile i8 0, i8* @_ZN6Halide7Runtime8Internal22halide_gpu_device_lockE release, align 1
  ret i32 %2
}

; Function Attrs: nounwind
define weak i32 @halide_default_trace(i8* %user_context, %struct.halide_trace_event_t* %e) #4 {
entry:
  %0 = atomicrmw add i32* @_ZZ20halide_default_traceE3ids, i32 1 seq_cst
  %call = tail call i32 @halide_get_trace_file(i8* %user_context) #16
  %cmp = icmp sgt i32 %call, 0
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %type = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 4
  %lanes = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 4, i32 2
  %1 = load i16, i16* %lanes, align 2, !tbaa !138
  %conv = zext i16 %1 to i32
  %bits.i = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 4, i32 1
  %2 = load i8, i8* %bits.i, align 1, !tbaa !144
  %conv.i = zext i8 %2 to i32
  %add.i = add nuw nsw i32 %conv.i, 7
  %div.i = lshr i32 %add.i, 3
  %mul = mul nuw nsw i32 %div.i, %conv
  %dimensions = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 8
  %3 = load i32, i32* %dimensions, align 8, !tbaa !145
  %mul3 = shl i32 %3, 2
  %func = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 0
  %4 = load i8*, i8** %func, align 8, !tbaa !146
  %call4 = tail call i64 @strlen(i8* %4) #14
  %5 = trunc i64 %call4 to i32
  %conv5 = add i32 %5, 1
  %trace_tag = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 3
  %6 = load i8*, i8** %trace_tag, align 8, !tbaa !147
  %tobool.not = icmp eq i8* %6, null
  br i1 %tobool.not, label %cond.end, label %cond.true

cond.true:                                        ; preds = %if.then
  %call7 = tail call i64 @strlen(i8* nonnull %6) #14
  %7 = trunc i64 %call7 to i32
  %phi.cast = add i32 %7, 1
  br label %cond.end

cond.end:                                         ; preds = %cond.true, %if.then
  %cond = phi i32 [ %phi.cast, %cond.true ], [ 1, %if.then ]
  %add11 = add i32 %mul3, 31
  %add12 = add i32 %add11, %mul
  %add13 = add i32 %add12, %conv5
  %add14 = add i32 %add13, %cond
  %and = and i32 %add14, -4
  %8 = load %"class.Halide::Runtime::Internal::TraceBuffer"*, %"class.Halide::Runtime::Internal::TraceBuffer"** @_ZN6Halide7Runtime8Internal19halide_trace_bufferE, align 8, !tbaa !14
  %lock.i.i.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %8, i64 0, i32 0, i32 0
  %cmp.i.i = icmp ult i32 %and, 1048577
  %cursor.i.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %8, i64 0, i32 1
  %overage.i.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %8, i64 0, i32 2
  %arraydecay.i.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %8, i64 0, i32 3, i64 0
  br i1 %cmp.i.i, label %while.body.i.i.us.i.preheader, label %while.body.i.i.i.preheader

while.body.i.i.i.preheader:                       ; preds = %cond.end
  %9 = bitcast i32* %cursor.i.i to <2 x i32>*
  br label %while.body.i.i.i

while.body.i.i.us.i.preheader:                    ; preds = %cond.end
  %10 = bitcast i32* %cursor.i.i to <2 x i32>*
  br label %while.body.i.i.us.i

while.body.i.i.us.i:                              ; preds = %while.body.i.i.us.i.backedge, %while.body.i.i.us.i.preheader
  %11 = load volatile i32, i32* %lock.i.i.i, align 4, !tbaa !148
  %and.i.i.us.i = and i32 %11, 1073741823
  %add.i.i.us.i = add nuw nsw i32 %and.i.i.us.i, 1
  %12 = cmpxchg i32* %lock.i.i.i, i32 %and.i.i.us.i, i32 %add.i.i.us.i seq_cst seq_cst
  %13 = extractvalue { i32, i1 } %12, 1
  br i1 %13, label %do.end.i.us.i, label %while.body.i.i.us.i.backedge

do.end.i.us.i:                                    ; preds = %while.body.i.i.us.i
  %14 = atomicrmw add i32* %cursor.i.i, i32 %and seq_cst
  %add.i.us.i = add i32 %14, %and
  %cmp2.i.us.i = icmp ugt i32 %add.i.us.i, 1048576
  br i1 %cmp2.i.us.i, label %while.body.us.i, label %_ZN6Halide7Runtime8Internal11TraceBuffer14acquire_packetEPvij.exit

while.body.us.i:                                  ; preds = %do.end.i.us.i
  %15 = atomicrmw add i32* %overage.i.i, i32 %and seq_cst
  %16 = atomicrmw sub i32* %lock.i.i.i, i32 1 seq_cst
  br label %while.body.i.i5.us.i

while.body.i.i5.us.i:                             ; preds = %while.body.i.i5.us.i, %while.body.us.i
  %17 = atomicrmw or i32* %lock.i.i.i, i32 1073741824 seq_cst
  %18 = cmpxchg i32* %lock.i.i.i, i32 1073741824, i32 -2147483648 seq_cst seq_cst
  %19 = extractvalue { i32, i1 } %18, 1
  br i1 %19, label %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i.us.i, label %while.body.i.i5.us.i

_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i.us.i: ; preds = %while.body.i.i5.us.i
  %20 = load i32, i32* %cursor.i.i, align 4, !tbaa !150
  %tobool.not.i.us.i = icmp eq i32 %20, 0
  br i1 %tobool.not.i.us.i, label %do.end.critedge.i.us.i, label %if.then.i9.us.i

if.then.i9.us.i:                                  ; preds = %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i.us.i
  %21 = load i32, i32* %overage.i.i, align 4, !tbaa !152
  %sub.i.us.i = sub i32 %20, %21
  store i32 %sub.i.us.i, i32* %cursor.i.i, align 4, !tbaa !150
  %conv.i.us.i = zext i32 %sub.i.us.i to i64
  %call.i.us.i = tail call i64 @write(i32 %call, i8* nonnull %arraydecay.i.i, i64 %conv.i.us.i) #14
  %conv5.i.us.i = trunc i64 %call.i.us.i to i32
  %cmp.i8.us.i = icmp eq i32 %sub.i.us.i, %conv5.i.us.i
  store <2 x i32> zeroinitializer, <2 x i32>* %10, align 4, !tbaa !41
  %22 = atomicrmw and i32* %lock.i.i.i, i32 2147483647 seq_cst
  br i1 %cmp.i8.us.i, label %while.body.i.i.us.i.backedge, label %if.then10.i.us.i

if.then10.i.us.i:                                 ; preds = %if.then.i9.us.i
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([144 x i8], [144 x i8]* @.str.32, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %while.body.i.i.us.i.backedge

do.end.critedge.i.us.i:                           ; preds = %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i.us.i
  %23 = atomicrmw and i32* %lock.i.i.i, i32 2147483647 seq_cst
  br label %while.body.i.i.us.i.backedge

while.body.i.i.us.i.backedge:                     ; preds = %do.end.critedge.i.us.i, %if.then10.i.us.i, %if.then.i9.us.i, %while.body.i.i.us.i
  br label %while.body.i.i.us.i, !llvm.loop !153

while.body.i.i.i:                                 ; preds = %while.body.i.i.i.backedge, %while.body.i.i.i.preheader
  %24 = load volatile i32, i32* %lock.i.i.i, align 4, !tbaa !148
  %and.i.i.i = and i32 %24, 1073741823
  %add.i.i.i = add nuw nsw i32 %and.i.i.i, 1
  %25 = cmpxchg i32* %lock.i.i.i, i32 %and.i.i.i, i32 %add.i.i.i seq_cst seq_cst
  %26 = extractvalue { i32, i1 } %25, 1
  br i1 %26, label %if.then.i.i, label %while.body.i.i.i.backedge

if.then.i.i:                                      ; preds = %while.body.i.i.i
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([120 x i8], [120 x i8]* @.str.31, i64 0, i64 0)) #14
  tail call void @abort() #14
  %27 = atomicrmw add i32* %cursor.i.i, i32 %and seq_cst
  %add.i.i400 = add i32 %27, %and
  %cmp2.i.i = icmp ugt i32 %add.i.i400, 1048576
  br i1 %cmp2.i.i, label %while.body.i, label %_ZN6Halide7Runtime8Internal11TraceBuffer14acquire_packetEPvij.exit

while.body.i:                                     ; preds = %if.then.i.i
  %28 = atomicrmw add i32* %overage.i.i, i32 %and seq_cst
  %29 = atomicrmw sub i32* %lock.i.i.i, i32 1 seq_cst
  br label %while.body.i.i5.i

while.body.i.i5.i:                                ; preds = %while.body.i.i5.i, %while.body.i
  %30 = atomicrmw or i32* %lock.i.i.i, i32 1073741824 seq_cst
  %31 = cmpxchg i32* %lock.i.i.i, i32 1073741824, i32 -2147483648 seq_cst seq_cst
  %32 = extractvalue { i32, i1 } %31, 1
  br i1 %32, label %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i.i, label %while.body.i.i5.i

_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i.i: ; preds = %while.body.i.i5.i
  %33 = load i32, i32* %cursor.i.i, align 4, !tbaa !150
  %tobool.not.i.i = icmp eq i32 %33, 0
  br i1 %tobool.not.i.i, label %do.end.critedge.i.i, label %if.then.i9.i

if.then.i9.i:                                     ; preds = %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i.i
  %34 = load i32, i32* %overage.i.i, align 4, !tbaa !152
  %sub.i.i = sub i32 %33, %34
  store i32 %sub.i.i, i32* %cursor.i.i, align 4, !tbaa !150
  %conv.i.i = zext i32 %sub.i.i to i64
  %call.i.i401 = tail call i64 @write(i32 %call, i8* nonnull %arraydecay.i.i, i64 %conv.i.i) #14
  %conv5.i.i = trunc i64 %call.i.i401 to i32
  %cmp.i8.i = icmp eq i32 %sub.i.i, %conv5.i.i
  store <2 x i32> zeroinitializer, <2 x i32>* %9, align 4, !tbaa !41
  %35 = atomicrmw and i32* %lock.i.i.i, i32 2147483647 seq_cst
  br i1 %cmp.i8.i, label %while.body.i.i.i.backedge, label %if.then10.i.i

if.then10.i.i:                                    ; preds = %if.then.i9.i
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([144 x i8], [144 x i8]* @.str.32, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %while.body.i.i.i.backedge

do.end.critedge.i.i:                              ; preds = %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i.i
  %36 = atomicrmw and i32* %lock.i.i.i, i32 2147483647 seq_cst
  br label %while.body.i.i.i.backedge

while.body.i.i.i.backedge:                        ; preds = %do.end.critedge.i.i, %if.then10.i.i, %if.then.i9.i, %while.body.i.i.i
  br label %while.body.i.i.i, !llvm.loop !153

_ZN6Halide7Runtime8Internal11TraceBuffer14acquire_packetEPvij.exit: ; preds = %if.then.i.i, %do.end.i.us.i
  %.lcssa.i = phi i32 [ %14, %do.end.i.us.i ], [ %27, %if.then.i.i ]
  %idx.ext.i.i = zext i32 %.lcssa.i to i64
  %add.ptr.i.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %8, i64 0, i32 3, i64 %idx.ext.i.i
  %cmp16 = icmp ugt i32 %and, 4096
  br i1 %cmp16, label %if.then17, label %if.end

if.then17:                                        ; preds = %_ZN6Halide7Runtime8Internal11TraceBuffer14acquire_packetEPvij.exit
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i404 = icmp eq i8* %call.i, null
  br i1 %tobool.not.i404, label %if.then.i415, label %if.else.i421

if.then.i415:                                     ; preds = %if.then17
  %conv.i4071 = zext i32 %and to i64
  %call.i4082 = tail call i8* @halide_uint64_to_string(i8* null, i8* null, i64 %conv.i4071, i32 1) #14
  %call.i41117 = tail call i8* @halide_string_to_string(i8* %call.i4082, i8* null, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.7.164, i64 0, i64 0)) #14
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE0ELy1024EED2Ev.exit

if.else.i421:                                     ; preds = %if.then17
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %conv.i4073 = zext i32 %and to i64
  %call.i4084 = tail call i8* @halide_uint64_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i64 %conv.i4073, i32 1) #14
  %call.i411 = tail call i8* @halide_string_to_string(i8* %call.i4084, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.7.164, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i.i416 = ptrtoint i8* %call.i411 to i64
  %sub.ptr.rhs.cast.i.i417 = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i418 = sub i64 1, %sub.ptr.rhs.cast.i.i417
  %add.i.i419 = add i64 %sub.ptr.sub.i.i418, %sub.ptr.lhs.cast.i.i416
  %call.i.i420 = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* null, i8* nonnull %call.i, i64 %add.i.i419) #14
  tail call void @halide_print(i8* null, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE0ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE0ELy1024EED2Ev.exit: ; preds = %if.else.i421, %if.then.i415
  tail call void @free(i8* %call.i) #14
  br label %if.end

if.end:                                           ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE0ELy1024EED2Ev.exit, %_ZN6Halide7Runtime8Internal11TraceBuffer14acquire_packetEPvij.exit
  %size = bitcast i8* %add.ptr.i.i to i32*
  store i32 %and, i32* %size, align 4, !tbaa !154
  %id = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 4
  %37 = bitcast i8* %id to i32*
  store i32 %0, i32* %37, align 4, !tbaa !156
  %38 = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 8
  %39 = bitcast %struct.halide_type_t* %type to i32*
  %40 = bitcast i8* %38 to i32*
  %41 = load i32, i32* %39, align 8
  store i32 %41, i32* %40, align 4
  %event = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 5
  %event22 = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 12
  %42 = bitcast i32* %event to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 4, !tbaa !18
  %dimensions26 = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 24
  %44 = bitcast i8* %dimensions26 to i32*
  %45 = bitcast i8* %event22 to <4 x i32>*
  store <4 x i32> %43, <4 x i32>* %45, align 4, !tbaa !18
  %coordinates = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 2
  %46 = load i32*, i32** %coordinates, align 8, !tbaa !157
  %tobool27.not = icmp eq i32* %46, null
  br i1 %tobool27.not, label %if.end33, label %if.then28

if.then28:                                        ; preds = %if.end
  %47 = bitcast i32* %46 to i8*
  %48 = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 28
  %conv31 = zext i32 %mul3 to i64
  %call32 = tail call i8* @memcpy(i8* nonnull %48, i8* nonnull %47, i64 %conv31) #14
  br label %if.end33

if.end33:                                         ; preds = %if.then28, %if.end
  %value = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 1
  %49 = load i8*, i8** %value, align 8, !tbaa !158
  %tobool34.not = icmp eq i8* %49, null
  br i1 %tobool34.not, label %if.end40, label %if.then35

if.then35:                                        ; preds = %if.end33
  %50 = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 28
  %51 = bitcast i8* %50 to i32*
  %52 = load i32, i32* %44, align 4, !tbaa !159
  %idx.ext.i = sext i32 %52 to i64
  %add.ptr.i424 = getelementptr inbounds i32, i32* %51, i64 %idx.ext.i
  %53 = bitcast i32* %add.ptr.i424 to i8*
  %conv38 = zext i32 %mul to i64
  %call39 = tail call i8* @memcpy(i8* nonnull %53, i8* nonnull %49, i64 %conv38) #14
  br label %if.end40

if.end40:                                         ; preds = %if.end33, %if.then35
  %54 = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 28
  %55 = bitcast i8* %54 to i32*
  %56 = load i32, i32* %44, align 4, !tbaa !159
  %idx.ext.i.i425 = sext i32 %56 to i64
  %add.ptr.i.i426 = getelementptr inbounds i32, i32* %55, i64 %idx.ext.i.i425
  %57 = bitcast i32* %add.ptr.i.i426 to i8*
  %lanes.i = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 10
  %58 = bitcast i8* %lanes.i to i16*
  %59 = load i16, i16* %58, align 2, !tbaa !160
  %conv.i427 = zext i16 %59 to i32
  %60 = getelementptr inbounds i8, i8* %add.ptr.i.i, i64 9
  %61 = load i8, i8* %60, align 1, !tbaa !144
  %conv.i.i428 = zext i8 %61 to i32
  %add.i.i429 = add nuw nsw i32 %conv.i.i428, 7
  %div.i.i = lshr i32 %add.i.i429, 3
  %mul.i = mul nuw nsw i32 %div.i.i, %conv.i427
  %idx.ext.i430 = zext i32 %mul.i to i64
  %add.ptr.i431 = getelementptr inbounds i8, i8* %57, i64 %idx.ext.i430
  %62 = load i8*, i8** %func, align 8, !tbaa !146
  %conv43 = zext i32 %conv5 to i64
  %call44 = tail call i8* @memcpy(i8* nonnull %add.ptr.i431, i8* %62, i64 %conv43) #14
  %63 = load i32, i32* %44, align 4, !tbaa !159
  %idx.ext.i.i.i = sext i32 %63 to i64
  %add.ptr.i.i.i = getelementptr inbounds i32, i32* %55, i64 %idx.ext.i.i.i
  %64 = bitcast i32* %add.ptr.i.i.i to i8*
  %65 = load i16, i16* %58, align 2, !tbaa !160
  %conv.i.i432 = zext i16 %65 to i32
  %66 = load i8, i8* %60, align 1, !tbaa !144
  %conv.i.i.i = zext i8 %66 to i32
  %add.i.i.i433 = add nuw nsw i32 %conv.i.i.i, 7
  %div.i.i.i = lshr i32 %add.i.i.i433, 3
  %mul.i.i = mul nuw nsw i32 %div.i.i.i, %conv.i.i432
  %idx.ext.i.i434 = zext i32 %mul.i.i to i64
  %add.ptr.i.i435 = getelementptr inbounds i8, i8* %64, i64 %idx.ext.i.i434
  br label %while.cond.i437

while.cond.i437:                                  ; preds = %while.cond.i437, %if.end40
  %f.0.i = phi i8* [ %add.ptr.i.i435, %if.end40 ], [ %incdec.ptr.i, %while.cond.i437 ]
  %incdec.ptr.i = getelementptr inbounds i8, i8* %f.0.i, i64 1
  %67 = load i8, i8* %f.0.i, align 1, !tbaa !18
  %tobool.not.i436 = icmp eq i8 %67, 0
  br i1 %tobool.not.i436, label %_ZN21halide_trace_packet_t9trace_tagEv.exit, label %while.cond.i437, !llvm.loop !161

_ZN21halide_trace_packet_t9trace_tagEv.exit:      ; preds = %while.cond.i437
  %68 = load i8*, i8** %trace_tag, align 8, !tbaa !147
  %tobool47.not = icmp eq i8* %68, null
  %spec.select = select i1 %tobool47.not, i8* getelementptr inbounds ([1 x i8], [1 x i8]* @.str.1.10, i64 0, i64 0), i8* %68
  %conv53 = zext i32 %cond to i64
  %call54 = tail call i8* @memcpy(i8* nonnull %incdec.ptr.i, i8* %spec.select, i64 %conv53) #14
  %69 = load %"class.Halide::Runtime::Internal::TraceBuffer"*, %"class.Halide::Runtime::Internal::TraceBuffer"** @_ZN6Halide7Runtime8Internal19halide_trace_bufferE, align 8, !tbaa !14
  fence seq_cst
  %lock.i.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %69, i64 0, i32 0, i32 0
  %70 = atomicrmw sub i32* %lock.i.i, i32 1 seq_cst
  %71 = load i32, i32* %event, align 4, !tbaa !162
  %cmp56 = icmp eq i32 %71, 9
  br i1 %cmp56, label %if.then57, label %if.end277

if.then57:                                        ; preds = %_ZN21halide_trace_packet_t9trace_tagEv.exit
  %72 = load %"class.Halide::Runtime::Internal::TraceBuffer"*, %"class.Halide::Runtime::Internal::TraceBuffer"** @_ZN6Halide7Runtime8Internal19halide_trace_bufferE, align 8, !tbaa !14
  %lock.i.i438 = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %72, i64 0, i32 0, i32 0
  br label %while.body.i.i

while.body.i.i:                                   ; preds = %while.body.i.i, %if.then57
  %73 = atomicrmw or i32* %lock.i.i438, i32 1073741824 seq_cst
  %74 = cmpxchg i32* %lock.i.i438, i32 1073741824, i32 -2147483648 seq_cst seq_cst
  %75 = extractvalue { i32, i1 } %74, 1
  br i1 %75, label %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i, label %while.body.i.i

_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i: ; preds = %while.body.i.i
  %cursor.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %72, i64 0, i32 1
  %76 = load i32, i32* %cursor.i, align 4, !tbaa !150
  %tobool.not.i439 = icmp eq i32 %76, 0
  br i1 %tobool.not.i439, label %do.end.critedge.i, label %if.then.i442

if.then.i442:                                     ; preds = %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i
  %overage.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %72, i64 0, i32 2
  %77 = load i32, i32* %overage.i, align 4, !tbaa !152
  %sub.i = sub i32 %76, %77
  store i32 %sub.i, i32* %cursor.i, align 4, !tbaa !150
  %arraydecay.i = getelementptr inbounds %"class.Halide::Runtime::Internal::TraceBuffer", %"class.Halide::Runtime::Internal::TraceBuffer"* %72, i64 0, i32 3, i64 0
  %conv.i440 = zext i32 %sub.i to i64
  %call.i441 = tail call i64 @write(i32 %call, i8* nonnull %arraydecay.i, i64 %conv.i440) #14
  %conv5.i = trunc i64 %call.i441 to i32
  %cmp.i = icmp eq i32 %sub.i, %conv5.i
  %78 = bitcast i32* %cursor.i to <2 x i32>*
  store <2 x i32> zeroinitializer, <2 x i32>* %78, align 4, !tbaa !41
  %79 = atomicrmw and i32* %lock.i.i438, i32 2147483647 seq_cst
  br i1 %cmp.i, label %if.end277, label %if.then10.i

if.then10.i:                                      ; preds = %if.then.i442
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([144 x i8], [144 x i8]* @.str.32, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %if.end277

do.end.critedge.i:                                ; preds = %_ZN6Halide7Runtime8Internal23SharedExclusiveSpinLock17acquire_exclusiveEv.exit.i
  %80 = atomicrmw and i32* %lock.i.i438, i32 2147483647 seq_cst
  br label %if.end277

if.else:                                          ; preds = %entry
  %call.i445 = tail call i8* @malloc(i64 4096) #14
  %tobool.not.i448 = icmp eq i8* %call.i445, null
  br i1 %tobool.not.i448, label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EEC2EPvPc.exit, label %if.then6.i451

if.then6.i451:                                    ; preds = %if.else
  %add.ptr.i449 = getelementptr inbounds i8, i8* %call.i445, i64 4095
  store i8 0, i8* %add.ptr.i449, align 1, !tbaa !18
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EEC2EPvPc.exit: ; preds = %if.then6.i451, %if.else
  %ss.sroa.74.0 = phi i8* [ %add.ptr.i449, %if.then6.i451 ], [ null, %if.else ]
  %bits = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 4, i32 1
  %81 = load i8, i8* %bits, align 1, !tbaa !163
  %conv60 = zext i8 %81 to i32
  br label %while.cond

while.cond:                                       ; preds = %while.cond, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EEC2EPvPc.exit
  %print_bits.0 = phi i32 [ 8, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EEC2EPvPc.exit ], [ %shl, %while.cond ]
  %cmp61 = icmp slt i32 %print_bits.0, %conv60
  %shl = shl i32 %print_bits.0, 1
  br i1 %cmp61, label %while.cond, label %do.body, !llvm.loop !164

do.body:                                          ; preds = %while.cond
  %cmp62 = icmp slt i32 %print_bits.0, 65
  br i1 %cmp62, label %do.end, label %if.then63

if.then63:                                        ; preds = %do.body
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([140 x i8], [140 x i8]* @.str.2.11, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then63, %do.body
  %event65 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 5
  %82 = load i32, i32* %event65, align 4, !tbaa !162
  %cmp66 = icmp slt i32 %82, 2
  %idxprom = zext i32 %82 to i64
  %arrayidx = getelementptr inbounds [11 x i8*], [11 x i8*]* @__const.halide_default_trace.event_types, i64 0, i64 %idxprom
  %83 = load i8*, i8** %arrayidx, align 8, !tbaa !14
  %call.i456 = tail call i8* @halide_string_to_string(i8* %call.i445, i8* %ss.sroa.74.0, i8* %83) #14
  %call.i459 = tail call i8* @halide_string_to_string(i8* %call.i456, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.20.177, i64 0, i64 0)) #14
  %func70 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 0
  %84 = load i8*, i8** %func70, align 8, !tbaa !146
  %call.i462 = tail call i8* @halide_string_to_string(i8* %call.i459, i8* %ss.sroa.74.0, i8* %84) #14
  %call.i465 = tail call i8* @halide_string_to_string(i8* %call.i462, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.141, i64 0, i64 0)) #14
  %value_index73 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 7
  %85 = load i32, i32* %value_index73, align 4, !tbaa !165
  %conv.i468 = sext i32 %85 to i64
  %call.i469 = tail call i8* @halide_int64_to_string(i8* %call.i465, i8* %ss.sroa.74.0, i64 %conv.i468, i32 1) #14
  %call.i472 = tail call i8* @halide_string_to_string(i8* %call.i469, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.22.179, i64 0, i64 0)) #14
  %lanes77 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 4, i32 2
  %86 = load i16, i16* %lanes77, align 2, !tbaa !138
  %cmp79 = icmp ugt i16 %86, 1
  br i1 %cmp79, label %if.then80, label %if.end82

if.then80:                                        ; preds = %do.end
  %call.i475 = tail call i8* @halide_string_to_string(i8* %call.i472, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.17, i64 0, i64 0)) #14
  br label %if.end82

if.end82:                                         ; preds = %if.then80, %do.end
  %ss.sroa.7.0 = phi i8* [ %call.i475, %if.then80 ], [ %call.i472, %do.end ]
  %dimensions83 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 8
  %87 = load i32, i32* %dimensions83, align 8, !tbaa !145
  %cmp84660 = icmp sgt i32 %87, 0
  br i1 %cmp84660, label %if.end100.peel, label %for.cond.cleanup

if.end100.peel:                                   ; preds = %if.end82
  %coordinates101 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 2
  %.pre = load i32*, i32** %coordinates101, align 8, !tbaa !157
  %.pre673 = load i32, i32* %.pre, align 4, !tbaa !41
  %conv.i484.peel = sext i32 %.pre673 to i64
  %call.i485.peel = tail call i8* @halide_int64_to_string(i8* %ss.sroa.7.0, i8* %ss.sroa.74.0, i64 %conv.i484.peel, i32 1) #14
  %88 = load i32, i32* %dimensions83, align 8, !tbaa !145
  %cmp84.peel = icmp sgt i32 %88, 1
  br i1 %cmp84.peel, label %if.then86, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %if.end100, %if.end100.peel, %if.end82
  %ss.sroa.7.1.lcssa = phi i8* [ %ss.sroa.7.0, %if.end82 ], [ %call.i485.peel, %if.end100.peel ], [ %call.i485, %if.end100 ]
  %89 = load i16, i16* %lanes77, align 2, !tbaa !138
  %cmp108 = icmp ugt i16 %89, 1
  %.sink684 = select i1 %cmp108, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.20, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.119, i64 0, i64 0)
  %call.i491 = tail call i8* @halide_string_to_string(i8* %ss.sroa.7.1.lcssa, i8* %ss.sroa.74.0, i8* %.sink684) #14
  br i1 %cmp66, label %if.then115, label %if.end263

if.then86:                                        ; preds = %if.end100.peel, %if.end100
  %indvars.iv670 = phi i64 [ %indvars.iv.next671, %if.end100 ], [ 1, %if.end100.peel ]
  %ss.sroa.7.1661 = phi i8* [ %call.i485, %if.end100 ], [ %call.i485.peel, %if.end100.peel ]
  %90 = load i16, i16* %lanes77, align 2, !tbaa !138
  %cmp90 = icmp ugt i16 %90, 1
  br i1 %cmp90, label %land.lhs.true, label %if.else97.split

land.lhs.true:                                    ; preds = %if.then86
  %conv89 = zext i16 %90 to i32
  %91 = trunc i64 %indvars.iv670 to i32
  %rem = urem i32 %91, %conv89
  %cmp94 = icmp eq i32 %rem, 0
  br i1 %cmp94, label %if.end100, label %if.else97.split

if.else97.split:                                  ; preds = %if.then86, %land.lhs.true
  br label %if.end100

if.end100:                                        ; preds = %land.lhs.true, %if.else97.split
  %.sink = phi i8* [ getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0), %if.else97.split ], [ getelementptr inbounds ([5 x i8], [5 x i8]* @.str.18, i64 0, i64 0), %land.lhs.true ]
  %call.i4786 = tail call i8* @halide_string_to_string(i8* %ss.sroa.7.1661, i8* %ss.sroa.74.0, i8* %.sink) #14
  %92 = load i32*, i32** %coordinates101, align 8, !tbaa !157
  %arrayidx103 = getelementptr inbounds i32, i32* %92, i64 %indvars.iv670
  %93 = load i32, i32* %arrayidx103, align 4, !tbaa !41
  %conv.i484 = sext i32 %93 to i64
  %call.i485 = tail call i8* @halide_int64_to_string(i8* %call.i4786, i8* %ss.sroa.74.0, i64 %conv.i484, i32 1) #14
  %indvars.iv.next671 = add nuw nsw i64 %indvars.iv670, 1
  %94 = load i32, i32* %dimensions83, align 8, !tbaa !145
  %95 = sext i32 %94 to i64
  %cmp84 = icmp slt i64 %indvars.iv.next671, %95
  br i1 %cmp84, label %if.then86, label %for.cond.cleanup, !llvm.loop !166

if.then115:                                       ; preds = %for.cond.cleanup
  %96 = load i16, i16* %lanes77, align 2, !tbaa !138
  %cmp119 = icmp ugt i16 %96, 1
  %.sink685 = select i1 %cmp119, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.22, i64 0, i64 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.23, i64 0, i64 0)
  %call.i497 = tail call i8* @halide_string_to_string(i8* %call.i491, i8* %ss.sroa.74.0, i8* %.sink685) #14
  %97 = load i16, i16* %lanes77, align 2, !tbaa !138
  %cmp130655.not = icmp eq i16 %97, 0
  br i1 %cmp130655.not, label %if.end263, label %if.end136.peel

if.end136.peel:                                   ; preds = %if.then115
  %code = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 4, i32 0
  %value245 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 1
  %98 = bitcast i8** %value245 to i8***
  %cmp214 = icmp sgt i32 %print_bits.0, 15
  %99 = bitcast i8** %value245 to i16**
  %100 = bitcast i8** %value245 to float**
  %101 = bitcast i8** %value245 to double**
  %102 = bitcast i8** %value245 to i32**
  %103 = bitcast i8** %value245 to i64**
  %.pre674 = load i8, i8* %code, align 8, !tbaa !168
  switch i8 %.pre674, label %for.inc253.peel [
    i8 0, label %if.then140.peel
    i8 1, label %if.then176.peel
    i8 2, label %do.body213.peel
    i8 3, label %if.then244.peel
  ]

if.then244.peel:                                  ; preds = %if.end136.peel
  %104 = load i8**, i8*** %98, align 8, !tbaa !158
  %105 = load i8*, i8** %104, align 8, !tbaa !14
  %call.i543.peel = tail call i8* @halide_pointer_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i8* %105) #14
  br label %for.inc253.peel

do.body213.peel:                                  ; preds = %if.end136.peel
  br i1 %cmp214, label %do.end218.peel, label %if.then215.peel

if.then215.peel:                                  ; preds = %do.body213.peel
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([142 x i8], [142 x i8]* @.str.24, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end218.peel

do.end218.peel:                                   ; preds = %if.then215.peel, %do.body213.peel
  switch i32 %print_bits.0, label %if.else232.peel [
    i32 32, label %if.then220.peel
    i32 16, label %if.then227.peel
  ]

if.then227.peel:                                  ; preds = %do.end218.peel
  %106 = load i16*, i16** %99, align 8, !tbaa !158
  %107 = load i16, i16* %106, align 2, !tbaa !169
  %call.i535.peel = tail call double @halide_float16_bits_to_double(i16 zeroext %107) #14
  %call2.i.peel = tail call i8* @halide_double_to_string(i8* %call.i497, i8* %ss.sroa.74.0, double %call.i535.peel, i32 1) #14
  br label %for.inc253.peel

if.then220.peel:                                  ; preds = %do.end218.peel
  %108 = load float*, float** %100, align 8, !tbaa !158
  %109 = load float, float* %108, align 4, !tbaa !170
  %conv.i533.peel = fpext float %109 to double
  %call.i534.peel = tail call i8* @halide_double_to_string(i8* %call.i497, i8* %ss.sroa.74.0, double %conv.i533.peel, i32 0) #14
  br label %for.inc253.peel

if.else232.peel:                                  ; preds = %do.end218.peel
  %110 = load double*, double** %101, align 8, !tbaa !158
  %111 = load double, double* %110, align 8, !tbaa !172
  %call.i540.peel = tail call i8* @halide_double_to_string(i8* %call.i497, i8* %ss.sroa.74.0, double %111, i32 1) #14
  br label %for.inc253.peel

if.then176.peel:                                  ; preds = %if.end136.peel
  switch i32 %print_bits.0, label %if.else199.peel [
    i32 8, label %if.then178.peel
    i32 16, label %if.then186.peel
    i32 32, label %if.then194.peel
  ]

if.then194.peel:                                  ; preds = %if.then176.peel
  %112 = load i32*, i32** %102, align 8, !tbaa !158
  %113 = load i32, i32* %112, align 4, !tbaa !41
  %conv.i526.peel = zext i32 %113 to i64
  %call.i527.peel = tail call i8* @halide_uint64_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i64 %conv.i526.peel, i32 1) #14
  br label %for.inc253.peel

if.then186.peel:                                  ; preds = %if.then176.peel
  %114 = load i16*, i16** %99, align 8, !tbaa !158
  %115 = load i16, i16* %114, align 2, !tbaa !169
  %conv.i522.peel = zext i16 %115 to i64
  %call.i523.peel = tail call i8* @halide_int64_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i64 %conv.i522.peel, i32 1) #14
  br label %for.inc253.peel

if.then178.peel:                                  ; preds = %if.then176.peel
  %116 = load i8*, i8** %value245, align 8, !tbaa !158
  %117 = load i8, i8* %116, align 1, !tbaa !18
  %conv.i518.peel = zext i8 %117 to i64
  %call.i519.peel = tail call i8* @halide_int64_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i64 %conv.i518.peel, i32 1) #14
  br label %for.inc253.peel

if.else199.peel:                                  ; preds = %if.then176.peel
  %118 = load i64*, i64** %103, align 8, !tbaa !158
  %119 = load i64, i64* %118, align 8, !tbaa !22
  %call.i530.peel = tail call i8* @halide_uint64_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i64 %119, i32 1) #14
  br label %for.inc253.peel

if.then140.peel:                                  ; preds = %if.end136.peel
  switch i32 %print_bits.0, label %if.else163.peel [
    i32 8, label %if.then142.peel
    i32 16, label %if.then150.peel
    i32 32, label %if.then158.peel
  ]

if.then158.peel:                                  ; preds = %if.then140.peel
  %120 = load i32*, i32** %102, align 8, !tbaa !158
  %121 = load i32, i32* %120, align 4, !tbaa !41
  %conv.i511.peel = sext i32 %121 to i64
  %call.i512.peel = tail call i8* @halide_int64_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i64 %conv.i511.peel, i32 1) #14
  br label %for.inc253.peel

if.then150.peel:                                  ; preds = %if.then140.peel
  %122 = load i16*, i16** %99, align 8, !tbaa !158
  %123 = load i16, i16* %122, align 2, !tbaa !169
  %conv.i507.peel = sext i16 %123 to i64
  %call.i508.peel = tail call i8* @halide_int64_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i64 %conv.i507.peel, i32 1) #14
  br label %for.inc253.peel

if.then142.peel:                                  ; preds = %if.then140.peel
  %124 = load i8*, i8** %value245, align 8, !tbaa !158
  %125 = load i8, i8* %124, align 1, !tbaa !18
  %conv.i503.peel = sext i8 %125 to i64
  %call.i504.peel = tail call i8* @halide_int64_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i64 %conv.i503.peel, i32 1) #14
  br label %for.inc253.peel

if.else163.peel:                                  ; preds = %if.then140.peel
  %126 = load i64*, i64** %103, align 8, !tbaa !158
  %127 = load i64, i64* %126, align 8, !tbaa !22
  %call.i515.peel = tail call i8* @halide_int64_to_string(i8* %call.i497, i8* %ss.sroa.74.0, i64 %127, i32 1) #14
  br label %for.inc253.peel

for.inc253.peel:                                  ; preds = %if.else163.peel, %if.then142.peel, %if.then150.peel, %if.then158.peel, %if.else199.peel, %if.then178.peel, %if.then186.peel, %if.then194.peel, %if.else232.peel, %if.then220.peel, %if.then227.peel, %if.then244.peel, %if.end136.peel
  %ss.sroa.7.7.peel = phi i8* [ %call.i497, %if.end136.peel ], [ %call.i543.peel, %if.then244.peel ], [ %call.i540.peel, %if.else232.peel ], [ %call2.i.peel, %if.then227.peel ], [ %call.i534.peel, %if.then220.peel ], [ %call.i530.peel, %if.else199.peel ], [ %call.i527.peel, %if.then194.peel ], [ %call.i523.peel, %if.then186.peel ], [ %call.i519.peel, %if.then178.peel ], [ %call.i515.peel, %if.else163.peel ], [ %call.i512.peel, %if.then158.peel ], [ %call.i508.peel, %if.then150.peel ], [ %call.i504.peel, %if.then142.peel ]
  %128 = load i16, i16* %lanes77, align 2, !tbaa !138
  %cmp130.peel = icmp ugt i16 %128, 1
  br i1 %cmp130.peel, label %if.end136, label %if.end263

for.cond.cleanup131:                              ; preds = %for.inc253
  %cmp259 = icmp ugt i16 %154, 1
  br i1 %cmp259, label %if.then260, label %if.end263

if.end136:                                        ; preds = %for.inc253.peel, %for.inc253
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.inc253 ], [ 1, %for.inc253.peel ]
  %ss.sroa.7.5656 = phi i8* [ %ss.sroa.7.7, %for.inc253 ], [ %ss.sroa.7.7.peel, %for.inc253.peel ]
  %call.i500 = tail call i8* @halide_string_to_string(i8* %ss.sroa.7.5656, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #14
  %129 = load i8, i8* %code, align 8, !tbaa !168
  switch i8 %129, label %for.inc253 [
    i8 0, label %if.then140
    i8 1, label %if.then176
    i8 2, label %do.body213
    i8 3, label %if.then244
  ]

if.then140:                                       ; preds = %if.end136
  switch i32 %print_bits.0, label %if.else163 [
    i32 8, label %if.then142
    i32 16, label %if.then150
    i32 32, label %if.then158
  ]

if.then142:                                       ; preds = %if.then140
  %130 = load i8*, i8** %value245, align 8, !tbaa !158
  %arrayidx145 = getelementptr inbounds i8, i8* %130, i64 %indvars.iv
  %131 = load i8, i8* %arrayidx145, align 1, !tbaa !18
  %conv.i503 = sext i8 %131 to i64
  %call.i504 = tail call i8* @halide_int64_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i64 %conv.i503, i32 1) #14
  br label %for.inc253

if.then150:                                       ; preds = %if.then140
  %132 = load i16*, i16** %99, align 8, !tbaa !158
  %arrayidx153 = getelementptr inbounds i16, i16* %132, i64 %indvars.iv
  %133 = load i16, i16* %arrayidx153, align 2, !tbaa !169
  %conv.i507 = sext i16 %133 to i64
  %call.i508 = tail call i8* @halide_int64_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i64 %conv.i507, i32 1) #14
  br label %for.inc253

if.then158:                                       ; preds = %if.then140
  %134 = load i32*, i32** %102, align 8, !tbaa !158
  %arrayidx161 = getelementptr inbounds i32, i32* %134, i64 %indvars.iv
  %135 = load i32, i32* %arrayidx161, align 4, !tbaa !41
  %conv.i511 = sext i32 %135 to i64
  %call.i512 = tail call i8* @halide_int64_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i64 %conv.i511, i32 1) #14
  br label %for.inc253

if.else163:                                       ; preds = %if.then140
  %136 = load i64*, i64** %103, align 8, !tbaa !158
  %arrayidx166 = getelementptr inbounds i64, i64* %136, i64 %indvars.iv
  %137 = load i64, i64* %arrayidx166, align 8, !tbaa !22
  %call.i515 = tail call i8* @halide_int64_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i64 %137, i32 1) #14
  br label %for.inc253

if.then176:                                       ; preds = %if.end136
  switch i32 %print_bits.0, label %if.else199 [
    i32 8, label %if.then178
    i32 16, label %if.then186
    i32 32, label %if.then194
  ]

if.then178:                                       ; preds = %if.then176
  %138 = load i8*, i8** %value245, align 8, !tbaa !158
  %arrayidx181 = getelementptr inbounds i8, i8* %138, i64 %indvars.iv
  %139 = load i8, i8* %arrayidx181, align 1, !tbaa !18
  %conv.i518 = zext i8 %139 to i64
  %call.i519 = tail call i8* @halide_int64_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i64 %conv.i518, i32 1) #14
  br label %for.inc253

if.then186:                                       ; preds = %if.then176
  %140 = load i16*, i16** %99, align 8, !tbaa !158
  %arrayidx189 = getelementptr inbounds i16, i16* %140, i64 %indvars.iv
  %141 = load i16, i16* %arrayidx189, align 2, !tbaa !169
  %conv.i522 = zext i16 %141 to i64
  %call.i523 = tail call i8* @halide_int64_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i64 %conv.i522, i32 1) #14
  br label %for.inc253

if.then194:                                       ; preds = %if.then176
  %142 = load i32*, i32** %102, align 8, !tbaa !158
  %arrayidx197 = getelementptr inbounds i32, i32* %142, i64 %indvars.iv
  %143 = load i32, i32* %arrayidx197, align 4, !tbaa !41
  %conv.i526 = zext i32 %143 to i64
  %call.i527 = tail call i8* @halide_uint64_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i64 %conv.i526, i32 1) #14
  br label %for.inc253

if.else199:                                       ; preds = %if.then176
  %144 = load i64*, i64** %103, align 8, !tbaa !158
  %arrayidx202 = getelementptr inbounds i64, i64* %144, i64 %indvars.iv
  %145 = load i64, i64* %arrayidx202, align 8, !tbaa !22
  %call.i530 = tail call i8* @halide_uint64_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i64 %145, i32 1) #14
  br label %for.inc253

do.body213:                                       ; preds = %if.end136
  br i1 %cmp214, label %do.end218, label %if.then215

if.then215:                                       ; preds = %do.body213
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([142 x i8], [142 x i8]* @.str.24, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end218

do.end218:                                        ; preds = %if.then215, %do.body213
  switch i32 %print_bits.0, label %if.else232 [
    i32 32, label %if.then220
    i32 16, label %if.then227
  ]

if.then220:                                       ; preds = %do.end218
  %146 = load float*, float** %100, align 8, !tbaa !158
  %arrayidx223 = getelementptr inbounds float, float* %146, i64 %indvars.iv
  %147 = load float, float* %arrayidx223, align 4, !tbaa !170
  %conv.i533 = fpext float %147 to double
  %call.i534 = tail call i8* @halide_double_to_string(i8* %call.i500, i8* %ss.sroa.74.0, double %conv.i533, i32 0) #14
  br label %for.inc253

if.then227:                                       ; preds = %do.end218
  %148 = load i16*, i16** %99, align 8, !tbaa !158
  %arrayidx230 = getelementptr inbounds i16, i16* %148, i64 %indvars.iv
  %149 = load i16, i16* %arrayidx230, align 2, !tbaa !169
  %call.i535 = tail call double @halide_float16_bits_to_double(i16 zeroext %149) #14
  %call2.i = tail call i8* @halide_double_to_string(i8* %call.i500, i8* %ss.sroa.74.0, double %call.i535, i32 1) #14
  br label %for.inc253

if.else232:                                       ; preds = %do.end218
  %150 = load double*, double** %101, align 8, !tbaa !158
  %arrayidx235 = getelementptr inbounds double, double* %150, i64 %indvars.iv
  %151 = load double, double* %arrayidx235, align 8, !tbaa !172
  %call.i540 = tail call i8* @halide_double_to_string(i8* %call.i500, i8* %ss.sroa.74.0, double %151, i32 1) #14
  br label %for.inc253

if.then244:                                       ; preds = %if.end136
  %152 = load i8**, i8*** %98, align 8, !tbaa !158
  %arrayidx247 = getelementptr inbounds i8*, i8** %152, i64 %indvars.iv
  %153 = load i8*, i8** %arrayidx247, align 8, !tbaa !14
  %call.i543 = tail call i8* @halide_pointer_to_string(i8* %call.i500, i8* %ss.sroa.74.0, i8* %153) #14
  br label %for.inc253

for.inc253:                                       ; preds = %if.then244, %if.else232, %if.then227, %if.then220, %if.else199, %if.then194, %if.then186, %if.then178, %if.else163, %if.then158, %if.then150, %if.then142, %if.end136
  %ss.sroa.7.7 = phi i8* [ %call.i500, %if.end136 ], [ %call.i543, %if.then244 ], [ %call.i540, %if.else232 ], [ %call2.i, %if.then227 ], [ %call.i534, %if.then220 ], [ %call.i530, %if.else199 ], [ %call.i527, %if.then194 ], [ %call.i523, %if.then186 ], [ %call.i519, %if.then178 ], [ %call.i515, %if.else163 ], [ %call.i512, %if.then158 ], [ %call.i508, %if.then150 ], [ %call.i504, %if.then142 ]
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %154 = load i16, i16* %lanes77, align 2, !tbaa !138
  %155 = zext i16 %154 to i64
  %cmp130 = icmp ult i64 %indvars.iv.next, %155
  br i1 %cmp130, label %if.end136, label %for.cond.cleanup131, !llvm.loop !174

if.then260:                                       ; preds = %for.cond.cleanup131
  %call.i546 = tail call i8* @halide_string_to_string(i8* %ss.sroa.7.7, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.25, i64 0, i64 0)) #14
  br label %if.end263

if.end263:                                        ; preds = %if.then260, %for.cond.cleanup131, %for.inc253.peel, %if.then115, %for.cond.cleanup
  %ss.sroa.7.8 = phi i8* [ %call.i546, %if.then260 ], [ %ss.sroa.7.7, %for.cond.cleanup131 ], [ %call.i491, %for.cond.cleanup ], [ %ss.sroa.7.7.peel, %for.inc253.peel ], [ %call.i497, %if.then115 ]
  %trace_tag264 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %e, i64 0, i32 3
  %156 = load i8*, i8** %trace_tag264, align 8, !tbaa !147
  %tobool265.not = icmp eq i8* %156, null
  br i1 %tobool265.not, label %if.end274, label %land.lhs.true266

land.lhs.true266:                                 ; preds = %if.end263
  %157 = load i8, i8* %156, align 1, !tbaa !18
  %tobool268.not = icmp eq i8 %157, 0
  br i1 %tobool268.not, label %if.end274, label %if.then269

if.then269:                                       ; preds = %land.lhs.true266
  %call.i549 = tail call i8* @halide_string_to_string(i8* %ss.sroa.7.8, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.26, i64 0, i64 0)) #14
  %158 = load i8*, i8** %trace_tag264, align 8, !tbaa !147
  %call.i552 = tail call i8* @halide_string_to_string(i8* %call.i549, i8* %ss.sroa.74.0, i8* %158) #14
  %call.i555 = tail call i8* @halide_string_to_string(i8* %call.i552, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.27, i64 0, i64 0)) #14
  br label %if.end274

if.end274:                                        ; preds = %if.then269, %land.lhs.true266, %if.end263
  %ss.sroa.7.9 = phi i8* [ %ss.sroa.7.8, %if.end263 ], [ %ss.sroa.7.8, %land.lhs.true266 ], [ %call.i555, %if.then269 ]
  %call.i558 = tail call i8* @halide_string_to_string(i8* %ss.sroa.7.9, i8* %ss.sroa.74.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.7.164, i64 0, i64 0)) #14
  br label %while.cond.i560

while.cond.i560:                                  ; preds = %while.cond.i560, %if.end274
  %159 = atomicrmw volatile xchg i8* @_ZN6Halide7Runtime8Internal22halide_trace_file_lockE, i8 1 acquire
  %tobool.not.i559 = icmp eq i8 %159, 0
  br i1 %tobool.not.i559, label %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit, label %while.cond.i560, !llvm.loop !175

_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit: ; preds = %while.cond.i560
  br i1 %tobool.not.i448, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  store atomic volatile i8 0, i8* @_ZN6Halide7Runtime8Internal22halide_trace_file_lockE release, align 1
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit
  %sub.ptr.lhs.cast.i.i563 = ptrtoint i8* %call.i558 to i64
  %sub.ptr.rhs.cast.i.i564 = ptrtoint i8* %call.i445 to i64
  %sub.ptr.sub.i.i565 = sub i64 1, %sub.ptr.rhs.cast.i.i564
  %add.i.i566 = add i64 %sub.ptr.sub.i.i565, %sub.ptr.lhs.cast.i.i563
  %call.i.i567 = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i445, i64 %add.i.i566) #14
  tail call void @halide_print(i8* %user_context, i8* nonnull %call.i445) #14
  store atomic volatile i8 0, i8* @_ZN6Halide7Runtime8Internal22halide_trace_file_lockE release, align 1
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i445, i64 %add.i.i566) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i445) #14
  br label %if.end277

if.end277:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy4096EED2Ev.exit, %do.end.critedge.i, %if.then10.i, %if.then.i442, %_ZN21halide_trace_packet_t9trace_tagEv.exit
  ret i32 %0
}

; Function Attrs: nounwind
define weak i32 @halide_get_trace_file(i8* %user_context) local_unnamed_addr #4 {
entry:
  br label %while.cond.i

while.cond.i:                                     ; preds = %while.cond.i, %entry
  %0 = atomicrmw volatile xchg i8* @_ZN6Halide7Runtime8Internal22halide_trace_file_lockE, i8 1 acquire
  %tobool.not.i = icmp eq i8 %0, 0
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit, label %while.cond.i, !llvm.loop !175

_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit: ; preds = %while.cond.i
  %1 = load i32, i32* @_ZN6Halide7Runtime8Internal17halide_trace_fileE, align 4, !tbaa !41
  %cmp = icmp slt i32 %1, 0
  br i1 %cmp, label %if.then, label %if.end11

if.then:                                          ; preds = %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit
  %call = tail call i8* @getenv(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.28, i64 0, i64 0)) #14
  %tobool.not = icmp eq i8* %call, null
  br i1 %tobool.not, label %if.else, label %if.then1

if.then1:                                         ; preds = %if.then
  %call2 = tail call i8* @fopen(i8* nonnull %call, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.29, i64 0, i64 0)) #14
  %tobool3.not = icmp eq i8* %call2, null
  br i1 %tobool3.not, label %if.then4, label %do.end

if.then4:                                         ; preds = %if.then1
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([139 x i8], [139 x i8]* @.str.30, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then4, %if.then1
  %call5 = tail call i32 @fileno(i8* %call2) #14
  tail call void @halide_set_trace_file(i32 %call5) #16
  store i8* %call2, i8** @_ZN6Halide7Runtime8Internal35halide_trace_file_internally_openedE, align 8, !tbaa !14
  %2 = load %"class.Halide::Runtime::Internal::TraceBuffer"*, %"class.Halide::Runtime::Internal::TraceBuffer"** @_ZN6Halide7Runtime8Internal19halide_trace_bufferE, align 8, !tbaa !14
  %tobool6.not = icmp eq %"class.Halide::Runtime::Internal::TraceBuffer"* %2, null
  br i1 %tobool6.not, label %if.then7, label %if.end11

if.then7:                                         ; preds = %do.end
  %call8 = tail call i8* @malloc(i64 1048588) #14
  store i8* %call8, i8** bitcast (%"class.Halide::Runtime::Internal::TraceBuffer"** @_ZN6Halide7Runtime8Internal19halide_trace_bufferE to i8**), align 8, !tbaa !14
  %cursor.i = getelementptr inbounds i8, i8* %call8, i64 4
  %3 = bitcast i8* %cursor.i to <2 x i32>*
  store <2 x i32> zeroinitializer, <2 x i32>* %3, align 4, !tbaa !41
  %lock.i.i = bitcast i8* %call8 to i32*
  store volatile i32 0, i32* %lock.i.i, align 4, !tbaa !148
  br label %if.end11

if.else:                                          ; preds = %if.then
  tail call void @halide_set_trace_file(i32 0) #16
  br label %if.end11

if.end11:                                         ; preds = %if.else, %if.then7, %do.end, %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit
  %4 = load i32, i32* @_ZN6Halide7Runtime8Internal17halide_trace_fileE, align 4, !tbaa !41
  store atomic volatile i8 0, i8* @_ZN6Halide7Runtime8Internal22halide_trace_file_lockE release, align 1
  ret i32 %4
}

declare i8* @memcpy(i8*, i8*, i64) local_unnamed_addr #1

declare i8* @fopen(i8*, i8*) local_unnamed_addr #1

declare i32 @fileno(i8*) local_unnamed_addr #1

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_set_trace_file(i32 %fd) local_unnamed_addr #2 {
entry:
  store i32 %fd, i32* @_ZN6Halide7Runtime8Internal17halide_trace_fileE, align 4, !tbaa !41
  ret void
}

; Function Attrs: nounwind mustprogress
define weak void @halide_trace_cleanup() #0 {
entry:
  %call = tail call i32 @halide_shutdown_trace() #16
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_shutdown_trace() local_unnamed_addr #0 {
entry:
  %0 = load i8*, i8** @_ZN6Halide7Runtime8Internal35halide_trace_file_internally_openedE, align 8, !tbaa !14
  %tobool.not = icmp eq i8* %0, null
  br i1 %tobool.not, label %return, label %if.then

if.then:                                          ; preds = %entry
  %call = tail call i32 @fclose(i8* nonnull %0) #14
  store i32 0, i32* @_ZN6Halide7Runtime8Internal17halide_trace_fileE, align 4, !tbaa !41
  store i8 0, i8* @_ZN6Halide7Runtime8Internal29halide_trace_file_initializedE, align 1, !tbaa !19
  store i8* null, i8** @_ZN6Halide7Runtime8Internal35halide_trace_file_internally_openedE, align 8, !tbaa !14
  %1 = load %"class.Halide::Runtime::Internal::TraceBuffer"*, %"class.Halide::Runtime::Internal::TraceBuffer"** @_ZN6Halide7Runtime8Internal19halide_trace_bufferE, align 8, !tbaa !14
  %tobool1.not = icmp eq %"class.Halide::Runtime::Internal::TraceBuffer"* %1, null
  br i1 %tobool1.not, label %return, label %if.then2

if.then2:                                         ; preds = %if.then
  %2 = bitcast %"class.Halide::Runtime::Internal::TraceBuffer"* %1 to i8*
  tail call void @free(i8* nonnull %2) #14
  br label %return

return:                                           ; preds = %if.then2, %if.then, %entry
  %retval.0 = phi i32 [ %call, %if.then2 ], [ %call, %if.then ], [ 0, %entry ]
  ret i32 %retval.0
}

declare i32 @fclose(i8*) local_unnamed_addr #1

; Function Attrs: nounwind willreturn mustprogress
define weak i32 (i8*, %struct.halide_trace_event_t*)* @halide_set_custom_trace(i32 (i8*, %struct.halide_trace_event_t*)* %t) local_unnamed_addr #2 {
entry:
  %0 = load i32 (i8*, %struct.halide_trace_event_t*)*, i32 (i8*, %struct.halide_trace_event_t*)** @_ZN6Halide7Runtime8Internal19halide_custom_traceE, align 8, !tbaa !14
  store i32 (i8*, %struct.halide_trace_event_t*)* %t, i32 (i8*, %struct.halide_trace_event_t*)** @_ZN6Halide7Runtime8Internal19halide_custom_traceE, align 8, !tbaa !14
  ret i32 (i8*, %struct.halide_trace_event_t*)* %0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_trace(i8* %user_context, %struct.halide_trace_event_t* %e) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, %struct.halide_trace_event_t*)*, i32 (i8*, %struct.halide_trace_event_t*)** @_ZN6Halide7Runtime8Internal19halide_custom_traceE, align 8, !tbaa !14
  %call = tail call i32 %0(i8* %user_context, %struct.halide_trace_event_t* %e) #14
  ret i32 %call
}

; Function Attrs: nounwind
define weak i32 @halide_trace_helper(i8* %user_context, i8* %func, i8* %value, i32* %coords, i32 %type_code, i32 %type_bits, i32 %type_lanes, i32 %code, i32 %parent_id, i32 %value_index, i32 %dimensions, i8* %trace_tag) local_unnamed_addr #4 {
entry:
  %event = alloca %struct.halide_trace_event_t, align 8
  %0 = bitcast %struct.halide_trace_event_t* %event to i8*
  call void @llvm.lifetime.start.p0i8(i64 56, i8* nonnull %0) #15
  %code.i.i = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 4, i32 0
  %bits.i.i = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 4, i32 1
  %lanes.i.i = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 4, i32 2
  %func1 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 0
  store i8* %func, i8** %func1, align 8, !tbaa !146
  %value2 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 1
  store i8* %value, i8** %value2, align 8, !tbaa !158
  %coordinates = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 2
  store i32* %coords, i32** %coordinates, align 8, !tbaa !157
  %trace_tag3 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 3
  store i8* %trace_tag, i8** %trace_tag3, align 8, !tbaa !147
  %conv = trunc i32 %type_code to i8
  store i8 %conv, i8* %code.i.i, align 8, !tbaa !168
  %conv5 = trunc i32 %type_bits to i8
  store i8 %conv5, i8* %bits.i.i, align 1, !tbaa !163
  %conv7 = trunc i32 %type_lanes to i16
  store i16 %conv7, i16* %lanes.i.i, align 2, !tbaa !138
  %event9 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 5
  store i32 %code, i32* %event9, align 4, !tbaa !162
  %parent_id10 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 6
  store i32 %parent_id, i32* %parent_id10, align 8, !tbaa !176
  %value_index11 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 7
  store i32 %value_index, i32* %value_index11, align 4, !tbaa !165
  %dimensions12 = getelementptr inbounds %struct.halide_trace_event_t, %struct.halide_trace_event_t* %event, i64 0, i32 8
  store i32 %dimensions, i32* %dimensions12, align 8, !tbaa !145
  %call = call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %0, i64 56) #14
  %add = add nsw i32 %type_bits, 7
  %div = sdiv i32 %add, 8
  %mul = mul nsw i32 %div, %type_lanes
  %conv13 = sext i32 %mul to i64
  %call14 = call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* %value, i64 %conv13) #14
  %1 = bitcast i32* %coords to i8*
  %conv15 = sext i32 %dimensions to i64
  %mul16 = shl nsw i64 %conv15, 2
  %call17 = call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* %1, i64 %mul16) #14
  %call18 = call i32 @halide_trace(i8* %user_context, %struct.halide_trace_event_t* nonnull %event) #14
  call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %0) #15
  ret i32 %call18
}

; Function Attrs: nounwind mustprogress
define linkonce zeroext i1 @_ZN6Halide7Runtime8Internal9ends_withEPKcS3_(i8* %filename, i8* %suffix) local_unnamed_addr #0 {
entry:
  br label %while.cond

while.cond:                                       ; preds = %while.cond, %entry
  %f.0 = phi i8* [ %filename, %entry ], [ %incdec.ptr, %while.cond ]
  %0 = load i8, i8* %f.0, align 1, !tbaa !18
  %tobool.not = icmp eq i8 %0, 0
  %incdec.ptr = getelementptr inbounds i8, i8* %f.0, i64 1
  br i1 %tobool.not, label %while.cond1, label %while.cond, !llvm.loop !177

while.cond1:                                      ; preds = %while.cond, %while.cond1
  %s.0 = phi i8* [ %incdec.ptr4, %while.cond1 ], [ %suffix, %while.cond ]
  %1 = load i8, i8* %s.0, align 1, !tbaa !18
  %tobool2.not = icmp eq i8 %1, 0
  %incdec.ptr4 = getelementptr inbounds i8, i8* %s.0, i64 1
  br i1 %tobool2.not, label %while.cond6.preheader, label %while.cond1, !llvm.loop !178

while.cond6.preheader:                            ; preds = %while.cond1
  %cmp34 = icmp ne i8* %s.0, %suffix
  %cmp735 = icmp ne i8* %f.0, %filename
  %2 = and i1 %cmp735, %cmp34
  br i1 %2, label %if.end, label %while.cond6.preheader.while.end13_crit_edge

while.cond6.preheader.while.end13_crit_edge:      ; preds = %while.cond6.preheader
  %cmp16.0 = icmp eq i8 0, 0
  br label %while.end13

if.end:                                           ; preds = %while.cond6.preheader, %if.end.while.body8_crit_edge
  %f.13649 = phi i8* [ %incdec.ptr11, %if.end.while.body8_crit_edge ], [ %f.0, %while.cond6.preheader ]
  %s.13748 = phi i8* [ %incdec.ptr12, %if.end.while.body8_crit_edge ], [ %s.0, %while.cond6.preheader ]
  %incdec.ptr11 = getelementptr inbounds i8, i8* %f.13649, i64 -1
  %incdec.ptr12 = getelementptr inbounds i8, i8* %s.13748, i64 -1
  %cmp = icmp ne i8* %incdec.ptr12, %suffix
  %cmp7 = icmp ne i8* %incdec.ptr11, %filename
  %3 = and i1 %cmp7, %cmp
  %.pre = load i8, i8* %incdec.ptr11, align 1, !tbaa !18
  %.pre45 = load i8, i8* %incdec.ptr12, align 1, !tbaa !18
  br i1 %3, label %if.end.while.body8_crit_edge, label %if.end.while.end13_crit_edge, !llvm.loop !179

if.end.while.end13_crit_edge:                     ; preds = %if.end
  %cmp16.1 = icmp eq i8 %.pre, %.pre45
  br label %while.end13

if.end.while.body8_crit_edge:                     ; preds = %if.end
  %cmp10.not = icmp eq i8 %.pre, %.pre45
  br i1 %cmp10.not, label %if.end, label %cleanup

while.end13:                                      ; preds = %if.end.while.end13_crit_edge, %while.cond6.preheader.while.end13_crit_edge
  %cmp16.phi = phi i1 [ %cmp16.0, %while.cond6.preheader.while.end13_crit_edge ], [ %cmp16.1, %if.end.while.end13_crit_edge ]
  br label %cleanup

cleanup:                                          ; preds = %if.end.while.body8_crit_edge, %while.end13
  %retval.0 = phi i1 [ %cmp16.phi, %while.end13 ], [ false, %if.end.while.body8_crit_edge ]
  ret i1 %retval.0
}

; Function Attrs: nounwind
define weak i32 @halide_debug_to_file(i8* %user_context, i8* %filename, i32 %type_code, %struct.halide_buffer_t* %buf) local_unnamed_addr #4 {
entry:
  %shape = alloca [4 x %struct.halide_dimension_t], align 16
  %header = alloca %"struct.Halide::Runtime::Internal::halide_tiff_header", align 2
  %offset = alloca i32, align 4
  %count = alloca i32, align 4
  %array_name = alloca [256 x i8], align 1
  %array_name43 = getelementptr inbounds [256 x i8], [256 x i8]* %array_name, i64 0, i64 0
  %header198 = alloca [129 x i8], align 1
  %tags = alloca [8 x i32], align 4
  %extents = alloca [4 x i32], align 4
  %name_header = alloca [2 x i32], align 4
  %payload_header = alloca [2 x i32], align 4
  %header289 = alloca [5 x i32], align 4
  %temp = alloca [4096 x i8], align 1
  %idx = alloca [4 x i32], align 4
  %zero = alloca i64, align 8
  %host.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 2
  %0 = load i8*, i8** %host.i, align 8, !tbaa !180
  %cmp.i = icmp eq i8* %0, null
  br i1 %cmp.i, label %_ZNK15halide_buffer_t15is_bounds_queryEv.exit, label %if.end

_ZNK15halide_buffer_t15is_bounds_queryEv.exit:    ; preds = %entry
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp2.i = icmp eq i64 %1, 0
  br i1 %cmp2.i, label %if.then, label %if.end

if.then:                                          ; preds = %_ZNK15halide_buffer_t15is_bounds_queryEv.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([51 x i8], [51 x i8]* @.str.34, i64 0, i64 0)) #14
  br label %return

if.end:                                           ; preds = %_ZNK15halide_buffer_t15is_bounds_queryEv.exit, %entry
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 5
  %2 = load i32, i32* %dimensions, align 4, !tbaa !183
  %cmp = icmp sgt i32 %2, 4
  br i1 %cmp, label %if.then1, label %if.end2

if.then1:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([59 x i8], [59 x i8]* @.str.1.35, i64 0, i64 0)) #14
  br label %return

if.end2:                                          ; preds = %if.end
  %call3 = tail call i32 @halide_copy_to_host(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %cmp4.not = icmp eq i32 %call3, 0
  br i1 %cmp4.not, label %if.end6, label %return

if.end6:                                          ; preds = %if.end2
  %call.i598 = tail call i8* @fopen(i8* %filename, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.2.36, i64 0, i64 0)) #14
  %cmp.i601.not = icmp eq i8* %call.i598, null
  br i1 %cmp.i601.not, label %return, label %if.end9

if.end9:                                          ; preds = %if.end6
  %3 = bitcast [4 x %struct.halide_dimension_t]* %shape to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %3) #15
  %min.i = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 0, i32 0
  %extent.i = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 0, i32 1
  %4 = bitcast [4 x %struct.halide_dimension_t]* %shape to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %4, align 16, !tbaa !41
  %min.i.1 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 1, i32 0
  %extent.i.1 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 1, i32 1
  %5 = bitcast i32* %min.i.1 to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %5, align 16, !tbaa !41
  %min.i.2 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 2, i32 0
  %extent.i.2 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 2, i32 1
  %6 = bitcast i32* %min.i.2 to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %6, align 16, !tbaa !41
  %min.i.3 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 3, i32 0
  %extent.i.3 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 3, i32 1
  %7 = bitcast i32* %min.i.3 to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %7, align 16, !tbaa !41
  %8 = load i32, i32* %dimensions, align 4, !tbaa !183
  %cmp11875 = icmp sgt i32 %8, 0
  br i1 %cmp11875, label %for.body.lr.ph, label %for.body22.preheader

for.body.lr.ph:                                   ; preds = %if.end9
  %dim = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 6
  %9 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !184
  %10 = zext i32 %8 to i64
  %11 = add nsw i64 %10, -1
  %12 = icmp ult i64 %11, 3
  %13 = select i1 %12, i64 %10, i64 4
  br label %for.body

for.cond19.preheader:                             ; preds = %for.body
  %cmp20873 = icmp slt i32 %8, 4
  br i1 %cmp20873, label %for.body22.preheader, label %for.cond.cleanup21

for.body22.preheader:                             ; preds = %for.cond19.preheader, %if.end9
  %elts.0.lcssa907 = phi i64 [ %mul, %for.cond19.preheader ], [ 1, %if.end9 ]
  %14 = sext i32 %8 to i64
  %15 = sub i32 3, %8
  %16 = zext i32 %15 to i64
  %17 = add nuw nsw i64 %16, 1
  %min.iters.check = icmp eq i32 %15, 0
  br i1 %min.iters.check, label %for.body22.preheader162, label %vector.ph

vector.ph:                                        ; preds = %for.body22.preheader
  %n.vec = and i64 %17, 8589934590
  %ind.end = add nsw i64 %n.vec, %14
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %offset.idx = add i64 %index, %14
  %induction36 = add i64 %offset.idx, 1
  %18 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 %offset.idx, i32 0
  %19 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 %induction36, i32 0
  %20 = bitcast i32* %18 to <2 x i32>*
  store <2 x i32> <i32 0, i32 1>, <2 x i32>* %20, align 16, !tbaa !41
  %21 = bitcast i32* %19 to <2 x i32>*
  store <2 x i32> <i32 0, i32 1>, <2 x i32>* %21, align 16, !tbaa !41
  %22 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 %offset.idx, i32 2
  %23 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 %induction36, i32 2
  store i32 0, i32* %22, align 8, !tbaa !185
  store i32 0, i32* %23, align 8, !tbaa !185
  %index.next = add i64 %index, 2
  %24 = icmp eq i64 %index.next, %n.vec
  br i1 %24, label %middle.block, label %vector.body, !llvm.loop !187

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %17, %n.vec
  br i1 %cmp.n, label %for.cond.cleanup21, label %for.body22.preheader162

for.body22.preheader162:                          ; preds = %for.body22.preheader, %middle.block
  %indvars.iv.ph = phi i64 [ %14, %for.body22.preheader ], [ %ind.end, %middle.block ]
  br label %for.body22

for.body:                                         ; preds = %for.body, %for.body.lr.ph
  %indvars.iv887 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next888, %for.body ]
  %elts.0877 = phi i64 [ 1, %for.body.lr.ph ], [ %mul, %for.body ]
  %arrayidx = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %9, i64 %indvars.iv887
  %arrayidx14 = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 %indvars.iv887
  %25 = bitcast %struct.halide_dimension_t* %arrayidx14 to i8*
  %26 = bitcast %struct.halide_dimension_t* %arrayidx to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 dereferenceable(16) %25, i8* nonnull align 4 dereferenceable(16) %26, i64 16, i1 false), !tbaa.struct !188
  %extent = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 %indvars.iv887, i32 1
  %27 = load i32, i32* %extent, align 4, !tbaa !189
  %conv903 = zext i32 %27 to i64
  %mul = mul i64 %elts.0877, %conv903
  %indvars.iv.next888 = add nuw nsw i64 %indvars.iv887, 1
  %exitcond.not17 = icmp eq i64 %indvars.iv.next888, %13
  br i1 %exitcond.not17, label %for.cond19.preheader, label %for.body, !llvm.loop !190

for.cond.cleanup21:                               ; preds = %for.body22, %middle.block, %for.cond19.preheader
  %elts.0.lcssa906 = phi i64 [ %mul, %for.cond19.preheader ], [ %elts.0.lcssa907, %middle.block ], [ %elts.0.lcssa907, %for.body22 ]
  %bits.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 4, i32 1
  %28 = load i8, i8* %bits.i, align 1, !tbaa !144
  %conv.i = zext i8 %28 to i32
  %add.i = add nuw nsw i32 %conv.i, 7
  %div.i = lshr i32 %add.i, 3
  %call34 = tail call zeroext i1 @_ZN6Halide7Runtime8Internal9ends_withEPKcS3_(i8* %filename, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.3.37, i64 0, i64 0)) #16
  br i1 %call34, label %if.then36, label %lor.lhs.false

for.body22:                                       ; preds = %for.body22.preheader162, %for.body22
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body22 ], [ %indvars.iv.ph, %for.body22.preheader162 ]
  %min = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 %indvars.iv, i32 0
  %29 = bitcast i32* %min to <2 x i32>*
  store <2 x i32> <i32 0, i32 1>, <2 x i32>* %29, align 16, !tbaa !41
  %stride = getelementptr inbounds [4 x %struct.halide_dimension_t], [4 x %struct.halide_dimension_t]* %shape, i64 0, i64 %indvars.iv, i32 2
  store i32 0, i32* %stride, align 8, !tbaa !185
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %lftr.wideiv = trunc i64 %indvars.iv.next to i32
  %exitcond886.not = icmp eq i32 %lftr.wideiv, 4
  br i1 %exitcond886.not, label %for.cond.cleanup21, label %for.body22, !llvm.loop !191

lor.lhs.false:                                    ; preds = %for.cond.cleanup21
  %call35 = tail call zeroext i1 @_ZN6Halide7Runtime8Internal9ends_withEPKcS3_(i8* %filename, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.4.38, i64 0, i64 0)) #16
  br i1 %call35, label %if.then36, label %if.else164

if.then36:                                        ; preds = %lor.lhs.false, %for.cond.cleanup21
  %30 = load i32, i32* %extent.i, align 4, !tbaa !189
  %31 = load i32, i32* %extent.i.1, align 4, !tbaa !189
  %32 = load i32, i32* %extent.i.3, align 4, !tbaa !189
  %switch = icmp ult i32 %32, 2
  %33 = load i32, i32* %extent.i.2, align 4, !tbaa !189
  %cmp50 = icmp slt i32 %33, 5
  %or.cond = and i1 %switch, %cmp50
  %depth.0 = select i1 %or.cond, i32 1, i32 %33
  %channels.0 = select i1 %or.cond, i32 %33, i32 %32
  %34 = bitcast %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header to i8*
  call void @llvm.lifetime.start.p0i8(i64 210, i8* nonnull %34) #15
  %byte_order_marker = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 0
  store i16 18761, i16* %byte_order_marker, align 2, !tbaa !192
  %version = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 1
  store i16 42, i16* %version, align 2, !tbaa !194
  %ifd0_offset = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 2
  store i32 8, i32* %ifd0_offset, align 2, !tbaa !195
  %entry_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 3
  store i16 15, i16* %entry_count, align 2, !tbaa !196
  %tag_code2.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 0, i32 0
  store i16 256, i16* %tag_code2.i, align 2, !tbaa !197
  %type_code.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 0, i32 1
  store i16 4, i16* %type_code.i, align 2, !tbaa !199
  %count3.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 0, i32 2
  store i32 1, i32* %count3.i, align 2, !tbaa !200
  %i32.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 0, i32 3, i32 0
  store i32 %30, i32* %i32.i, align 2, !tbaa !18
  %tag_code2.i632 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 1, i32 0
  store i16 257, i16* %tag_code2.i632, align 2, !tbaa !197
  %type_code.i633 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 1, i32 1
  store i16 4, i16* %type_code.i633, align 2, !tbaa !199
  %count3.i634 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 1, i32 2
  store i32 1, i32* %count3.i634, align 2, !tbaa !200
  %i32.i635 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 1, i32 3, i32 0
  store i32 %31, i32* %i32.i635, align 2, !tbaa !18
  %35 = trunc i32 %add.i to i16
  %conv68 = and i16 %35, 504
  %tag_code2.i643 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 2, i32 0
  store i16 258, i16* %tag_code2.i643, align 2, !tbaa !197
  %type_code.i644 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 2, i32 1
  store i16 3, i16* %type_code.i644, align 2, !tbaa !199
  %count3.i645 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 2, i32 2
  store i32 1, i32* %count3.i645, align 2, !tbaa !200
  %value4.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 2, i32 3
  %i16.i = bitcast %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock"* %value4.i to i16*
  store i16 %conv68, i16* %i16.i, align 2, !tbaa !18
  %tag_code2.i653 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 3, i32 0
  store i16 259, i16* %tag_code2.i653, align 2, !tbaa !197
  %type_code.i654 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 3, i32 1
  store i16 3, i16* %type_code.i654, align 2, !tbaa !199
  %count3.i655 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 3, i32 2
  store i32 1, i32* %count3.i655, align 2, !tbaa !200
  %value4.i656 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 3, i32 3
  %i16.i657 = bitcast %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock"* %value4.i656 to i16*
  store i16 1, i16* %i16.i657, align 2, !tbaa !18
  %cmp71 = icmp sgt i32 %channels.0, 2
  %conv72 = select i1 %cmp71, i16 2, i16 1
  %tag_code2.i665 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 4, i32 0
  store i16 262, i16* %tag_code2.i665, align 2, !tbaa !197
  %type_code.i666 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 4, i32 1
  store i16 3, i16* %type_code.i666, align 2, !tbaa !199
  %count3.i667 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 4, i32 2
  store i32 1, i32* %count3.i667, align 2, !tbaa !200
  %value4.i668 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 4, i32 3
  %i16.i669 = bitcast %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock"* %value4.i668 to i16*
  store i16 %conv72, i16* %i16.i669, align 2, !tbaa !18
  %tag_code2.i677 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 5, i32 0
  store i16 273, i16* %tag_code2.i677, align 2, !tbaa !197
  %type_code.i678 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 5, i32 1
  store i16 4, i16* %type_code.i678, align 2, !tbaa !199
  %count3.i679 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 5, i32 2
  store i32 %channels.0, i32* %count3.i679, align 2, !tbaa !200
  %i32.i680 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 5, i32 3, i32 0
  store i32 210, i32* %i32.i680, align 2, !tbaa !18
  %conv75 = trunc i32 %channels.0 to i16
  %tag_code2.i688 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 6, i32 0
  store i16 277, i16* %tag_code2.i688, align 2, !tbaa !197
  %type_code.i689 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 6, i32 1
  store i16 3, i16* %type_code.i689, align 2, !tbaa !199
  %count3.i690 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 6, i32 2
  store i32 1, i32* %count3.i690, align 2, !tbaa !200
  %value4.i691 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 6, i32 3
  %i16.i692 = bitcast %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock"* %value4.i691 to i16*
  store i16 %conv75, i16* %i16.i692, align 2, !tbaa !18
  %tag_code2.i706 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 7, i32 0
  store i16 278, i16* %tag_code2.i706, align 2, !tbaa !197
  %type_code.i707 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 7, i32 1
  store i16 4, i16* %type_code.i707, align 2, !tbaa !199
  %count3.i708 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 7, i32 2
  store i32 1, i32* %count3.i708, align 2, !tbaa !200
  %i32.i709 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 7, i32 3, i32 0
  store i32 %31, i32* %i32.i709, align 2, !tbaa !18
  %cmp80 = icmp eq i32 %channels.0, 1
  %36 = trunc i64 %elts.0.lcssa906 to i32
  %conv86595 = mul i32 %div.i, %36
  %mul84 = shl i32 %channels.0, 2
  %add = add i32 %mul84, 210
  %add.sink = select i1 %cmp80, i32 %conv86595, i32 %add
  %37 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 8, i32 0
  store i16 279, i16* %37, align 2
  %38 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 8, i32 1
  store i16 4, i16* %38, align 2
  %39 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 8, i32 2
  store i32 %channels.0, i32* %39, align 2
  %40 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 8, i32 3, i32 0
  store i32 %add.sink, i32* %40, align 2
  %tag_code2.i732 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 9, i32 0
  store i16 282, i16* %tag_code2.i732, align 2, !tbaa !197
  %type_code3.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 9, i32 1
  store i16 5, i16* %type_code3.i, align 2, !tbaa !199
  %count4.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 9, i32 2
  %41 = bitcast i32* %count4.i to <2 x i32>*
  store <2 x i32> <i32 1, i32 194>, <2 x i32>* %41, align 2, !tbaa !18
  %tag_code2.i741 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 10, i32 0
  store i16 283, i16* %tag_code2.i741, align 2, !tbaa !197
  %type_code3.i742 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 10, i32 1
  store i16 5, i16* %type_code3.i742, align 2, !tbaa !199
  %count4.i743 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 10, i32 2
  %42 = bitcast i32* %count4.i743 to <2 x i32>*
  store <2 x i32> <i32 1, i32 202>, <2 x i32>* %42, align 2, !tbaa !18
  %tag_code2.i759 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 11, i32 0
  store i16 284, i16* %tag_code2.i759, align 2, !tbaa !197
  %type_code.i760 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 11, i32 1
  store i16 3, i16* %type_code.i760, align 2, !tbaa !199
  %count3.i761 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 11, i32 2
  store i32 1, i32* %count3.i761, align 2, !tbaa !200
  %value4.i762 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 11, i32 3
  %i16.i763 = bitcast %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock"* %value4.i762 to i16*
  store i16 2, i16* %i16.i763, align 2, !tbaa !18
  %tag_code2.i754 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 12, i32 0
  store i16 296, i16* %tag_code2.i754, align 2, !tbaa !197
  %type_code.i755 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 12, i32 1
  store i16 3, i16* %type_code.i755, align 2, !tbaa !199
  %count3.i756 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 12, i32 2
  store i32 1, i32* %count3.i756, align 2, !tbaa !200
  %value4.i757 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 12, i32 3
  %i16.i758 = bitcast %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock"* %value4.i757 to i16*
  store i16 1, i16* %i16.i758, align 2, !tbaa !18
  %idxprom92 = sext i32 %type_code to i64
  %arrayidx93 = getelementptr inbounds [10 x i16], [10 x i16]* @_ZN6Halide7Runtime8Internal30pixel_type_to_tiff_sample_typeE, i64 0, i64 %idxprom92
  %43 = load i16, i16* %arrayidx93, align 2, !tbaa !169
  %tag_code2.i749 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 13, i32 0
  store i16 339, i16* %tag_code2.i749, align 2, !tbaa !197
  %type_code.i750 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 13, i32 1
  store i16 3, i16* %type_code.i750, align 2, !tbaa !199
  %count3.i751 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 13, i32 2
  store i32 1, i32* %count3.i751, align 2, !tbaa !200
  %value4.i752 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 13, i32 3
  %i16.i753 = bitcast %"class.Halide::Runtime::Internal::SharedExclusiveSpinLock"* %value4.i752 to i16*
  store i16 %43, i16* %i16.i753, align 2, !tbaa !18
  %tag_code2.i745 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 14, i32 0
  store i16 -32539, i16* %tag_code2.i745, align 2, !tbaa !197
  %type_code.i746 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 14, i32 1
  store i16 4, i16* %type_code.i746, align 2, !tbaa !199
  %count3.i747 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 14, i32 2
  store i32 1, i32* %count3.i747, align 2, !tbaa !200
  %i32.i748 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 4, i64 14, i32 3, i32 0
  store i32 %depth.0, i32* %i32.i748, align 2, !tbaa !18
  %ifd0_end = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 5
  %44 = bitcast i32* %ifd0_end to <4 x i32>*
  store <4 x i32> <i32 0, i32 1, i32 1, i32 1>, <4 x i32>* %44, align 2, !tbaa !41
  %arrayidx100 = getelementptr inbounds %"struct.Halide::Runtime::Internal::halide_tiff_header", %"struct.Halide::Runtime::Internal::halide_tiff_header"* %header, i64 0, i32 7, i64 1
  store i32 1, i32* %arrayidx100, align 2, !tbaa !41
  %call.i736 = call i64 @fwrite(i8* nonnull %34, i64 210, i64 1, i8* nonnull %call.i598) #14
  %cmp.i737.not = icmp eq i64 %call.i736, 0
  br i1 %cmp.i737.not, label %cleanup154, label %if.end103

if.end103:                                        ; preds = %if.then36
  %cmp104 = icmp sgt i32 %channels.0, 1
  br i1 %cmp104, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731.lr.ph, label %cleanup154.thread

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731.lr.ph: ; preds = %if.end103
  %45 = bitcast i32* %offset to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %45) #15
  %mul108 = shl i32 %channels.0, 3
  %add109 = add i32 %mul108, 210
  store i32 %add109, i32* %offset, align 4, !tbaa !41
  %mul123 = mul i32 %depth.0, %div.i
  %46 = load i32, i32* %extent.i, align 4
  %47 = load i32, i32* %extent.i.1, align 4
  %mul124 = mul i32 %mul123, %46
  %mul125 = mul i32 %mul124, %47
  br label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731: ; preds = %if.end118, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731.lr.ph
  %i111.0865 = phi i32 [ 0, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731.lr.ph ], [ %inc128, %if.end118 ]
  %call.i727 = call i64 @fwrite(i8* nonnull %45, i64 4, i64 1, i8* nonnull %call.i598) #14
  %cmp.i728.not = icmp eq i64 %call.i727, 0
  br i1 %cmp.i728.not, label %cleanup151.thread, label %if.end118

if.end118:                                        ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731
  %48 = load i32, i32* %offset, align 4, !tbaa !41
  %add126 = add nsw i32 %mul125, %48
  store i32 %add126, i32* %offset, align 4, !tbaa !41
  %inc128 = add nuw nsw i32 %i111.0865, 1
  %exitcond881.not = icmp eq i32 %inc128, %channels.0
  br i1 %exitcond881.not, label %for.end129, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731, !llvm.loop !201

for.end129:                                       ; preds = %if.end118
  %49 = bitcast i32* %count to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %49) #15
  store i32 %mul125, i32* %count, align 4, !tbaa !41
  %inc146.1 = add nuw nsw i32 0, 1
  br label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720

for.cond138:                                      ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720
  %exitcond.not = icmp eq i32 %inc146.phi, %channels.0
  br i1 %exitcond.not, label %cleanup151, label %for.cond138._ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720_crit_edge, !llvm.loop !202

for.cond138._ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720_crit_edge: ; preds = %for.cond138
  %inc146.0 = add nuw nsw i32 %inc146.phi, 1
  br label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720: ; preds = %for.cond138._ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720_crit_edge, %for.end129
  %inc146.phi = phi i32 [ %inc146.0, %for.cond138._ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720_crit_edge ], [ %inc146.1, %for.end129 ]
  %call.i716 = call i64 @fwrite(i8* nonnull %49, i64 4, i64 1, i8* nonnull %call.i598) #14
  %cmp.i717.not = icmp eq i64 %call.i716, 0
  br i1 %cmp.i717.not, label %select.unfold, label %for.cond138

select.unfold:                                    ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit720
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %49) #15
  br label %cleanup151.thread

cleanup151.thread:                                ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731, %select.unfold
  %retval.2.ph = phi i32 [ -5, %select.unfold ], [ -4, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit731 ]
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %45) #15
  br label %cleanup154

cleanup151:                                       ; preds = %for.cond138
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %49) #15
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %45) #15
  br label %cleanup154.thread

cleanup154.thread:                                ; preds = %cleanup151, %if.end103
  call void @llvm.lifetime.end.p0i8(i64 210, i8* nonnull %34) #15
  br label %if.end311

cleanup154:                                       ; preds = %cleanup151.thread, %if.then36
  %retval.4 = phi i32 [ -3, %if.then36 ], [ %retval.2.ph, %cleanup151.thread ]
  call void @llvm.lifetime.end.p0i8(i64 210, i8* nonnull %34) #15
  br label %cleanup433

if.else164:                                       ; preds = %lor.lhs.false
  %call165 = tail call zeroext i1 @_ZN6Halide7Runtime8Internal9ends_withEPKcS3_(i8* %filename, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.5.39, i64 0, i64 0)) #16
  br i1 %call165, label %while.cond, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit631

while.cond:                                       ; preds = %if.else164, %while.cond
  %end.0 = phi i8* [ %incdec.ptr167, %while.cond ], [ %filename, %if.else164 ]
  %50 = load i8, i8* %end.0, align 1, !tbaa !18
  %tobool.not = icmp eq i8 %50, 0
  %incdec.ptr167 = getelementptr inbounds i8, i8* %end.0, i64 1
  br i1 %tobool.not, label %while.body171, label %while.cond, !llvm.loop !203

while.cond174.preheader:                          ; preds = %while.body171
  %end.1872.lcssa883 = ptrtoint i8* %end.1872 to i64
  %51 = ptrtoint i8* %filename to i64
  %52 = sub i64 %51, %end.1872.lcssa883
  br label %while.cond174

while.body171:                                    ; preds = %while.cond, %while.body171
  %end.1872 = phi i8* [ %incdec.ptr172.ptr, %while.body171 ], [ %end.0, %while.cond ]
  %incdec.ptr172.ptr = getelementptr inbounds i8, i8* %end.1872, i64 -1
  %.pr = load i8, i8* %incdec.ptr172.ptr, align 1, !tbaa !18
  %cmp170.not = icmp eq i8 %.pr, 46
  br i1 %cmp170.not, label %while.cond174.preheader, label %while.body171, !llvm.loop !204

while.cond174:                                    ; preds = %land.rhs176, %while.cond174.preheader
  %start.0.idx = phi i64 [ %start.0.add, %land.rhs176 ], [ -1, %while.cond174.preheader ]
  %start.0.ptr.ptr = getelementptr inbounds i8, i8* %end.1872, i64 %start.0.idx
  %cmp175.not = icmp eq i8* %start.0.ptr.ptr, %filename
  br i1 %cmp175.not, label %while.end183, label %land.rhs176

land.rhs176:                                      ; preds = %while.cond174
  %start.0.add = add nsw i64 %start.0.idx, -1
  %arrayidx177.ptr = getelementptr inbounds i8, i8* %end.1872, i64 %start.0.add
  %53 = load i8, i8* %arrayidx177.ptr, align 1, !tbaa !18
  %cmp179.not = icmp eq i8 %53, 47
  br i1 %cmp179.not, label %while.end183, label %while.cond174, !llvm.loop !205

while.end183:                                     ; preds = %land.rhs176, %while.cond174
  %start.0.idx.lcssa = phi i64 [ %52, %while.cond174 ], [ %start.0.idx, %land.rhs176 ]
  %54 = trunc i64 %start.0.idx.lcssa to i32
  %conv184 = xor i32 %54, -1
  %55 = getelementptr inbounds [256 x i8], [256 x i8]* %array_name, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %55) #15
  %cmp186.not868 = icmp eq i64 %start.0.idx.lcssa, -1
  br i1 %cmp186.not868, label %iter.check, label %while.body187.preheader

while.body187.preheader:                          ; preds = %while.end183
  %56 = xor i64 %start.0.idx.lcssa, -1
  %min.iters.check40 = icmp ugt i64 %start.0.idx.lcssa, -33
  br i1 %min.iters.check40, label %while.body187.preheader160, label %vector.memcheck

vector.memcheck:                                  ; preds = %while.body187.preheader
  %57 = xor i64 %start.0.idx.lcssa, -1
  %scevgep44 = getelementptr [256 x i8], [256 x i8]* %array_name, i64 0, i64 %57
  %scevgep45 = getelementptr i8, i8* %end.1872, i64 %start.0.idx.lcssa
  %scevgep46 = getelementptr i8, i8* %end.1872, i64 -1
  %bound0 = icmp ult i8* %array_name43, %scevgep46
  %bound1 = icmp ult i8* %scevgep45, %scevgep44
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %while.body187.preheader160, label %vector.ph42

vector.ph42:                                      ; preds = %vector.memcheck
  %n.vec48 = and i64 %56, -32
  %ind.end52 = getelementptr [256 x i8], [256 x i8]* %array_name, i64 0, i64 %n.vec48
  %ind.end54 = add i64 %start.0.idx.lcssa, %n.vec48
  br label %vector.body39

vector.body39:                                    ; preds = %vector.body39, %vector.ph42
  %index49 = phi i64 [ 0, %vector.ph42 ], [ %index.next50, %vector.body39 ]
  %next.gep = getelementptr [256 x i8], [256 x i8]* %array_name, i64 0, i64 %index49
  %offset.idx57 = add i64 %start.0.idx.lcssa, %index49
  %58 = getelementptr inbounds i8, i8* %end.1872, i64 %offset.idx57
  %59 = bitcast i8* %58 to <16 x i8>*
  %wide.load = load <16 x i8>, <16 x i8>* %59, align 1, !tbaa !18, !alias.scope !206
  %60 = getelementptr inbounds i8, i8* %58, i64 16
  %61 = bitcast i8* %60 to <16 x i8>*
  %wide.load58 = load <16 x i8>, <16 x i8>* %61, align 1, !tbaa !18, !alias.scope !206
  %62 = bitcast i8* %next.gep to <16 x i8>*
  store <16 x i8> %wide.load, <16 x i8>* %62, align 1, !tbaa !18, !alias.scope !209, !noalias !206
  %63 = getelementptr i8, i8* %next.gep, i64 16
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %wide.load58, <16 x i8>* %64, align 1, !tbaa !18, !alias.scope !209, !noalias !206
  %index.next50 = add i64 %index49, 32
  %65 = icmp eq i64 %index.next50, %n.vec48
  br i1 %65, label %middle.block37, label %vector.body39, !llvm.loop !211

middle.block37:                                   ; preds = %vector.body39
  %cmp.n55 = icmp eq i64 %n.vec48, %56
  br i1 %cmp.n55, label %while.cond191.preheader, label %while.body187.preheader160

while.body187.preheader160:                       ; preds = %vector.memcheck, %while.body187.preheader, %middle.block37
  %dst.0870.ph = phi i8* [ %55, %vector.memcheck ], [ %55, %while.body187.preheader ], [ %ind.end52, %middle.block37 ]
  %start.1869.idx.ph = phi i64 [ %start.0.idx.lcssa, %vector.memcheck ], [ %start.0.idx.lcssa, %while.body187.preheader ], [ %ind.end54, %middle.block37 ]
  br label %while.body187

while.cond191.preheader:                          ; preds = %while.body187, %middle.block37
  %incdec.ptr189.lcssa = phi i8* [ %ind.end52, %middle.block37 ], [ %incdec.ptr189, %while.body187 ]
  %add.ptr = getelementptr inbounds [256 x i8], [256 x i8]* %array_name, i64 0, i64 256
  %cmp193866 = icmp ult i8* %incdec.ptr189.lcssa, %add.ptr
  br i1 %cmp193866, label %iter.check, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705

iter.check:                                       ; preds = %while.cond191.preheader, %while.end183
  %dst.0.lcssa911 = phi i8* [ %incdec.ptr189.lcssa, %while.cond191.preheader ], [ %55, %while.end183 ]
  %dst.0.lcssa91162 = ptrtoint i8* %dst.0.lcssa911 to i64
  %scevgep = getelementptr inbounds [256 x i8], [256 x i8]* %array_name, i64 1, i64 0
  %66 = sub i64 0, %dst.0.lcssa91162
  %scevgep63 = getelementptr [256 x i8], [256 x i8]* %array_name, i64 1, i64 %66
  %exitcount.ptrcnt.to.int = ptrtoint i8* %scevgep63 to i64
  %min.iters.check65 = icmp ult i8* %scevgep63, inttoptr (i64 4 to i8*)
  br i1 %min.iters.check65, label %while.body194.preheader, label %vector.main.loop.iter.check

vector.main.loop.iter.check:                      ; preds = %iter.check
  %min.iters.check67 = icmp ult i8* %scevgep63, inttoptr (i64 32 to i8*)
  br i1 %min.iters.check67, label %vec.epilog.ph, label %vector.ph68

vector.ph68:                                      ; preds = %vector.main.loop.iter.check
  %n.vec70 = and i64 %exitcount.ptrcnt.to.int, -32
  %next.gep74.0 = getelementptr i8, i8* %dst.0.lcssa911, i64 0
  %index.next72.0 = add i64 0, 32
  br label %vector.body61

vector.body61:                                    ; preds = %vector.body61.vector.body61_crit_edge, %vector.ph68
  %index.next72.phi = phi i64 [ %index.next72.0, %vector.ph68 ], [ %index.next72.1, %vector.body61.vector.body61_crit_edge ]
  %next.gep74.phi = phi i8* [ %next.gep74.0, %vector.ph68 ], [ %next.gep74.1, %vector.body61.vector.body61_crit_edge ]
  %67 = bitcast i8* %next.gep74.phi to <16 x i8>*
  store <16 x i8> zeroinitializer, <16 x i8>* %67, align 1, !tbaa !18
  %68 = getelementptr i8, i8* %next.gep74.phi, i64 16
  %69 = bitcast i8* %68 to <16 x i8>*
  store <16 x i8> zeroinitializer, <16 x i8>* %69, align 1, !tbaa !18
  %70 = icmp eq i64 %index.next72.phi, %n.vec70
  br i1 %70, label %middle.block59, label %vector.body61.vector.body61_crit_edge, !llvm.loop !212

vector.body61.vector.body61_crit_edge:            ; preds = %vector.body61
  %next.gep74.1 = getelementptr i8, i8* %dst.0.lcssa911, i64 %index.next72.phi
  %index.next72.1 = add i64 %index.next72.phi, 32
  br label %vector.body61

middle.block59:                                   ; preds = %vector.body61
  %cmp.n73 = icmp eq i64 %n.vec70, %exitcount.ptrcnt.to.int
  br i1 %cmp.n73, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705, label %vec.epilog.iter.check

vec.epilog.iter.check:                            ; preds = %middle.block59
  %ind.end85 = getelementptr i8, i8* %dst.0.lcssa911, i64 %n.vec70
  %n.vec.remaining = and i64 %exitcount.ptrcnt.to.int, 28
  %min.epilog.iters.check = icmp eq i64 %n.vec.remaining, 0
  br i1 %min.epilog.iters.check, label %while.body194.preheader, label %vec.epilog.ph

vec.epilog.ph:                                    ; preds = %vector.main.loop.iter.check, %vec.epilog.iter.check
  %vec.epilog.resume.val = phi i64 [ %n.vec70, %vec.epilog.iter.check ], [ 0, %vector.main.loop.iter.check ]
  %71 = sub i64 0, %dst.0.lcssa91162
  %scevgep76 = getelementptr [256 x i8], [256 x i8]* %array_name, i64 1, i64 %71
  %exitcount.ptrcnt.to.int78 = ptrtoint i8* %scevgep76 to i64
  %n.vec80 = and i64 %exitcount.ptrcnt.to.int78, -4
  %ind.end84 = getelementptr i8, i8* %dst.0.lcssa911, i64 %n.vec80
  br label %vec.epilog.vector.body

vec.epilog.vector.body:                           ; preds = %vec.epilog.vector.body, %vec.epilog.ph
  %index81 = phi i64 [ %vec.epilog.resume.val, %vec.epilog.ph ], [ %index.next82, %vec.epilog.vector.body ]
  %next.gep87 = getelementptr i8, i8* %dst.0.lcssa911, i64 %index81
  %72 = bitcast i8* %next.gep87 to <4 x i8>*
  store <4 x i8> zeroinitializer, <4 x i8>* %72, align 1, !tbaa !18
  %index.next82 = add i64 %index81, 4
  %73 = icmp eq i64 %index.next82, %n.vec80
  br i1 %73, label %vec.epilog.middle.block, label %vec.epilog.vector.body, !llvm.loop !213

vec.epilog.middle.block:                          ; preds = %vec.epilog.vector.body
  %cmp.n86 = icmp eq i64 %n.vec80, %exitcount.ptrcnt.to.int78
  br i1 %cmp.n86, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705, label %while.body194.preheader

while.body194.preheader:                          ; preds = %iter.check, %vec.epilog.iter.check, %vec.epilog.middle.block
  %dst.1867.ph = phi i8* [ %dst.0.lcssa911, %iter.check ], [ %ind.end85, %vec.epilog.iter.check ], [ %ind.end84, %vec.epilog.middle.block ]
  br label %while.body194

while.body187:                                    ; preds = %while.body187.preheader160, %while.body187
  %dst.0870 = phi i8* [ %incdec.ptr189, %while.body187 ], [ %dst.0870.ph, %while.body187.preheader160 ]
  %start.1869.idx = phi i64 [ %start.1869.add, %while.body187 ], [ %start.1869.idx.ph, %while.body187.preheader160 ]
  %start.1869.ptr = getelementptr inbounds i8, i8* %end.1872, i64 %start.1869.idx
  %start.1869.add = add nuw nsw i64 %start.1869.idx, 1
  %74 = load i8, i8* %start.1869.ptr, align 1, !tbaa !18
  %incdec.ptr189 = getelementptr inbounds i8, i8* %dst.0870, i64 1
  store i8 %74, i8* %dst.0870, align 1, !tbaa !18
  %cmp186.not = icmp eq i64 %start.1869.add, -1
  br i1 %cmp186.not, label %while.cond191.preheader, label %while.body187, !llvm.loop !214

while.body194:                                    ; preds = %while.body194.preheader, %while.body194
  %dst.1867 = phi i8* [ %incdec.ptr195, %while.body194 ], [ %dst.1867.ph, %while.body194.preheader ]
  %incdec.ptr195 = getelementptr inbounds i8, i8* %dst.1867, i64 1
  store i8 0, i8* %dst.1867, align 1, !tbaa !18
  %exitcond882.not = icmp eq i8* %incdec.ptr195, %scevgep
  br i1 %exitcond882.not, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705, label %while.body194, !llvm.loop !215

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705: ; preds = %while.body194, %middle.block59, %vec.epilog.middle.block, %while.cond191.preheader
  %add197 = sub i32 6, %54
  %and = and i32 %add197, -8
  %75 = getelementptr inbounds [129 x i8], [129 x i8]* %header198, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 129, i8* nonnull %75) #15
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(129) %75, i8* nonnull align 1 dereferenceable(129) getelementptr inbounds ([129 x i8], [129 x i8]* @__const.halide_debug_to_file.header, i64 0, i64 0), i64 129, i1 false)
  %call.i701 = call i64 @fwrite(i8* nonnull %75, i64 128, i64 1, i8* nonnull %call.i598) #14
  %76 = load i32, i32* %dimensions, align 4, !tbaa !183
  %cmp19.i.i = icmp sgt i32 %76, 0
  br i1 %cmp19.i.i, label %for.body.lr.ph.i.i, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge: ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705
  %sub.i694.0 = sub nsw i64 1, 0
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

for.body.lr.ph.i.i:                               ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705
  %dim.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 6
  %77 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i.i, align 8, !tbaa !184
  %wide.trip.count.i.i = zext i32 %76 to i64
  %min.iters.check91 = icmp ult i32 %76, 3
  br i1 %min.iters.check91, label %for.body.i.i.preheader, label %vector.ph92

vector.ph92:                                      ; preds = %for.body.lr.ph.i.i
  %n.vec94 = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body90

vector.body90:                                    ; preds = %pred.load.continue103, %vector.ph92
  %index95 = phi i64 [ 0, %vector.ph92 ], [ %index.next96, %pred.load.continue103 ]
  %vec.phi = phi i64 [ 0, %vector.ph92 ], [ %predphi, %pred.load.continue103 ]
  %vec.phi101 = phi i64 [ 0, %vector.ph92 ], [ %predphi104, %pred.load.continue103 ]
  %induction100 = or i64 %index95, 1
  %78 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %index95, i32 2
  %79 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %induction100, i32 2
  %80 = load i32, i32* %78, align 4, !tbaa !185
  %81 = load i32, i32* %79, align 4, !tbaa !185
  %82 = icmp sgt i32 %80, 0
  %83 = icmp sgt i32 %81, 0
  %84 = zext i32 %80 to i64
  %85 = zext i32 %81 to i64
  br i1 %82, label %pred.load.if, label %pred.load.continue

pred.load.if:                                     ; preds = %vector.body90
  %86 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %index95, i32 1
  %87 = load i32, i32* %86, align 4, !tbaa !189
  br label %pred.load.continue

pred.load.continue:                               ; preds = %pred.load.if, %vector.body90
  %88 = phi i32 [ poison, %vector.body90 ], [ %87, %pred.load.if ]
  br i1 %83, label %pred.load.if102, label %pred.load.continue103

pred.load.if102:                                  ; preds = %pred.load.continue
  %89 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %induction100, i32 1
  %90 = load i32, i32* %89, align 4, !tbaa !189
  br label %pred.load.continue103

pred.load.continue103:                            ; preds = %pred.load.if102, %pred.load.continue
  %91 = phi i32 [ poison, %pred.load.continue ], [ %90, %pred.load.if102 ]
  %92 = add nsw i32 %88, -1
  %93 = add nsw i32 %91, -1
  %94 = sext i32 %92 to i64
  %95 = sext i32 %93 to i64
  %96 = mul nsw i64 %94, %84
  %97 = mul nsw i64 %95, %85
  %98 = select i1 %82, i64 %96, i64 0
  %predphi = add i64 %vec.phi, %98
  %99 = select i1 %83, i64 %97, i64 0
  %predphi104 = add i64 %vec.phi101, %99
  %index.next96 = add i64 %index95, 2
  %100 = icmp eq i64 %index.next96, %n.vec94
  br i1 %100, label %middle.block88, label %vector.body90, !llvm.loop !217

middle.block88:                                   ; preds = %pred.load.continue103
  %bin.rdx = add i64 %predphi104, %predphi
  %cmp.n98 = icmp eq i64 %n.vec94, %wide.trip.count.i.i
  br i1 %cmp.n98, label %for.body.i13.i.preheader, label %for.body.i.i.preheader

for.body.i.i.preheader:                           ; preds = %for.body.lr.ph.i.i, %middle.block88
  %indvars.iv.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %n.vec94, %middle.block88 ]
  %index.021.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %bin.rdx, %middle.block88 ]
  br label %for.body.i.i

for.body.i.i:                                     ; preds = %for.body.i.i.preheader, %if.end.i.i
  %indvars.iv.i.i = phi i64 [ %indvars.iv.next.i.i, %if.end.i.i ], [ %indvars.iv.i.i.ph, %for.body.i.i.preheader ]
  %index.021.i.i = phi i64 [ %index.1.i.i, %if.end.i.i ], [ %index.021.i.i.ph, %for.body.i.i.preheader ]
  %stride2.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %indvars.iv.i.i, i32 2
  %101 = load i32, i32* %stride2.i.i, align 4, !tbaa !185
  %cmp3.i.i = icmp sgt i32 %101, 0
  br i1 %cmp3.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %for.body.i.i
  %conv18.i.i = zext i32 %101 to i64
  %extent.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %indvars.iv.i.i, i32 1
  %102 = load i32, i32* %extent.i.i, align 4, !tbaa !189
  %sub.i.i = add nsw i32 %102, -1
  %conv7.i.i = sext i32 %sub.i.i to i64
  %mul.i.i = mul nsw i64 %conv7.i.i, %conv18.i.i
  %add.i.i693 = add nsw i64 %mul.i.i, %index.021.i.i
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %for.body.i.i
  %index.1.i.i = phi i64 [ %add.i.i693, %if.then.i.i ], [ %index.021.i.i, %for.body.i.i ]
  %indvars.iv.next.i.i = add nuw nsw i64 %indvars.iv.i.i, 1
  %exitcond.not.i.i = icmp eq i64 %indvars.iv.next.i.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i.i, label %for.body.i13.i.preheader, label %for.body.i.i, !llvm.loop !218

for.body.i13.i.preheader:                         ; preds = %if.end.i.i, %middle.block88
  %index.1.i.i.lcssa = phi i64 [ %bin.rdx, %middle.block88 ], [ %index.1.i.i, %if.end.i.i ]
  %min.iters.check108 = icmp ult i32 %76, 3
  br i1 %min.iters.check108, label %for.body.i13.i.preheader157, label %vector.ph109

vector.ph109:                                     ; preds = %for.body.i13.i.preheader
  %n.vec111 = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body107

vector.body107:                                   ; preds = %pred.load.continue123, %vector.ph109
  %index112 = phi i64 [ 0, %vector.ph109 ], [ %index.next113, %pred.load.continue123 ]
  %vec.phi118 = phi i64 [ 0, %vector.ph109 ], [ %predphi124, %pred.load.continue123 ]
  %vec.phi119 = phi i64 [ 0, %vector.ph109 ], [ %predphi125, %pred.load.continue123 ]
  %induction117 = or i64 %index112, 1
  %103 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %index112, i32 2
  %104 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %induction117, i32 2
  %105 = load i32, i32* %103, align 4, !tbaa !185
  %106 = load i32, i32* %104, align 4, !tbaa !185
  %107 = icmp slt i32 %105, 0
  %108 = icmp slt i32 %106, 0
  %109 = sext i32 %105 to i64
  %110 = sext i32 %106 to i64
  br i1 %107, label %pred.load.if120, label %pred.load.continue121

pred.load.if120:                                  ; preds = %vector.body107
  %111 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %index112, i32 1
  %112 = load i32, i32* %111, align 4, !tbaa !189
  br label %pred.load.continue121

pred.load.continue121:                            ; preds = %pred.load.if120, %vector.body107
  %113 = phi i32 [ poison, %vector.body107 ], [ %112, %pred.load.if120 ]
  br i1 %108, label %pred.load.if122, label %pred.load.continue123

pred.load.if122:                                  ; preds = %pred.load.continue121
  %114 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %induction117, i32 1
  %115 = load i32, i32* %114, align 4, !tbaa !189
  br label %pred.load.continue123

pred.load.continue123:                            ; preds = %pred.load.if122, %pred.load.continue121
  %116 = phi i32 [ poison, %pred.load.continue121 ], [ %115, %pred.load.if122 ]
  %117 = add nsw i32 %113, -1
  %118 = add nsw i32 %116, -1
  %119 = sext i32 %117 to i64
  %120 = sext i32 %118 to i64
  %121 = mul nsw i64 %119, %109
  %122 = mul nsw i64 %120, %110
  %123 = select i1 %107, i64 %121, i64 0
  %predphi124 = add i64 %vec.phi118, %123
  %124 = select i1 %108, i64 %122, i64 0
  %predphi125 = add i64 %vec.phi119, %124
  %index.next113 = add i64 %index112, 2
  %125 = icmp eq i64 %index.next113, %n.vec111
  br i1 %125, label %middle.block105, label %vector.body107, !llvm.loop !219

middle.block105:                                  ; preds = %pred.load.continue123
  %bin.rdx126 = add i64 %predphi125, %predphi124
  %cmp.n115 = icmp eq i64 %n.vec111, %wide.trip.count.i.i
  br i1 %cmp.n115, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i.preheader157

for.body.i13.i.preheader157:                      ; preds = %for.body.i13.i.preheader, %middle.block105
  %indvars.iv.i10.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %n.vec111, %middle.block105 ]
  %index.018.i.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %bin.rdx126, %middle.block105 ]
  br label %for.body.i13.i

for.body.i13.i:                                   ; preds = %for.body.i13.i.preheader157, %if.end.i24.i
  %indvars.iv.i10.i = phi i64 [ %indvars.iv.next.i22.i, %if.end.i24.i ], [ %indvars.iv.i10.i.ph, %for.body.i13.i.preheader157 ]
  %index.018.i.i = phi i64 [ %index.1.i21.i, %if.end.i24.i ], [ %index.018.i.i.ph, %for.body.i13.i.preheader157 ]
  %stride2.i11.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %indvars.iv.i10.i, i32 2
  %126 = load i32, i32* %stride2.i11.i, align 4, !tbaa !185
  %cmp3.i12.i = icmp slt i32 %126, 0
  br i1 %cmp3.i12.i, label %if.then.i20.i, label %if.end.i24.i

if.then.i20.i:                                    ; preds = %for.body.i13.i
  %conv.i14.i = sext i32 %126 to i64
  %extent.i15.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %77, i64 %indvars.iv.i10.i, i32 1
  %127 = load i32, i32* %extent.i15.i, align 4, !tbaa !189
  %sub.i16.i = add nsw i32 %127, -1
  %conv7.i17.i = sext i32 %sub.i16.i to i64
  %mul.i18.i = mul nsw i64 %conv7.i17.i, %conv.i14.i
  %add.i19.i = add nsw i64 %mul.i18.i, %index.018.i.i
  br label %if.end.i24.i

if.end.i24.i:                                     ; preds = %if.then.i20.i, %for.body.i13.i
  %index.1.i21.i = phi i64 [ %add.i19.i, %if.then.i20.i ], [ %index.018.i.i, %for.body.i13.i ]
  %indvars.iv.next.i22.i = add nuw nsw i64 %indvars.iv.i10.i, 1
  %exitcond.not.i23.i = icmp eq i64 %indvars.iv.next.i22.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i23.i, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i, !llvm.loop !220

_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit: ; preds = %if.end.i24.i, %middle.block105
  %index.1.i21.i.lcssa = phi i64 [ %bin.rdx126, %middle.block105 ], [ %index.1.i21.i, %if.end.i24.i ]
  %add8.i.i = add nsw i64 %index.1.i.i.lcssa, 1
  %sub.i694.1 = sub nsw i64 %add8.i.i, %index.1.i21.i.lcssa
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

_ZNK15halide_buffer_t13size_in_bytesEv.exit:      ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit
  %add8.i27.i = phi i64 [ 1, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %add8.i.i, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %sub.i694.phi = phi i64 [ %sub.i694.0, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit705._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %sub.i694.1, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %128 = load i8, i8* %bits.i, align 1, !tbaa !144
  %conv.i.i696 = zext i8 %128 to i64
  %add.i4.i = add nuw nsw i64 %conv.i.i696, 7
  %div.i.i697 = lshr i64 %add.i4.i, 3
  %mul.i698 = mul i64 %div.i.i697, %sub.i694.phi
  %129 = trunc i64 %mul.i698 to i32
  %130 = add i32 %129, 7
  %131 = and i32 %130, 7
  %conv204 = xor i32 %131, 7
  %conv205 = zext i32 %conv204 to i64
  %add206 = add i64 %mul.i698, %conv205
  %tobool207.not = icmp ult i64 %add206, 4294967296
  br i1 %tobool207.not, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit687, label %cleanup278.thread

cleanup278.thread:                                ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit
  call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.6.40, i64 0, i64 0)) #14
  call void @llvm.lifetime.end.p0i8(i64 129, i8* nonnull %75) #15
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %55) #15
  br label %cleanup433

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit687: ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit
  %132 = icmp sgt i32 %76, 2
  %spec.store.select = select i1 %132, i32 %76, i32 2
  %133 = bitcast [8 x i32]* %tags to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %133) #15
  %arrayinit.begin = getelementptr inbounds [8 x i32], [8 x i32]* %tags, i64 0, i64 0
  store i32 14, i32* %arrayinit.begin, align 4, !tbaa !41
  %arrayinit.element = getelementptr inbounds [8 x i32], [8 x i32]* %tags, i64 0, i64 1
  %add214 = shl i32 %spec.store.select, 2
  %and215 = add i32 %add214, 4
  %mul216 = and i32 %and215, -8
  %add217 = add i32 %and, 40
  %add218 = add i32 %add217, %mul216
  %add220 = add i32 %add218, %129
  %add221 = add i32 %add220, %conv204
  store i32 %add221, i32* %arrayinit.element, align 4, !tbaa !41
  %arrayinit.element222 = getelementptr inbounds [8 x i32], [8 x i32]* %tags, i64 0, i64 2
  %134 = bitcast i32* %arrayinit.element222 to <2 x i32>*
  store <2 x i32> <i32 6, i32 8>, <2 x i32>* %134, align 4, !tbaa !41
  %arrayinit.element224 = getelementptr inbounds [8 x i32], [8 x i32]* %tags, i64 0, i64 4
  %idxprom225 = sext i32 %type_code to i64
  %arrayidx226 = getelementptr inbounds [10 x i8], [10 x i8]* @_ZN6Halide7Runtime8Internal31pixel_type_to_matlab_class_codeE, i64 0, i64 %idxprom225
  %135 = load i8, i8* %arrayidx226, align 1, !tbaa !18
  %conv227 = zext i8 %135 to i32
  store i32 %conv227, i32* %arrayinit.element224, align 4, !tbaa !41
  %arrayinit.element228 = getelementptr inbounds [8 x i32], [8 x i32]* %tags, i64 0, i64 5
  %136 = bitcast i32* %arrayinit.element228 to <2 x i32>*
  store <2 x i32> <i32 1, i32 5>, <2 x i32>* %136, align 4, !tbaa !41
  %arrayinit.element230 = getelementptr inbounds [8 x i32], [8 x i32]* %tags, i64 0, i64 7
  store i32 %add214, i32* %arrayinit.element230, align 4, !tbaa !41
  %call.i683 = call i64 @fwrite(i8* nonnull %133, i64 32, i64 1, i8* nonnull %call.i598) #14
  %cmp.i684.not = icmp eq i64 %call.i683, 0
  br i1 %cmp.i684.not, label %cleanup278, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit676

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit676: ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit687
  %137 = bitcast [4 x i32]* %extents to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %137) #15
  %arrayinit.begin235 = getelementptr inbounds [4 x i32], [4 x i32]* %extents, i64 0, i64 0
  %138 = load i32, i32* %extent.i, align 4, !tbaa !189
  store i32 %138, i32* %arrayinit.begin235, align 4, !tbaa !41
  %arrayinit.element238 = getelementptr inbounds [4 x i32], [4 x i32]* %extents, i64 0, i64 1
  %139 = load i32, i32* %extent.i.1, align 4, !tbaa !189
  store i32 %139, i32* %arrayinit.element238, align 4, !tbaa !41
  %arrayinit.element241 = getelementptr inbounds [4 x i32], [4 x i32]* %extents, i64 0, i64 2
  %140 = load i32, i32* %extent.i.2, align 4, !tbaa !189
  store i32 %140, i32* %arrayinit.element241, align 4, !tbaa !41
  %arrayinit.element244 = getelementptr inbounds [4 x i32], [4 x i32]* %extents, i64 0, i64 3
  %141 = load i32, i32* %extent.i.3, align 4, !tbaa !189
  store i32 %141, i32* %arrayinit.element244, align 4, !tbaa !41
  %conv248 = sext i32 %mul216 to i64
  %call.i672 = call i64 @fwrite(i8* nonnull %137, i64 %conv248, i64 1, i8* nonnull %call.i598) #14
  %cmp.i673.not = icmp eq i64 %call.i672, 0
  br i1 %cmp.i673.not, label %cleanup274, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit664

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit664: ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit676
  %142 = bitcast [2 x i32]* %name_header to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %142) #15
  %arrayinit.begin252 = getelementptr inbounds [2 x i32], [2 x i32]* %name_header, i64 0, i64 0
  store i32 1, i32* %arrayinit.begin252, align 4, !tbaa !41
  %arrayinit.element253 = getelementptr inbounds [2 x i32], [2 x i32]* %name_header, i64 0, i64 1
  store i32 %conv184, i32* %arrayinit.element253, align 4, !tbaa !41
  %call.i660 = call i64 @fwrite(i8* nonnull %142, i64 8, i64 1, i8* nonnull %call.i598) #14
  %cmp.i661.not = icmp eq i64 %call.i660, 0
  br i1 %cmp.i661.not, label %cleanup273, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit652

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit652: ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit664
  %conv258 = zext i32 %and to i64
  %call.i648 = call i64 @fwrite(i8* nonnull %55, i64 %conv258, i64 1, i8* nonnull %call.i598) #14
  %cmp.i649.not = icmp eq i64 %call.i648, 0
  br i1 %cmp.i649.not, label %cleanup273, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit642

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit642: ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit652
  %143 = bitcast [2 x i32]* %payload_header to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %143) #15
  %arrayinit.begin262 = getelementptr inbounds [2 x i32], [2 x i32]* %payload_header, i64 0, i64 0
  %arrayidx264 = getelementptr inbounds [10 x i8], [10 x i8]* @_ZN6Halide7Runtime8Internal30pixel_type_to_matlab_type_codeE, i64 0, i64 %idxprom225
  %144 = load i8, i8* %arrayidx264, align 1, !tbaa !18
  %conv265 = zext i8 %144 to i32
  store i32 %conv265, i32* %arrayinit.begin262, align 4, !tbaa !41
  %arrayinit.element266 = getelementptr inbounds [2 x i32], [2 x i32]* %payload_header, i64 0, i64 1
  store i32 %129, i32* %arrayinit.element266, align 4, !tbaa !41
  %call.i638 = call i64 @fwrite(i8* nonnull %143, i64 8, i64 1, i8* nonnull %call.i598) #14
  %cmp.i639.not = icmp eq i64 %call.i638, 0
  %cleanup.dest.slot.5 = zext i1 %cmp.i639.not to i32
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %143) #15
  br label %cleanup273

cleanup273:                                       ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit642, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit652, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit664
  %cleanup.dest.slot.6 = phi i32 [ %cleanup.dest.slot.5, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit642 ], [ 1, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit664 ], [ 1, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit652 ]
  %retval.6 = phi i32 [ -11, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit642 ], [ -9, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit664 ], [ -10, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit652 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %142) #15
  br label %cleanup274

cleanup274:                                       ; preds = %cleanup273, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit676
  %cleanup.dest.slot.7 = phi i32 [ %cleanup.dest.slot.6, %cleanup273 ], [ 1, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit676 ]
  %retval.7 = phi i32 [ %retval.6, %cleanup273 ], [ -8, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit676 ]
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %137) #15
  br label %cleanup278

cleanup278:                                       ; preds = %cleanup274, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit687
  %cleanup.dest.slot.8 = phi i32 [ %cleanup.dest.slot.7, %cleanup274 ], [ 1, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit687 ]
  %retval.8 = phi i32 [ %retval.7, %cleanup274 ], [ -7, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit687 ]
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %133) #15
  call void @llvm.lifetime.end.p0i8(i64 129, i8* nonnull %75) #15
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %55) #15
  %cond442 = icmp eq i32 %cleanup.dest.slot.8, 0
  br i1 %cond442, label %if.end311, label %cleanup433

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit631: ; preds = %if.else164
  %145 = bitcast [5 x i32]* %header289 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %145) #15
  %arrayinit.begin290 = getelementptr inbounds [5 x i32], [5 x i32]* %header289, i64 0, i64 0
  %146 = load i32, i32* %extent.i, align 4, !tbaa !189
  store i32 %146, i32* %arrayinit.begin290, align 4, !tbaa !41
  %arrayinit.element293 = getelementptr inbounds [5 x i32], [5 x i32]* %header289, i64 0, i64 1
  %147 = load i32, i32* %extent.i.1, align 4, !tbaa !189
  store i32 %147, i32* %arrayinit.element293, align 4, !tbaa !41
  %arrayinit.element296 = getelementptr inbounds [5 x i32], [5 x i32]* %header289, i64 0, i64 2
  %148 = load i32, i32* %extent.i.2, align 4, !tbaa !189
  store i32 %148, i32* %arrayinit.element296, align 4, !tbaa !41
  %arrayinit.element299 = getelementptr inbounds [5 x i32], [5 x i32]* %header289, i64 0, i64 3
  %149 = load i32, i32* %extent.i.3, align 4, !tbaa !189
  store i32 %149, i32* %arrayinit.element299, align 4, !tbaa !41
  %arrayinit.element302 = getelementptr inbounds [5 x i32], [5 x i32]* %header289, i64 0, i64 4
  store i32 %type_code, i32* %arrayinit.element302, align 4, !tbaa !41
  %call.i627 = call i64 @fwrite(i8* nonnull %145, i64 20, i64 1, i8* nonnull %call.i598) #14
  %cmp.i628.not = icmp eq i64 %call.i627, 0
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %145) #15
  br i1 %cmp.i628.not, label %cleanup433, label %if.end311

if.end311:                                        ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit631, %cleanup278, %cleanup154.thread
  %final_padding_bytes.0 = phi i32 [ %conv204, %cleanup278 ], [ 0, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit631 ], [ 0, %cleanup154.thread ]
  %150 = getelementptr inbounds [4096 x i8], [4096 x i8]* %temp, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 4096, i8* nonnull %150) #15
  %div = udiv i32 4096, %div.i
  %151 = load i32, i32* %extent.i.3, align 4, !tbaa !189
  %cmp320856 = icmp sgt i32 %151, 0
  br i1 %cmp320856, label %for.body322.lr.ph, label %if.end412

for.body322.lr.ph:                                ; preds = %if.end311
  %152 = load i32, i32* %min.i.3, align 16, !tbaa !221
  %153 = bitcast [4 x i32]* %idx to i8*
  %arrayinit.begin357 = getelementptr inbounds [4 x i32], [4 x i32]* %idx, i64 0, i64 0
  %arrayinit.element358 = getelementptr inbounds [4 x i32], [4 x i32]* %idx, i64 0, i64 1
  %arrayinit.element359 = getelementptr inbounds [4 x i32], [4 x i32]* %idx, i64 0, i64 2
  %arrayinit.element360 = getelementptr inbounds [4 x i32], [4 x i32]* %idx, i64 0, i64 3
  %dim.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 6
  %conv368 = zext i32 %div.i to i64
  %mul373 = mul nuw nsw i32 %div, %div.i
  %conv374 = zext i32 %mul373 to i64
  %.pre891 = load i32, i32* %min.i.2, align 16, !tbaa !221
  %.pre892 = load i32, i32* %extent.i.2, align 4, !tbaa !189
  %.pre893 = load i32, i32* %min.i.1, align 16
  %.pre894 = load i32, i32* %extent.i.1, align 4
  %.pre = load i32, i32* %extent.i, align 4
  %154 = load i32, i32* %min.i, align 16
  %155 = load i32, i32* %extent.i, align 4
  %156 = load i32, i32* %min.i, align 16
  %add352 = add nsw i32 %156, %155
  %.pre15 = load i32, i32* %extent.i.1, align 4
  %.pre16 = load i32, i32* %min.i.1, align 16
  %.pre896 = load i32, i32* %extent.i.2, align 4
  %.pre897 = load i32, i32* %min.i.2, align 16
  %.pre898 = load i32, i32* %extent.i.3, align 4
  %.pre899 = load i32, i32* %min.i.3, align 16
  br label %for.body322

for.body322:                                      ; preds = %for.inc399, %for.body322.lr.ph
  %157 = phi i32 [ %152, %for.body322.lr.ph ], [ %218, %for.inc399 ]
  %158 = phi i32 [ %151, %for.body322.lr.ph ], [ %219, %for.inc399 ]
  %159 = phi i32 [ %.pre891, %for.body322.lr.ph ], [ %220, %for.inc399 ]
  %160 = phi i32 [ %.pre892, %for.body322.lr.ph ], [ %221, %for.inc399 ]
  %161 = phi i32 [ %.pre892, %for.body322.lr.ph ], [ %222, %for.inc399 ]
  %162 = phi i32 [ %.pre891, %for.body322.lr.ph ], [ %223, %for.inc399 ]
  %dim3.0858 = phi i32 [ %152, %for.body322.lr.ph ], [ %inc400, %for.inc399 ]
  %counter.0857 = phi i32 [ 0, %for.body322.lr.ph ], [ %counter.1.lcssa, %for.inc399 ]
  %cmp331848 = icmp sgt i32 %161, 0
  br i1 %cmp331848, label %for.body333, label %for.inc399

for.body333:                                      ; preds = %for.body322, %for.inc394
  %163 = phi i32 [ %212, %for.inc394 ], [ %.pre893, %for.body322 ]
  %164 = phi i32 [ %213, %for.inc394 ], [ %.pre894, %for.body322 ]
  %165 = phi i32 [ %214, %for.inc394 ], [ %159, %for.body322 ]
  %166 = phi i32 [ %215, %for.inc394 ], [ %160, %for.body322 ]
  %167 = phi i32 [ %216, %for.inc394 ], [ %.pre894, %for.body322 ]
  %168 = phi i32 [ %217, %for.inc394 ], [ %.pre893, %for.body322 ]
  %dim2.0850 = phi i32 [ %inc395, %for.inc394 ], [ %162, %for.body322 ]
  %counter.1849 = phi i32 [ %counter.2.lcssa, %for.inc394 ], [ %counter.0857, %for.body322 ]
  %cmp342839 = icmp sgt i32 %167, 0
  br i1 %cmp342839, label %for.body344, label %for.inc394

for.body344:                                      ; preds = %for.body333, %for.inc389
  %169 = phi i32 [ %209, %for.inc389 ], [ %163, %for.body333 ]
  %170 = phi i32 [ %210, %for.inc389 ], [ %164, %for.body333 ]
  %171 = phi i32 [ %211, %for.inc389 ], [ %.pre, %for.body333 ]
  %dim1.0841 = phi i32 [ %inc390, %for.inc389 ], [ %168, %for.body333 ]
  %counter.2840 = phi i32 [ %counter.6797, %for.inc389 ], [ %counter.1849, %for.body333 ]
  %cmp353834 = icmp sgt i32 %171, 0
  br i1 %cmp353834, label %for.body355, label %for.inc389

for.body355:                                      ; preds = %for.body344, %for.inc384
  %dim0.0836 = phi i32 [ %inc385, %for.inc384 ], [ %154, %for.body344 ]
  %counter.3835 = phi i32 [ %counter.4, %for.inc384 ], [ %counter.2840, %for.body344 ]
  %inc356 = add nsw i32 %counter.3835, 1
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %153) #15
  store i32 %dim0.0836, i32* %arrayinit.begin357, align 4, !tbaa !41
  store i32 %dim1.0841, i32* %arrayinit.element358, align 4, !tbaa !41
  store i32 %dim2.0850, i32* %arrayinit.element359, align 4, !tbaa !41
  store i32 %dim3.0858, i32* %arrayinit.element360, align 4, !tbaa !41
  %172 = load i32, i32* %dimensions, align 4, !tbaa !183
  %cmp17.i = icmp sgt i32 %172, 0
  br i1 %cmp17.i, label %for.body.lr.ph.i, label %_ZNK15halide_buffer_t10address_ofEPKi.exit

for.body.lr.ph.i:                                 ; preds = %for.body355
  %173 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i, align 8, !tbaa !184
  %wide.trip.count.i = zext i32 %172 to i64
  %stride.i621920 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %173, i64 0, i32 2
  %174 = load i32, i32* %stride.i621920, align 4, !tbaa !185
  %conv.i622921 = sext i32 %174 to i64
  %min.i623922 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %173, i64 0, i32 0
  %175 = load i32, i32* %min.i623922, align 4, !tbaa !221
  %sub.i923 = sub nsw i32 %dim0.0836, %175
  %conv7.i924 = sext i32 %sub.i923 to i64
  %mul.i925 = mul nsw i64 %conv7.i924, %conv.i622921
  %exitcond.not.i927 = icmp eq i32 %172, 1
  br i1 %exitcond.not.i927, label %_ZNK15halide_buffer_t10address_ofEPKi.exit, label %for.body.i.for.body.i_crit_edge.preheader, !llvm.loop !222

for.body.i.for.body.i_crit_edge.preheader:        ; preds = %for.body.lr.ph.i
  %stride.i62126 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %173, i64 1, i32 2
  %176 = load i32, i32* %stride.i62126, align 4, !tbaa !185
  %conv.i62227 = sext i32 %176 to i64
  %min.i62328 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %173, i64 1, i32 0
  %177 = load i32, i32* %min.i62328, align 4, !tbaa !221
  %sub.i29 = sub nsw i32 %dim1.0841, %177
  %conv7.i30 = sext i32 %sub.i29 to i64
  %mul.i31 = mul nsw i64 %conv7.i30, %conv.i62227
  %add.i62432 = add nsw i64 %mul.i31, %mul.i925
  %exitcond.not.i33 = icmp eq i32 %172, 2
  br i1 %exitcond.not.i33, label %_ZNK15halide_buffer_t10address_ofEPKi.exit, label %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.lr.ph, !llvm.loop !222

for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.lr.ph: ; preds = %for.body.i.for.body.i_crit_edge.preheader
  %178 = add nsw i64 %wide.trip.count.i, -2
  %min.iters.check131 = icmp ult i64 %178, 5
  br i1 %min.iters.check131, label %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.preheader, label %vector.ph132

vector.ph132:                                     ; preds = %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.lr.ph
  %n.mod.vf133 = and i64 %178, 3
  %179 = icmp eq i64 %n.mod.vf133, 0
  %180 = select i1 %179, i64 4, i64 %n.mod.vf133
  %n.vec134 = sub nsw i64 %178, %180
  %ind.end138 = add nsw i64 %n.vec134, 2
  %181 = insertelement <2 x i64> <i64 poison, i64 0>, i64 %add.i62432, i32 0
  br label %vector.body130

vector.body130:                                   ; preds = %vector.body130, %vector.ph132
  %index135 = phi i64 [ 0, %vector.ph132 ], [ %index.next136, %vector.body130 ]
  %vec.phi141 = phi <2 x i64> [ %181, %vector.ph132 ], [ %201, %vector.body130 ]
  %vec.phi142 = phi <2 x i64> [ zeroinitializer, %vector.ph132 ], [ %202, %vector.body130 ]
  %offset.idx140 = or i64 %index135, 2
  %182 = add i64 %offset.idx140, 2
  %183 = getelementptr inbounds [4 x i32], [4 x i32]* %idx, i64 0, i64 %offset.idx140
  %184 = bitcast i32* %183 to <2 x i32>*
  %wide.load143 = load <2 x i32>, <2 x i32>* %184, align 4, !tbaa !41
  %185 = getelementptr inbounds i32, i32* %183, i64 2
  %186 = bitcast i32* %185 to <2 x i32>*
  %wide.load144 = load <2 x i32>, <2 x i32>* %186, align 4, !tbaa !41
  %187 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %173, i64 %offset.idx140, i32 2
  %188 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %173, i64 %182, i32 2
  %189 = getelementptr inbounds i32, i32* %187, i64 -2
  %190 = bitcast i32* %189 to <8 x i32>*
  %191 = getelementptr inbounds i32, i32* %188, i64 -2
  %192 = bitcast i32* %191 to <8 x i32>*
  %wide.vec = load <8 x i32>, <8 x i32>* %190, align 4, !tbaa !41
  %wide.vec145 = load <8 x i32>, <8 x i32>* %192, align 4, !tbaa !41
  %strided.vec = shufflevector <8 x i32> %wide.vec, <8 x i32> poison, <2 x i32> <i32 0, i32 4>
  %strided.vec146 = shufflevector <8 x i32> %wide.vec145, <8 x i32> poison, <2 x i32> <i32 0, i32 4>
  %strided.vec147 = shufflevector <8 x i32> %wide.vec, <8 x i32> poison, <2 x i32> <i32 2, i32 6>
  %strided.vec148 = shufflevector <8 x i32> %wide.vec145, <8 x i32> poison, <2 x i32> <i32 2, i32 6>
  %193 = sext <2 x i32> %strided.vec147 to <2 x i64>
  %194 = sext <2 x i32> %strided.vec148 to <2 x i64>
  %195 = sub nsw <2 x i32> %wide.load143, %strided.vec
  %196 = sub nsw <2 x i32> %wide.load144, %strided.vec146
  %197 = sext <2 x i32> %195 to <2 x i64>
  %198 = sext <2 x i32> %196 to <2 x i64>
  %199 = mul nsw <2 x i64> %197, %193
  %200 = mul nsw <2 x i64> %198, %194
  %201 = add <2 x i64> %199, %vec.phi141
  %202 = add <2 x i64> %200, %vec.phi142
  %index.next136 = add i64 %index135, 4
  %203 = icmp eq i64 %index.next136, %n.vec134
  br i1 %203, label %middle.block128, label %vector.body130, !llvm.loop !223

middle.block128:                                  ; preds = %vector.body130
  %bin.rdx149 = add <2 x i64> %202, %201
  %204 = call i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %bin.rdx149)
  br label %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.preheader

for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.preheader: ; preds = %middle.block128, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.lr.ph
  %indvars.iv.next.i35.ph = phi i64 [ 2, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.lr.ph ], [ %ind.end138, %middle.block128 ]
  %add.i62434.ph = phi i64 [ %add.i62432, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.lr.ph ], [ %204, %middle.block128 ]
  br label %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge

for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge: ; preds = %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.preheader, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge
  %indvars.iv.next.i35 = phi i64 [ %indvars.iv.next.i, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge ], [ %indvars.iv.next.i35.ph, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.preheader ]
  %add.i62434 = phi i64 [ %add.i624, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge ], [ %add.i62434.ph, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge.preheader ]
  %arrayidx3.i.phi.trans.insert.phi.trans.insert = getelementptr inbounds [4 x i32], [4 x i32]* %idx, i64 0, i64 %indvars.iv.next.i35
  %.pre895.pre = load i32, i32* %arrayidx3.i.phi.trans.insert.phi.trans.insert, align 4, !tbaa !41
  %stride.i621 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %173, i64 %indvars.iv.next.i35, i32 2
  %205 = load i32, i32* %stride.i621, align 4, !tbaa !185
  %conv.i622 = sext i32 %205 to i64
  %min.i623 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %173, i64 %indvars.iv.next.i35, i32 0
  %206 = load i32, i32* %min.i623, align 4, !tbaa !221
  %sub.i = sub nsw i32 %.pre895.pre, %206
  %conv7.i = sext i32 %sub.i to i64
  %mul.i = mul nsw i64 %conv7.i, %conv.i622
  %add.i624 = add nsw i64 %mul.i, %add.i62434
  %indvars.iv.next.i = add nuw nsw i64 %indvars.iv.next.i35, 1
  %exitcond.not.i = icmp eq i64 %indvars.iv.next.i, %wide.trip.count.i
  br i1 %exitcond.not.i, label %_ZNK15halide_buffer_t10address_ofEPKi.exit, label %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge, !llvm.loop !224

_ZNK15halide_buffer_t10address_ofEPKi.exit:       ; preds = %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge, %for.body.i.for.body.i_crit_edge.preheader, %for.body.lr.ph.i, %for.body355
  %index.0.lcssa.i = phi i64 [ 0, %for.body355 ], [ %mul.i925, %for.body.lr.ph.i ], [ %add.i62432, %for.body.i.for.body.i_crit_edge.preheader ], [ %add.i624, %for.body.i.for.body.i_crit_edge.for.body.i.for.body.i_crit_edge_crit_edge ]
  %207 = load i8*, i8** %host.i, align 8, !tbaa !180
  %208 = load i8, i8* %bits.i, align 1, !tbaa !144
  %conv.i.i = zext i8 %208 to i64
  %add.i.i = add nuw nsw i64 %conv.i.i, 7
  %div.i.i = lshr i64 %add.i.i, 3
  %mul9.i = mul nsw i64 %div.i.i, %index.0.lcssa.i
  %add.ptr.i = getelementptr inbounds i8, i8* %207, i64 %mul9.i
  %mul366 = mul nsw i32 %counter.3835, %div.i
  %idx.ext = sext i32 %mul366 to i64
  %add.ptr367 = getelementptr inbounds [4096 x i8], [4096 x i8]* %temp, i64 0, i64 %idx.ext
  %call369 = call i8* @memcpy(i8* nonnull %add.ptr367, i8* %add.ptr.i, i64 %conv368) #14
  %cmp370 = icmp eq i32 %inc356, %div
  br i1 %cmp370, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit619, label %for.inc384

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit619: ; preds = %_ZNK15halide_buffer_t10address_ofEPKi.exit
  %call.i615 = call i64 @fwrite(i8* nonnull %150, i64 %conv374, i64 1, i8* nonnull %call.i598) #14
  %cmp.i616.not = icmp eq i64 %call.i615, 0
  br i1 %cmp.i616.not, label %cleanup425.loopexit, label %for.inc384

for.inc384:                                       ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit619, %_ZNK15halide_buffer_t10address_ofEPKi.exit
  %counter.4 = phi i32 [ 0, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit619 ], [ %inc356, %_ZNK15halide_buffer_t10address_ofEPKi.exit ]
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %153) #15
  %inc385 = add nsw i32 %dim0.0836, 1
  %cmp353 = icmp slt i32 %inc385, %add352
  br i1 %cmp353, label %for.body355, label %for.inc389, !llvm.loop !225

for.inc389:                                       ; preds = %for.inc384, %for.body344
  %209 = phi i32 [ %169, %for.body344 ], [ %.pre16, %for.inc384 ]
  %210 = phi i32 [ %170, %for.body344 ], [ %.pre15, %for.inc384 ]
  %211 = phi i32 [ %171, %for.body344 ], [ %155, %for.inc384 ]
  %counter.6797 = phi i32 [ %counter.2840, %for.body344 ], [ %counter.4, %for.inc384 ]
  %inc390 = add nsw i32 %dim1.0841, 1
  %add341 = add nsw i32 %209, %210
  %cmp342 = icmp slt i32 %inc390, %add341
  br i1 %cmp342, label %for.body344, label %for.inc394, !llvm.loop !226

for.inc394:                                       ; preds = %for.inc389, %for.body333
  %212 = phi i32 [ %163, %for.body333 ], [ %209, %for.inc389 ]
  %213 = phi i32 [ %164, %for.body333 ], [ %210, %for.inc389 ]
  %214 = phi i32 [ %165, %for.body333 ], [ %.pre897, %for.inc389 ]
  %215 = phi i32 [ %166, %for.body333 ], [ %.pre896, %for.inc389 ]
  %216 = phi i32 [ %167, %for.body333 ], [ %210, %for.inc389 ]
  %217 = phi i32 [ %168, %for.body333 ], [ %209, %for.inc389 ]
  %counter.2.lcssa = phi i32 [ %counter.1849, %for.body333 ], [ %counter.6797, %for.inc389 ]
  %inc395 = add nsw i32 %dim2.0850, 1
  %add330 = add nsw i32 %215, %214
  %cmp331 = icmp slt i32 %inc395, %add330
  br i1 %cmp331, label %for.body333, label %for.inc399, !llvm.loop !227

for.inc399:                                       ; preds = %for.inc394, %for.body322
  %218 = phi i32 [ %157, %for.body322 ], [ %.pre899, %for.inc394 ]
  %219 = phi i32 [ %158, %for.body322 ], [ %.pre898, %for.inc394 ]
  %220 = phi i32 [ %159, %for.body322 ], [ %214, %for.inc394 ]
  %221 = phi i32 [ %160, %for.body322 ], [ %215, %for.inc394 ]
  %222 = phi i32 [ %161, %for.body322 ], [ %215, %for.inc394 ]
  %223 = phi i32 [ %162, %for.body322 ], [ %214, %for.inc394 ]
  %counter.1.lcssa = phi i32 [ %counter.0857, %for.body322 ], [ %counter.2.lcssa, %for.inc394 ]
  %inc400 = add nsw i32 %dim3.0858, 1
  %add319 = add nsw i32 %219, %218
  %cmp320 = icmp slt i32 %inc400, %add319
  br i1 %cmp320, label %for.body322, label %for.end403, !llvm.loop !228

for.end403:                                       ; preds = %for.inc399
  %cmp404 = icmp sgt i32 %counter.1.lcssa, 0
  br i1 %cmp404, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit612, label %if.end412

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit612: ; preds = %for.end403
  %mul407 = mul nsw i32 %counter.1.lcssa, %div.i
  %conv408 = sext i32 %mul407 to i64
  %call.i608 = call i64 @fwrite(i8* nonnull %150, i64 %conv408, i64 1, i8* nonnull %call.i598) #14
  %cmp.i609.not = icmp eq i64 %call.i608, 0
  br i1 %cmp.i609.not, label %cleanup425, label %if.end412

if.end412:                                        ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit612, %for.end403, %if.end311
  %224 = bitcast i64* %zero to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %224) #15
  store i64 0, i64* %zero, align 8, !tbaa !22
  %tobool413.not = icmp eq i32 %final_padding_bytes.0, 0
  br i1 %tobool413.not, label %if.end423, label %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit

_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit: ; preds = %if.end412
  %conv415 = zext i32 %final_padding_bytes.0 to i64
  %call.i604 = call i64 @fwrite(i8* nonnull %224, i64 %conv415, i64 1, i8* nonnull %call.i598) #14
  %cmp.i605.not = icmp eq i64 %call.i604, 0
  br i1 %cmp.i605.not, label %cleanup424, label %if.end423

if.end423:                                        ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit, %if.end412
  br label %cleanup424

cleanup424:                                       ; preds = %if.end423, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit
  %retval.21 = phi i32 [ 0, %if.end423 ], [ -16, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %224) #15
  br label %cleanup425

cleanup425.loopexit:                              ; preds = %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit619
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %153) #15
  br label %cleanup425

cleanup425:                                       ; preds = %cleanup425.loopexit, %cleanup424, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit612
  %retval.22 = phi i32 [ %retval.21, %cleanup424 ], [ -14, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit612 ], [ -13, %cleanup425.loopexit ]
  call void @llvm.lifetime.end.p0i8(i64 4096, i8* nonnull %150) #15
  br label %cleanup433

cleanup433:                                       ; preds = %cleanup425, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit631, %cleanup278, %cleanup278.thread, %cleanup154
  %retval.23 = phi i32 [ %retval.22, %cleanup425 ], [ %retval.4, %cleanup154 ], [ %retval.8, %cleanup278 ], [ -12, %_ZN6Halide7Runtime8Internal10ScopedFile5writeEPKvm.exit631 ], [ -6, %cleanup278.thread ]
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %3) #15
  %call.i = call i32 @fclose(i8* nonnull %call.i598) #14
  br label %return

return:                                           ; preds = %cleanup433, %if.end6, %if.end2, %if.then1, %if.then
  %retval.26 = phi i32 [ -1, %if.then ], [ -1, %if.then1 ], [ %call3, %if.end2 ], [ %retval.23, %cleanup433 ], [ -2, %if.end6 ]
  ret i32 %retval.26
}

declare i64 @fwrite(i8*, i64, i64, i8*) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void @halide_cache_cleanup() #0 {
entry:
  tail call void @halide_memoization_cache_cleanup() #16
  ret void
}

; Function Attrs: nounwind mustprogress
define weak void @halide_memoization_cache_cleanup() local_unnamed_addr #0 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %while.end
  store i64 0, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  store %"struct.Halide::Runtime::Internal::CacheEntry"* null, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE, align 8, !tbaa !14
  store %"struct.Halide::Runtime::Internal::CacheEntry"* null, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE, align 8, !tbaa !14
  ret void

for.body:                                         ; preds = %while.end, %entry
  %__begin1.018 = phi %"struct.Halide::Runtime::Internal::CacheEntry"** [ getelementptr inbounds ([256 x %"struct.Halide::Runtime::Internal::CacheEntry"*], [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*]* @_ZN6Halide7Runtime8Internal13cache_entriesE, i64 0, i64 0), %entry ], [ %incdec.ptr, %while.end ]
  %0 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %__begin1.018, align 8, !tbaa !14
  store %"struct.Halide::Runtime::Internal::CacheEntry"* null, %"struct.Halide::Runtime::Internal::CacheEntry"** %__begin1.018, align 8, !tbaa !14
  %cmp2.not16 = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %0, null
  br i1 %cmp2.not16, label %while.end, label %while.body

while.body:                                       ; preds = %for.body, %while.body
  %entry1.017 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %1, %while.body ], [ %0, %for.body ]
  %next3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry1.017, i64 0, i32 0
  %1 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next3, align 8, !tbaa !229
  tail call void @_ZN6Halide7Runtime8Internal10CacheEntry7destroyEv(%"struct.Halide::Runtime::Internal::CacheEntry"* nonnull dereferenceable(96) %entry1.017) #16
  %2 = bitcast %"struct.Halide::Runtime::Internal::CacheEntry"* %entry1.017 to i8*
  tail call void @halide_free(i8* null, i8* nonnull %2) #14
  %cmp2.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %1, null
  br i1 %cmp2.not, label %while.end, label %while.body, !llvm.loop !231

while.end:                                        ; preds = %while.body, %for.body
  %incdec.ptr = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %__begin1.018, i64 1
  %cmp.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"** %incdec.ptr, getelementptr inbounds ([256 x %"struct.Halide::Runtime::Internal::CacheEntry"*], [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*]* @_ZN6Halide7Runtime8Internal13cache_entriesE, i64 1, i64 0)
  br i1 %cmp.not, label %for.cond.cleanup, label %for.body
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal10CacheEntry7destroyEv(%"struct.Halide::Runtime::Internal::CacheEntry"* nonnull dereferenceable(96) %this) local_unnamed_addr #0 align 2 {
entry:
  %tuple_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 8
  %0 = load i32, i32* %tuple_count, align 8, !tbaa !232
  %cmp11.not = icmp eq i32 %0, 0
  br i1 %cmp11.not, label %for.cond.cleanup, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %entry
  %buf = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 11
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %entry
  %metadata_storage = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 3
  %1 = load i8*, i8** %metadata_storage, align 8, !tbaa !233
  tail call void @halide_free(i8* null, i8* %1) #14
  ret void

for.body:                                         ; preds = %for.body, %for.body.lr.ph
  %indvars.iv = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next, %for.body ]
  %2 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf, align 8, !tbaa !234
  %arrayidx = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %2, i64 %indvars.iv
  %call = tail call i32 @halide_device_free(i8* null, %struct.halide_buffer_t* %arrayidx) #14
  %3 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf, align 8, !tbaa !234
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %3, i64 %indvars.iv, i32 2
  %4 = load i8*, i8** %host, align 8, !tbaa !180
  %call6 = tail call %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* %4) #16
  %5 = bitcast %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call6 to i8*
  tail call void @halide_free(i8* null, i8* %5) #14
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %6 = load i32, i32* %tuple_count, align 8, !tbaa !232
  %7 = zext i32 %6 to i64
  %cmp = icmp ult i64 %indvars.iv.next, %7
  br i1 %cmp, label %for.body, label %for.cond.cleanup, !llvm.loop !235
}

; Function Attrs: nounwind willreturn mustprogress
define linkonce %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* %host) local_unnamed_addr #2 {
entry:
  %add.ptr = getelementptr inbounds i8, i8* %host, i64 -32
  %0 = bitcast i8* %add.ptr to %"struct.Halide::Runtime::Internal::CacheBlockHeader"*
  ret %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %0
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal18copy_memory_helperERKNS1_11device_copyEixx(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %copy, i32 %d, i64 %src_off, i64 %dst_off) local_unnamed_addr #0 {
entry:
  %cmp41 = icmp sgt i32 %d, -1
  br i1 %cmp41, label %land.rhs, label %while.end

land.rhs:                                         ; preds = %entry, %while.body
  %d.addr.042 = phi i32 [ %dec, %while.body ], [ %d, %entry ]
  %idxprom36 = zext i32 %d.addr.042 to i64
  %arrayidx = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 3, i64 %idxprom36
  %0 = load i64, i64* %arrayidx, align 8, !tbaa !22
  %cmp1 = icmp eq i64 %0, 1
  br i1 %cmp1, label %while.body, label %while.end

while.body:                                       ; preds = %land.rhs
  %dec = add nsw i32 %d.addr.042, -1
  %cmp = icmp sgt i32 %d.addr.042, 0
  br i1 %cmp, label %land.rhs, label %if.then, !llvm.loop !236

while.end:                                        ; preds = %land.rhs, %entry
  %d.addr.0.lcssa = phi i32 [ %d, %entry ], [ %d.addr.042, %land.rhs ]
  %cmp2 = icmp eq i32 %d.addr.0.lcssa, -1
  br i1 %cmp2, label %if.then, label %for.cond.preheader

for.cond.preheader:                               ; preds = %while.end
  %idxprom5 = sext i32 %d.addr.0.lcssa to i64
  %arrayidx6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 3, i64 %idxprom5
  %1 = load i64, i64* %arrayidx6, align 8, !tbaa !22
  %cmp737.not = icmp eq i64 %1, 0
  br i1 %cmp737.not, label %if.end, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %for.cond.preheader
  %sub = add nsw i32 %d.addr.0.lcssa, -1
  %arrayidx9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 4, i64 %idxprom5
  %arrayidx12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 5, i64 %idxprom5
  %inc.0 = add nuw i64 0, 1
  br label %for.body

if.then:                                          ; preds = %while.body, %while.end
  %src = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 0
  %2 = load i64, i64* %src, align 8, !tbaa !237
  %add = add i64 %2, %src_off
  %3 = inttoptr i64 %add to i8*
  %dst = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 1
  %4 = load i64, i64* %dst, align 8, !tbaa !239
  %add3 = add i64 %4, %dst_off
  %5 = inttoptr i64 %add3 to i8*
  %chunk_size = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 6
  %6 = load i64, i64* %chunk_size, align 8, !tbaa !240
  %call = tail call i8* @memcpy(i8* %5, i8* %3, i64 %6) #14
  br label %if.end

for.body:                                         ; preds = %for.body.for.body_crit_edge, %for.body.lr.ph
  %inc.phi = phi i64 [ %inc.0, %for.body.lr.ph ], [ %inc.1, %for.body.for.body_crit_edge ]
  %src_off.addr.039 = phi i64 [ %src_off, %for.body.lr.ph ], [ %add10, %for.body.for.body_crit_edge ]
  %dst_off.addr.038 = phi i64 [ %dst_off, %for.body.lr.ph ], [ %add13, %for.body.for.body_crit_edge ]
  tail call void @_ZN6Halide7Runtime8Internal18copy_memory_helperERKNS1_11device_copyEixx(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %copy, i32 %sub, i64 %src_off.addr.039, i64 %dst_off.addr.038) #16
  %7 = load i64, i64* %arrayidx9, align 8, !tbaa !22
  %add10 = add i64 %7, %src_off.addr.039
  %8 = load i64, i64* %arrayidx12, align 8, !tbaa !22
  %add13 = add i64 %8, %dst_off.addr.038
  %9 = load i64, i64* %arrayidx6, align 8, !tbaa !22
  %cmp7 = icmp ult i64 %inc.phi, %9
  br i1 %cmp7, label %for.body.for.body_crit_edge, label %if.end, !llvm.loop !241

for.body.for.body_crit_edge:                      ; preds = %for.body
  %inc.1 = add nuw i64 %inc.phi, 1
  br label %for.body

if.end:                                           ; preds = %for.body, %if.then, %for.cond.preheader
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal11copy_memoryERKNS1_11device_copyEPv(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %copy, i8* %user_context) local_unnamed_addr #0 {
entry:
  %src = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 0
  %0 = load i64, i64* %src, align 8, !tbaa !237
  %dst = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 1
  %1 = load i64, i64* %dst, align 8, !tbaa !239
  %cmp.not = icmp eq i64 %0, %1
  br i1 %cmp.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %src_begin = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i64 0, i32 2
  %2 = load i64, i64* %src_begin, align 8, !tbaa !242
  tail call void @_ZN6Halide7Runtime8Internal18copy_memory_helperERKNS1_11device_copyEixx(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %copy, i32 15, i64 %2, i64 0) #16
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal16make_buffer_copyEPK15halide_buffer_tbS4_b(%"struct.Halide::Runtime::Internal::device_copy"* noalias sret(%"struct.Halide::Runtime::Internal::device_copy") align 8 %agg.result, %struct.halide_buffer_t* %src, i1 zeroext %src_host, %struct.halide_buffer_t* %dst, i1 zeroext %dst_host) local_unnamed_addr #0 {
entry:
  %c = alloca %"struct.Halide::Runtime::Internal::device_copy", align 8
  %0 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %c to i8*
  call void @llvm.lifetime.start.p0i8(i64 416, i8* nonnull %0) #15
  br i1 %src_host, label %cond.true, label %cond.false

cond.true:                                        ; preds = %entry
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 2
  %1 = load i8*, i8** %host, align 8, !tbaa !180
  %2 = ptrtoint i8* %1 to i64
  br label %cond.end

cond.false:                                       ; preds = %entry
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 0
  %3 = load i64, i64* %device, align 8, !tbaa !182
  br label %cond.end

cond.end:                                         ; preds = %cond.false, %cond.true
  %cond = phi i64 [ %2, %cond.true ], [ %3, %cond.false ]
  %src2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 0
  store i64 %cond, i64* %src2, align 8, !tbaa !237
  br i1 %dst_host, label %cond.true4, label %cond.false6

cond.true4:                                       ; preds = %cond.end
  %host5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 2
  %4 = load i8*, i8** %host5, align 8, !tbaa !180
  %5 = ptrtoint i8* %4 to i64
  br label %cond.end8

cond.false6:                                      ; preds = %cond.end
  %device7 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 0
  %6 = load i64, i64* %device7, align 8, !tbaa !182
  br label %cond.end8

cond.end8:                                        ; preds = %cond.false6, %cond.true4
  %cond9 = phi i64 [ %5, %cond.true4 ], [ %6, %cond.false6 ]
  %dst10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 1
  store i64 %cond9, i64* %dst10, align 8, !tbaa !239
  %bits.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 4, i32 1
  %7 = load i8, i8* %bits.i, align 1, !tbaa !144
  %conv.i = zext i8 %7 to i32
  %add.i = add nuw nsw i32 %conv.i, 7
  %div.i = lshr i32 %add.i, 3
  %conv = zext i32 %div.i to i64
  %chunk_size = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 6
  store i64 %conv, i64* %chunk_size, align 8, !tbaa !240
  %arrayidx = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 0
  %arrayidx12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 0
  %arrayidx14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 0
  %arrayidx.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 1
  %8 = bitcast i64* %arrayidx to <2 x i64>*
  store <2 x i64> <i64 1, i64 1>, <2 x i64>* %8, align 8, !tbaa !22
  %arrayidx12.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 1
  %9 = bitcast i64* %arrayidx12 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %9, align 8, !tbaa !22
  %arrayidx14.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 1
  %10 = bitcast i64* %arrayidx14 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %10, align 8, !tbaa !22
  %arrayidx.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 2
  %arrayidx12.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 2
  %arrayidx14.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 2
  %arrayidx.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 3
  %11 = bitcast i64* %arrayidx.2 to <2 x i64>*
  store <2 x i64> <i64 1, i64 1>, <2 x i64>* %11, align 8, !tbaa !22
  %arrayidx12.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 3
  %12 = bitcast i64* %arrayidx12.2 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %12, align 8, !tbaa !22
  %arrayidx14.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 3
  %13 = bitcast i64* %arrayidx14.2 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %13, align 8, !tbaa !22
  %arrayidx.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 4
  %arrayidx12.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 4
  %arrayidx14.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 4
  %arrayidx.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 5
  %14 = bitcast i64* %arrayidx.4 to <2 x i64>*
  store <2 x i64> <i64 1, i64 1>, <2 x i64>* %14, align 8, !tbaa !22
  %arrayidx12.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 5
  %15 = bitcast i64* %arrayidx12.4 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %15, align 8, !tbaa !22
  %arrayidx14.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 5
  %16 = bitcast i64* %arrayidx14.4 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %16, align 8, !tbaa !22
  %arrayidx.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 6
  %arrayidx12.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 6
  %arrayidx14.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 6
  %arrayidx.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 7
  %17 = bitcast i64* %arrayidx.6 to <2 x i64>*
  store <2 x i64> <i64 1, i64 1>, <2 x i64>* %17, align 8, !tbaa !22
  %arrayidx12.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 7
  %18 = bitcast i64* %arrayidx12.6 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %18, align 8, !tbaa !22
  %arrayidx14.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 7
  %19 = bitcast i64* %arrayidx14.6 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %19, align 8, !tbaa !22
  %arrayidx.8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 8
  %arrayidx12.8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 8
  %arrayidx14.8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 8
  %arrayidx.9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 9
  %20 = bitcast i64* %arrayidx.8 to <2 x i64>*
  store <2 x i64> <i64 1, i64 1>, <2 x i64>* %20, align 8, !tbaa !22
  %arrayidx12.9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 9
  %21 = bitcast i64* %arrayidx12.8 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %21, align 8, !tbaa !22
  %arrayidx14.9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 9
  %22 = bitcast i64* %arrayidx14.8 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %22, align 8, !tbaa !22
  %arrayidx.10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 10
  %arrayidx12.10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 10
  %arrayidx14.10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 10
  %arrayidx.11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 11
  %23 = bitcast i64* %arrayidx.10 to <2 x i64>*
  store <2 x i64> <i64 1, i64 1>, <2 x i64>* %23, align 8, !tbaa !22
  %arrayidx12.11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 11
  %24 = bitcast i64* %arrayidx12.10 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %24, align 8, !tbaa !22
  %arrayidx14.11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 11
  %25 = bitcast i64* %arrayidx14.10 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %25, align 8, !tbaa !22
  %arrayidx.12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 12
  %arrayidx12.12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 12
  %arrayidx14.12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 12
  %arrayidx.13 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 13
  %26 = bitcast i64* %arrayidx.12 to <2 x i64>*
  store <2 x i64> <i64 1, i64 1>, <2 x i64>* %26, align 8, !tbaa !22
  %arrayidx12.13 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 13
  %27 = bitcast i64* %arrayidx12.12 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %27, align 8, !tbaa !22
  %arrayidx14.13 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 13
  %28 = bitcast i64* %arrayidx14.12 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %28, align 8, !tbaa !22
  %arrayidx.14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 14
  %arrayidx12.14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 14
  %arrayidx14.14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 14
  %arrayidx.15 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 15
  %29 = bitcast i64* %arrayidx.14 to <2 x i64>*
  store <2 x i64> <i64 1, i64 1>, <2 x i64>* %29, align 8, !tbaa !22
  %arrayidx12.15 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 15
  %30 = bitcast i64* %arrayidx12.14 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %30, align 8, !tbaa !22
  %arrayidx14.15 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 15
  %31 = bitcast i64* %arrayidx14.14 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %31, align 8, !tbaa !22
  %src_begin = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 2
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 5
  %32 = load i32, i32* %dimensions, align 4, !tbaa !183
  %cmp17272 = icmp sgt i32 %32, 0
  br i1 %cmp17272, label %for.body19.lr.ph, label %cond.end8.for.cond.cleanup18_crit_edge

cond.end8.for.cond.cleanup18_crit_edge:           ; preds = %cond.end8
  %mul37.0 = mul i64 %conv, 0
  br label %for.cond.cleanup18

for.body19.lr.ph:                                 ; preds = %cond.end8
  %dim = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 6
  %33 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !184
  %dim23 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 6
  %34 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim23, align 8, !tbaa !184
  %wide.trip.count = zext i32 %32 to i64
  %min.iters.check = icmp ult i32 %32, 5
  br i1 %min.iters.check, label %for.body19.preheader, label %vector.ph

for.body19.preheader:                             ; preds = %middle.block, %for.body19.lr.ph
  %indvars.iv284.ph = phi i64 [ 0, %for.body19.lr.ph ], [ %n.vec, %middle.block ]
  %.ph = phi i64 [ 0, %for.body19.lr.ph ], [ %61, %middle.block ]
  br label %for.body19

vector.ph:                                        ; preds = %for.body19.lr.ph
  %n.mod.vf = and i64 %wide.trip.count, 3
  %35 = icmp eq i64 %n.mod.vf, 0
  %36 = select i1 %35, i64 4, i64 %n.mod.vf
  %n.vec = sub nsw i64 %wide.trip.count, %36
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vec.phi = phi <2 x i64> [ zeroinitializer, %vector.ph ], [ %58, %vector.body ]
  %vec.phi2 = phi <2 x i64> [ zeroinitializer, %vector.ph ], [ %59, %vector.body ]
  %37 = or i64 %index, 2
  %38 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %33, i64 %index, i32 2
  %39 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %33, i64 %37, i32 2
  %40 = getelementptr inbounds i32, i32* %38, i64 -2
  %41 = bitcast i32* %40 to <8 x i32>*
  %42 = getelementptr inbounds i32, i32* %39, i64 -2
  %43 = bitcast i32* %42 to <8 x i32>*
  %wide.vec = load <8 x i32>, <8 x i32>* %41, align 4, !tbaa !41
  %wide.vec3 = load <8 x i32>, <8 x i32>* %43, align 4, !tbaa !41
  %strided.vec5 = shufflevector <8 x i32> %wide.vec, <8 x i32> poison, <2 x i32> <i32 2, i32 6>
  %strided.vec6 = shufflevector <8 x i32> %wide.vec3, <8 x i32> poison, <2 x i32> <i32 2, i32 6>
  %44 = sext <2 x i32> %strided.vec5 to <2 x i64>
  %45 = sext <2 x i32> %strided.vec6 to <2 x i64>
  %46 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %34, i64 %index, i32 0
  %47 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %34, i64 %37, i32 0
  %48 = bitcast i32* %46 to <8 x i32>*
  %49 = bitcast i32* %47 to <8 x i32>*
  %wide.vec7 = load <8 x i32>, <8 x i32>* %48, align 4, !tbaa !221
  %wide.vec8 = load <8 x i32>, <8 x i32>* %49, align 4, !tbaa !221
  %50 = sub nsw <8 x i32> %wide.vec7, %wide.vec
  %51 = shufflevector <8 x i32> %50, <8 x i32> undef, <2 x i32> <i32 0, i32 4>
  %52 = sub nsw <8 x i32> %wide.vec8, %wide.vec3
  %53 = shufflevector <8 x i32> %52, <8 x i32> undef, <2 x i32> <i32 0, i32 4>
  %54 = sext <2 x i32> %51 to <2 x i64>
  %55 = sext <2 x i32> %53 to <2 x i64>
  %56 = mul nsw <2 x i64> %54, %44
  %57 = mul nsw <2 x i64> %55, %45
  %58 = add <2 x i64> %56, %vec.phi
  %59 = add <2 x i64> %57, %vec.phi2
  %index.next = add i64 %index, 4
  %60 = icmp eq i64 %index.next, %n.vec
  br i1 %60, label %middle.block, label %vector.body, !llvm.loop !243

middle.block:                                     ; preds = %vector.body
  %bin.rdx = add <2 x i64> %59, %58
  %61 = call i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %bin.rdx)
  br label %for.body19.preheader

for.cond.cleanup18:                               ; preds = %for.body19.for.cond.cleanup18_crit_edge, %cond.end8.for.cond.cleanup18_crit_edge
  %mul37.phi = phi i64 [ %mul37.0, %cond.end8.for.cond.cleanup18_crit_edge ], [ %mul37.1, %for.body19.for.cond.cleanup18_crit_edge ]
  store i64 %mul37.phi, i64* %src_begin, align 8, !tbaa !242
  %dimensions39 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 5
  %62 = load i32, i32* %dimensions39, align 4, !tbaa !183
  %cmp40.not = icmp eq i32 %32, %62
  br i1 %cmp40.not, label %lor.lhs.false, label %if.then

for.body19:                                       ; preds = %for.body19.preheader, %for.body19
  %indvars.iv284 = phi i64 [ %indvars.iv.next285, %for.body19 ], [ %indvars.iv284.ph, %for.body19.preheader ]
  %63 = phi i64 [ %add, %for.body19 ], [ %.ph, %for.body19.preheader ]
  %stride = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %33, i64 %indvars.iv284, i32 2
  %64 = load i32, i32* %stride, align 4, !tbaa !185
  %conv22 = sext i32 %64 to i64
  %min = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %34, i64 %indvars.iv284, i32 0
  %65 = load i32, i32* %min, align 4, !tbaa !221
  %min29 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %33, i64 %indvars.iv284, i32 0
  %66 = load i32, i32* %min29, align 4, !tbaa !221
  %sub = sub nsw i32 %65, %66
  %conv30 = sext i32 %sub to i64
  %mul = mul nsw i64 %conv30, %conv22
  %add = add i64 %mul, %63
  %indvars.iv.next285 = add nuw nsw i64 %indvars.iv284, 1
  %exitcond286.not = icmp eq i64 %indvars.iv.next285, %wide.trip.count
  br i1 %exitcond286.not, label %for.body19.for.cond.cleanup18_crit_edge, label %for.body19, !llvm.loop !244

for.body19.for.cond.cleanup18_crit_edge:          ; preds = %for.body19
  %mul37.1 = mul i64 %add, %conv
  br label %for.cond.cleanup18

lor.lhs.false:                                    ; preds = %for.cond.cleanup18
  %bits.i253 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 4, i32 1
  %67 = load i8, i8* %bits.i253, align 1, !tbaa !144
  %conv.i254 = zext i8 %67 to i32
  %add.i255 = add nuw nsw i32 %conv.i254, 7
  %div.i256 = lshr i32 %add.i255, 3
  %cmp45.not = icmp ne i32 %div.i, %div.i256
  %cmp48 = icmp sgt i32 %32, 16
  %or.cond261 = or i1 %cmp48, %cmp45.not
  br i1 %or.cond261, label %if.then, label %if.end

if.then:                                          ; preds = %lor.lhs.false, %for.cond.cleanup18
  %68 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %agg.result to i8*
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(416) %68, i8 0, i64 416, i1 false)
  br label %cleanup

if.end:                                           ; preds = %lor.lhs.false
  %cmp50 = icmp eq i32 %div.i, 0
  br i1 %cmp50, label %if.then51, label %for.cond54.preheader

for.cond54.preheader:                             ; preds = %if.end
  br i1 %cmp17272, label %for.body58.lr.ph, label %while.end

for.body58.lr.ph:                                 ; preds = %for.cond54.preheader
  %dim60 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 6
  %69 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim60, align 8, !tbaa !184
  %dim70 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 6
  %70 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim70, align 8, !tbaa !184
  %wide.trip.count282 = zext i32 %32 to i64
  br label %for.body58

if.then51:                                        ; preds = %if.end
  %71 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %agg.result to i8*
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(416) %71, i8 0, i64 416, i1 false)
  br label %cleanup

while.cond.preheader:                             ; preds = %for.cond.cleanup94
  %.pre = load i64, i64* %chunk_size, align 8, !tbaa !240
  %.pre290 = load i64, i64* %arrayidx12, align 8, !tbaa !22
  %cmp139263 = icmp eq i64 %.pre, %.pre290
  br i1 %cmp139263, label %land.rhs.lr.ph, label %while.end

land.rhs.lr.ph:                                   ; preds = %while.cond.preheader
  %.pre291 = load i64, i64* %arrayidx14, align 8, !tbaa !22
  %72 = bitcast i64* %arrayidx.1 to <2 x i64>*
  %73 = bitcast i64* %arrayidx to <2 x i64>*
  %74 = bitcast i64* %arrayidx12.1 to <2 x i64>*
  %75 = bitcast i64* %arrayidx12 to <2 x i64>*
  %76 = bitcast i64* %arrayidx14.1 to <2 x i64>*
  %77 = bitcast i64* %arrayidx14 to <2 x i64>*
  %78 = bitcast i64* %arrayidx.3 to <2 x i64>*
  %79 = bitcast i64* %arrayidx.2 to <2 x i64>*
  %80 = bitcast i64* %arrayidx12.3 to <2 x i64>*
  %81 = bitcast i64* %arrayidx12.2 to <2 x i64>*
  %82 = bitcast i64* %arrayidx14.3 to <2 x i64>*
  %83 = bitcast i64* %arrayidx14.2 to <2 x i64>*
  %84 = bitcast i64* %arrayidx.5 to <2 x i64>*
  %85 = bitcast i64* %arrayidx.4 to <2 x i64>*
  %86 = bitcast i64* %arrayidx12.5 to <2 x i64>*
  %87 = bitcast i64* %arrayidx12.4 to <2 x i64>*
  %88 = bitcast i64* %arrayidx14.5 to <2 x i64>*
  %89 = bitcast i64* %arrayidx14.4 to <2 x i64>*
  %90 = bitcast i64* %arrayidx.7 to <2 x i64>*
  %91 = bitcast i64* %arrayidx.6 to <2 x i64>*
  %92 = bitcast i64* %arrayidx12.7 to <2 x i64>*
  %93 = bitcast i64* %arrayidx12.6 to <2 x i64>*
  %94 = bitcast i64* %arrayidx14.7 to <2 x i64>*
  %95 = bitcast i64* %arrayidx14.6 to <2 x i64>*
  %96 = bitcast i64* %arrayidx.9 to <2 x i64>*
  %97 = bitcast i64* %arrayidx.8 to <2 x i64>*
  %98 = bitcast i64* %arrayidx12.9 to <2 x i64>*
  %99 = bitcast i64* %arrayidx12.8 to <2 x i64>*
  %100 = bitcast i64* %arrayidx14.9 to <2 x i64>*
  %101 = bitcast i64* %arrayidx14.8 to <2 x i64>*
  %102 = bitcast i64* %arrayidx.11 to <2 x i64>*
  %103 = bitcast i64* %arrayidx.10 to <2 x i64>*
  %104 = bitcast i64* %arrayidx12.11 to <2 x i64>*
  %105 = bitcast i64* %arrayidx12.10 to <2 x i64>*
  %106 = bitcast i64* %arrayidx14.11 to <2 x i64>*
  %107 = bitcast i64* %arrayidx14.10 to <2 x i64>*
  %108 = bitcast i64* %arrayidx.13 to <2 x i64>*
  %109 = bitcast i64* %arrayidx.12 to <2 x i64>*
  %110 = bitcast i64* %arrayidx12.13 to <2 x i64>*
  %111 = bitcast i64* %arrayidx12.12 to <2 x i64>*
  %112 = bitcast i64* %arrayidx14.13 to <2 x i64>*
  %113 = bitcast i64* %arrayidx14.12 to <2 x i64>*
  br label %land.rhs

for.body58:                                       ; preds = %for.cond.cleanup94, %for.body58.lr.ph
  %indvars.iv278 = phi i64 [ 0, %for.body58.lr.ph ], [ %indvars.iv.next279, %for.cond.cleanup94 ]
  %stride63 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %69, i64 %indvars.iv278, i32 2
  %114 = load i32, i32* %stride63, align 4, !tbaa !185
  %conv64 = sext i32 %114 to i64
  %mul68 = mul nsw i64 %conv64, %conv
  %stride73 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %70, i64 %indvars.iv278, i32 2
  %115 = load i32, i32* %stride73, align 4, !tbaa !185
  %conv74 = sext i32 %115 to i64
  %mul78 = mul nsw i64 %conv74, %conv
  %cmp80264.not = icmp eq i64 %indvars.iv278, 0
  br i1 %cmp80264.not, label %for.end91, label %for.body81.lr.ph

for.body81.lr.ph:                                 ; preds = %for.body58
  %cmp86.not = icmp eq i64 %mul68, 0
  br i1 %cmp86.not, label %for.body81.preheader, label %for.body81.us

for.body81.preheader:                             ; preds = %for.body81.lr.ph
  %116 = trunc i64 %indvars.iv278 to i32
  br label %for.end91

for.body81.us:                                    ; preds = %for.body81.lr.ph, %for.inc89.us
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.inc89.us ], [ 0, %for.body81.lr.ph ]
  %arrayidx84.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 %indvars.iv
  %117 = load i64, i64* %arrayidx84.us, align 8, !tbaa !22
  %cmp85.us = icmp ult i64 %mul68, %117
  br i1 %cmp85.us, label %for.end91.loopexit, label %for.inc89.us

for.inc89.us:                                     ; preds = %for.body81.us
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, %indvars.iv278
  br i1 %exitcond.not, label %for.end91.loopexit, label %for.body81.us, !llvm.loop !245

for.end91.loopexit:                               ; preds = %for.inc89.us, %for.body81.us
  %insert.0.lcssa.ph.in = phi i64 [ %indvars.iv278, %for.inc89.us ], [ %indvars.iv, %for.body81.us ]
  %insert.0.lcssa.ph = trunc i64 %insert.0.lcssa.ph.in to i32
  br label %for.end91

for.end91:                                        ; preds = %for.end91.loopexit, %for.body81.preheader, %for.body58
  %insert.0.lcssa = phi i32 [ 0, %for.body58 ], [ %insert.0.lcssa.ph, %for.end91.loopexit ], [ %116, %for.body81.preheader ]
  %118 = zext i32 %insert.0.lcssa to i64
  %cmp93267 = icmp ugt i64 %indvars.iv278, %118
  br i1 %cmp93267, label %for.body95.preheader, label %for.cond.cleanup94

for.body95.preheader:                             ; preds = %for.end91
  %119 = sext i32 %insert.0.lcssa to i64
  br label %for.body95

for.cond.cleanup94:                               ; preds = %for.body95, %for.end91
  %extent122 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %69, i64 %indvars.iv278, i32 1
  %120 = load i32, i32* %extent122, align 4, !tbaa !189
  %conv123 = sext i32 %120 to i64
  %arrayidx126 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 %118
  store i64 %conv123, i64* %arrayidx126, align 8, !tbaa !22
  %arrayidx129 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 %118
  store i64 %mul68, i64* %arrayidx129, align 8, !tbaa !22
  %arrayidx132 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 %118
  store i64 %mul78, i64* %arrayidx132, align 8, !tbaa !22
  %indvars.iv.next279 = add nuw nsw i64 %indvars.iv278, 1
  %exitcond283.not = icmp eq i64 %indvars.iv.next279, %wide.trip.count282
  br i1 %exitcond283.not, label %while.cond.preheader, label %for.body58, !llvm.loop !246

for.body95:                                       ; preds = %for.body95, %for.body95.preheader
  %indvars.iv280 = phi i64 [ %indvars.iv278, %for.body95.preheader ], [ %indvars.iv.next281, %for.body95 ]
  %indvars.iv.next281 = add nsw i64 %indvars.iv280, -1
  %arrayidx99 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 %indvars.iv.next281
  %121 = load i64, i64* %arrayidx99, align 8, !tbaa !22
  %arrayidx102 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 3, i64 %indvars.iv280
  store i64 %121, i64* %arrayidx102, align 8, !tbaa !22
  %arrayidx106 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 %indvars.iv.next281
  %122 = load i64, i64* %arrayidx106, align 8, !tbaa !22
  %arrayidx109 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 5, i64 %indvars.iv280
  store i64 %122, i64* %arrayidx109, align 8, !tbaa !22
  %arrayidx113 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 %indvars.iv.next281
  %123 = load i64, i64* %arrayidx113, align 8, !tbaa !22
  %arrayidx116 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i64 0, i32 4, i64 %indvars.iv280
  store i64 %123, i64* %arrayidx116, align 8, !tbaa !22
  %cmp93 = icmp sgt i64 %indvars.iv.next281, %119
  br i1 %cmp93, label %for.body95, label %for.cond.cleanup94, !llvm.loop !247

land.rhs:                                         ; preds = %while.body, %land.rhs.lr.ph
  %124 = phi i64 [ %.pre291, %land.rhs.lr.ph ], [ %152, %while.body ]
  %125 = phi i64 [ %.pre, %land.rhs.lr.ph ], [ %mul147, %while.body ]
  %cmp143 = icmp eq i64 %125, %124
  br i1 %cmp143, label %while.body, label %while.end

while.body:                                       ; preds = %land.rhs
  %126 = load i64, i64* %arrayidx, align 8, !tbaa !22
  %mul147 = mul i64 %126, %124
  store i64 %mul147, i64* %chunk_size, align 8, !tbaa !240
  %127 = load <2 x i64>, <2 x i64>* %72, align 8, !tbaa !22
  store <2 x i64> %127, <2 x i64>* %73, align 8, !tbaa !22
  %128 = load <2 x i64>, <2 x i64>* %74, align 8, !tbaa !22
  store <2 x i64> %128, <2 x i64>* %75, align 8, !tbaa !22
  %129 = load <2 x i64>, <2 x i64>* %76, align 8, !tbaa !22
  store <2 x i64> %129, <2 x i64>* %77, align 8, !tbaa !22
  %130 = load <2 x i64>, <2 x i64>* %78, align 8, !tbaa !22
  store <2 x i64> %130, <2 x i64>* %79, align 8, !tbaa !22
  %131 = load <2 x i64>, <2 x i64>* %80, align 8, !tbaa !22
  store <2 x i64> %131, <2 x i64>* %81, align 8, !tbaa !22
  %132 = load <2 x i64>, <2 x i64>* %82, align 8, !tbaa !22
  store <2 x i64> %132, <2 x i64>* %83, align 8, !tbaa !22
  %133 = load <2 x i64>, <2 x i64>* %84, align 8, !tbaa !22
  store <2 x i64> %133, <2 x i64>* %85, align 8, !tbaa !22
  %134 = load <2 x i64>, <2 x i64>* %86, align 8, !tbaa !22
  store <2 x i64> %134, <2 x i64>* %87, align 8, !tbaa !22
  %135 = load <2 x i64>, <2 x i64>* %88, align 8, !tbaa !22
  store <2 x i64> %135, <2 x i64>* %89, align 8, !tbaa !22
  %136 = load <2 x i64>, <2 x i64>* %90, align 8, !tbaa !22
  store <2 x i64> %136, <2 x i64>* %91, align 8, !tbaa !22
  %137 = load <2 x i64>, <2 x i64>* %92, align 8, !tbaa !22
  store <2 x i64> %137, <2 x i64>* %93, align 8, !tbaa !22
  %138 = load <2 x i64>, <2 x i64>* %94, align 8, !tbaa !22
  store <2 x i64> %138, <2 x i64>* %95, align 8, !tbaa !22
  %139 = load <2 x i64>, <2 x i64>* %96, align 8, !tbaa !22
  store <2 x i64> %139, <2 x i64>* %97, align 8, !tbaa !22
  %140 = load <2 x i64>, <2 x i64>* %98, align 8, !tbaa !22
  store <2 x i64> %140, <2 x i64>* %99, align 8, !tbaa !22
  %141 = load <2 x i64>, <2 x i64>* %100, align 8, !tbaa !22
  store <2 x i64> %141, <2 x i64>* %101, align 8, !tbaa !22
  %142 = load <2 x i64>, <2 x i64>* %102, align 8, !tbaa !22
  store <2 x i64> %142, <2 x i64>* %103, align 8, !tbaa !22
  %143 = load <2 x i64>, <2 x i64>* %104, align 8, !tbaa !22
  store <2 x i64> %143, <2 x i64>* %105, align 8, !tbaa !22
  %144 = load <2 x i64>, <2 x i64>* %106, align 8, !tbaa !22
  store <2 x i64> %144, <2 x i64>* %107, align 8, !tbaa !22
  %145 = load <2 x i64>, <2 x i64>* %108, align 8, !tbaa !22
  store <2 x i64> %145, <2 x i64>* %109, align 8, !tbaa !22
  %146 = load <2 x i64>, <2 x i64>* %110, align 8, !tbaa !22
  store <2 x i64> %146, <2 x i64>* %111, align 8, !tbaa !22
  %147 = load <2 x i64>, <2 x i64>* %112, align 8, !tbaa !22
  store <2 x i64> %147, <2 x i64>* %113, align 8, !tbaa !22
  %148 = load i64, i64* %arrayidx.15, align 8, !tbaa !22
  store i64 %148, i64* %arrayidx.14, align 8, !tbaa !22
  %149 = load i64, i64* %arrayidx12.15, align 8, !tbaa !22
  store i64 %149, i64* %arrayidx12.14, align 8, !tbaa !22
  %150 = load i64, i64* %arrayidx14.15, align 8, !tbaa !22
  store i64 %150, i64* %arrayidx14.14, align 8, !tbaa !22
  store i64 1, i64* %arrayidx.15, align 8, !tbaa !22
  store i64 0, i64* %arrayidx12.15, align 8, !tbaa !22
  store i64 0, i64* %arrayidx14.15, align 8, !tbaa !22
  %151 = extractelement <2 x i64> %128, i32 0
  %cmp139 = icmp eq i64 %mul147, %151
  %152 = extractelement <2 x i64> %129, i32 0
  br i1 %cmp139, label %land.rhs, label %while.end, !llvm.loop !248

while.end:                                        ; preds = %while.body, %land.rhs, %while.cond.preheader, %for.cond54.preheader
  %153 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %agg.result to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(416) %153, i8* nonnull align 8 dereferenceable(416) %0, i64 416, i1 false), !tbaa.struct !249
  br label %cleanup

cleanup:                                          ; preds = %while.end, %if.then51, %if.then
  call void @llvm.lifetime.end.p0i8(i64 416, i8* nonnull %0) #15
  ret void
}

; Function Attrs: argmemonly nofree nosync nounwind willreturn writeonly
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #5

; Function Attrs: nounwind mustprogress
define linkonce zeroext i1 @_ZN6Halide7Runtime8Internal10keys_equalEPKhS3_m(i8* %key1, i8* %key2, i64 %key_size) local_unnamed_addr #0 {
entry:
  %call = tail call i32 @memcmp(i8* %key1, i8* %key2, i64 %key_size) #14
  %cmp = icmp eq i32 %call, 0
  ret i1 %cmp
}

declare i32 @memcmp(i8*, i8*, i64) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define linkonce zeroext i1 @_ZN6Halide7Runtime8Internal16buffer_has_shapeEPK15halide_buffer_tPK18halide_dimension_t(%struct.halide_buffer_t* %buf, %struct.halide_dimension_t* %shape) local_unnamed_addr #0 {
entry:
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 5
  %0 = load i32, i32* %dimensions, align 4, !tbaa !183
  %cmp9 = icmp sgt i32 %0, 0
  br i1 %cmp9, label %for.body.lr.ph, label %return

for.body.lr.ph:                                   ; preds = %entry
  %dim = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 6
  %1 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !184
  %2 = zext i32 %0 to i64
  br label %for.body

for.cond:                                         ; preds = %_ZNK18halide_dimension_tneERKS_.exit
  %exitcond.not = icmp eq i64 %indvars.iv.next, %2
  br i1 %exitcond.not, label %return, label %for.body, !llvm.loop !250

for.body:                                         ; preds = %for.cond, %for.body.lr.ph
  %indvars.iv = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next, %for.cond ]
  %min.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %1, i64 %indvars.iv, i32 0
  %3 = load i32, i32* %min.i.i, align 4, !tbaa !221
  %min2.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %shape, i64 %indvars.iv, i32 0
  %4 = load i32, i32* %min2.i.i, align 4, !tbaa !221
  %cmp.i.i = icmp eq i32 %3, %4
  br i1 %cmp.i.i, label %land.lhs.true.i.i, label %return

land.lhs.true.i.i:                                ; preds = %for.body
  %extent.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %1, i64 %indvars.iv, i32 1
  %5 = load i32, i32* %extent.i.i, align 4, !tbaa !189
  %extent3.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %shape, i64 %indvars.iv, i32 1
  %6 = load i32, i32* %extent3.i.i, align 4, !tbaa !189
  %cmp4.i.i = icmp eq i32 %5, %6
  br i1 %cmp4.i.i, label %land.lhs.true5.i.i, label %return

land.lhs.true5.i.i:                               ; preds = %land.lhs.true.i.i
  %stride.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %1, i64 %indvars.iv, i32 2
  %7 = load i32, i32* %stride.i.i, align 4, !tbaa !185
  %stride6.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %shape, i64 %indvars.iv, i32 2
  %8 = load i32, i32* %stride6.i.i, align 4, !tbaa !185
  %cmp7.i.i = icmp eq i32 %7, %8
  br i1 %cmp7.i.i, label %_ZNK18halide_dimension_tneERKS_.exit, label %return

_ZNK18halide_dimension_tneERKS_.exit:             ; preds = %land.lhs.true5.i.i
  %flags.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %1, i64 %indvars.iv, i32 3
  %9 = load i32, i32* %flags.i.i, align 4, !tbaa !251
  %flags8.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %shape, i64 %indvars.iv, i32 3
  %10 = load i32, i32* %flags8.i.i, align 4, !tbaa !251
  %cmp9.i.i.not = icmp eq i32 %9, %10
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  br i1 %cmp9.i.i.not, label %for.cond, label %return

return:                                           ; preds = %_ZNK18halide_dimension_tneERKS_.exit, %land.lhs.true5.i.i, %land.lhs.true.i.i, %for.body, %for.cond, %entry
  %cmp.lcssa = phi i1 [ true, %entry ], [ false, %_ZNK18halide_dimension_tneERKS_.exit ], [ true, %for.cond ], [ false, %land.lhs.true5.i.i ], [ false, %land.lhs.true.i.i ], [ false, %for.body ]
  ret i1 %cmp.lcssa
}

; Function Attrs: nounwind mustprogress
define linkonce zeroext i1 @_ZN6Halide7Runtime8Internal10CacheEntry4initEPKhmjPK15halide_buffer_tiPPS5_by(%"struct.Halide::Runtime::Internal::CacheEntry"* nonnull dereferenceable(96) %this, i8* %cache_key, i64 %cache_key_size, i32 %key_hash, %struct.halide_buffer_t* %computed_bounds_buf, i32 %tuples, %struct.halide_buffer_t** %tuple_buffers, i1 zeroext %has_eviction_key_arg, i64 %eviction_key_arg) local_unnamed_addr #0 align 2 {
entry:
  %frombool = zext i1 %has_eviction_key_arg to i8
  %0 = bitcast %"struct.Halide::Runtime::Internal::CacheEntry"* %this to <2 x %"struct.Halide::Runtime::Internal::CacheEntry"*>*
  store <2 x %"struct.Halide::Runtime::Internal::CacheEntry"*> zeroinitializer, <2 x %"struct.Halide::Runtime::Internal::CacheEntry"*>* %0, align 8, !tbaa !14
  %less_recent = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::CacheEntry"* null, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent, align 8, !tbaa !252
  %key_size = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 4
  store i64 %cache_key_size, i64* %key_size, align 8, !tbaa !253
  %hash = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 6
  store i32 %key_hash, i32* %hash, align 8, !tbaa !254
  %in_use_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 7
  store i32 0, i32* %in_use_count, align 4, !tbaa !255
  %tuple_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 8
  store i32 %tuples, i32* %tuple_count, align 8, !tbaa !232
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %computed_bounds_buf, i64 0, i32 5
  %1 = load i32, i32* %dimensions, align 4, !tbaa !183
  %dimensions2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 9
  store i32 %1, i32* %dimensions2, align 4, !tbaa !256
  %conv = zext i32 %tuples to i64
  %mul = mul nuw nsw i64 %conv, 56
  %conv5 = sext i32 %1 to i64
  %add8 = add i32 %tuples, 1
  %conv9 = zext i32 %add8 to i64
  %mul6 = shl nuw nsw i64 %conv9, 4
  %mul10 = mul i64 %mul6, %conv5
  %add11 = add i64 %mul10, %mul
  %add13 = add i64 %add11, %cache_key_size
  %call = tail call i8* @halide_malloc(i8* null, i64 %add13) #14
  %metadata_storage = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 3
  store i8* %call, i8** %metadata_storage, align 8, !tbaa !233
  %tobool.not = icmp eq i8* %call, null
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %buf = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 11
  %2 = bitcast %struct.halide_buffer_t** %buf to i8**
  store i8* %call, i8** %2, align 8, !tbaa !234
  %add.ptr = getelementptr inbounds i8, i8* %call, i64 %mul
  %computed_bounds = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 10
  %3 = bitcast %struct.halide_dimension_t** %computed_bounds to i8**
  store i8* %add.ptr, i8** %3, align 8, !tbaa !257
  %add.ptr18 = getelementptr inbounds i8, i8* %call, i64 %add11
  %key = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 5
  store i8* %add.ptr18, i8** %key, align 8, !tbaa !258
  %4 = load i64, i64* %key_size, align 8, !tbaa !253
  %cmp117.not = icmp eq i64 %4, 0
  br i1 %cmp117.not, label %for.cond23.preheader, label %for.body.preheader

for.body.preheader:                               ; preds = %if.end
  %5 = load i8, i8* %cache_key, align 1, !tbaa !18
  store i8 %5, i8* %add.ptr18, align 1, !tbaa !18
  %6 = load i64, i64* %key_size, align 8, !tbaa !253
  %cmp130 = icmp ugt i64 %6, 1
  br i1 %cmp130, label %for.body.for.body_crit_edge, label %for.cond23.preheader, !llvm.loop !259

for.cond23.preheader:                             ; preds = %for.body.for.body_crit_edge, %for.body.preheader, %if.end
  %7 = load i32, i32* %dimensions2, align 4, !tbaa !256
  %cmp25115 = icmp sgt i32 %7, 0
  br i1 %cmp25115, label %for.body27.lr.ph, label %for.cond36.preheader

for.body27.lr.ph:                                 ; preds = %for.cond23.preheader
  %dim = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %computed_bounds_buf, i64 0, i32 6
  br label %for.body27

for.body.for.body_crit_edge:                      ; preds = %for.body.preheader, %for.body.for.body_crit_edge
  %inc131 = phi i64 [ %inc, %for.body.for.body_crit_edge ], [ 1, %for.body.preheader ]
  %.pre = load i8*, i8** %key, align 8, !tbaa !258
  %arrayidx = getelementptr inbounds i8, i8* %cache_key, i64 %inc131
  %8 = load i8, i8* %arrayidx, align 1, !tbaa !18
  %arrayidx21 = getelementptr inbounds i8, i8* %.pre, i64 %inc131
  store i8 %8, i8* %arrayidx21, align 1, !tbaa !18
  %inc = add nuw i64 %inc131, 1
  %9 = load i64, i64* %key_size, align 8, !tbaa !253
  %cmp = icmp ult i64 %inc, %9
  br i1 %cmp, label %for.body.for.body_crit_edge, label %for.cond23.preheader, !llvm.loop !259

for.cond36.preheader:                             ; preds = %for.body27, %for.cond23.preheader
  %10 = load i32, i32* %tuple_count, align 8, !tbaa !232
  %cmp38113.not = icmp eq i32 %10, 0
  br i1 %cmp38113.not, label %for.cond.cleanup39, label %for.body40

for.body27:                                       ; preds = %for.body27, %for.body27.lr.ph
  %indvars.iv121 = phi i64 [ 0, %for.body27.lr.ph ], [ %indvars.iv.next122, %for.body27 ]
  %11 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !184
  %arrayidx28 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i64 %indvars.iv121
  %12 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %computed_bounds, align 8, !tbaa !257
  %arrayidx31 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i64 %indvars.iv121
  %13 = bitcast %struct.halide_dimension_t* %arrayidx31 to i8*
  %14 = bitcast %struct.halide_dimension_t* %arrayidx28 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 dereferenceable(16) %13, i8* nonnull align 4 dereferenceable(16) %14, i64 16, i1 false), !tbaa.struct !188
  %indvars.iv.next122 = add nuw nsw i64 %indvars.iv121, 1
  %15 = load i32, i32* %dimensions2, align 4, !tbaa !256
  %16 = sext i32 %15 to i64
  %cmp25 = icmp slt i64 %indvars.iv.next122, %16
  br i1 %cmp25, label %for.body27, label %for.cond36.preheader, !llvm.loop !260

for.cond36.loopexit:                              ; preds = %for.body59.for.body59_crit_edge, %for.body59.preheader, %for.body40
  %17 = load i32, i32* %tuple_count, align 8, !tbaa !232
  %18 = zext i32 %17 to i64
  %cmp38 = icmp ult i64 %indvars.iv.next120, %18
  br i1 %cmp38, label %for.body40, label %for.cond.cleanup39, !llvm.loop !261

for.cond.cleanup39:                               ; preds = %for.cond36.loopexit, %for.cond36.preheader
  %has_eviction_key = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 13
  store i8 %frombool, i8* %has_eviction_key, align 8, !tbaa !262
  %eviction_key = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %this, i64 0, i32 12
  store i64 %eviction_key_arg, i64* %eviction_key, align 8, !tbaa !263
  br label %cleanup

for.body40:                                       ; preds = %for.cond36.preheader, %for.cond36.loopexit
  %indvars.iv119 = phi i64 [ %indvars.iv.next120, %for.cond36.loopexit ], [ 0, %for.cond36.preheader ]
  %arrayidx42 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv119
  %19 = bitcast %struct.halide_buffer_t** %arrayidx42 to i8**
  %20 = load i8*, i8** %19, align 8, !tbaa !14
  %21 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf, align 8, !tbaa !234
  %arrayidx45 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %21, i64 %indvars.iv119
  %22 = bitcast %struct.halide_buffer_t* %arrayidx45 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(56) %22, i8* nonnull align 8 dereferenceable(56) %20, i64 56, i1 false), !tbaa.struct !264
  %23 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %computed_bounds, align 8, !tbaa !257
  %indvars.iv.next120 = add nuw nsw i64 %indvars.iv119, 1
  %24 = load i32, i32* %dimensions2, align 4, !tbaa !256
  %25 = trunc i64 %indvars.iv.next120 to i32
  %mul49 = mul i32 %24, %25
  %idx.ext = zext i32 %mul49 to i64
  %add.ptr50 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %23, i64 %idx.ext
  %26 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf, align 8, !tbaa !234
  %dim54 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %26, i64 %indvars.iv119, i32 6
  store %struct.halide_dimension_t* %add.ptr50, %struct.halide_dimension_t** %dim54, align 8, !tbaa !184
  %cmp57111 = icmp sgt i32 %24, 0
  br i1 %cmp57111, label %for.body59.preheader, label %for.cond36.loopexit

for.body59.preheader:                             ; preds = %for.body40
  %27 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx42, align 8, !tbaa !14
  %dim62125 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %27, i64 0, i32 6
  %28 = bitcast %struct.halide_dimension_t** %dim62125 to i8**
  %29 = load i8*, i8** %28, align 8, !tbaa !184
  %30 = bitcast %struct.halide_dimension_t* %add.ptr50 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 dereferenceable(16) %30, i8* nonnull align 4 dereferenceable(16) %29, i64 16, i1 false), !tbaa.struct !188
  %31 = load i32, i32* %dimensions2, align 4, !tbaa !256
  %cmp57128 = icmp sgt i32 %31, 1
  br i1 %cmp57128, label %for.body59.for.body59_crit_edge, label %for.cond36.loopexit, !llvm.loop !266

for.body59.for.body59_crit_edge:                  ; preds = %for.body59.preheader, %for.body59.for.body59_crit_edge
  %indvars.iv.next129 = phi i64 [ %indvars.iv.next, %for.body59.for.body59_crit_edge ], [ 1, %for.body59.preheader ]
  %.pre123 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf, align 8, !tbaa !234
  %dim68.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %.pre123, i64 %indvars.iv119, i32 6
  %.pre124 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim68.phi.trans.insert, align 8, !tbaa !184
  %32 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx42, align 8, !tbaa !14
  %dim62 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %32, i64 0, i32 6
  %33 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim62, align 8, !tbaa !184
  %arrayidx64 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %33, i64 %indvars.iv.next129
  %arrayidx70 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %.pre124, i64 %indvars.iv.next129
  %34 = bitcast %struct.halide_dimension_t* %arrayidx70 to i8*
  %35 = bitcast %struct.halide_dimension_t* %arrayidx64 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 dereferenceable(16) %34, i8* nonnull align 4 dereferenceable(16) %35, i64 16, i1 false), !tbaa.struct !188
  %indvars.iv.next = add nuw nsw i64 %indvars.iv.next129, 1
  %36 = load i32, i32* %dimensions2, align 4, !tbaa !256
  %37 = sext i32 %36 to i64
  %cmp57 = icmp slt i64 %indvars.iv.next, %37
  br i1 %cmp57, label %for.body59.for.body59_crit_edge, label %for.cond36.loopexit, !llvm.loop !266

cleanup:                                          ; preds = %for.cond.cleanup39, %entry
  %38 = xor i1 %tobool.not, true
  ret i1 %38
}

; Function Attrs: nounwind mustprogress
define linkonce i32 @_ZN6Halide7Runtime8Internal8djb_hashEPKhm(i8* %key, i64 %key_size) local_unnamed_addr #0 {
entry:
  %cmp8.not = icmp eq i64 %key_size, 0
  br i1 %cmp8.not, label %for.cond.cleanup, label %entry.for.body_crit_edge

entry.for.body_crit_edge:                         ; preds = %entry
  %inc.1 = add nuw i64 0, 1
  %arrayidx.1 = getelementptr inbounds i8, i8* %key, i64 0
  %add.1 = mul i32 5381, 33
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %entry
  %h.0.lcssa = phi i32 [ 5381, %entry ], [ %add1, %for.body ]
  ret i32 %h.0.lcssa

for.body:                                         ; preds = %entry.for.body_crit_edge, %for.body.for.body_crit_edge
  %add.phi = phi i32 [ %add.0, %for.body.for.body_crit_edge ], [ %add.1, %entry.for.body_crit_edge ]
  %arrayidx.phi = phi i8* [ %arrayidx.0, %for.body.for.body_crit_edge ], [ %arrayidx.1, %entry.for.body_crit_edge ]
  %inc.phi = phi i64 [ %inc.0, %for.body.for.body_crit_edge ], [ %inc.1, %entry.for.body_crit_edge ]
  %0 = load i8, i8* %arrayidx.phi, align 1, !tbaa !18
  %conv = zext i8 %0 to i32
  %add1 = add i32 %add.phi, %conv
  %exitcond.not = icmp eq i64 %inc.phi, %key_size
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body.for.body_crit_edge, !llvm.loop !267

for.body.for.body_crit_edge:                      ; preds = %for.body
  %inc.0 = add nuw i64 %inc.phi, 1
  %arrayidx.0 = getelementptr inbounds i8, i8* %key, i64 %inc.phi
  %add.0 = mul i32 %add1, 33
  br label %for.body
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal11prune_cacheEv() local_unnamed_addr #0 {
entry:
  %0 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE, align 8, !tbaa !14
  %1 = load i64, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  %2 = load i64, i64* @_ZN6Halide7Runtime8Internal14max_cache_sizeE, align 8, !tbaa !22
  %cmp84 = icmp sgt i64 %1, %2
  %cmp185 = icmp ne %"struct.Halide::Runtime::Internal::CacheEntry"* %0, null
  %3 = and i1 %cmp185, %cmp84
  br i1 %3, label %while.body, label %while.end42

while.body:                                       ; preds = %entry, %if.end41
  %4 = phi i64 [ %74, %if.end41 ], [ %2, %entry ]
  %5 = phi i64 [ %75, %if.end41 ], [ %1, %entry ]
  %prune_candidate.086 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %6, %if.end41 ], [ %0, %entry ]
  %more_recent2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 1
  %6 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent2, align 8, !tbaa !268
  %in_use_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 7
  %7 = load i32, i32* %in_use_count, align 4, !tbaa !255
  %cmp3 = icmp eq i32 %7, 0
  br i1 %cmp3, label %if.then, label %if.end41

if.then:                                          ; preds = %while.body
  %hash = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 6
  %8 = load i32, i32* %hash, align 8, !tbaa !254
  %9 = and i32 %8, 255
  %idxprom = zext i32 %9 to i64
  %arrayidx = getelementptr inbounds [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*], [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*]* @_ZN6Halide7Runtime8Internal13cache_entriesE, i64 0, i64 %idxprom
  %10 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %arrayidx, align 8, !tbaa !14
  %cmp5 = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %10, %prune_candidate.086
  br i1 %cmp5, label %if.then6, label %while.cond9

if.then6:                                         ; preds = %if.then
  %next = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 0
  %11 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next, align 8, !tbaa !229
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %11, %"struct.Halide::Runtime::Internal::CacheEntry"** %arrayidx, align 8, !tbaa !14
  br label %if.end21

while.cond9:                                      ; preds = %if.then, %land.rhs11
  %prev_hash_entry.0 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %12, %land.rhs11 ], [ %10, %if.then ]
  %cmp10.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %prev_hash_entry.0, null
  br i1 %cmp10.not, label %if.then18, label %land.rhs11

land.rhs11:                                       ; preds = %while.cond9
  %next12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prev_hash_entry.0, i64 0, i32 0
  %12 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next12, align 8, !tbaa !229
  %cmp13.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %12, %prune_candidate.086
  br i1 %cmp13.not, label %do.end, label %while.cond9, !llvm.loop !269

if.then18:                                        ; preds = %while.cond9
  tail call void @halide_print(i8* null, i8* getelementptr inbounds ([126 x i8], [126 x i8]* @.str.2.42, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %land.rhs11, %if.then18
  %next19 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 0
  %13 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next19, align 8, !tbaa !229
  %next20 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prev_hash_entry.0, i64 0, i32 0
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %13, %"struct.Halide::Runtime::Internal::CacheEntry"** %next20, align 8, !tbaa !229
  br label %if.end21

if.end21:                                         ; preds = %do.end, %if.then6
  %14 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE, align 8, !tbaa !14
  %cmp22 = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %14, %prune_candidate.086
  br i1 %cmp22, label %if.then23, label %if.end24

if.then23:                                        ; preds = %if.end21
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %6, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE, align 8, !tbaa !14
  br label %if.end24

if.end24:                                         ; preds = %if.then23, %if.end21
  %cmp25.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %6, null
  br i1 %cmp25.not, label %if.end28, label %if.then26

if.then26:                                        ; preds = %if.end24
  %less_recent = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 2
  %15 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent, align 8, !tbaa !252
  %less_recent27 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %6, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %15, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent27, align 8, !tbaa !252
  br label %if.end28

if.end28:                                         ; preds = %if.then26, %if.end24
  %16 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE, align 8, !tbaa !14
  %cmp29 = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %16, %prune_candidate.086
  %less_recent31 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 2
  %17 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent31, align 8, !tbaa !252
  br i1 %cmp29, label %if.then30, label %if.end32

if.then30:                                        ; preds = %if.end28
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %17, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE, align 8, !tbaa !14
  br label %if.end32

if.end32:                                         ; preds = %if.then30, %if.end28
  %cmp34.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %17, null
  br i1 %cmp34.not, label %if.end37, label %if.then35

if.then35:                                        ; preds = %if.end32
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %6, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent31, align 8, !tbaa !252
  br label %if.end37

if.end37:                                         ; preds = %if.then35, %if.end32
  %tuple_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 8
  %18 = load i32, i32* %tuple_count, align 8, !tbaa !232
  %cmp3882.not = icmp eq i32 %18, 0
  br i1 %cmp3882.not, label %for.cond.cleanup, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %if.end37
  %buf = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086, i64 0, i32 11
  %19 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf, align 8, !tbaa !234
  %_ZN6Halide7Runtime8Internal18current_cache_sizeE.promoted = load i64, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  %wide.trip.count = zext i32 %18 to i64
  br label %for.body

for.cond.for.cond.cleanup_crit_edge:              ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit
  store i64 %sub, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond.for.cond.cleanup_crit_edge, %if.end37
  tail call void @_ZN6Halide7Runtime8Internal10CacheEntry7destroyEv(%"struct.Halide::Runtime::Internal::CacheEntry"* nonnull dereferenceable(96) %prune_candidate.086) #16
  %20 = bitcast %"struct.Halide::Runtime::Internal::CacheEntry"* %prune_candidate.086 to i8*
  tail call void @halide_free(i8* null, i8* nonnull %20) #14
  %.pre92 = load i64, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  %.pre93 = load i64, i64* @_ZN6Halide7Runtime8Internal14max_cache_sizeE, align 8, !tbaa !22
  br label %if.end41

for.body:                                         ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit, %for.body.lr.ph
  %indvars.iv = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next, %_ZNK15halide_buffer_t13size_in_bytesEv.exit ]
  %sub89 = phi i64 [ %_ZN6Halide7Runtime8Internal18current_cache_sizeE.promoted, %for.body.lr.ph ], [ %sub, %_ZNK15halide_buffer_t13size_in_bytesEv.exit ]
  %dimensions.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %19, i64 %indvars.iv, i32 5
  %21 = load i32, i32* %dimensions.i.i, align 4, !tbaa !183
  %cmp19.i.i = icmp sgt i32 %21, 0
  br i1 %cmp19.i.i, label %for.body.lr.ph.i.i, label %for.body._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge

for.body._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge: ; preds = %for.body
  %sub.i.neg.0 = add i64 0, -1
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

for.body.lr.ph.i.i:                               ; preds = %for.body
  %dim.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %19, i64 %indvars.iv, i32 6
  %22 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i.i, align 8, !tbaa !184
  %wide.trip.count.i.i = zext i32 %21 to i64
  %min.iters.check28 = icmp ult i32 %21, 3
  br i1 %min.iters.check28, label %for.body.i.i.preheader, label %vector.ph29

vector.ph29:                                      ; preds = %for.body.lr.ph.i.i
  %n.vec31 = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body27

vector.body27:                                    ; preds = %pred.load.continue43, %vector.ph29
  %index32 = phi i64 [ 0, %vector.ph29 ], [ %index.next33, %pred.load.continue43 ]
  %vec.phi38 = phi i64 [ 0, %vector.ph29 ], [ %predphi44, %pred.load.continue43 ]
  %vec.phi39 = phi i64 [ 0, %vector.ph29 ], [ %predphi45, %pred.load.continue43 ]
  %induction37 = or i64 %index32, 1
  %23 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %index32, i32 2
  %24 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %induction37, i32 2
  %25 = load i32, i32* %23, align 4, !tbaa !185
  %26 = load i32, i32* %24, align 4, !tbaa !185
  %27 = icmp sgt i32 %25, 0
  %28 = icmp sgt i32 %26, 0
  %29 = zext i32 %25 to i64
  %30 = zext i32 %26 to i64
  br i1 %27, label %pred.load.if40, label %pred.load.continue41

pred.load.if40:                                   ; preds = %vector.body27
  %31 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %index32, i32 1
  %32 = load i32, i32* %31, align 4, !tbaa !189
  br label %pred.load.continue41

pred.load.continue41:                             ; preds = %pred.load.if40, %vector.body27
  %33 = phi i32 [ poison, %vector.body27 ], [ %32, %pred.load.if40 ]
  br i1 %28, label %pred.load.if42, label %pred.load.continue43

pred.load.if42:                                   ; preds = %pred.load.continue41
  %34 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %induction37, i32 1
  %35 = load i32, i32* %34, align 4, !tbaa !189
  br label %pred.load.continue43

pred.load.continue43:                             ; preds = %pred.load.if42, %pred.load.continue41
  %36 = phi i32 [ poison, %pred.load.continue41 ], [ %35, %pred.load.if42 ]
  %37 = add nsw i32 %33, -1
  %38 = add nsw i32 %36, -1
  %39 = sext i32 %37 to i64
  %40 = sext i32 %38 to i64
  %41 = mul nsw i64 %39, %29
  %42 = mul nsw i64 %40, %30
  %43 = select i1 %27, i64 %41, i64 0
  %predphi44 = add i64 %vec.phi38, %43
  %44 = select i1 %28, i64 %42, i64 0
  %predphi45 = add i64 %vec.phi39, %44
  %index.next33 = add i64 %index32, 2
  %45 = icmp eq i64 %index.next33, %n.vec31
  br i1 %45, label %middle.block25, label %vector.body27, !llvm.loop !270

middle.block25:                                   ; preds = %pred.load.continue43
  %bin.rdx46 = add i64 %predphi45, %predphi44
  %cmp.n35 = icmp eq i64 %n.vec31, %wide.trip.count.i.i
  br i1 %cmp.n35, label %for.body.i13.i.preheader, label %for.body.i.i.preheader

for.body.i.i.preheader:                           ; preds = %for.body.lr.ph.i.i, %middle.block25
  %indvars.iv.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %n.vec31, %middle.block25 ]
  %index.021.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %bin.rdx46, %middle.block25 ]
  br label %for.body.i.i

for.body.i.i:                                     ; preds = %for.body.i.i.preheader, %if.end.i.i
  %indvars.iv.i.i = phi i64 [ %indvars.iv.next.i.i, %if.end.i.i ], [ %indvars.iv.i.i.ph, %for.body.i.i.preheader ]
  %index.021.i.i = phi i64 [ %index.1.i.i, %if.end.i.i ], [ %index.021.i.i.ph, %for.body.i.i.preheader ]
  %stride2.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %indvars.iv.i.i, i32 2
  %46 = load i32, i32* %stride2.i.i, align 4, !tbaa !185
  %cmp3.i.i = icmp sgt i32 %46, 0
  br i1 %cmp3.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %for.body.i.i
  %conv18.i.i = zext i32 %46 to i64
  %extent.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %indvars.iv.i.i, i32 1
  %47 = load i32, i32* %extent.i.i, align 4, !tbaa !189
  %sub.i.i = add nsw i32 %47, -1
  %conv7.i.i = sext i32 %sub.i.i to i64
  %mul.i.i = mul nsw i64 %conv7.i.i, %conv18.i.i
  %add.i.i = add nsw i64 %mul.i.i, %index.021.i.i
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %for.body.i.i
  %index.1.i.i = phi i64 [ %add.i.i, %if.then.i.i ], [ %index.021.i.i, %for.body.i.i ]
  %indvars.iv.next.i.i = add nuw nsw i64 %indvars.iv.i.i, 1
  %exitcond.not.i.i = icmp eq i64 %indvars.iv.next.i.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i.i, label %for.body.i13.i.preheader, label %for.body.i.i, !llvm.loop !271

for.body.i13.i.preheader:                         ; preds = %if.end.i.i, %middle.block25
  %index.1.i.i.lcssa = phi i64 [ %bin.rdx46, %middle.block25 ], [ %index.1.i.i, %if.end.i.i ]
  %min.iters.check = icmp ult i32 %21, 3
  br i1 %min.iters.check, label %for.body.i13.i.preheader48, label %vector.ph

vector.ph:                                        ; preds = %for.body.i13.i.preheader
  %n.vec = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body

vector.body:                                      ; preds = %pred.load.continue23, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %pred.load.continue23 ]
  %vec.phi = phi i64 [ 0, %vector.ph ], [ %predphi, %pred.load.continue23 ]
  %vec.phi21 = phi i64 [ 0, %vector.ph ], [ %predphi24, %pred.load.continue23 ]
  %induction20 = or i64 %index, 1
  %48 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %index, i32 2
  %49 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %induction20, i32 2
  %50 = load i32, i32* %48, align 4, !tbaa !185
  %51 = load i32, i32* %49, align 4, !tbaa !185
  %52 = icmp slt i32 %50, 0
  %53 = icmp slt i32 %51, 0
  %54 = sext i32 %50 to i64
  %55 = sext i32 %51 to i64
  br i1 %52, label %pred.load.if, label %pred.load.continue

pred.load.if:                                     ; preds = %vector.body
  %56 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %index, i32 1
  %57 = load i32, i32* %56, align 4, !tbaa !189
  br label %pred.load.continue

pred.load.continue:                               ; preds = %pred.load.if, %vector.body
  %58 = phi i32 [ poison, %vector.body ], [ %57, %pred.load.if ]
  br i1 %53, label %pred.load.if22, label %pred.load.continue23

pred.load.if22:                                   ; preds = %pred.load.continue
  %59 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %induction20, i32 1
  %60 = load i32, i32* %59, align 4, !tbaa !189
  br label %pred.load.continue23

pred.load.continue23:                             ; preds = %pred.load.if22, %pred.load.continue
  %61 = phi i32 [ poison, %pred.load.continue ], [ %60, %pred.load.if22 ]
  %62 = add nsw i32 %58, -1
  %63 = add nsw i32 %61, -1
  %64 = sext i32 %62 to i64
  %65 = sext i32 %63 to i64
  %66 = mul nsw i64 %64, %54
  %67 = mul nsw i64 %65, %55
  %68 = select i1 %52, i64 %66, i64 0
  %predphi = add i64 %vec.phi, %68
  %69 = select i1 %53, i64 %67, i64 0
  %predphi24 = add i64 %vec.phi21, %69
  %index.next = add i64 %index, 2
  %70 = icmp eq i64 %index.next, %n.vec
  br i1 %70, label %middle.block, label %vector.body, !llvm.loop !272

middle.block:                                     ; preds = %pred.load.continue23
  %bin.rdx = add i64 %predphi24, %predphi
  %cmp.n = icmp eq i64 %n.vec, %wide.trip.count.i.i
  br i1 %cmp.n, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i.preheader48

for.body.i13.i.preheader48:                       ; preds = %for.body.i13.i.preheader, %middle.block
  %indvars.iv.i10.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %n.vec, %middle.block ]
  %index.018.i.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %bin.rdx, %middle.block ]
  br label %for.body.i13.i

for.body.i13.i:                                   ; preds = %for.body.i13.i.preheader48, %if.end.i24.i
  %indvars.iv.i10.i = phi i64 [ %indvars.iv.next.i22.i, %if.end.i24.i ], [ %indvars.iv.i10.i.ph, %for.body.i13.i.preheader48 ]
  %index.018.i.i = phi i64 [ %index.1.i21.i, %if.end.i24.i ], [ %index.018.i.i.ph, %for.body.i13.i.preheader48 ]
  %stride2.i11.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %indvars.iv.i10.i, i32 2
  %71 = load i32, i32* %stride2.i11.i, align 4, !tbaa !185
  %cmp3.i12.i = icmp slt i32 %71, 0
  br i1 %cmp3.i12.i, label %if.then.i20.i, label %if.end.i24.i

if.then.i20.i:                                    ; preds = %for.body.i13.i
  %conv.i14.i = sext i32 %71 to i64
  %extent.i15.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %22, i64 %indvars.iv.i10.i, i32 1
  %72 = load i32, i32* %extent.i15.i, align 4, !tbaa !189
  %sub.i16.i = add nsw i32 %72, -1
  %conv7.i17.i = sext i32 %sub.i16.i to i64
  %mul.i18.i = mul nsw i64 %conv7.i17.i, %conv.i14.i
  %add.i19.i = add nsw i64 %mul.i18.i, %index.018.i.i
  br label %if.end.i24.i

if.end.i24.i:                                     ; preds = %if.then.i20.i, %for.body.i13.i
  %index.1.i21.i = phi i64 [ %add.i19.i, %if.then.i20.i ], [ %index.018.i.i, %for.body.i13.i ]
  %indvars.iv.next.i22.i = add nuw nsw i64 %indvars.iv.i10.i, 1
  %exitcond.not.i23.i = icmp eq i64 %indvars.iv.next.i22.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i23.i, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i, !llvm.loop !273

_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit: ; preds = %if.end.i24.i, %middle.block
  %index.1.i21.i.lcssa = phi i64 [ %bin.rdx, %middle.block ], [ %index.1.i21.i, %if.end.i24.i ]
  %add8.i.i.neg = xor i64 %index.1.i.i.lcssa, -1
  %sub.i.neg.1 = add i64 %index.1.i21.i.lcssa, %add8.i.i.neg
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

_ZNK15halide_buffer_t13size_in_bytesEv.exit:      ; preds = %for.body._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit
  %sub.i.neg.phi = phi i64 [ %sub.i.neg.0, %for.body._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %sub.i.neg.1, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %bits.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %19, i64 %indvars.iv, i32 4, i32 1
  %73 = load i8, i8* %bits.i.i, align 1, !tbaa !144
  %conv.i.i = zext i8 %73 to i64
  %add.i4.i = add nuw nsw i64 %conv.i.i, 7
  %div.i.i = lshr i64 %add.i4.i, 3
  %mul.i.neg = mul i64 %div.i.i, %sub.i.neg.phi
  %sub = add i64 %mul.i.neg, %sub89
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond.not, label %for.cond.for.cond.cleanup_crit_edge, label %for.body, !llvm.loop !274

if.end41:                                         ; preds = %for.cond.cleanup, %while.body
  %74 = phi i64 [ %.pre93, %for.cond.cleanup ], [ %4, %while.body ]
  %75 = phi i64 [ %.pre92, %for.cond.cleanup ], [ %5, %while.body ]
  %cmp = icmp sgt i64 %75, %74
  %cmp1 = icmp ne %"struct.Halide::Runtime::Internal::CacheEntry"* %6, null
  %76 = and i1 %cmp1, %cmp
  br i1 %76, label %while.body, label %while.end42, !llvm.loop !275

while.end42:                                      ; preds = %if.end41, %entry
  ret void
}

; Function Attrs: nounwind
define weak void @halide_memoization_cache_set_size(i64 %size) local_unnamed_addr #4 {
entry:
  %cmp = icmp eq i64 %size, 0
  %spec.store.select = select i1 %cmp, i64 1048576, i64 %size
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  store i64 %spec.store.select, i64* @_ZN6Halide7Runtime8Internal14max_cache_sizeE, align 8, !tbaa !22
  tail call void @_ZN6Halide7Runtime8Internal11prune_cacheEv() #16
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  ret void
}

; Function Attrs: nounwind
define weak i32 @halide_memoization_cache_lookup(i8* %user_context, i8* %cache_key, i32 %size, %struct.halide_buffer_t* %computed_bounds, i32 %tuple_count, %struct.halide_buffer_t** %tuple_buffers) local_unnamed_addr #4 {
entry:
  %conv = sext i32 %size to i64
  %call = tail call i32 @_ZN6Halide7Runtime8Internal8djb_hashEPKhm(i8* %cache_key, i64 %conv) #16
  %0 = and i32 %call, 255
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  %idxprom = zext i32 %0 to i64
  %arrayidx = getelementptr inbounds [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*], [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*]* @_ZN6Halide7Runtime8Internal13cache_entriesE, i64 0, i64 %idxprom
  %entry3.0220 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %arrayidx, align 8, !tbaa !14
  %cmp.not221 = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0220, null
  br i1 %cmp.not221, label %for.cond75.preheader, label %while.body.lr.ph

while.body.lr.ph:                                 ; preds = %entry
  %cmp16215 = icmp sgt i32 %tuple_count, 0
  %1 = sext i32 %tuple_count to i64
  br i1 %cmp16215, label %while.body.us, label %while.body

while.body.us:                                    ; preds = %while.body.lr.ph, %if.end73.us
  %entry3.0222.us = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %entry3.0.us, %if.end73.us ], [ %entry3.0220, %while.body.lr.ph ]
  %hash.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222.us, i64 0, i32 6
  %2 = load i32, i32* %hash.us, align 8, !tbaa !254
  %cmp4.us = icmp eq i32 %2, %call
  br i1 %cmp4.us, label %land.lhs.true.us, label %if.end73.us

land.lhs.true.us:                                 ; preds = %while.body.us
  %key_size.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222.us, i64 0, i32 4
  %3 = load i64, i64* %key_size.us, align 8, !tbaa !253
  %cmp6.us = icmp eq i64 %3, %conv
  br i1 %cmp6.us, label %land.lhs.true7.us, label %if.end73.us

land.lhs.true7.us:                                ; preds = %land.lhs.true.us
  %key.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222.us, i64 0, i32 5
  %4 = load i8*, i8** %key.us, align 8, !tbaa !258
  %call9.us = tail call zeroext i1 @_ZN6Halide7Runtime8Internal10keys_equalEPKhS3_m(i8* %4, i8* %cache_key, i64 %conv) #16
  br i1 %call9.us, label %land.lhs.true10.us, label %if.end73.us

land.lhs.true10.us:                               ; preds = %land.lhs.true7.us
  %computed_bounds11.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222.us, i64 0, i32 10
  %5 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %computed_bounds11.us, align 8, !tbaa !257
  %call12.us = tail call zeroext i1 @_ZN6Halide7Runtime8Internal16buffer_has_shapeEPK15halide_buffer_tPK18halide_dimension_t(%struct.halide_buffer_t* %computed_bounds, %struct.halide_dimension_t* %5) #16
  br i1 %call12.us, label %land.lhs.true13.us, label %if.end73.us

land.lhs.true13.us:                               ; preds = %land.lhs.true10.us
  %tuple_count14.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222.us, i64 0, i32 8
  %6 = load i32, i32* %tuple_count14.us, align 8, !tbaa !232
  %cmp15.us = icmp eq i32 %6, %tuple_count
  br i1 %cmp15.us, label %for.cond.preheader.us, label %if.end73.us

for.cond.preheader.us:                            ; preds = %land.lhs.true13.us
  %buf.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222.us, i64 0, i32 11
  br label %for.body.us

for.body.us:                                      ; preds = %for.body.us, %for.cond.preheader.us
  %indvars.iv226.us = phi i64 [ 0, %for.cond.preheader.us ], [ %indvars.iv.next227.us, %for.body.us ]
  %arrayidx18.us = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv226.us
  %7 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx18.us, align 8, !tbaa !14
  %8 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf.us, align 8, !tbaa !234
  %dim.us = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %8, i64 %indvars.iv226.us, i32 6
  %9 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.us, align 8, !tbaa !184
  %call21.us = tail call zeroext i1 @_ZN6Halide7Runtime8Internal16buffer_has_shapeEPK15halide_buffer_tPK18halide_dimension_t(%struct.halide_buffer_t* %7, %struct.halide_dimension_t* %9) #16
  %indvars.iv.next227.us = add nuw nsw i64 %indvars.iv226.us, 1
  %cmp16.us = icmp slt i64 %indvars.iv.next227.us, %1
  %10 = and i1 %cmp16.us, %call21.us
  br i1 %10, label %for.body.us, label %for.cond.cleanup.us, !llvm.loop !276

for.cond.cleanup.us:                              ; preds = %for.body.us
  br i1 %call21.us, label %if.then23, label %if.end73.us

if.end73.us:                                      ; preds = %for.cond.cleanup.us, %land.lhs.true13.us, %land.lhs.true10.us, %land.lhs.true7.us, %land.lhs.true.us, %while.body.us
  %next.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222.us, i64 0, i32 0
  %entry3.0.us = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next.us, align 8, !tbaa !14
  %cmp.not.us = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0.us, null
  br i1 %cmp.not.us, label %for.cond75.preheader, label %while.body.us, !llvm.loop !277

for.cond75.preheader:                             ; preds = %if.end73, %if.end73.us, %entry
  %cmp76210 = icmp sgt i32 %tuple_count, 0
  br i1 %cmp76210, label %for.body78.preheader, label %cleanup119

for.body78.preheader:                             ; preds = %for.cond75.preheader
  %wide.trip.count = zext i32 %tuple_count to i64
  br label %for.body78

while.body:                                       ; preds = %while.body.lr.ph, %if.end73
  %entry3.0222 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %entry3.0, %if.end73 ], [ %entry3.0220, %while.body.lr.ph ]
  %hash = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222, i64 0, i32 6
  %11 = load i32, i32* %hash, align 8, !tbaa !254
  %cmp4 = icmp eq i32 %11, %call
  br i1 %cmp4, label %land.lhs.true, label %if.end73

land.lhs.true:                                    ; preds = %while.body
  %key_size = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222, i64 0, i32 4
  %12 = load i64, i64* %key_size, align 8, !tbaa !253
  %cmp6 = icmp eq i64 %12, %conv
  br i1 %cmp6, label %land.lhs.true7, label %if.end73

land.lhs.true7:                                   ; preds = %land.lhs.true
  %key = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222, i64 0, i32 5
  %13 = load i8*, i8** %key, align 8, !tbaa !258
  %call9 = tail call zeroext i1 @_ZN6Halide7Runtime8Internal10keys_equalEPKhS3_m(i8* %13, i8* %cache_key, i64 %conv) #16
  br i1 %call9, label %land.lhs.true10, label %if.end73

land.lhs.true10:                                  ; preds = %land.lhs.true7
  %computed_bounds11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222, i64 0, i32 10
  %14 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %computed_bounds11, align 8, !tbaa !257
  %call12 = tail call zeroext i1 @_ZN6Halide7Runtime8Internal16buffer_has_shapeEPK15halide_buffer_tPK18halide_dimension_t(%struct.halide_buffer_t* %computed_bounds, %struct.halide_dimension_t* %14) #16
  br i1 %call12, label %land.lhs.true13, label %if.end73

land.lhs.true13:                                  ; preds = %land.lhs.true10
  %tuple_count14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222, i64 0, i32 8
  %15 = load i32, i32* %tuple_count14, align 8, !tbaa !232
  %cmp15 = icmp eq i32 %15, %tuple_count
  br i1 %cmp15, label %if.then23, label %if.end73

if.then23:                                        ; preds = %land.lhs.true13, %for.cond.cleanup.us
  %.us-phi = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %entry3.0222.us, %for.cond.cleanup.us ], [ %entry3.0222, %land.lhs.true13 ]
  %16 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE, align 8, !tbaa !14
  %cmp24.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %.us-phi, %16
  br i1 %cmp24.not, label %if.end57, label %do.body

do.body:                                          ; preds = %if.then23
  %more_recent = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %.us-phi, i64 0, i32 1
  %17 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent, align 8, !tbaa !268
  %cmp26.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %17, null
  br i1 %cmp26.not, label %if.then27, label %do.end

if.then27:                                        ; preds = %do.body
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([129 x i8], [129 x i8]* @.str.3.43, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then27, %do.body
  %less_recent = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %.us-phi, i64 0, i32 2
  %18 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent, align 8, !tbaa !252
  %cmp28.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %18, null
  br i1 %cmp28.not, label %do.body33, label %if.then29

if.then29:                                        ; preds = %do.end
  %19 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent, align 8, !tbaa !268
  %more_recent32 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %18, i64 0, i32 1
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %19, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent32, align 8, !tbaa !268
  %.pr = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent, align 8, !tbaa !268
  br label %do.body41

do.body33:                                        ; preds = %do.end
  %20 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE, align 8, !tbaa !14
  %cmp34 = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %20, %.us-phi
  br i1 %cmp34, label %do.end38, label %if.then35

if.then35:                                        ; preds = %do.body33
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([128 x i8], [128 x i8]* @.str.4.44, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end38

do.end38:                                         ; preds = %if.then35, %do.body33
  %21 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent, align 8, !tbaa !268
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %21, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE, align 8, !tbaa !14
  br label %do.body41

do.body41:                                        ; preds = %do.end38, %if.then29
  %22 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %.pr, %if.then29 ], [ %21, %do.end38 ]
  %cmp43.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %22, null
  br i1 %cmp43.not, label %if.then44, label %do.end47

if.then44:                                        ; preds = %do.body41
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([129 x i8], [129 x i8]* @.str.5.45, i64 0, i64 0)) #14
  tail call void @abort() #14
  %.pre = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent, align 8, !tbaa !268
  br label %do.end47

do.end47:                                         ; preds = %if.then44, %do.body41
  %23 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %.pre, %if.then44 ], [ %22, %do.body41 ]
  %24 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent, align 8, !tbaa !252
  %less_recent50 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %23, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %24, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent50, align 8, !tbaa !252
  store %"struct.Halide::Runtime::Internal::CacheEntry"* null, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent, align 8, !tbaa !268
  %25 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE, align 8, !tbaa !14
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %25, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent, align 8, !tbaa !252
  %cmp53.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %25, null
  br i1 %cmp53.not, label %if.end56, label %if.then54

if.then54:                                        ; preds = %do.end47
  %more_recent55 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %25, i64 0, i32 1
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %.us-phi, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent55, align 8, !tbaa !268
  br label %if.end56

if.end56:                                         ; preds = %if.then54, %do.end47
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %.us-phi, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE, align 8, !tbaa !14
  br label %if.end57

if.end57:                                         ; preds = %if.end56, %if.then23
  br i1 %cmp16215, label %for.body62.lr.ph, label %cleanup119.loopexit223

for.body62.lr.ph:                                 ; preds = %if.end57
  %buf66 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %.us-phi, i64 0, i32 11
  %wide.trip.count230 = zext i32 %tuple_count to i64
  br label %for.body62

for.body62:                                       ; preds = %for.body62, %for.body62.lr.ph
  %indvars.iv228 = phi i64 [ 0, %for.body62.lr.ph ], [ %indvars.iv.next229, %for.body62 ]
  %arrayidx65 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv228
  %26 = bitcast %struct.halide_buffer_t** %arrayidx65 to i8**
  %27 = load i8*, i8** %26, align 8, !tbaa !14
  %28 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf66, align 8, !tbaa !234
  %arrayidx68 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %28, i64 %indvars.iv228
  %29 = bitcast %struct.halide_buffer_t* %arrayidx68 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(56) %27, i8* nonnull align 8 dereferenceable(56) %29, i64 56, i1 false), !tbaa.struct !264
  %indvars.iv.next229 = add nuw nsw i64 %indvars.iv228, 1
  %exitcond231.not = icmp eq i64 %indvars.iv.next229, %wide.trip.count230
  br i1 %exitcond231.not, label %cleanup119.loopexit223, label %for.body62, !llvm.loop !278

if.end73:                                         ; preds = %land.lhs.true13, %land.lhs.true10, %land.lhs.true7, %land.lhs.true, %while.body
  %next = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0222, i64 0, i32 0
  %entry3.0 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next, align 8, !tbaa !14
  %cmp.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %entry3.0, null
  br i1 %cmp.not, label %for.cond75.preheader, label %while.body, !llvm.loop !277

for.body78:                                       ; preds = %for.inc114, %for.body78.preheader
  %indvars.iv = phi i64 [ 0, %for.body78.preheader ], [ %indvars.iv.next, %for.inc114 ]
  %arrayidx81 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv
  %30 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx81, align 8, !tbaa !14
  %dimensions.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %30, i64 0, i32 5
  %31 = load i32, i32* %dimensions.i.i, align 4, !tbaa !183
  %cmp19.i.i = icmp sgt i32 %31, 0
  br i1 %cmp19.i.i, label %for.body.lr.ph.i.i, label %for.body78._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge

for.body78._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge: ; preds = %for.body78
  %sub.i.0 = sub nsw i64 1, 0
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

for.body.lr.ph.i.i:                               ; preds = %for.body78
  %dim.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %30, i64 0, i32 6
  %32 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i.i, align 8, !tbaa !184
  %wide.trip.count.i.i = zext i32 %31 to i64
  %min.iters.check38 = icmp ult i32 %31, 3
  br i1 %min.iters.check38, label %for.body.i.i.preheader, label %vector.ph39

vector.ph39:                                      ; preds = %for.body.lr.ph.i.i
  %n.vec41 = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body37

vector.body37:                                    ; preds = %pred.load.continue53, %vector.ph39
  %index42 = phi i64 [ 0, %vector.ph39 ], [ %index.next43, %pred.load.continue53 ]
  %vec.phi48 = phi i64 [ 0, %vector.ph39 ], [ %predphi54, %pred.load.continue53 ]
  %vec.phi49 = phi i64 [ 0, %vector.ph39 ], [ %predphi55, %pred.load.continue53 ]
  %induction47 = or i64 %index42, 1
  %33 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %index42, i32 2
  %34 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %induction47, i32 2
  %35 = load i32, i32* %33, align 4, !tbaa !185
  %36 = load i32, i32* %34, align 4, !tbaa !185
  %37 = icmp sgt i32 %35, 0
  %38 = icmp sgt i32 %36, 0
  %39 = zext i32 %35 to i64
  %40 = zext i32 %36 to i64
  br i1 %37, label %pred.load.if50, label %pred.load.continue51

pred.load.if50:                                   ; preds = %vector.body37
  %41 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %index42, i32 1
  %42 = load i32, i32* %41, align 4, !tbaa !189
  br label %pred.load.continue51

pred.load.continue51:                             ; preds = %pred.load.if50, %vector.body37
  %43 = phi i32 [ poison, %vector.body37 ], [ %42, %pred.load.if50 ]
  br i1 %38, label %pred.load.if52, label %pred.load.continue53

pred.load.if52:                                   ; preds = %pred.load.continue51
  %44 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %induction47, i32 1
  %45 = load i32, i32* %44, align 4, !tbaa !189
  br label %pred.load.continue53

pred.load.continue53:                             ; preds = %pred.load.if52, %pred.load.continue51
  %46 = phi i32 [ poison, %pred.load.continue51 ], [ %45, %pred.load.if52 ]
  %47 = add nsw i32 %43, -1
  %48 = add nsw i32 %46, -1
  %49 = sext i32 %47 to i64
  %50 = sext i32 %48 to i64
  %51 = mul nsw i64 %49, %39
  %52 = mul nsw i64 %50, %40
  %53 = select i1 %37, i64 %51, i64 0
  %predphi54 = add i64 %vec.phi48, %53
  %54 = select i1 %38, i64 %52, i64 0
  %predphi55 = add i64 %vec.phi49, %54
  %index.next43 = add i64 %index42, 2
  %55 = icmp eq i64 %index.next43, %n.vec41
  br i1 %55, label %middle.block35, label %vector.body37, !llvm.loop !279

middle.block35:                                   ; preds = %pred.load.continue53
  %bin.rdx56 = add i64 %predphi55, %predphi54
  %cmp.n45 = icmp eq i64 %n.vec41, %wide.trip.count.i.i
  br i1 %cmp.n45, label %for.body.i13.i.preheader, label %for.body.i.i.preheader

for.body.i.i.preheader:                           ; preds = %for.body.lr.ph.i.i, %middle.block35
  %indvars.iv.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %n.vec41, %middle.block35 ]
  %index.021.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %bin.rdx56, %middle.block35 ]
  br label %for.body.i.i

for.body.i.i:                                     ; preds = %for.body.i.i.preheader, %if.end.i.i
  %indvars.iv.i.i = phi i64 [ %indvars.iv.next.i.i, %if.end.i.i ], [ %indvars.iv.i.i.ph, %for.body.i.i.preheader ]
  %index.021.i.i = phi i64 [ %index.1.i.i, %if.end.i.i ], [ %index.021.i.i.ph, %for.body.i.i.preheader ]
  %stride2.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %indvars.iv.i.i, i32 2
  %56 = load i32, i32* %stride2.i.i, align 4, !tbaa !185
  %cmp3.i.i = icmp sgt i32 %56, 0
  br i1 %cmp3.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %for.body.i.i
  %conv18.i.i = zext i32 %56 to i64
  %extent.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %indvars.iv.i.i, i32 1
  %57 = load i32, i32* %extent.i.i, align 4, !tbaa !189
  %sub.i.i = add nsw i32 %57, -1
  %conv7.i.i = sext i32 %sub.i.i to i64
  %mul.i.i = mul nsw i64 %conv7.i.i, %conv18.i.i
  %add.i.i = add nsw i64 %mul.i.i, %index.021.i.i
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %for.body.i.i
  %index.1.i.i = phi i64 [ %add.i.i, %if.then.i.i ], [ %index.021.i.i, %for.body.i.i ]
  %indvars.iv.next.i.i = add nuw nsw i64 %indvars.iv.i.i, 1
  %exitcond.not.i.i = icmp eq i64 %indvars.iv.next.i.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i.i, label %for.body.i13.i.preheader, label %for.body.i.i, !llvm.loop !280

for.body.i13.i.preheader:                         ; preds = %if.end.i.i, %middle.block35
  %index.1.i.i.lcssa = phi i64 [ %bin.rdx56, %middle.block35 ], [ %index.1.i.i, %if.end.i.i ]
  %min.iters.check = icmp ult i32 %31, 3
  br i1 %min.iters.check, label %for.body.i13.i.preheader58, label %vector.ph

vector.ph:                                        ; preds = %for.body.i13.i.preheader
  %n.vec = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body

vector.body:                                      ; preds = %pred.load.continue33, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %pred.load.continue33 ]
  %vec.phi = phi i64 [ 0, %vector.ph ], [ %predphi, %pred.load.continue33 ]
  %vec.phi31 = phi i64 [ 0, %vector.ph ], [ %predphi34, %pred.load.continue33 ]
  %induction30 = or i64 %index, 1
  %58 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %index, i32 2
  %59 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %induction30, i32 2
  %60 = load i32, i32* %58, align 4, !tbaa !185
  %61 = load i32, i32* %59, align 4, !tbaa !185
  %62 = icmp slt i32 %60, 0
  %63 = icmp slt i32 %61, 0
  %64 = sext i32 %60 to i64
  %65 = sext i32 %61 to i64
  br i1 %62, label %pred.load.if, label %pred.load.continue

pred.load.if:                                     ; preds = %vector.body
  %66 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %index, i32 1
  %67 = load i32, i32* %66, align 4, !tbaa !189
  br label %pred.load.continue

pred.load.continue:                               ; preds = %pred.load.if, %vector.body
  %68 = phi i32 [ poison, %vector.body ], [ %67, %pred.load.if ]
  br i1 %63, label %pred.load.if32, label %pred.load.continue33

pred.load.if32:                                   ; preds = %pred.load.continue
  %69 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %induction30, i32 1
  %70 = load i32, i32* %69, align 4, !tbaa !189
  br label %pred.load.continue33

pred.load.continue33:                             ; preds = %pred.load.if32, %pred.load.continue
  %71 = phi i32 [ poison, %pred.load.continue ], [ %70, %pred.load.if32 ]
  %72 = add nsw i32 %68, -1
  %73 = add nsw i32 %71, -1
  %74 = sext i32 %72 to i64
  %75 = sext i32 %73 to i64
  %76 = mul nsw i64 %74, %64
  %77 = mul nsw i64 %75, %65
  %78 = select i1 %62, i64 %76, i64 0
  %predphi = add i64 %vec.phi, %78
  %79 = select i1 %63, i64 %77, i64 0
  %predphi34 = add i64 %vec.phi31, %79
  %index.next = add i64 %index, 2
  %80 = icmp eq i64 %index.next, %n.vec
  br i1 %80, label %middle.block, label %vector.body, !llvm.loop !281

middle.block:                                     ; preds = %pred.load.continue33
  %bin.rdx = add i64 %predphi34, %predphi
  %cmp.n = icmp eq i64 %n.vec, %wide.trip.count.i.i
  br i1 %cmp.n, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i.preheader58

for.body.i13.i.preheader58:                       ; preds = %for.body.i13.i.preheader, %middle.block
  %indvars.iv.i10.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %n.vec, %middle.block ]
  %index.018.i.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %bin.rdx, %middle.block ]
  br label %for.body.i13.i

for.body.i13.i:                                   ; preds = %for.body.i13.i.preheader58, %if.end.i24.i
  %indvars.iv.i10.i = phi i64 [ %indvars.iv.next.i22.i, %if.end.i24.i ], [ %indvars.iv.i10.i.ph, %for.body.i13.i.preheader58 ]
  %index.018.i.i = phi i64 [ %index.1.i21.i, %if.end.i24.i ], [ %index.018.i.i.ph, %for.body.i13.i.preheader58 ]
  %stride2.i11.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %indvars.iv.i10.i, i32 2
  %81 = load i32, i32* %stride2.i11.i, align 4, !tbaa !185
  %cmp3.i12.i = icmp slt i32 %81, 0
  br i1 %cmp3.i12.i, label %if.then.i20.i, label %if.end.i24.i

if.then.i20.i:                                    ; preds = %for.body.i13.i
  %conv.i14.i = sext i32 %81 to i64
  %extent.i15.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %32, i64 %indvars.iv.i10.i, i32 1
  %82 = load i32, i32* %extent.i15.i, align 4, !tbaa !189
  %sub.i16.i = add nsw i32 %82, -1
  %conv7.i17.i = sext i32 %sub.i16.i to i64
  %mul.i18.i = mul nsw i64 %conv7.i17.i, %conv.i14.i
  %add.i19.i = add nsw i64 %mul.i18.i, %index.018.i.i
  br label %if.end.i24.i

if.end.i24.i:                                     ; preds = %if.then.i20.i, %for.body.i13.i
  %index.1.i21.i = phi i64 [ %add.i19.i, %if.then.i20.i ], [ %index.018.i.i, %for.body.i13.i ]
  %indvars.iv.next.i22.i = add nuw nsw i64 %indvars.iv.i10.i, 1
  %exitcond.not.i23.i = icmp eq i64 %indvars.iv.next.i22.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i23.i, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i, !llvm.loop !282

_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit: ; preds = %if.end.i24.i, %middle.block
  %index.1.i21.i.lcssa = phi i64 [ %bin.rdx, %middle.block ], [ %index.1.i21.i, %if.end.i24.i ]
  %add8.i.i = add nsw i64 %index.1.i.i.lcssa, 1
  %sub.i.1 = sub nsw i64 %add8.i.i, %index.1.i21.i.lcssa
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

_ZNK15halide_buffer_t13size_in_bytesEv.exit:      ; preds = %for.body78._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit
  %add8.i27.i = phi i64 [ 1, %for.body78._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %add8.i.i, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %sub.i.phi = phi i64 [ %sub.i.0, %for.body78._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %sub.i.1, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %bits.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %30, i64 0, i32 4, i32 1
  %83 = load i8, i8* %bits.i.i, align 1, !tbaa !144
  %conv.i.i = zext i8 %83 to i64
  %add.i4.i = add nuw nsw i64 %conv.i.i, 7
  %div.i.i = lshr i64 %add.i4.i, 3
  %mul.i = mul i64 %div.i.i, %sub.i.phi
  %add84 = add i64 %mul.i, 32
  %call85 = tail call i8* @halide_malloc(i8* %user_context, i64 %add84) #14
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %30, i64 0, i32 2
  store i8* %call85, i8** %host, align 8, !tbaa !180
  %cmp87 = icmp eq i8* %call85, null
  br i1 %cmp87, label %for.cond89.preheader, label %for.inc114

for.cond89.preheader:                             ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit
  %cmp90208.not = icmp eq i64 %indvars.iv, 0
  br i1 %cmp90208.not, label %cleanup119, label %for.body92

for.body92:                                       ; preds = %for.cond89.preheader, %for.body92
  %indvars.iv224 = phi i64 [ %indvars.iv.next225, %for.body92 ], [ %indvars.iv, %for.cond89.preheader ]
  %sub = add nuw nsw i64 %indvars.iv224, 4294967295
  %84 = and i64 %sub, 4294967295
  %arrayidx94 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %84
  %85 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx94, align 8, !tbaa !14
  %host95 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %85, i64 0, i32 2
  %86 = load i8*, i8** %host95, align 8, !tbaa !180
  %call96 = tail call %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* %86) #16
  %87 = bitcast %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call96 to i8*
  tail call void @halide_free(i8* %user_context, i8* %87) #14
  %88 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx94, align 8, !tbaa !14
  %host100 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %88, i64 0, i32 2
  store i8* null, i8** %host100, align 8, !tbaa !180
  %89 = icmp sgt i64 %indvars.iv224, 1
  %indvars.iv.next225 = add nsw i64 %indvars.iv224, -1
  br i1 %89, label %for.body92, label %cleanup119, !llvm.loop !283

for.inc114:                                       ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit
  %add.ptr = getelementptr inbounds i8, i8* %call85, i64 32
  store i8* %add.ptr, i8** %host, align 8, !tbaa !180
  %call108 = tail call %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* nonnull %add.ptr) #16
  %hash109 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheBlockHeader", %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call108, i64 0, i32 1
  store i32 %call, i32* %hash109, align 8, !tbaa !284
  %entry110 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheBlockHeader", %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call108, i64 0, i32 0
  store %"struct.Halide::Runtime::Internal::CacheEntry"* null, %"struct.Halide::Runtime::Internal::CacheEntry"** %entry110, align 8, !tbaa !286
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond.not, label %cleanup119, label %for.body78, !llvm.loop !287

cleanup119.loopexit223:                           ; preds = %for.body62, %if.end57
  %in_use_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %.us-phi, i64 0, i32 7
  %90 = load i32, i32* %in_use_count, align 4, !tbaa !255
  %add = add i32 %90, %tuple_count
  store i32 %add, i32* %in_use_count, align 4, !tbaa !255
  br label %cleanup119

cleanup119:                                       ; preds = %for.inc114, %for.body92, %cleanup119.loopexit223, %for.cond89.preheader, %for.cond75.preheader
  %retval.6 = phi i32 [ 1, %for.cond75.preheader ], [ 0, %cleanup119.loopexit223 ], [ -1, %for.cond89.preheader ], [ -1, %for.body92 ], [ 1, %for.inc114 ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  ret i32 %retval.6
}

; Function Attrs: nounwind
define weak i32 @halide_memoization_cache_store(i8* %user_context, i8* %cache_key, i32 %size, %struct.halide_buffer_t* %computed_bounds, i32 %tuple_count, %struct.halide_buffer_t** %tuple_buffers, i1 zeroext %has_eviction_key, i64 %eviction_key) local_unnamed_addr #4 {
entry:
  %0 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, align 8, !tbaa !14
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %0, i64 0, i32 2
  %1 = load i8*, i8** %host, align 8, !tbaa !180
  %call = tail call %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* %1) #16
  %hash = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheBlockHeader", %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call, i64 0, i32 1
  %2 = load i32, i32* %hash, align 8, !tbaa !284
  %3 = and i32 %2, 255
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  %idxprom = zext i32 %3 to i64
  %arrayidx7 = getelementptr inbounds [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*], [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*]* @_ZN6Halide7Runtime8Internal13cache_entriesE, i64 0, i64 %idxprom
  %entry6.0228 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %arrayidx7, align 8, !tbaa !14
  %cmp.not229 = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0228, null
  br i1 %cmp.not229, label %for.cond61.preheader, label %while.body.lr.ph

while.body.lr.ph:                                 ; preds = %entry
  %conv10 = sext i32 %size to i64
  %cmp22221 = icmp sgt i32 %tuple_count, 0
  br i1 %cmp22221, label %while.body.us.preheader, label %while.body

while.body.us.preheader:                          ; preds = %while.body.lr.ph
  %4 = zext i32 %tuple_count to i64
  br label %while.body.us

while.body.us:                                    ; preds = %if.end59.us, %while.body.us.preheader
  %entry6.0230.us = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %entry6.0.us, %if.end59.us ], [ %entry6.0228, %while.body.us.preheader ]
  %hash8.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230.us, i64 0, i32 6
  %5 = load i32, i32* %hash8.us, align 8, !tbaa !254
  %cmp9.us = icmp eq i32 %5, %2
  br i1 %cmp9.us, label %land.lhs.true.us, label %if.end59.us

land.lhs.true.us:                                 ; preds = %while.body.us
  %key_size.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230.us, i64 0, i32 4
  %6 = load i64, i64* %key_size.us, align 8, !tbaa !253
  %cmp11.us = icmp eq i64 %6, %conv10
  br i1 %cmp11.us, label %land.lhs.true12.us, label %if.end59.us

land.lhs.true12.us:                               ; preds = %land.lhs.true.us
  %key.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230.us, i64 0, i32 5
  %7 = load i8*, i8** %key.us, align 8, !tbaa !258
  %call14.us = tail call zeroext i1 @_ZN6Halide7Runtime8Internal10keys_equalEPKhS3_m(i8* %7, i8* %cache_key, i64 %conv10) #16
  br i1 %call14.us, label %land.lhs.true15.us, label %if.end59.us

land.lhs.true15.us:                               ; preds = %land.lhs.true12.us
  %computed_bounds16.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230.us, i64 0, i32 10
  %8 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %computed_bounds16.us, align 8, !tbaa !257
  %call17.us = tail call zeroext i1 @_ZN6Halide7Runtime8Internal16buffer_has_shapeEPK15halide_buffer_tPK18halide_dimension_t(%struct.halide_buffer_t* %computed_bounds, %struct.halide_dimension_t* %8) #16
  br i1 %call17.us, label %land.lhs.true18.us, label %if.end59.us

land.lhs.true18.us:                               ; preds = %land.lhs.true15.us
  %tuple_count19.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230.us, i64 0, i32 8
  %9 = load i32, i32* %tuple_count19.us, align 8, !tbaa !232
  %cmp20.us = icmp eq i32 %9, %tuple_count
  br i1 %cmp20.us, label %for.body.lr.ph.us, label %if.end59.us

for.cond.cleanup.us:                              ; preds = %for.body.us
  br i1 %call30.us, label %do.body.us, label %if.end59.us

do.body.us:                                       ; preds = %for.cond.cleanup.us
  %10 = and i8 %spec.select.us, 1
  %tobool41.not.us = icmp eq i8 %10, 0
  br i1 %tobool41.not.us, label %if.then42.us, label %for.body48.us.preheader

for.body48.us.preheader:                          ; preds = %if.then42.us, %do.body.us
  %indvars.iv.next245.1 = add nuw nsw i64 0, 1
  %arrayidx50.us.1 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 0
  br label %for.body48.us

if.then42.us:                                     ; preds = %do.body.us
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([122 x i8], [122 x i8]* @.str.9.46, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %for.body48.us.preheader

if.end59.us:                                      ; preds = %for.cond.cleanup.us, %land.lhs.true18.us, %land.lhs.true15.us, %land.lhs.true12.us, %land.lhs.true.us, %while.body.us
  %next.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230.us, i64 0, i32 0
  %entry6.0.us = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next.us, align 8, !tbaa !14
  %cmp.not.us = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0.us, null
  br i1 %cmp.not.us, label %for.cond61.preheader, label %while.body.us, !llvm.loop !288

for.body48.us:                                    ; preds = %for.body48.us.for.body48.us_crit_edge, %for.body48.us.preheader
  %arrayidx50.us.phi = phi %struct.halide_buffer_t** [ %arrayidx50.us.0, %for.body48.us.for.body48.us_crit_edge ], [ %arrayidx50.us.1, %for.body48.us.preheader ]
  %indvars.iv.next245.phi = phi i64 [ %indvars.iv.next245.0, %for.body48.us.for.body48.us_crit_edge ], [ %indvars.iv.next245.1, %for.body48.us.preheader ]
  %11 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx50.us.phi, align 8, !tbaa !14
  %host51.us = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %11, i64 0, i32 2
  %12 = load i8*, i8** %host51.us, align 8, !tbaa !180
  %call52.us = tail call %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* %12) #16
  %entry53.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheBlockHeader", %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call52.us, i64 0, i32 0
  store %"struct.Halide::Runtime::Internal::CacheEntry"* null, %"struct.Halide::Runtime::Internal::CacheEntry"** %entry53.us, align 8, !tbaa !286
  %exitcond247.not = icmp eq i64 %indvars.iv.next245.phi, %4
  br i1 %exitcond247.not, label %cleanup132, label %for.body48.us.for.body48.us_crit_edge, !llvm.loop !289

for.body48.us.for.body48.us_crit_edge:            ; preds = %for.body48.us
  %indvars.iv.next245.0 = add nuw nsw i64 %indvars.iv.next245.phi, 1
  %arrayidx50.us.0 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv.next245.phi
  br label %for.body48.us

for.body.us:                                      ; preds = %for.body.lr.ph.us, %for.body.us
  %13 = phi %struct.halide_buffer_t* [ %.pre, %for.body.lr.ph.us ], [ %16, %for.body.us ]
  %indvars.iv242 = phi i64 [ 0, %for.body.lr.ph.us ], [ %indvars.iv.next243, %for.body.us ]
  %no_host_pointers_equal.0222.us = phi i8 [ 1, %for.body.lr.ph.us ], [ %spec.select.us, %for.body.us ]
  %arrayidx24.us = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv242
  %14 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx24.us, align 8, !tbaa !14
  %dim.us = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %13, i64 %indvars.iv242, i32 6
  %15 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.us, align 8, !tbaa !184
  %call30.us = tail call zeroext i1 @_ZN6Halide7Runtime8Internal16buffer_has_shapeEPK15halide_buffer_tPK18halide_dimension_t(%struct.halide_buffer_t* %14, %struct.halide_dimension_t* %15) #16
  %16 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf27.us, align 8, !tbaa !234
  %host35.us = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %16, i64 %indvars.iv242, i32 2
  %17 = load i8*, i8** %host35.us, align 8, !tbaa !180
  %host36.us = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %14, i64 0, i32 2
  %18 = load i8*, i8** %host36.us, align 8, !tbaa !180
  %cmp37.us = icmp eq i8* %17, %18
  %spec.select.us = select i1 %cmp37.us, i8 0, i8 %no_host_pointers_equal.0222.us
  %indvars.iv.next243 = add nuw nsw i64 %indvars.iv242, 1
  %cmp22.us = icmp ult i64 %indvars.iv.next243, %4
  %19 = and i1 %cmp22.us, %call30.us
  br i1 %19, label %for.body.us, label %for.cond.cleanup.us, !llvm.loop !290

for.body.lr.ph.us:                                ; preds = %land.lhs.true18.us
  %buf27.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230.us, i64 0, i32 11
  %.pre = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %buf27.us, align 8, !tbaa !234
  br label %for.body.us

for.cond61.preheader:                             ; preds = %if.end59, %if.end59.us, %entry
  %cmp62218 = icmp sgt i32 %tuple_count, 0
  br i1 %cmp62218, label %for.body64.preheader, label %for.cond.cleanup63

for.body64.preheader:                             ; preds = %for.cond61.preheader
  %wide.trip.count240 = zext i32 %tuple_count to i64
  br label %for.body64

while.body:                                       ; preds = %while.body.lr.ph, %if.end59
  %entry6.0230 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %entry6.0, %if.end59 ], [ %entry6.0228, %while.body.lr.ph ]
  %hash8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230, i64 0, i32 6
  %20 = load i32, i32* %hash8, align 8, !tbaa !254
  %cmp9 = icmp eq i32 %20, %2
  br i1 %cmp9, label %land.lhs.true, label %if.end59

land.lhs.true:                                    ; preds = %while.body
  %key_size = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230, i64 0, i32 4
  %21 = load i64, i64* %key_size, align 8, !tbaa !253
  %cmp11 = icmp eq i64 %21, %conv10
  br i1 %cmp11, label %land.lhs.true12, label %if.end59

land.lhs.true12:                                  ; preds = %land.lhs.true
  %key = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230, i64 0, i32 5
  %22 = load i8*, i8** %key, align 8, !tbaa !258
  %call14 = tail call zeroext i1 @_ZN6Halide7Runtime8Internal10keys_equalEPKhS3_m(i8* %22, i8* %cache_key, i64 %conv10) #16
  br i1 %call14, label %land.lhs.true15, label %if.end59

land.lhs.true15:                                  ; preds = %land.lhs.true12
  %computed_bounds16 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230, i64 0, i32 10
  %23 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %computed_bounds16, align 8, !tbaa !257
  %call17 = tail call zeroext i1 @_ZN6Halide7Runtime8Internal16buffer_has_shapeEPK15halide_buffer_tPK18halide_dimension_t(%struct.halide_buffer_t* %computed_bounds, %struct.halide_dimension_t* %23) #16
  br i1 %call17, label %land.lhs.true18, label %if.end59

land.lhs.true18:                                  ; preds = %land.lhs.true15
  %tuple_count19 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230, i64 0, i32 8
  %24 = load i32, i32* %tuple_count19, align 8, !tbaa !232
  %cmp20 = icmp eq i32 %24, %tuple_count
  br i1 %cmp20, label %cleanup132, label %if.end59

if.end59:                                         ; preds = %land.lhs.true18, %land.lhs.true15, %land.lhs.true12, %land.lhs.true, %while.body
  %next = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0230, i64 0, i32 0
  %entry6.0 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next, align 8, !tbaa !14
  %cmp.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %entry6.0, null
  br i1 %cmp.not, label %for.cond61.preheader, label %while.body, !llvm.loop !288

for.cond.cleanup63:                               ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit, %for.cond61.preheader
  %added_size.0.lcssa = phi i64 [ 0, %for.cond61.preheader ], [ %add, %_ZNK15halide_buffer_t13size_in_bytesEv.exit ]
  %25 = load i64, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  %add73 = add i64 %25, %added_size.0.lcssa
  store i64 %add73, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  tail call void @_ZN6Halide7Runtime8Internal11prune_cacheEv() #16
  %call74 = tail call i8* @halide_malloc(i8* null, i64 96) #14
  %tobool75.not = icmp eq i8* %call74, null
  br i1 %tobool75.not, label %if.then83, label %if.then76

for.body64:                                       ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit, %for.body64.preheader
  %indvars.iv238 = phi i64 [ 0, %for.body64.preheader ], [ %indvars.iv.next239, %_ZNK15halide_buffer_t13size_in_bytesEv.exit ]
  %added_size.0219 = phi i64 [ 0, %for.body64.preheader ], [ %add, %_ZNK15halide_buffer_t13size_in_bytesEv.exit ]
  %arrayidx67 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv238
  %26 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx67, align 8, !tbaa !14
  %dimensions.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %26, i64 0, i32 5
  %27 = load i32, i32* %dimensions.i.i, align 4, !tbaa !183
  %cmp19.i.i = icmp sgt i32 %27, 0
  br i1 %cmp19.i.i, label %for.body.lr.ph.i.i, label %for.body64._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge

for.body64._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge: ; preds = %for.body64
  %sub.i.0 = sub nsw i64 1, 0
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

for.body.lr.ph.i.i:                               ; preds = %for.body64
  %dim.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %26, i64 0, i32 6
  %28 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i.i, align 8, !tbaa !184
  %wide.trip.count.i.i = zext i32 %27 to i64
  %min.iters.check24 = icmp ult i32 %27, 3
  br i1 %min.iters.check24, label %for.body.i.i.preheader, label %vector.ph25

vector.ph25:                                      ; preds = %for.body.lr.ph.i.i
  %n.vec27 = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body23

vector.body23:                                    ; preds = %pred.load.continue39, %vector.ph25
  %index28 = phi i64 [ 0, %vector.ph25 ], [ %index.next29, %pred.load.continue39 ]
  %vec.phi34 = phi i64 [ 0, %vector.ph25 ], [ %predphi40, %pred.load.continue39 ]
  %vec.phi35 = phi i64 [ 0, %vector.ph25 ], [ %predphi41, %pred.load.continue39 ]
  %induction33 = or i64 %index28, 1
  %29 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %index28, i32 2
  %30 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %induction33, i32 2
  %31 = load i32, i32* %29, align 4, !tbaa !185
  %32 = load i32, i32* %30, align 4, !tbaa !185
  %33 = icmp sgt i32 %31, 0
  %34 = icmp sgt i32 %32, 0
  %35 = zext i32 %31 to i64
  %36 = zext i32 %32 to i64
  br i1 %33, label %pred.load.if36, label %pred.load.continue37

pred.load.if36:                                   ; preds = %vector.body23
  %37 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %index28, i32 1
  %38 = load i32, i32* %37, align 4, !tbaa !189
  br label %pred.load.continue37

pred.load.continue37:                             ; preds = %pred.load.if36, %vector.body23
  %39 = phi i32 [ poison, %vector.body23 ], [ %38, %pred.load.if36 ]
  br i1 %34, label %pred.load.if38, label %pred.load.continue39

pred.load.if38:                                   ; preds = %pred.load.continue37
  %40 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %induction33, i32 1
  %41 = load i32, i32* %40, align 4, !tbaa !189
  br label %pred.load.continue39

pred.load.continue39:                             ; preds = %pred.load.if38, %pred.load.continue37
  %42 = phi i32 [ poison, %pred.load.continue37 ], [ %41, %pred.load.if38 ]
  %43 = add nsw i32 %39, -1
  %44 = add nsw i32 %42, -1
  %45 = sext i32 %43 to i64
  %46 = sext i32 %44 to i64
  %47 = mul nsw i64 %45, %35
  %48 = mul nsw i64 %46, %36
  %49 = select i1 %33, i64 %47, i64 0
  %predphi40 = add i64 %vec.phi34, %49
  %50 = select i1 %34, i64 %48, i64 0
  %predphi41 = add i64 %vec.phi35, %50
  %index.next29 = add i64 %index28, 2
  %51 = icmp eq i64 %index.next29, %n.vec27
  br i1 %51, label %middle.block21, label %vector.body23, !llvm.loop !291

middle.block21:                                   ; preds = %pred.load.continue39
  %bin.rdx42 = add i64 %predphi41, %predphi40
  %cmp.n31 = icmp eq i64 %n.vec27, %wide.trip.count.i.i
  br i1 %cmp.n31, label %for.body.i13.i.preheader, label %for.body.i.i.preheader

for.body.i.i.preheader:                           ; preds = %for.body.lr.ph.i.i, %middle.block21
  %indvars.iv.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %n.vec27, %middle.block21 ]
  %index.021.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %bin.rdx42, %middle.block21 ]
  br label %for.body.i.i

for.body.i.i:                                     ; preds = %for.body.i.i.preheader, %if.end.i.i
  %indvars.iv.i.i = phi i64 [ %indvars.iv.next.i.i, %if.end.i.i ], [ %indvars.iv.i.i.ph, %for.body.i.i.preheader ]
  %index.021.i.i = phi i64 [ %index.1.i.i, %if.end.i.i ], [ %index.021.i.i.ph, %for.body.i.i.preheader ]
  %stride2.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %indvars.iv.i.i, i32 2
  %52 = load i32, i32* %stride2.i.i, align 4, !tbaa !185
  %cmp3.i.i = icmp sgt i32 %52, 0
  br i1 %cmp3.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %for.body.i.i
  %conv18.i.i = zext i32 %52 to i64
  %extent.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %indvars.iv.i.i, i32 1
  %53 = load i32, i32* %extent.i.i, align 4, !tbaa !189
  %sub.i.i = add nsw i32 %53, -1
  %conv7.i.i = sext i32 %sub.i.i to i64
  %mul.i.i = mul nsw i64 %conv7.i.i, %conv18.i.i
  %add.i.i = add nsw i64 %mul.i.i, %index.021.i.i
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %for.body.i.i
  %index.1.i.i = phi i64 [ %add.i.i, %if.then.i.i ], [ %index.021.i.i, %for.body.i.i ]
  %indvars.iv.next.i.i = add nuw nsw i64 %indvars.iv.i.i, 1
  %exitcond.not.i.i = icmp eq i64 %indvars.iv.next.i.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i.i, label %for.body.i13.i.preheader, label %for.body.i.i, !llvm.loop !292

for.body.i13.i.preheader:                         ; preds = %if.end.i.i, %middle.block21
  %index.1.i.i.lcssa = phi i64 [ %bin.rdx42, %middle.block21 ], [ %index.1.i.i, %if.end.i.i ]
  %min.iters.check = icmp ult i32 %27, 3
  br i1 %min.iters.check, label %for.body.i13.i.preheader44, label %vector.ph

vector.ph:                                        ; preds = %for.body.i13.i.preheader
  %n.vec = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body

vector.body:                                      ; preds = %pred.load.continue19, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %pred.load.continue19 ]
  %vec.phi = phi i64 [ 0, %vector.ph ], [ %predphi, %pred.load.continue19 ]
  %vec.phi17 = phi i64 [ 0, %vector.ph ], [ %predphi20, %pred.load.continue19 ]
  %induction16 = or i64 %index, 1
  %54 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %index, i32 2
  %55 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %induction16, i32 2
  %56 = load i32, i32* %54, align 4, !tbaa !185
  %57 = load i32, i32* %55, align 4, !tbaa !185
  %58 = icmp slt i32 %56, 0
  %59 = icmp slt i32 %57, 0
  %60 = sext i32 %56 to i64
  %61 = sext i32 %57 to i64
  br i1 %58, label %pred.load.if, label %pred.load.continue

pred.load.if:                                     ; preds = %vector.body
  %62 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %index, i32 1
  %63 = load i32, i32* %62, align 4, !tbaa !189
  br label %pred.load.continue

pred.load.continue:                               ; preds = %pred.load.if, %vector.body
  %64 = phi i32 [ poison, %vector.body ], [ %63, %pred.load.if ]
  br i1 %59, label %pred.load.if18, label %pred.load.continue19

pred.load.if18:                                   ; preds = %pred.load.continue
  %65 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %induction16, i32 1
  %66 = load i32, i32* %65, align 4, !tbaa !189
  br label %pred.load.continue19

pred.load.continue19:                             ; preds = %pred.load.if18, %pred.load.continue
  %67 = phi i32 [ poison, %pred.load.continue ], [ %66, %pred.load.if18 ]
  %68 = add nsw i32 %64, -1
  %69 = add nsw i32 %67, -1
  %70 = sext i32 %68 to i64
  %71 = sext i32 %69 to i64
  %72 = mul nsw i64 %70, %60
  %73 = mul nsw i64 %71, %61
  %74 = select i1 %58, i64 %72, i64 0
  %predphi = add i64 %vec.phi, %74
  %75 = select i1 %59, i64 %73, i64 0
  %predphi20 = add i64 %vec.phi17, %75
  %index.next = add i64 %index, 2
  %76 = icmp eq i64 %index.next, %n.vec
  br i1 %76, label %middle.block, label %vector.body, !llvm.loop !293

middle.block:                                     ; preds = %pred.load.continue19
  %bin.rdx = add i64 %predphi20, %predphi
  %cmp.n = icmp eq i64 %n.vec, %wide.trip.count.i.i
  br i1 %cmp.n, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i.preheader44

for.body.i13.i.preheader44:                       ; preds = %for.body.i13.i.preheader, %middle.block
  %indvars.iv.i10.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %n.vec, %middle.block ]
  %index.018.i.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %bin.rdx, %middle.block ]
  br label %for.body.i13.i

for.body.i13.i:                                   ; preds = %for.body.i13.i.preheader44, %if.end.i24.i
  %indvars.iv.i10.i = phi i64 [ %indvars.iv.next.i22.i, %if.end.i24.i ], [ %indvars.iv.i10.i.ph, %for.body.i13.i.preheader44 ]
  %index.018.i.i = phi i64 [ %index.1.i21.i, %if.end.i24.i ], [ %index.018.i.i.ph, %for.body.i13.i.preheader44 ]
  %stride2.i11.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %indvars.iv.i10.i, i32 2
  %77 = load i32, i32* %stride2.i11.i, align 4, !tbaa !185
  %cmp3.i12.i = icmp slt i32 %77, 0
  br i1 %cmp3.i12.i, label %if.then.i20.i, label %if.end.i24.i

if.then.i20.i:                                    ; preds = %for.body.i13.i
  %conv.i14.i = sext i32 %77 to i64
  %extent.i15.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %28, i64 %indvars.iv.i10.i, i32 1
  %78 = load i32, i32* %extent.i15.i, align 4, !tbaa !189
  %sub.i16.i = add nsw i32 %78, -1
  %conv7.i17.i = sext i32 %sub.i16.i to i64
  %mul.i18.i = mul nsw i64 %conv7.i17.i, %conv.i14.i
  %add.i19.i = add nsw i64 %mul.i18.i, %index.018.i.i
  br label %if.end.i24.i

if.end.i24.i:                                     ; preds = %if.then.i20.i, %for.body.i13.i
  %index.1.i21.i = phi i64 [ %add.i19.i, %if.then.i20.i ], [ %index.018.i.i, %for.body.i13.i ]
  %indvars.iv.next.i22.i = add nuw nsw i64 %indvars.iv.i10.i, 1
  %exitcond.not.i23.i = icmp eq i64 %indvars.iv.next.i22.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i23.i, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i, !llvm.loop !294

_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit: ; preds = %if.end.i24.i, %middle.block
  %index.1.i21.i.lcssa = phi i64 [ %bin.rdx, %middle.block ], [ %index.1.i21.i, %if.end.i24.i ]
  %add8.i.i = add nsw i64 %index.1.i.i.lcssa, 1
  %sub.i.1 = sub nsw i64 %add8.i.i, %index.1.i21.i.lcssa
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

_ZNK15halide_buffer_t13size_in_bytesEv.exit:      ; preds = %for.body64._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit
  %add8.i27.i = phi i64 [ 1, %for.body64._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %add8.i.i, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %sub.i.phi = phi i64 [ %sub.i.0, %for.body64._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %sub.i.1, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %bits.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %26, i64 0, i32 4, i32 1
  %79 = load i8, i8* %bits.i.i, align 1, !tbaa !144
  %conv.i.i = zext i8 %79 to i64
  %add.i4.i = add nuw nsw i64 %conv.i.i, 7
  %div.i.i = lshr i64 %add.i4.i, 3
  %mul.i = mul i64 %div.i.i, %sub.i.phi
  %add = add i64 %mul.i, %added_size.0219
  %indvars.iv.next239 = add nuw nsw i64 %indvars.iv238, 1
  %exitcond241.not = icmp eq i64 %indvars.iv.next239, %wide.trip.count240
  br i1 %exitcond241.not, label %for.cond.cleanup63, label %for.body64, !llvm.loop !295

if.then76:                                        ; preds = %for.cond.cleanup63
  %80 = bitcast i8* %call74 to %"struct.Halide::Runtime::Internal::CacheEntry"*
  %conv77 = sext i32 %size to i64
  %call79 = tail call zeroext i1 @_ZN6Halide7Runtime8Internal10CacheEntry4initEPKhmjPK15halide_buffer_tiPPS5_by(%"struct.Halide::Runtime::Internal::CacheEntry"* nonnull dereferenceable(96) %80, i8* %cache_key, i64 %conv77, i32 %2, %struct.halide_buffer_t* %computed_bounds, i32 %tuple_count, %struct.halide_buffer_t** nonnull %tuple_buffers, i1 zeroext %has_eviction_key, i64 %eviction_key) #16
  br i1 %call79, label %if.end101, label %if.then83

if.then83:                                        ; preds = %if.then76, %for.cond.cleanup63
  %81 = load i64, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  %sub = sub i64 %81, %added_size.0.lcssa
  store i64 %sub, i64* @_ZN6Halide7Runtime8Internal18current_cache_sizeE, align 8, !tbaa !22
  br i1 %cmp62218, label %for.body88.preheader, label %for.cond.cleanup87

for.body88.preheader:                             ; preds = %if.then83
  %wide.trip.count = zext i32 %tuple_count to i64
  %indvars.iv.next.0 = add nuw nsw i64 0, 1
  %arrayidx90.0 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 0
  br label %for.body88

for.cond.cleanup87:                               ; preds = %for.body88, %if.then83
  br i1 %tobool75.not, label %cleanup132, label %if.then99

for.body88:                                       ; preds = %for.body88.for.body88_crit_edge, %for.body88.preheader
  %arrayidx90.phi = phi %struct.halide_buffer_t** [ %arrayidx90.0, %for.body88.preheader ], [ %arrayidx90.1, %for.body88.for.body88_crit_edge ]
  %indvars.iv.next.phi = phi i64 [ %indvars.iv.next.0, %for.body88.preheader ], [ %indvars.iv.next.1, %for.body88.for.body88_crit_edge ]
  %82 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx90.phi, align 8, !tbaa !14
  %host91 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %82, i64 0, i32 2
  %83 = load i8*, i8** %host91, align 8, !tbaa !180
  %call92 = tail call %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* %83) #16
  %entry93 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheBlockHeader", %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call92, i64 0, i32 0
  store %"struct.Halide::Runtime::Internal::CacheEntry"* null, %"struct.Halide::Runtime::Internal::CacheEntry"** %entry93, align 8, !tbaa !286
  %exitcond.not = icmp eq i64 %indvars.iv.next.phi, %wide.trip.count
  br i1 %exitcond.not, label %for.cond.cleanup87, label %for.body88.for.body88_crit_edge, !llvm.loop !296

for.body88.for.body88_crit_edge:                  ; preds = %for.body88
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.next.phi, 1
  %arrayidx90.1 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv.next.phi
  br label %for.body88

if.then99:                                        ; preds = %for.cond.cleanup87
  tail call void @halide_free(i8* %user_context, i8* nonnull %call74) #14
  br label %cleanup132

if.end101:                                        ; preds = %if.then76
  %84 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %arrayidx7, align 8, !tbaa !14
  %next104 = bitcast i8* %call74 to %"struct.Halide::Runtime::Internal::CacheEntry"**
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %84, %"struct.Halide::Runtime::Internal::CacheEntry"** %next104, align 8, !tbaa !229
  %85 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE, align 8, !tbaa !14
  %less_recent = getelementptr inbounds i8, i8* %call74, i64 16
  %86 = bitcast i8* %less_recent to %"struct.Halide::Runtime::Internal::CacheEntry"**
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %85, %"struct.Halide::Runtime::Internal::CacheEntry"** %86, align 8, !tbaa !252
  %cmp105.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %85, null
  br i1 %cmp105.not, label %if.end107, label %if.then106

if.then106:                                       ; preds = %if.end101
  %more_recent = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %85, i64 0, i32 1
  %87 = bitcast %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent to i8**
  store i8* %call74, i8** %87, align 8, !tbaa !268
  br label %if.end107

if.end107:                                        ; preds = %if.then106, %if.end101
  store i8* %call74, i8** bitcast (%"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE to i8**), align 8, !tbaa !14
  %88 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE, align 8, !tbaa !14
  %cmp108 = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %88, null
  br i1 %cmp108, label %if.then109, label %if.end110

if.then109:                                       ; preds = %if.end107
  store i8* %call74, i8** bitcast (%"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE to i8**), align 8, !tbaa !14
  br label %if.end110

if.end110:                                        ; preds = %if.then109, %if.end107
  %89 = bitcast %"struct.Halide::Runtime::Internal::CacheEntry"** %arrayidx7 to i8**
  store i8* %call74, i8** %89, align 8, !tbaa !14
  %in_use_count = getelementptr inbounds i8, i8* %call74, i64 52
  %90 = bitcast i8* %in_use_count to i32*
  store i32 %tuple_count, i32* %90, align 4, !tbaa !255
  br i1 %cmp62218, label %for.body117.preheader, label %cleanup132

for.body117.preheader:                            ; preds = %if.end110
  %wide.trip.count236 = zext i32 %tuple_count to i64
  %indvars.iv.next235.0 = add nuw nsw i64 0, 1
  %arrayidx119.0 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 0
  br label %for.body117

for.body117:                                      ; preds = %for.body117.for.body117_crit_edge, %for.body117.preheader
  %arrayidx119.phi = phi %struct.halide_buffer_t** [ %arrayidx119.0, %for.body117.preheader ], [ %arrayidx119.1, %for.body117.for.body117_crit_edge ]
  %indvars.iv.next235.phi = phi i64 [ %indvars.iv.next235.0, %for.body117.preheader ], [ %indvars.iv.next235.1, %for.body117.for.body117_crit_edge ]
  %91 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %arrayidx119.phi, align 8, !tbaa !14
  %host120 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %91, i64 0, i32 2
  %92 = load i8*, i8** %host120, align 8, !tbaa !180
  %call121 = tail call %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* %92) #16
  %93 = bitcast %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call121 to i8**
  store i8* %call74, i8** %93, align 8, !tbaa !286
  %exitcond237.not = icmp eq i64 %indvars.iv.next235.phi, %wide.trip.count236
  br i1 %exitcond237.not, label %cleanup132, label %for.body117.for.body117_crit_edge, !llvm.loop !297

for.body117.for.body117_crit_edge:                ; preds = %for.body117
  %indvars.iv.next235.1 = add nuw nsw i64 %indvars.iv.next235.phi, 1
  %arrayidx119.1 = getelementptr inbounds %struct.halide_buffer_t*, %struct.halide_buffer_t** %tuple_buffers, i64 %indvars.iv.next235.phi
  br label %for.body117

cleanup132:                                       ; preds = %land.lhs.true18, %for.body48.us, %for.body117, %if.end110, %if.then99, %for.cond.cleanup87
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  ret i32 0
}

; Function Attrs: nounwind
define weak void @halide_memoization_cache_release(i8* %user_context, i8* %host) local_unnamed_addr #4 {
entry:
  %call = tail call %"struct.Halide::Runtime::Internal::CacheBlockHeader"* @_ZN6Halide7Runtime8Internal21get_pointer_to_headerEPh(i8* %host) #16
  %entry2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheBlockHeader", %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call, i64 0, i32 0
  %0 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %entry2, align 8, !tbaa !286
  %cmp = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %0, null
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %1 = bitcast %"struct.Halide::Runtime::Internal::CacheBlockHeader"* %call to i8*
  tail call void @halide_free(i8* %user_context, i8* %1) #14
  br label %if.end6

if.else:                                          ; preds = %entry
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  %in_use_count = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %0, i64 0, i32 7
  %2 = load i32, i32* %in_use_count, align 4, !tbaa !255
  %cmp3.not = icmp eq i32 %2, 0
  br i1 %cmp3.not, label %if.then4, label %do.end

if.then4:                                         ; preds = %if.else
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([123 x i8], [123 x i8]* @.str.12.47, i64 0, i64 0)) #14
  tail call void @abort() #14
  %.pre = load i32, i32* %in_use_count, align 4, !tbaa !255
  br label %do.end

do.end:                                           ; preds = %if.then4, %if.else
  %3 = phi i32 [ %.pre, %if.then4 ], [ %2, %if.else ]
  %dec = add i32 %3, -1
  store i32 %dec, i32* %in_use_count, align 4, !tbaa !255
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  br label %if.end6

if.end6:                                          ; preds = %do.end, %if.then
  ret void
}

; Function Attrs: nounwind
define weak void @halide_memoization_cache_evict(i8* %user_context, i64 %eviction_key) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  br label %for.body

for.cond.cleanup:                                 ; preds = %if.end25
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal16memoization_lockE) #14
  ret void

for.body:                                         ; preds = %if.end25, %entry
  %__begin1.059 = phi %"struct.Halide::Runtime::Internal::CacheEntry"** [ getelementptr inbounds ([256 x %"struct.Halide::Runtime::Internal::CacheEntry"*], [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*]* @_ZN6Halide7Runtime8Internal13cache_entriesE, i64 0, i64 0), %entry ], [ %incdec.ptr, %if.end25 ]
  %0 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %__begin1.059, align 8, !tbaa !14
  %cmp2.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %0, null
  br i1 %cmp2.not, label %if.end25, label %while.body

while.body:                                       ; preds = %for.body, %if.end24
  %prev.058 = phi %"struct.Halide::Runtime::Internal::CacheEntry"** [ %prev.1, %if.end24 ], [ %__begin1.059, %for.body ]
  %entry1.056 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %1, %if.end24 ], [ %0, %for.body ]
  %next4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry1.056, i64 0, i32 0
  %1 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %next4, align 8, !tbaa !229
  %has_eviction_key = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry1.056, i64 0, i32 13
  %2 = load i8, i8* %has_eviction_key, align 8, !tbaa !262, !range !21
  %tobool.not = icmp eq i8 %2, 0
  br i1 %tobool.not, label %if.end24, label %land.lhs.true

land.lhs.true:                                    ; preds = %while.body
  %eviction_key5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry1.056, i64 0, i32 12
  %3 = load i64, i64* %eviction_key5, align 8, !tbaa !263
  %cmp6 = icmp eq i64 %3, %eviction_key
  br i1 %cmp6, label %if.then7, label %if.end24

if.then7:                                         ; preds = %land.lhs.true
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %1, %"struct.Halide::Runtime::Internal::CacheEntry"** %prev.058, align 8, !tbaa !14
  %more_recent = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry1.056, i64 0, i32 1
  %4 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent, align 8, !tbaa !268
  %cmp8.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %4, null
  %less_recent12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %entry1.056, i64 0, i32 2
  %5 = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent12, align 8, !tbaa !252
  br i1 %cmp8.not, label %if.else, label %if.then9

if.then9:                                         ; preds = %if.then7
  %less_recent11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %4, i64 0, i32 2
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %5, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent11, align 8, !tbaa !252
  %.pre = load %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %less_recent12, align 8, !tbaa !252
  br label %if.end

if.else:                                          ; preds = %if.then7
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %5, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal18most_recently_usedE, align 8, !tbaa !14
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then9
  %6 = phi %"struct.Halide::Runtime::Internal::CacheEntry"* [ %5, %if.else ], [ %.pre, %if.then9 ]
  %cmp14.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %6, null
  %more_recent18 = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry", %"struct.Halide::Runtime::Internal::CacheEntry"* %6, i64 0, i32 1
  %_ZN6Halide7Runtime8Internal19least_recently_usedE.sink = select i1 %cmp14.not, %"struct.Halide::Runtime::Internal::CacheEntry"** @_ZN6Halide7Runtime8Internal19least_recently_usedE, %"struct.Halide::Runtime::Internal::CacheEntry"** %more_recent18
  store %"struct.Halide::Runtime::Internal::CacheEntry"* %4, %"struct.Halide::Runtime::Internal::CacheEntry"** %_ZN6Halide7Runtime8Internal19least_recently_usedE.sink, align 8, !tbaa !14
  tail call void @_ZN6Halide7Runtime8Internal10CacheEntry7destroyEv(%"struct.Halide::Runtime::Internal::CacheEntry"* nonnull dereferenceable(96) %entry1.056) #16
  %7 = bitcast %"struct.Halide::Runtime::Internal::CacheEntry"* %entry1.056 to i8*
  tail call void @halide_free(i8* %user_context, i8* nonnull %7) #14
  br label %if.end24

if.end24:                                         ; preds = %if.end, %land.lhs.true, %while.body
  %prev.1 = phi %"struct.Halide::Runtime::Internal::CacheEntry"** [ %prev.058, %if.end ], [ %next4, %land.lhs.true ], [ %next4, %while.body ]
  %cmp3.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"* %1, null
  br i1 %cmp3.not, label %if.end25, label %while.body, !llvm.loop !298

if.end25:                                         ; preds = %if.end24, %for.body
  %incdec.ptr = getelementptr inbounds %"struct.Halide::Runtime::Internal::CacheEntry"*, %"struct.Halide::Runtime::Internal::CacheEntry"** %__begin1.059, i64 1
  %cmp.not = icmp eq %"struct.Halide::Runtime::Internal::CacheEntry"** %incdec.ptr, getelementptr inbounds ([256 x %"struct.Halide::Runtime::Internal::CacheEntry"*], [256 x %"struct.Halide::Runtime::Internal::CacheEntry"*]* @_ZN6Halide7Runtime8Internal13cache_entriesE, i64 1, i64 0)
  br i1 %cmp.not, label %for.cond.cleanup, label %for.body
}

; Function Attrs: nounwind
define weak i8* @halide_string_to_string(i8* %dst, i8* %end, i8* %arg) local_unnamed_addr #4 {
entry:
  %cmp.not = icmp ult i8* %dst, %end
  br i1 %cmp.not, label %if.end, label %return

if.end:                                           ; preds = %entry
  %tobool.not = icmp eq i8* %arg, null
  %spec.select = select i1 %tobool.not, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.50, i64 0, i64 0), i8* %arg
  br label %if.end5

if.then4:                                         ; preds = %if.end8
  store i8 0, i8* %dst.addr.023, align 1, !tbaa !18
  br label %return

if.end5:                                          ; preds = %if.end8, %if.end
  %arg.addr.124 = phi i8* [ %spec.select, %if.end ], [ %incdec.ptr9, %if.end8 ]
  %dst.addr.023 = phi i8* [ %dst, %if.end ], [ %incdec.ptr, %if.end8 ]
  %0 = load i8, i8* %arg.addr.124, align 1, !tbaa !18
  store i8 %0, i8* %dst.addr.023, align 1, !tbaa !18
  %cmp6 = icmp eq i8 %0, 0
  br i1 %cmp6, label %return, label %if.end8

if.end8:                                          ; preds = %if.end5
  %incdec.ptr = getelementptr inbounds i8, i8* %dst.addr.023, i64 1
  %incdec.ptr9 = getelementptr inbounds i8, i8* %arg.addr.124, i64 1
  %cmp3 = icmp eq i8* %incdec.ptr, %end
  br i1 %cmp3, label %if.then4, label %if.end5

return:                                           ; preds = %if.end5, %if.then4, %entry
  %retval.0 = phi i8* [ %end, %if.then4 ], [ %dst, %entry ], [ %dst.addr.023, %if.end5 ]
  ret i8* %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_uint64_to_string(i8* %dst, i8* %end, i64 %arg, i32 %min_digits) local_unnamed_addr #0 {
entry:
  %buf = alloca [32 x i8], align 1
  %0 = getelementptr inbounds [32 x i8], [32 x i8]* %buf, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %0) #15
  %arrayidx = getelementptr inbounds [32 x i8], [32 x i8]* %buf, i64 0, i64 31
  store i8 0, i8* %arrayidx, align 1, !tbaa !18
  %add.ptr = getelementptr inbounds [32 x i8], [32 x i8]* %buf, i64 0, i64 30
  %cmp13 = icmp sgt i32 %min_digits, 0
  %tobool14 = icmp ne i64 %arg, 0
  %1 = or i1 %tobool14, %cmp13
  br i1 %1, label %entry.for.body_crit_edge, label %for.cond.cleanup

entry.for.body_crit_edge:                         ; preds = %entry
  %inc.1 = add nuw nsw i32 0, 1
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %entry
  %digits.0.lcssa = phi i8* [ %add.ptr, %entry ], [ %incdec.ptr, %for.body ]
  %incdec.ptr1 = getelementptr inbounds i8, i8* %digits.0.lcssa, i64 1
  %call = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* nonnull %incdec.ptr1) #16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %0) #15
  ret i8* %call

for.body:                                         ; preds = %entry.for.body_crit_edge, %for.body.for.body_crit_edge
  %arg.addr.017 = phi i64 [ %div, %for.body.for.body_crit_edge ], [ %arg, %entry.for.body_crit_edge ]
  %digits.016 = phi i8* [ %incdec.ptr, %for.body.for.body_crit_edge ], [ %add.ptr, %entry.for.body_crit_edge ]
  %inc.phi = phi i32 [ %inc.0, %for.body.for.body_crit_edge ], [ %inc.1, %entry.for.body_crit_edge ]
  %div = udiv i64 %arg.addr.017, 10
  %mul.neg = mul i64 %div, -10
  %sub = add i64 %mul.neg, %arg.addr.017
  %2 = trunc i64 %sub to i8
  %conv = add i8 %2, 48
  store i8 %conv, i8* %digits.016, align 1, !tbaa !18
  %incdec.ptr = getelementptr inbounds i8, i8* %digits.016, i64 -1
  %cmp = icmp slt i32 %inc.phi, %min_digits
  %3 = icmp ugt i64 %arg.addr.017, 9
  %4 = or i1 %3, %cmp
  br i1 %4, label %for.body.for.body_crit_edge, label %for.cond.cleanup, !llvm.loop !299

for.body.for.body_crit_edge:                      ; preds = %for.body
  %inc.0 = add nuw nsw i32 %inc.phi, 1
  br label %for.body
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_int64_to_string(i8* %dst, i8* %end, i64 %arg, i32 %min_digits) local_unnamed_addr #0 {
entry:
  %cmp = icmp slt i64 %arg, 0
  %cmp1 = icmp ult i8* %dst, %end
  %or.cond = and i1 %cmp1, %cmp
  br i1 %or.cond, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %incdec.ptr = getelementptr inbounds i8, i8* %dst, i64 1
  store i8 45, i8* %dst, align 1, !tbaa !18
  %sub = sub nsw i64 0, %arg
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %arg.addr.0 = phi i64 [ %sub, %if.then ], [ %arg, %entry ]
  %dst.addr.0 = phi i8* [ %incdec.ptr, %if.then ], [ %dst, %entry ]
  %call = tail call i8* @halide_uint64_to_string(i8* %dst.addr.0, i8* %end, i64 %arg.addr.0, i32 %min_digits) #16
  ret i8* %call
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_double_to_string(i8* %dst, i8* %end, double %arg, i32 %scientific) local_unnamed_addr #0 {
entry:
  %arg.addr = alloca double, align 8
  %bits = alloca i64, align 8
  %buf = alloca [512 x i8], align 1
  store double %arg, double* %arg.addr, align 8, !tbaa !172
  %0 = bitcast i64* %bits to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %0) #15
  store i64 0, i64* %bits, align 8, !tbaa !22
  %1 = bitcast double* %arg.addr to i8*
  %call = call i8* @memcpy(i8* nonnull %0, i8* nonnull %1, i64 8) #14
  %2 = load i64, i64* %bits, align 8, !tbaa !22
  %and = and i64 %2, 4503599627370495
  %shr = lshr i64 %2, 52
  %3 = trunc i64 %shr to i32
  %conv = and i32 %3, 2047
  %cmp = icmp eq i32 %conv, 2047
  br i1 %cmp, label %if.then, label %if.else15

if.then:                                          ; preds = %entry
  %tobool.not = icmp eq i64 %and, 0
  %tobool10.not = icmp sgt i64 %2, -1
  br i1 %tobool.not, label %if.else9, label %if.then4

if.then4:                                         ; preds = %if.then
  br i1 %tobool10.not, label %if.else, label %if.then6

if.then6:                                         ; preds = %if.then4
  %call7 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.1.57, i64 0, i64 0)) #16
  br label %cleanup147

if.else:                                          ; preds = %if.then4
  %call8 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.2.58, i64 0, i64 0)) #16
  br label %cleanup147

if.else9:                                         ; preds = %if.then
  br i1 %tobool10.not, label %if.else13, label %if.then11

if.then11:                                        ; preds = %if.else9
  %call12 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.3.59, i64 0, i64 0)) #16
  br label %cleanup147

if.else13:                                        ; preds = %if.else9
  %call14 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.4.60, i64 0, i64 0)) #16
  br label %cleanup147

if.else15:                                        ; preds = %entry
  %cmp16 = icmp eq i32 %conv, 0
  %cmp17 = icmp eq i64 %and, 0
  %or.cond = and i1 %cmp17, %cmp16
  br i1 %or.cond, label %if.then18, label %if.end32

if.then18:                                        ; preds = %if.else15
  %tobool19.not = icmp eq i32 %scientific, 0
  %tobool27.not = icmp sgt i64 %2, -1
  br i1 %tobool19.not, label %if.else26, label %if.then20

if.then20:                                        ; preds = %if.then18
  br i1 %tobool27.not, label %if.else24, label %if.then22

if.then22:                                        ; preds = %if.then20
  %call23 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.5.61, i64 0, i64 0)) #16
  br label %cleanup147

if.else24:                                        ; preds = %if.then20
  %call25 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.6.62, i64 0, i64 0)) #16
  br label %cleanup147

if.else26:                                        ; preds = %if.then18
  br i1 %tobool27.not, label %if.else30, label %if.then28

if.then28:                                        ; preds = %if.else26
  %call29 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.7.63, i64 0, i64 0)) #16
  br label %cleanup147

if.else30:                                        ; preds = %if.else26
  %call31 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.8.64, i64 0, i64 0)) #16
  br label %cleanup147

if.end32:                                         ; preds = %if.else15
  %tobool33.not = icmp sgt i64 %2, -1
  br i1 %tobool33.not, label %if.end36, label %if.then34

if.then34:                                        ; preds = %if.end32
  %call35 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.9.65, i64 0, i64 0)) #16
  %4 = load double, double* %arg.addr, align 8, !tbaa !172
  %fneg = fneg double %4
  store double %fneg, double* %arg.addr, align 8, !tbaa !172
  br label %if.end36

if.end36:                                         ; preds = %if.then34, %if.end32
  %dst.addr.0 = phi i8* [ %call35, %if.then34 ], [ %dst, %if.end32 ]
  %tobool37.not = icmp eq i32 %scientific, 0
  br i1 %tobool37.not, label %if.else61, label %while.condthread-pre-split

while.condthread-pre-split:                       ; preds = %if.end36
  %.pr = load double, double* %arg.addr, align 8, !tbaa !172
  %cmp39276 = fcmp olt double %.pr, 1.000000e+00
  br i1 %cmp39276, label %while.condthread-pre-split.while.body_crit_edge, label %while.cond40thread-pre-split

while.condthread-pre-split.while.body_crit_edge:  ; preds = %while.condthread-pre-split
  %dec.1 = add nsw i32 0, -1
  br label %while.body

while.body:                                       ; preds = %while.condthread-pre-split.while.body_crit_edge, %while.body.while.body_crit_edge
  %dec.phi = phi i32 [ %dec.0, %while.body.while.body_crit_edge ], [ %dec.1, %while.condthread-pre-split.while.body_crit_edge ]
  %5 = phi double [ %mul, %while.body.while.body_crit_edge ], [ %.pr, %while.condthread-pre-split.while.body_crit_edge ]
  %mul = fmul double %5, 1.000000e+01
  %cmp39 = fcmp olt double %mul, 1.000000e+00
  br i1 %cmp39, label %while.body.while.body_crit_edge, label %while.cond.while.cond40thread-pre-split_crit_edge, !llvm.loop !300

while.body.while.body_crit_edge:                  ; preds = %while.body
  %dec.0 = add nsw i32 %dec.phi, -1
  br label %while.body

while.cond.while.cond40thread-pre-split_crit_edge: ; preds = %while.body
  store double %mul, double* %arg.addr, align 8, !tbaa !172
  br label %while.cond40thread-pre-split

while.cond40thread-pre-split:                     ; preds = %while.cond.while.cond40thread-pre-split_crit_edge, %while.condthread-pre-split
  %.pr261 = phi double [ %mul, %while.cond.while.cond40thread-pre-split_crit_edge ], [ %.pr, %while.condthread-pre-split ]
  %exponent_base_10.0.lcssa = phi i32 [ %dec.phi, %while.cond.while.cond40thread-pre-split_crit_edge ], [ 0, %while.condthread-pre-split ]
  %cmp41272 = fcmp ult double %.pr261, 1.000000e+01
  br i1 %cmp41272, label %while.end43, label %while.body42

while.body42:                                     ; preds = %while.cond40thread-pre-split, %while.body42
  %exponent_base_10.1273 = phi i32 [ %inc, %while.body42 ], [ %exponent_base_10.0.lcssa, %while.cond40thread-pre-split ]
  %6 = phi double [ %div, %while.body42 ], [ %.pr261, %while.cond40thread-pre-split ]
  %div = fdiv double %6, 1.000000e+01
  %inc = add nsw i32 %exponent_base_10.1273, 1
  %cmp41 = fcmp ult double %div, 1.000000e+01
  br i1 %cmp41, label %while.cond40.while.end43_crit_edge, label %while.body42, !llvm.loop !301

while.cond40.while.end43_crit_edge:               ; preds = %while.body42
  store double %div, double* %arg.addr, align 8, !tbaa !172
  br label %while.end43

while.end43:                                      ; preds = %while.cond40.while.end43_crit_edge, %while.cond40thread-pre-split
  %.lcssa = phi double [ %div, %while.cond40.while.end43_crit_edge ], [ %.pr261, %while.cond40thread-pre-split ]
  %exponent_base_10.1.lcssa = phi i32 [ %inc, %while.cond40.while.end43_crit_edge ], [ %exponent_base_10.0.lcssa, %while.cond40thread-pre-split ]
  %mul44 = fmul double %.lcssa, 1.000000e+06
  %add = fadd double %mul44, 5.000000e-01
  %conv45 = fptoui double %add to i64
  %div46 = udiv i64 %conv45, 1000000
  %mul47.neg = mul i64 %div46, -1000000
  %sub48 = add i64 %mul47.neg, %conv45
  %call49 = call i8* @halide_int64_to_string(i8* %dst.addr.0, i8* %end, i64 %div46, i32 1) #16
  %call50 = call i8* @halide_string_to_string(i8* %call49, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.141, i64 0, i64 0)) #16
  %call51 = call i8* @halide_int64_to_string(i8* %call50, i8* %end, i64 %sub48, i32 6) #16
  %cmp52 = icmp sgt i32 %exponent_base_10.1.lcssa, -1
  br i1 %cmp52, label %if.then53, label %if.else55

if.then53:                                        ; preds = %while.end43
  %call54 = call i8* @halide_string_to_string(i8* %call51, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.11.67, i64 0, i64 0)) #16
  br label %if.end58

if.else55:                                        ; preds = %while.end43
  %call56 = call i8* @halide_string_to_string(i8* %call51, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.12.68, i64 0, i64 0)) #16
  %sub57 = sub nsw i32 0, %exponent_base_10.1.lcssa
  br label %if.end58

if.end58:                                         ; preds = %if.else55, %if.then53
  %exponent_base_10.2 = phi i32 [ %exponent_base_10.1.lcssa, %if.then53 ], [ %sub57, %if.else55 ]
  %dst.addr.1 = phi i8* [ %call54, %if.then53 ], [ %call56, %if.else55 ]
  %conv59262 = zext i32 %exponent_base_10.2 to i64
  %call60 = call i8* @halide_int64_to_string(i8* %dst.addr.1, i8* %end, i64 %conv59262, i32 2) #16
  br label %cleanup147

if.else61:                                        ; preds = %if.end36
  br i1 %cmp16, label %if.then63, label %if.end65

if.then63:                                        ; preds = %if.else61
  %call64 = call i8* @halide_double_to_string(i8* %dst.addr.0, i8* %end, double 0.000000e+00, i32 0) #16
  br label %cleanup147

if.end65:                                         ; preds = %if.else61
  %add67 = or i64 %and, 4503599627370496
  %sub69 = add nsw i32 %conv, -1075
  %cmp70 = icmp ult i32 %conv, 1075
  br i1 %cmp70, label %if.then71, label %if.end104

if.then71:                                        ; preds = %if.end65
  %cmp72 = icmp ult i32 %conv, 1023
  %sub76 = sub nuw nsw i32 1075, %conv
  %sh_prom = zext i32 %sub76 to i64
  %shr77 = lshr i64 %add67, %sh_prom
  %shl80 = shl i64 %shr77, %sh_prom
  %integer_part.0 = select i1 %cmp72, i64 0, i64 %shr77
  %sub81 = select i1 %cmp72, i64 0, i64 %shl80
  %f.0.in = sub i64 %add67, %sub81
  %f.0 = uitofp i64 %f.0.in to double
  %conv84258 = zext i32 %sub69 to i64
  %shl85 = shl i64 %conv84258, 52
  %add87 = add i64 %shl85, 4696837146684686336
  %7 = bitcast i64 %add87 to double
  %mul89 = fmul double %7, %f.0
  %add90 = fadd double %mul89, 5.000000e-01
  %conv91 = fptoui double %add90 to i64
  %conv92 = uitofp i64 %conv91 to double
  %cmp93 = fcmp oeq double %add90, %conv92
  %and95 = and i64 %conv91, 1
  %tobool96.not = icmp ne i64 %and95, 0
  %not.or.cond259 = and i1 %cmp93, %tobool96.not
  %dec98 = sext i1 %not.or.cond259 to i64
  %fractional_part.0 = add i64 %dec98, %conv91
  %cmp100 = icmp eq i64 %fractional_part.0, 1000000
  %inc102 = zext i1 %cmp100 to i64
  %spec.select = add nuw i64 %integer_part.0, %inc102
  %spec.select260 = select i1 %cmp100, i64 0, i64 %fractional_part.0
  br label %if.end104

if.end104:                                        ; preds = %if.then71, %if.end65
  %integer_part.2 = phi i64 [ %spec.select, %if.then71 ], [ %add67, %if.end65 ]
  %integer_exponent.0 = phi i32 [ 0, %if.then71 ], [ %sub69, %if.end65 ]
  %fractional_part.2 = phi i64 [ %spec.select260, %if.then71 ], [ 0, %if.end65 ]
  %8 = getelementptr inbounds [512 x i8], [512 x i8]* %buf, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %8) #15
  %add.ptr = getelementptr inbounds [512 x i8], [512 x i8]* %buf, i64 0, i64 512
  %add.ptr105 = getelementptr inbounds [512 x i8], [512 x i8]* %buf, i64 0, i64 480
  %call108 = call i8* @halide_int64_to_string(i8* nonnull %add.ptr105, i8* nonnull %add.ptr, i64 %integer_part.2, i32 1) #16
  %cmp109267 = icmp sgt i32 %integer_exponent.0, 0
  br i1 %cmp109267, label %for.cond111.preheader, label %for.cond.cleanup

for.cond111.preheader:                            ; preds = %if.end104, %if.end137
  %i.0270 = phi i32 [ %inc139, %if.end137 ], [ 0, %if.end104 ]
  %int_part_ptr.0268 = phi i8* [ %int_part_ptr.1, %if.end137 ], [ %add.ptr105, %if.end104 ]
  %cmp113.not264 = icmp eq i8* %call108, %int_part_ptr.0268
  br i1 %cmp113.not264, label %if.end137, label %for.body115

for.cond.cleanup:                                 ; preds = %if.end137, %if.end104
  %int_part_ptr.0.lcssa = phi i8* [ %add.ptr105, %if.end104 ], [ %int_part_ptr.1, %if.end137 ]
  %call141 = call i8* @halide_string_to_string(i8* %dst.addr.0, i8* %end, i8* %int_part_ptr.0.lcssa) #16
  %call142 = call i8* @halide_string_to_string(i8* %call141, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.141, i64 0, i64 0)) #16
  %call143 = call i8* @halide_int64_to_string(i8* %call142, i8* %end, i64 %fractional_part.2, i32 6) #16
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %8) #15
  br label %cleanup147

for.cond.cleanup114:                              ; preds = %for.body115
  br i1 %cmp124, label %if.then135, label %if.end137

for.body115:                                      ; preds = %for.cond111.preheader, %for.body115
  %p.0266.pn = phi i8* [ %p.0266, %for.body115 ], [ %call108, %for.cond111.preheader ]
  %carry.0265 = phi i32 [ %carry.1, %for.body115 ], [ 0, %for.cond111.preheader ]
  %p.0266 = getelementptr inbounds i8, i8* %p.0266.pn, i64 -1
  %9 = load i8, i8* %p.0266, align 1, !tbaa !18
  %sub117 = add i8 %9, -48
  %conv119 = sext i8 %sub117 to i32
  %mul120 = shl nsw i32 %conv119, 1
  %add121 = or i32 %mul120, %carry.0265
  %10 = trunc i32 %add121 to i8
  %cmp124 = icmp sgt i8 %10, 9
  %sub127 = add nsw i32 %add121, 246
  %carry.1 = zext i1 %cmp124 to i32
  %new_digit.0.in = select i1 %cmp124, i32 %sub127, i32 %add121
  %11 = trunc i32 %new_digit.0.in to i8
  %conv133 = add i8 %11, 48
  store i8 %conv133, i8* %p.0266, align 1, !tbaa !18
  %cmp113.not = icmp eq i8* %p.0266, %int_part_ptr.0268
  br i1 %cmp113.not, label %for.cond.cleanup114, label %for.body115, !llvm.loop !302

if.then135:                                       ; preds = %for.cond.cleanup114
  %incdec.ptr136 = getelementptr inbounds i8, i8* %int_part_ptr.0268, i64 -1
  store i8 49, i8* %incdec.ptr136, align 1, !tbaa !18
  br label %if.end137

if.end137:                                        ; preds = %if.then135, %for.cond.cleanup114, %for.cond111.preheader
  %int_part_ptr.1 = phi i8* [ %incdec.ptr136, %if.then135 ], [ %int_part_ptr.0268, %for.cond.cleanup114 ], [ %call108, %for.cond111.preheader ]
  %inc139 = add nuw nsw i32 %i.0270, 1
  %exitcond.not = icmp eq i32 %inc139, %integer_exponent.0
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.cond111.preheader, !llvm.loop !303

cleanup147:                                       ; preds = %for.cond.cleanup, %if.then63, %if.end58, %if.else30, %if.then28, %if.else24, %if.then22, %if.else13, %if.then11, %if.else, %if.then6
  %retval.1 = phi i8* [ %call7, %if.then6 ], [ %call8, %if.else ], [ %call12, %if.then11 ], [ %call14, %if.else13 ], [ %call23, %if.then22 ], [ %call25, %if.else24 ], [ %call29, %if.then28 ], [ %call31, %if.else30 ], [ %call64, %if.then63 ], [ %call60, %if.end58 ], [ %call143, %for.cond.cleanup ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %0) #15
  ret i8* %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_pointer_to_string(i8* %dst, i8* %end, i8* %arg) local_unnamed_addr #0 {
entry:
  %buf = alloca [20 x i8], align 1
  %0 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %0) #15
  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 dereferenceable(20) %0, i8 0, i64 20, i1 false)
  %add.ptr = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 18
  %1 = ptrtoint i8* %arg to i64
  %and = and i64 %1, 15
  %arrayidx = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and
  %2 = load i8, i8* %arrayidx, align 1, !tbaa !18
  %incdec.ptr = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 17
  store i8 %2, i8* %add.ptr, align 1, !tbaa !18
  %shr = lshr i64 %1, 4
  %tobool.not = icmp eq i64 %shr, 0
  br i1 %tobool.not, label %cleanup, label %for.cond

for.cond:                                         ; preds = %entry
  %and.1 = and i64 %shr, 15
  %arrayidx.1 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.1
  %3 = load i8, i8* %arrayidx.1, align 1, !tbaa !18
  %incdec.ptr.1 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 16
  store i8 %3, i8* %incdec.ptr, align 1, !tbaa !18
  %shr.1 = lshr i64 %1, 8
  %tobool.not.1 = icmp eq i64 %shr.1, 0
  br i1 %tobool.not.1, label %cleanup, label %for.cond.1

cleanup:                                          ; preds = %for.cond.14, %for.cond.13, %for.cond.12, %for.cond.11, %for.cond.10, %for.cond.9, %for.cond.8, %for.cond.7, %for.cond.6, %for.cond.5, %for.cond.4, %for.cond.3, %for.cond.2, %for.cond.1, %for.cond, %entry
  %buf_ptr.016.lcssa = phi i8* [ %add.ptr, %entry ], [ %incdec.ptr, %for.cond ], [ %incdec.ptr.1, %for.cond.1 ], [ %incdec.ptr.2, %for.cond.2 ], [ %incdec.ptr.3, %for.cond.3 ], [ %incdec.ptr.4, %for.cond.4 ], [ %incdec.ptr.5, %for.cond.5 ], [ %incdec.ptr.6, %for.cond.6 ], [ %incdec.ptr.7, %for.cond.7 ], [ %incdec.ptr.8, %for.cond.8 ], [ %incdec.ptr.9, %for.cond.9 ], [ %incdec.ptr.10, %for.cond.10 ], [ %incdec.ptr.11, %for.cond.11 ], [ %incdec.ptr.12, %for.cond.12 ], [ %incdec.ptr.13, %for.cond.13 ], [ %incdec.ptr.14, %for.cond.14 ]
  %incdec.ptr.lcssa = phi i8* [ %incdec.ptr, %entry ], [ %incdec.ptr.1, %for.cond ], [ %incdec.ptr.2, %for.cond.1 ], [ %incdec.ptr.3, %for.cond.2 ], [ %incdec.ptr.4, %for.cond.3 ], [ %incdec.ptr.5, %for.cond.4 ], [ %incdec.ptr.6, %for.cond.5 ], [ %incdec.ptr.7, %for.cond.6 ], [ %incdec.ptr.8, %for.cond.7 ], [ %incdec.ptr.9, %for.cond.8 ], [ %incdec.ptr.10, %for.cond.9 ], [ %incdec.ptr.11, %for.cond.10 ], [ %incdec.ptr.12, %for.cond.11 ], [ %incdec.ptr.13, %for.cond.12 ], [ %incdec.ptr.14, %for.cond.13 ], [ %incdec.ptr.15, %for.cond.14 ]
  %incdec.ptr1 = getelementptr inbounds i8, i8* %buf_ptr.016.lcssa, i64 -2
  store i8 120, i8* %incdec.ptr.lcssa, align 1, !tbaa !18
  store i8 48, i8* %incdec.ptr1, align 1, !tbaa !18
  %call = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* nonnull %incdec.ptr1) #16
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %0) #15
  ret i8* %call

for.cond.1:                                       ; preds = %for.cond
  %and.2 = and i64 %shr.1, 15
  %arrayidx.2 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.2
  %4 = load i8, i8* %arrayidx.2, align 1, !tbaa !18
  %incdec.ptr.2 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 15
  store i8 %4, i8* %incdec.ptr.1, align 1, !tbaa !18
  %shr.2 = lshr i64 %1, 12
  %tobool.not.2 = icmp eq i64 %shr.2, 0
  br i1 %tobool.not.2, label %cleanup, label %for.cond.2

for.cond.2:                                       ; preds = %for.cond.1
  %and.3 = and i64 %shr.2, 15
  %arrayidx.3 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.3
  %5 = load i8, i8* %arrayidx.3, align 1, !tbaa !18
  %incdec.ptr.3 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 14
  store i8 %5, i8* %incdec.ptr.2, align 1, !tbaa !18
  %shr.3 = lshr i64 %1, 16
  %tobool.not.3 = icmp eq i64 %shr.3, 0
  br i1 %tobool.not.3, label %cleanup, label %for.cond.3

for.cond.3:                                       ; preds = %for.cond.2
  %and.4 = and i64 %shr.3, 15
  %arrayidx.4 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.4
  %6 = load i8, i8* %arrayidx.4, align 1, !tbaa !18
  %incdec.ptr.4 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 13
  store i8 %6, i8* %incdec.ptr.3, align 1, !tbaa !18
  %shr.4 = lshr i64 %1, 20
  %tobool.not.4 = icmp eq i64 %shr.4, 0
  br i1 %tobool.not.4, label %cleanup, label %for.cond.4

for.cond.4:                                       ; preds = %for.cond.3
  %and.5 = and i64 %shr.4, 15
  %arrayidx.5 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.5
  %7 = load i8, i8* %arrayidx.5, align 1, !tbaa !18
  %incdec.ptr.5 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 12
  store i8 %7, i8* %incdec.ptr.4, align 1, !tbaa !18
  %shr.5 = lshr i64 %1, 24
  %tobool.not.5 = icmp eq i64 %shr.5, 0
  br i1 %tobool.not.5, label %cleanup, label %for.cond.5

for.cond.5:                                       ; preds = %for.cond.4
  %and.6 = and i64 %shr.5, 15
  %arrayidx.6 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.6
  %8 = load i8, i8* %arrayidx.6, align 1, !tbaa !18
  %incdec.ptr.6 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 11
  store i8 %8, i8* %incdec.ptr.5, align 1, !tbaa !18
  %shr.6 = lshr i64 %1, 28
  %tobool.not.6 = icmp eq i64 %shr.6, 0
  br i1 %tobool.not.6, label %cleanup, label %for.cond.6

for.cond.6:                                       ; preds = %for.cond.5
  %and.7 = and i64 %shr.6, 15
  %arrayidx.7 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.7
  %9 = load i8, i8* %arrayidx.7, align 1, !tbaa !18
  %incdec.ptr.7 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 10
  store i8 %9, i8* %incdec.ptr.6, align 1, !tbaa !18
  %shr.7 = lshr i64 %1, 32
  %tobool.not.7 = icmp eq i64 %shr.7, 0
  br i1 %tobool.not.7, label %cleanup, label %for.cond.7

for.cond.7:                                       ; preds = %for.cond.6
  %and.8 = and i64 %shr.7, 15
  %arrayidx.8 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.8
  %10 = load i8, i8* %arrayidx.8, align 1, !tbaa !18
  %incdec.ptr.8 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 9
  store i8 %10, i8* %incdec.ptr.7, align 1, !tbaa !18
  %shr.8 = lshr i64 %1, 36
  %tobool.not.8 = icmp eq i64 %shr.8, 0
  br i1 %tobool.not.8, label %cleanup, label %for.cond.8

for.cond.8:                                       ; preds = %for.cond.7
  %and.9 = and i64 %shr.8, 15
  %arrayidx.9 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.9
  %11 = load i8, i8* %arrayidx.9, align 1, !tbaa !18
  %incdec.ptr.9 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 8
  store i8 %11, i8* %incdec.ptr.8, align 1, !tbaa !18
  %shr.9 = lshr i64 %1, 40
  %tobool.not.9 = icmp eq i64 %shr.9, 0
  br i1 %tobool.not.9, label %cleanup, label %for.cond.9

for.cond.9:                                       ; preds = %for.cond.8
  %and.10 = and i64 %shr.9, 15
  %arrayidx.10 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.10
  %12 = load i8, i8* %arrayidx.10, align 1, !tbaa !18
  %incdec.ptr.10 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 7
  store i8 %12, i8* %incdec.ptr.9, align 1, !tbaa !18
  %shr.10 = lshr i64 %1, 44
  %tobool.not.10 = icmp eq i64 %shr.10, 0
  br i1 %tobool.not.10, label %cleanup, label %for.cond.10

for.cond.10:                                      ; preds = %for.cond.9
  %and.11 = and i64 %shr.10, 15
  %arrayidx.11 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.11
  %13 = load i8, i8* %arrayidx.11, align 1, !tbaa !18
  %incdec.ptr.11 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 6
  store i8 %13, i8* %incdec.ptr.10, align 1, !tbaa !18
  %shr.11 = lshr i64 %1, 48
  %tobool.not.11 = icmp eq i64 %shr.11, 0
  br i1 %tobool.not.11, label %cleanup, label %for.cond.11

for.cond.11:                                      ; preds = %for.cond.10
  %and.12 = and i64 %shr.11, 15
  %arrayidx.12 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.12
  %14 = load i8, i8* %arrayidx.12, align 1, !tbaa !18
  %incdec.ptr.12 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 5
  store i8 %14, i8* %incdec.ptr.11, align 1, !tbaa !18
  %shr.12 = lshr i64 %1, 52
  %tobool.not.12 = icmp eq i64 %shr.12, 0
  br i1 %tobool.not.12, label %cleanup, label %for.cond.12

for.cond.12:                                      ; preds = %for.cond.11
  %and.13 = and i64 %shr.12, 15
  %arrayidx.13 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.13
  %15 = load i8, i8* %arrayidx.13, align 1, !tbaa !18
  %incdec.ptr.13 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 4
  store i8 %15, i8* %incdec.ptr.12, align 1, !tbaa !18
  %shr.13 = lshr i64 %1, 56
  %tobool.not.13 = icmp eq i64 %shr.13, 0
  br i1 %tobool.not.13, label %cleanup, label %for.cond.13

for.cond.13:                                      ; preds = %for.cond.12
  %and.14 = and i64 %shr.13, 15
  %arrayidx.14 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %and.14
  %16 = load i8, i8* %arrayidx.14, align 1, !tbaa !18
  %incdec.ptr.14 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 3
  store i8 %16, i8* %incdec.ptr.13, align 1, !tbaa !18
  %shr.14 = lshr i64 %1, 60
  %tobool.not.14 = icmp eq i64 %shr.14, 0
  br i1 %tobool.not.14, label %cleanup, label %for.cond.14

for.cond.14:                                      ; preds = %for.cond.13
  %arrayidx.15 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13.71, i64 0, i64 %shr.14
  %17 = load i8, i8* %arrayidx.15, align 1, !tbaa !18
  %incdec.ptr.15 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i64 0, i64 2
  store i8 %17, i8* %incdec.ptr.14, align 1, !tbaa !18
  br label %cleanup
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_type_to_string(i8* %dst, i8* %end, %struct.halide_type_t* %t) local_unnamed_addr #0 {
entry:
  %code = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %t, i64 0, i32 0
  %0 = load i8, i8* %code, align 2, !tbaa !304
  %1 = icmp ult i8 %0, 4
  br i1 %1, label %switch.lookup, label %sw.epilog

switch.lookup:                                    ; preds = %entry
  %2 = sext i8 %0 to i64
  %switch.gep = getelementptr inbounds [4 x i8*], [4 x i8*]* @switch.table.halide_type_to_string, i64 0, i64 %2
  %switch.load = load i8*, i8** %switch.gep, align 8
  br label %sw.epilog

sw.epilog:                                        ; preds = %entry, %switch.lookup
  %code_name.0 = phi i8* [ %switch.load, %switch.lookup ], [ getelementptr inbounds ([14 x i8], [14 x i8]* @.str.18.72, i64 0, i64 0), %entry ]
  %call = tail call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* nonnull %code_name.0) #16
  %bits = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %t, i64 0, i32 1
  %3 = load i8, i8* %bits, align 1, !tbaa !144
  %conv4 = zext i8 %3 to i64
  %call5 = tail call i8* @halide_uint64_to_string(i8* %call, i8* %end, i64 %conv4, i32 1) #16
  %lanes = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %t, i64 0, i32 2
  %4 = load i16, i16* %lanes, align 2, !tbaa !305
  %cmp.not = icmp eq i16 %4, 1
  br i1 %cmp.not, label %if.end, label %if.then

if.then:                                          ; preds = %sw.epilog
  %call7 = tail call i8* @halide_string_to_string(i8* %call5, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.19.77, i64 0, i64 0)) #16
  %5 = load i16, i16* %lanes, align 2, !tbaa !305
  %conv9 = zext i16 %5 to i64
  %call10 = tail call i8* @halide_uint64_to_string(i8* %call7, i8* %end, i64 %conv9, i32 1) #16
  br label %if.end

if.end:                                           ; preds = %if.then, %sw.epilog
  %dst.addr.0 = phi i8* [ %call10, %if.then ], [ %call5, %sw.epilog ]
  ret i8* %dst.addr.0
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_buffer_to_string(i8* %dst, i8* %end, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %call = tail call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.20.78, i64 0, i64 0)) #16
  br label %return

if.end:                                           ; preds = %entry
  %call1 = tail call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.21.79, i64 0, i64 0)) #16
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !182
  %call2 = tail call i8* @halide_uint64_to_string(i8* %call1, i8* %end, i64 %0, i32 1) #16
  %call3 = tail call i8* @halide_string_to_string(i8* %call2, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #16
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %1 = bitcast %struct.halide_device_interface_t** %device_interface to i8**
  %2 = load i8*, i8** %1, align 8, !tbaa !306
  %call4 = tail call i8* @halide_pointer_to_string(i8* %call3, i8* %end, i8* %2) #16
  %call5 = tail call i8* @halide_string_to_string(i8* %call4, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #16
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 2
  %3 = load i8*, i8** %host, align 8, !tbaa !180
  %call6 = tail call i8* @halide_pointer_to_string(i8* %call5, i8* %end, i8* %3) #16
  %call7 = tail call i8* @halide_string_to_string(i8* %call6, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #16
  %flags = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %4 = load i64, i64* %flags, align 8, !tbaa !307
  %call8 = tail call i8* @halide_uint64_to_string(i8* %call7, i8* %end, i64 %4, i32 1) #16
  %call9 = tail call i8* @halide_string_to_string(i8* %call8, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #16
  %type = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 4
  %call10 = tail call i8* @halide_type_to_string(i8* %call9, i8* %end, %struct.halide_type_t* nonnull %type) #16
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 5
  %5 = load i32, i32* %dimensions, align 4, !tbaa !183
  %cmp1179 = icmp sgt i32 %5, 0
  br i1 %cmp1179, label %for.body.lr.ph, label %for.cond.cleanup

for.body.lr.ph:                                   ; preds = %if.end
  %dim = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 6
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %if.end
  %dst.addr.0.lcssa = phi i8* [ %call10, %if.end ], [ %call26, %for.body ]
  %call27 = tail call i8* @halide_string_to_string(i8* %dst.addr.0.lcssa, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.119, i64 0, i64 0)) #16
  br label %return

for.body:                                         ; preds = %for.body, %for.body.lr.ph
  %indvars.iv = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next, %for.body ]
  %dst.addr.080 = phi i8* [ %call10, %for.body.lr.ph ], [ %call26, %for.body ]
  %call12 = tail call i8* @halide_string_to_string(i8* %dst.addr.080, i8* %end, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.23.82, i64 0, i64 0)) #16
  %6 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !184
  %min = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %6, i64 %indvars.iv, i32 0
  %7 = load i32, i32* %min, align 4, !tbaa !221
  %conv = sext i32 %7 to i64
  %call13 = tail call i8* @halide_int64_to_string(i8* %call12, i8* %end, i64 %conv, i32 1) #16
  %call14 = tail call i8* @halide_string_to_string(i8* %call13, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #16
  %8 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !184
  %extent = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %8, i64 %indvars.iv, i32 1
  %9 = load i32, i32* %extent, align 4, !tbaa !189
  %conv18 = sext i32 %9 to i64
  %call19 = tail call i8* @halide_int64_to_string(i8* %call14, i8* %end, i64 %conv18, i32 1) #16
  %call20 = tail call i8* @halide_string_to_string(i8* %call19, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #16
  %10 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !184
  %stride = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %10, i64 %indvars.iv, i32 2
  %11 = load i32, i32* %stride, align 4, !tbaa !185
  %conv24 = sext i32 %11 to i64
  %call25 = tail call i8* @halide_int64_to_string(i8* %call20, i8* %end, i64 %conv24, i32 1) #16
  %call26 = tail call i8* @halide_string_to_string(i8* %call25, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.24.83, i64 0, i64 0)) #16
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %12 = load i32, i32* %dimensions, align 4, !tbaa !183
  %13 = sext i32 %12 to i64
  %cmp11 = icmp slt i64 %indvars.iv.next, %13
  br i1 %cmp11, label %for.body, label %for.cond.cleanup, !llvm.loop !308

return:                                           ; preds = %for.cond.cleanup, %if.then
  %retval.0 = phi i8* [ %call, %if.then ], [ %call27, %for.cond.cleanup ]
  ret i8* %retval.0
}

; Function Attrs: alwaysinline nounwind willreturn mustprogress
define weak i32 @halide_malloc_alignment() local_unnamed_addr #6 {
entry:
  ret i32 32
}

; Function Attrs: nounwind
define weak i32 @halide_reuse_device_allocations(i8* %user_context, i1 zeroext %flag) local_unnamed_addr #4 {
entry:
  %frombool = zext i1 %flag to i8
  store i8 %frombool, i8* @_ZN6Halide7Runtime8Internal36halide_reuse_device_allocations_flagE, align 1, !tbaa !19
  br i1 %flag, label %if.end5, label %if.then

if.then:                                          ; preds = %entry
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal21allocation_pools_lockE) #14
  %p.014 = load %struct.halide_device_allocation_pool*, %struct.halide_device_allocation_pool** @_ZN6Halide7Runtime8Internal23device_allocation_poolsE, align 8, !tbaa !14
  %cmp.not15 = icmp eq %struct.halide_device_allocation_pool* %p.014, null
  br i1 %cmp.not15, label %for.cond.cleanup, label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %if.then
  %err.0.lcssa = phi i32 [ 0, %if.then ], [ %spec.select, %for.body ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal21allocation_pools_lockE) #14
  br label %if.end5

for.body:                                         ; preds = %if.then, %for.body
  %p.017 = phi %struct.halide_device_allocation_pool* [ %p.0, %for.body ], [ %p.014, %if.then ]
  %err.016 = phi i32 [ %spec.select, %for.body ], [ 0, %if.then ]
  %release_unused = getelementptr inbounds %struct.halide_device_allocation_pool, %struct.halide_device_allocation_pool* %p.017, i64 0, i32 0
  %0 = load i32 (i8*)*, i32 (i8*)** %release_unused, align 8, !tbaa !309
  %call = tail call i32 %0(i8* %user_context) #14
  %tobool3.not = icmp eq i32 %call, 0
  %spec.select = select i1 %tobool3.not, i32 %err.016, i32 %call
  %next = getelementptr inbounds %struct.halide_device_allocation_pool, %struct.halide_device_allocation_pool* %p.017, i64 0, i32 1
  %p.0 = load %struct.halide_device_allocation_pool*, %struct.halide_device_allocation_pool** %next, align 8, !tbaa !14
  %cmp.not = icmp eq %struct.halide_device_allocation_pool* %p.0, null
  br i1 %cmp.not, label %for.cond.cleanup, label %for.body, !llvm.loop !311

if.end5:                                          ; preds = %for.cond.cleanup, %entry
  %err.2 = phi i32 [ 0, %entry ], [ %err.0.lcssa, %for.cond.cleanup ]
  ret i32 %err.2
}

; Function Attrs: nounwind willreturn mustprogress
define weak zeroext i1 @halide_can_reuse_device_allocations(i8* %user_context) local_unnamed_addr #2 {
entry:
  %0 = load i8, i8* @_ZN6Halide7Runtime8Internal36halide_reuse_device_allocations_flagE, align 1, !tbaa !19, !range !21
  %tobool = icmp ne i8 %0, 0
  ret i1 %tobool
}

; Function Attrs: nounwind
define weak void @halide_register_device_allocation_pool(%struct.halide_device_allocation_pool* %pool) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal21allocation_pools_lockE) #14
  %0 = load %struct.halide_device_allocation_pool*, %struct.halide_device_allocation_pool** @_ZN6Halide7Runtime8Internal23device_allocation_poolsE, align 8, !tbaa !14
  %next = getelementptr inbounds %struct.halide_device_allocation_pool, %struct.halide_device_allocation_pool* %pool, i64 0, i32 1
  store %struct.halide_device_allocation_pool* %0, %struct.halide_device_allocation_pool** %next, align 8, !tbaa !312
  store %struct.halide_device_allocation_pool* %pool, %struct.halide_device_allocation_pool** @_ZN6Halide7Runtime8Internal23device_allocation_poolsE, align 8, !tbaa !14
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal21allocation_pools_lockE) #14
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %flags.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %0 = load i64, i64* %flags.i.i, align 8, !tbaa !307
  %and.i.i = and i64 %0, 2
  %cmp.i.i.not = icmp eq i64 %and.i.i, 0
  br i1 %cmp.i.i.not, label %return, label %if.end

if.end:                                           ; preds = %entry
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %1 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %and.i.i46 = and i64 %0, 1
  %cmp.i.i47.not = icmp eq i64 %and.i.i46, 0
  br i1 %cmp.i.i47.not, label %if.end9, label %return

if.end9:                                          ; preds = %if.end
  %cmp = icmp eq %struct.halide_device_interface_t* %1, null
  br i1 %cmp, label %return, label %if.end15

if.end15:                                         ; preds = %if.end9
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %1, i64 0, i32 15
  %2 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %copy_to_host = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %2, i64 0, i32 6
  %3 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %copy_to_host, align 8, !tbaa !315
  %call16 = tail call i32 %3(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %cmp17.not = icmp eq i32 %call16, 0
  br i1 %cmp17.not, label %if.end23, label %return

if.end23:                                         ; preds = %if.end15
  %4 = load i64, i64* %flags.i.i, align 8, !tbaa !307
  %and.i.i44 = and i64 %4, -3
  store i64 %and.i.i44, i64* %flags.i.i, align 8, !tbaa !307
  %call24 = tail call i32 @halide_msan_annotate_buffer_is_initialized(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  br label %return

return:                                           ; preds = %if.end23, %if.end15, %if.end9, %if.end, %entry
  %retval.2 = phi i32 [ 0, %entry ], [ 0, %if.end23 ], [ -14, %if.end ], [ -19, %if.end9 ], [ -14, %if.end15 ]
  ret i32 %retval.2
}

; Function Attrs: nounwind mustprogress
define weak void @halide_device_release(i8* %user_context, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface, i64 0, i32 15
  %0 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %device_release = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %0, i64 0, i32 5
  %1 = load i32 (i8*)*, i32 (i8*)** %device_release, align 8, !tbaa !317
  %call = tail call i32 %1(i8* %user_context) #14
  ret void
}

; Function Attrs: nounwind
define weak i32 @halide_copy_to_host(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.6.88, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end16.i.split

if.end16.i.split:                                 ; preds = %if.end16.i
  %call11 = tail call i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #16
  br label %cleanup

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split, label %cleanup

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %call12 = tail call i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* %buf) #16
  br label %cleanup

cleanup:                                          ; preds = %if.end16.i.split, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ %call11, %if.end16.i.split ], [ %call12, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define linkonce i32 @copy_to_device_already_locked(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.7.89, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit, %if.end16.i
  %cmp1 = icmp eq %struct.halide_device_interface_t* %device_interface, null
  br i1 %cmp1, label %if.then2, label %if.end11

if.then2:                                         ; preds = %if.end
  %device_interface5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %4 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface5, align 8, !tbaa !306
  %cmp6 = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp6, label %if.then7, label %if.end11

if.then7:                                         ; preds = %if.then2
  %call8 = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %cleanup

if.end11:                                         ; preds = %if.then2, %if.end
  %device_interface.addr.0 = phi %struct.halide_device_interface_t* [ %device_interface, %if.end ], [ %4, %if.then2 ]
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %5 = load i64, i64* %device, align 8, !tbaa !182
  %tobool.not = icmp eq i64 %5, 0
  br i1 %tobool.not, label %if.then18, label %land.lhs.true

land.lhs.true:                                    ; preds = %if.end11
  %device_interface12 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %6 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface12, align 8, !tbaa !306
  %cmp13.not = icmp eq %struct.halide_device_interface_t* %6, %device_interface.addr.0
  br i1 %cmp13.not, label %if.end27, label %if.then14

if.then14:                                        ; preds = %land.lhs.true
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.9.90, i64 0, i64 0)) #14
  br label %cleanup

if.then18:                                        ; preds = %if.end11
  %call19 = tail call i32 @halide_device_malloc(i8* %user_context, %struct.halide_buffer_t* nonnull %buf, %struct.halide_device_interface_t* nonnull %device_interface.addr.0) #16
  %cmp20.not = icmp eq i32 %call19, 0
  br i1 %cmp20.not, label %if.end27, label %cleanup

if.end27:                                         ; preds = %if.then18, %land.lhs.true
  %flags.i.i97 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %7 = load i64, i64* %flags.i.i97, align 8, !tbaa !307
  %and.i.i98 = and i64 %7, 1
  %cmp.i.i99.not = icmp eq i64 %and.i.i98, 0
  br i1 %cmp.i.i99.not, label %cleanup, label %if.then29

if.then29:                                        ; preds = %if.end27
  %and.i.i96 = and i64 %7, 2
  %cmp.i.i.not = icmp eq i64 %and.i.i96, 0
  br i1 %cmp.i.i.not, label %if.else, label %cleanup

if.else:                                          ; preds = %if.then29
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface.addr.0, i64 0, i32 15
  %8 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %copy_to_device = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %8, i64 0, i32 7
  %9 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %copy_to_device, align 8, !tbaa !318
  %call44 = tail call i32 %9(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %cmp45 = icmp eq i32 %call44, 0
  br i1 %cmp45, label %if.then46, label %cleanup

if.then46:                                        ; preds = %if.else
  %10 = load i64, i64* %flags.i.i97, align 8, !tbaa !307
  %and.i.i = and i64 %10, -2
  store i64 %and.i.i, i64* %flags.i.i97, align 8, !tbaa !307
  br label %cleanup

cleanup:                                          ; preds = %if.then46, %if.else, %if.then29, %if.end27, %if.then18, %if.then14, %if.then7, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ %call8, %if.then7 ], [ -42, %if.then14 ], [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.then46 ], [ %call19, %if.then18 ], [ -15, %if.then29 ], [ -15, %if.else ], [ 0, %if.end27 ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_malloc(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.17.91, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup12

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface3.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface3.phi.trans.insert, align 8, !tbaa !306
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp4.not = icmp eq %struct.halide_device_interface_t* %4, null
  %cmp5.not = icmp eq %struct.halide_device_interface_t* %4, %device_interface
  %or.cond = or i1 %cmp4.not, %cmp5.not
  br i1 %or.cond, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([59 x i8], [59 x i8]* @.str.20.92, i64 0, i64 0)) #14
  br label %cleanup12

if.end7:                                          ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %device_malloc = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i64 0, i32 2
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_malloc, align 8, !tbaa !320
  %call9 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i64 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %10() #14
  %tobool.not = icmp eq i32 %call9, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -16
  ret i32 %spec.select

cleanup12:                                        ; preds = %if.then6, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ -42, %if.then6 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind
define weak i32 @halide_copy_to_device(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %call = tail call i32 @copy_to_device_already_locked(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) #16
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_sync(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.16.93, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup8

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !306
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2 = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp2, label %if.then3, label %if.end5

if.then3:                                         ; preds = %if.end
  %call4 = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %cleanup8

if.end5:                                          ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %device_sync = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 4
  %6 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_sync, align 8, !tbaa !322
  %call6 = tail call i32 %6(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %tobool.not = icmp eq i32 %call6, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -17
  ret i32 %spec.select

cleanup8:                                         ; preds = %if.then3, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ %call4, %if.then3 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_free(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.21.96, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup12

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !306
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2.not = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp2.not, label %if.end11, label %if.then3

if.then3:                                         ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %device_free = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i64 0, i32 3
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_free, align 8, !tbaa !323
  %call5 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i64 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %10() #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %11 = load i64, i64* %device, align 8, !tbaa !182
  %cmp7 = icmp eq i64 %11, 0
  br i1 %cmp7, label %do.end, label %if.then8

if.then8:                                         ; preds = %if.then3
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([127 x i8], [127 x i8]* @.str.22.97, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then8, %if.then3
  %tobool.not = icmp eq i32 %call5, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -18
  ret i32 %spec.select

if.end11:                                         ; preds = %if.end
  %flags3.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %12 = load i64, i64* %flags3.i.i, align 8, !tbaa !307
  %and.i.i = and i64 %12, -3
  store i64 %and.i.i, i64* %flags3.i.i, align 8, !tbaa !307
  br label %cleanup12

cleanup12:                                        ; preds = %if.end11, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.end11 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak void @halide_device_free_as_destructor(i8* %user_context, i8* %obj) local_unnamed_addr #0 {
entry:
  %0 = bitcast i8* %obj to %struct.halide_buffer_t*
  %call = tail call i32 @halide_device_free(i8* %user_context, %struct.halide_buffer_t* %0) #16
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_and_host_malloc(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.23.98, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup14

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface3.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface3.phi.trans.insert, align 8, !tbaa !306
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp4.not = icmp eq %struct.halide_device_interface_t* %4, null
  %cmp5.not = icmp eq %struct.halide_device_interface_t* %4, %device_interface
  %or.cond = or i1 %cmp4.not, %cmp5.not
  br i1 %or.cond, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([68 x i8], [68 x i8]* @.str.25.99, i64 0, i64 0)) #14
  br label %cleanup14

if.end7:                                          ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %device_and_host_malloc = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i64 0, i32 8
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_and_host_malloc, align 8, !tbaa !324
  %call9 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i64 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %10() #14
  %cmp11.not = icmp eq i32 %call9, 0
  br i1 %cmp11.not, label %cleanup14, label %if.then12

if.then12:                                        ; preds = %if.end7
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.26.100, i64 0, i64 0)) #14
  br label %cleanup14

cleanup14:                                        ; preds = %if.then12, %if.end7, %if.then6, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ -42, %if.then6 ], [ -16, %if.then12 ], [ 0, %if.end7 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_and_host_free(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.27.101, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup18

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !306
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2.not = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp2.not, label %if.else11, label %if.then3

if.then3:                                         ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %device_and_host_free = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i64 0, i32 9
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_and_host_free, align 8, !tbaa !325
  %call5 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i64 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %10() #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %11 = load i64, i64* %device, align 8, !tbaa !182
  %cmp7 = icmp eq i64 %11, 0
  br i1 %cmp7, label %do.end, label %if.then8

if.then8:                                         ; preds = %if.then3
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([127 x i8], [127 x i8]* @.str.28.102, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then8, %if.then3
  %tobool.not = icmp eq i32 %call5, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -18
  ret i32 %spec.select

if.else11:                                        ; preds = %if.end
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 2
  %12 = load i8*, i8** %host, align 8, !tbaa !180
  %tobool12.not = icmp eq i8* %12, null
  br i1 %tobool12.not, label %if.end17, label %if.then13

if.then13:                                        ; preds = %if.else11
  tail call void @halide_free(i8* %user_context, i8* nonnull %12) #14
  store i8* null, i8** %host, align 8, !tbaa !180
  br label %if.end17

if.end17:                                         ; preds = %if.then13, %if.else11
  %flags3.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %13 = load i64, i64* %flags3.i.i, align 8, !tbaa !307
  %and.i.i = and i64 %13, -3
  store i64 %and.i.i, i64* %flags3.i.i, align 8, !tbaa !307
  br label %cleanup18

cleanup18:                                        ; preds = %if.end17, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.end17 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_and_host_malloc(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.29.103, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %if.end, label %cleanup13

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit, %if.end16.i
  %dimensions.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 5
  %4 = load i32, i32* %dimensions.i.i, align 4, !tbaa !183
  %cmp19.i.i = icmp sgt i32 %4, 0
  br i1 %cmp19.i.i, label %for.body.lr.ph.i.i, label %if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge

if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge: ; preds = %if.end
  %sub.i.0 = sub nsw i64 1, 0
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

for.body.lr.ph.i.i:                               ; preds = %if.end
  %dim.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 6
  %5 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i.i, align 8, !tbaa !184
  %wide.trip.count.i.i = zext i32 %4 to i64
  %min.iters.check = icmp ult i32 %4, 3
  br i1 %min.iters.check, label %for.body.i.i.preheader, label %vector.ph

vector.ph:                                        ; preds = %for.body.lr.ph.i.i
  %n.vec = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body

vector.body:                                      ; preds = %pred.load.continue6, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %pred.load.continue6 ]
  %vec.phi = phi i64 [ 0, %vector.ph ], [ %predphi, %pred.load.continue6 ]
  %vec.phi4 = phi i64 [ 0, %vector.ph ], [ %predphi7, %pred.load.continue6 ]
  %induction3 = or i64 %index, 1
  %6 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %index, i32 2
  %7 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %induction3, i32 2
  %8 = load i32, i32* %6, align 4, !tbaa !185
  %9 = load i32, i32* %7, align 4, !tbaa !185
  %10 = icmp sgt i32 %8, 0
  %11 = icmp sgt i32 %9, 0
  %12 = zext i32 %8 to i64
  %13 = zext i32 %9 to i64
  br i1 %10, label %pred.load.if, label %pred.load.continue

pred.load.if:                                     ; preds = %vector.body
  %14 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %index, i32 1
  %15 = load i32, i32* %14, align 4, !tbaa !189
  br label %pred.load.continue

pred.load.continue:                               ; preds = %pred.load.if, %vector.body
  %16 = phi i32 [ poison, %vector.body ], [ %15, %pred.load.if ]
  br i1 %11, label %pred.load.if5, label %pred.load.continue6

pred.load.if5:                                    ; preds = %pred.load.continue
  %17 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %induction3, i32 1
  %18 = load i32, i32* %17, align 4, !tbaa !189
  br label %pred.load.continue6

pred.load.continue6:                              ; preds = %pred.load.if5, %pred.load.continue
  %19 = phi i32 [ poison, %pred.load.continue ], [ %18, %pred.load.if5 ]
  %20 = add nsw i32 %16, -1
  %21 = add nsw i32 %19, -1
  %22 = sext i32 %20 to i64
  %23 = sext i32 %21 to i64
  %24 = mul nsw i64 %22, %12
  %25 = mul nsw i64 %23, %13
  %26 = select i1 %10, i64 %24, i64 0
  %predphi = add i64 %vec.phi, %26
  %27 = select i1 %11, i64 %25, i64 0
  %predphi7 = add i64 %vec.phi4, %27
  %index.next = add i64 %index, 2
  %28 = icmp eq i64 %index.next, %n.vec
  br i1 %28, label %middle.block, label %vector.body, !llvm.loop !326

middle.block:                                     ; preds = %pred.load.continue6
  %bin.rdx = add i64 %predphi7, %predphi
  %cmp.n = icmp eq i64 %n.vec, %wide.trip.count.i.i
  br i1 %cmp.n, label %for.body.i13.i.preheader, label %for.body.i.i.preheader

for.body.i.i.preheader:                           ; preds = %for.body.lr.ph.i.i, %middle.block
  %indvars.iv.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %n.vec, %middle.block ]
  %index.021.i.i.ph = phi i64 [ 0, %for.body.lr.ph.i.i ], [ %bin.rdx, %middle.block ]
  br label %for.body.i.i

for.body.i.i:                                     ; preds = %for.body.i.i.preheader, %if.end.i.i
  %indvars.iv.i.i = phi i64 [ %indvars.iv.next.i.i, %if.end.i.i ], [ %indvars.iv.i.i.ph, %for.body.i.i.preheader ]
  %index.021.i.i = phi i64 [ %index.1.i.i, %if.end.i.i ], [ %index.021.i.i.ph, %for.body.i.i.preheader ]
  %stride2.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %indvars.iv.i.i, i32 2
  %29 = load i32, i32* %stride2.i.i, align 4, !tbaa !185
  %cmp3.i.i = icmp sgt i32 %29, 0
  br i1 %cmp3.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %for.body.i.i
  %conv18.i.i = zext i32 %29 to i64
  %extent.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %indvars.iv.i.i, i32 1
  %30 = load i32, i32* %extent.i.i, align 4, !tbaa !189
  %sub.i.i = add nsw i32 %30, -1
  %conv7.i.i = sext i32 %sub.i.i to i64
  %mul.i.i = mul nsw i64 %conv7.i.i, %conv18.i.i
  %add.i.i = add nsw i64 %mul.i.i, %index.021.i.i
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %for.body.i.i
  %index.1.i.i = phi i64 [ %add.i.i, %if.then.i.i ], [ %index.021.i.i, %for.body.i.i ]
  %indvars.iv.next.i.i = add nuw nsw i64 %indvars.iv.i.i, 1
  %exitcond.not.i.i = icmp eq i64 %indvars.iv.next.i.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i.i, label %for.body.i13.i.preheader, label %for.body.i.i, !llvm.loop !327

for.body.i13.i.preheader:                         ; preds = %if.end.i.i, %middle.block
  %index.1.i.i.lcssa = phi i64 [ %bin.rdx, %middle.block ], [ %index.1.i.i, %if.end.i.i ]
  %min.iters.check11 = icmp ult i32 %4, 3
  br i1 %min.iters.check11, label %for.body.i13.i.preheader31, label %vector.ph12

vector.ph12:                                      ; preds = %for.body.i13.i.preheader
  %n.vec14 = and i64 %wide.trip.count.i.i, 4294967294
  br label %vector.body10

vector.body10:                                    ; preds = %pred.load.continue26, %vector.ph12
  %index15 = phi i64 [ 0, %vector.ph12 ], [ %index.next16, %pred.load.continue26 ]
  %vec.phi21 = phi i64 [ 0, %vector.ph12 ], [ %predphi27, %pred.load.continue26 ]
  %vec.phi22 = phi i64 [ 0, %vector.ph12 ], [ %predphi28, %pred.load.continue26 ]
  %induction20 = or i64 %index15, 1
  %31 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %index15, i32 2
  %32 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %induction20, i32 2
  %33 = load i32, i32* %31, align 4, !tbaa !185
  %34 = load i32, i32* %32, align 4, !tbaa !185
  %35 = icmp slt i32 %33, 0
  %36 = icmp slt i32 %34, 0
  %37 = sext i32 %33 to i64
  %38 = sext i32 %34 to i64
  br i1 %35, label %pred.load.if23, label %pred.load.continue24

pred.load.if23:                                   ; preds = %vector.body10
  %39 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %index15, i32 1
  %40 = load i32, i32* %39, align 4, !tbaa !189
  br label %pred.load.continue24

pred.load.continue24:                             ; preds = %pred.load.if23, %vector.body10
  %41 = phi i32 [ poison, %vector.body10 ], [ %40, %pred.load.if23 ]
  br i1 %36, label %pred.load.if25, label %pred.load.continue26

pred.load.if25:                                   ; preds = %pred.load.continue24
  %42 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %induction20, i32 1
  %43 = load i32, i32* %42, align 4, !tbaa !189
  br label %pred.load.continue26

pred.load.continue26:                             ; preds = %pred.load.if25, %pred.load.continue24
  %44 = phi i32 [ poison, %pred.load.continue24 ], [ %43, %pred.load.if25 ]
  %45 = add nsw i32 %41, -1
  %46 = add nsw i32 %44, -1
  %47 = sext i32 %45 to i64
  %48 = sext i32 %46 to i64
  %49 = mul nsw i64 %47, %37
  %50 = mul nsw i64 %48, %38
  %51 = select i1 %35, i64 %49, i64 0
  %predphi27 = add i64 %vec.phi21, %51
  %52 = select i1 %36, i64 %50, i64 0
  %predphi28 = add i64 %vec.phi22, %52
  %index.next16 = add i64 %index15, 2
  %53 = icmp eq i64 %index.next16, %n.vec14
  br i1 %53, label %middle.block8, label %vector.body10, !llvm.loop !328

middle.block8:                                    ; preds = %pred.load.continue26
  %bin.rdx29 = add i64 %predphi28, %predphi27
  %cmp.n18 = icmp eq i64 %n.vec14, %wide.trip.count.i.i
  br i1 %cmp.n18, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i.preheader31

for.body.i13.i.preheader31:                       ; preds = %for.body.i13.i.preheader, %middle.block8
  %indvars.iv.i10.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %n.vec14, %middle.block8 ]
  %index.018.i.i.ph = phi i64 [ 0, %for.body.i13.i.preheader ], [ %bin.rdx29, %middle.block8 ]
  br label %for.body.i13.i

for.body.i13.i:                                   ; preds = %for.body.i13.i.preheader31, %if.end.i24.i
  %indvars.iv.i10.i = phi i64 [ %indvars.iv.next.i22.i, %if.end.i24.i ], [ %indvars.iv.i10.i.ph, %for.body.i13.i.preheader31 ]
  %index.018.i.i = phi i64 [ %index.1.i21.i, %if.end.i24.i ], [ %index.018.i.i.ph, %for.body.i13.i.preheader31 ]
  %stride2.i11.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %indvars.iv.i10.i, i32 2
  %54 = load i32, i32* %stride2.i11.i, align 4, !tbaa !185
  %cmp3.i12.i = icmp slt i32 %54, 0
  br i1 %cmp3.i12.i, label %if.then.i20.i, label %if.end.i24.i

if.then.i20.i:                                    ; preds = %for.body.i13.i
  %conv.i14.i = sext i32 %54 to i64
  %extent.i15.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i64 %indvars.iv.i10.i, i32 1
  %55 = load i32, i32* %extent.i15.i, align 4, !tbaa !189
  %sub.i16.i = add nsw i32 %55, -1
  %conv7.i17.i = sext i32 %sub.i16.i to i64
  %mul.i18.i = mul nsw i64 %conv7.i17.i, %conv.i14.i
  %add.i19.i = add nsw i64 %mul.i18.i, %index.018.i.i
  br label %if.end.i24.i

if.end.i24.i:                                     ; preds = %if.then.i20.i, %for.body.i13.i
  %index.1.i21.i = phi i64 [ %add.i19.i, %if.then.i20.i ], [ %index.018.i.i, %for.body.i13.i ]
  %indvars.iv.next.i22.i = add nuw nsw i64 %indvars.iv.i10.i, 1
  %exitcond.not.i23.i = icmp eq i64 %indvars.iv.next.i22.i, %wide.trip.count.i.i
  br i1 %exitcond.not.i23.i, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i13.i, !llvm.loop !329

_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit: ; preds = %if.end.i24.i, %middle.block8
  %index.1.i21.i.lcssa = phi i64 [ %bin.rdx29, %middle.block8 ], [ %index.1.i21.i, %if.end.i24.i ]
  %add8.i.i = add nsw i64 %index.1.i.i.lcssa, 1
  %sub.i.1 = sub nsw i64 %add8.i.i, %index.1.i21.i.lcssa
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

_ZNK15halide_buffer_t13size_in_bytesEv.exit:      ; preds = %if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit
  %add8.i27.i = phi i64 [ 1, %if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %add8.i.i, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %sub.i.phi = phi i64 [ %sub.i.0, %if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %sub.i.1, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %bits.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 4, i32 1
  %56 = load i8, i8* %bits.i.i, align 1, !tbaa !144
  %conv.i.i = zext i8 %56 to i64
  %add.i4.i = add nuw nsw i64 %conv.i.i, 7
  %div.i.i = lshr i64 %add.i4.i, 3
  %mul.i = mul i64 %div.i.i, %sub.i.phi
  %call2 = tail call i8* @halide_malloc(i8* %user_context, i64 %mul.i) #14
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 2
  store i8* %call2, i8** %host, align 8, !tbaa !180
  %cmp4 = icmp eq i8* %call2, null
  br i1 %cmp4, label %cleanup13, label %if.end6

if.end6:                                          ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit
  %call7 = tail call i32 @halide_device_malloc(i8* %user_context, %struct.halide_buffer_t* nonnull %buf, %struct.halide_device_interface_t* %device_interface) #16
  %cmp8.not = icmp eq i32 %call7, 0
  br i1 %cmp8.not, label %cleanup13, label %if.then9

if.then9:                                         ; preds = %if.end6
  %57 = load i8*, i8** %host, align 8, !tbaa !180
  tail call void @halide_free(i8* %user_context, i8* %57) #14
  store i8* null, i8** %host, align 8, !tbaa !180
  br label %cleanup13

cleanup13:                                        ; preds = %if.then9, %if.end6, %_ZNK15halide_buffer_t13size_in_bytesEv.exit, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ -1, %_ZNK15halide_buffer_t13size_in_bytesEv.exit ], [ %call7, %if.then9 ], [ 0, %if.end6 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_and_host_free(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.30.104, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end16.i.split

if.end16.i.split:                                 ; preds = %if.end16.i
  %call11 = tail call i32 @halide_device_free(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #16
  br label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split, label %cleanup

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %call12 = tail call i32 @halide_device_free(i8* %user_context, %struct.halide_buffer_t* %buf) #16
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split, %if.end16.i.split
  %phi.call = phi i32 [ %call11, %if.end16.i.split ], [ %call12, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split ]
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 2
  %4 = load i8*, i8** %host, align 8, !tbaa !180
  %tobool.not = icmp eq i8* %4, null
  br i1 %tobool.not, label %if.end5, label %if.then2

if.then2:                                         ; preds = %if.end
  tail call void @halide_free(i8* %user_context, i8* nonnull %4) #14
  store i8* null, i8** %host, align 8, !tbaa !180
  br label %if.end5

if.end5:                                          ; preds = %if.then2, %if.end
  %flags3.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %5 = load i64, i64* %flags3.i.i, align 8, !tbaa !307
  %and.i.i18 = and i64 %5, -4
  store i64 %and.i.i18, i64* %flags3.i.i, align 8, !tbaa !307
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ %phi.call, %if.end5 ], [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_wrap_native(i8* %user_context, %struct.halide_buffer_t* %buf, i64 %handle, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.31.105, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup12

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !306
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2.not = icmp eq %struct.halide_device_interface_t* %4, null
  %cmp3.not = icmp eq %struct.halide_device_interface_t* %4, %device_interface
  %or.cond = or i1 %cmp2.not, %cmp3.not
  br i1 %or.cond, label %if.end5, label %if.then4

if.then4:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([64 x i8], [64 x i8]* @.str.32.106, i64 0, i64 0)) #14
  br label %cleanup12

if.end5:                                          ; preds = %if.end
  %device_interface1 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %6() #14
  store %struct.halide_device_interface_t* %device_interface, %struct.halide_device_interface_t** %device_interface1, align 8, !tbaa !306
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %wrap_native = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i64 0, i32 14
  %8 = load i32 (i8*, %struct.halide_buffer_t*, i64)*, i32 (i8*, %struct.halide_buffer_t*, i64)** %wrap_native, align 8, !tbaa !330
  %call8 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf, i64 %handle) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i64 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %10() #14
  %tobool.not = icmp eq i32 %call8, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -16
  ret i32 %spec.select

cleanup12:                                        ; preds = %if.then4, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ -42, %if.then4 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_detach_native(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.33.107, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !306
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2.not = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp2.not, label %cleanup, label %if.then3

if.then3:                                         ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %detach_native = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i64 0, i32 15
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %detach_native, align 8, !tbaa !331
  %call5 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i64 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %10() #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %11 = load i64, i64* %device, align 8, !tbaa !182
  %cmp7 = icmp eq i64 %11, 0
  br i1 %cmp7, label %do.end, label %if.then8

if.then8:                                         ; preds = %if.then3
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([127 x i8], [127 x i8]* @.str.34.108, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then8, %if.then3
  %tobool.not = icmp eq i32 %call5, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -33
  ret i32 %spec.select

cleanup:                                          ; preds = %if.end, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.end ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_wrap_native(i8* %user_context, %struct.halide_buffer_t* %buf, i64 %handle) local_unnamed_addr #0 {
entry:
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !182
  %cmp.not = icmp eq i64 %0, 0
  br i1 %cmp.not, label %if.end, label %return

if.end:                                           ; preds = %entry
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %1 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %1, i64 0, i32 15
  %2 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %2, i64 0, i32 0
  %3 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %3() #14
  store i64 %handle, i64* %device, align 8, !tbaa !182
  br label %return

return:                                           ; preds = %if.end, %entry
  %retval.0 = phi i32 [ 0, %if.end ], [ -32, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_detach_native(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.35, i64 0, i64 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !306
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !182
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !307
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %.pre = load i64, i64* %device.phi.trans.insert, align 8, !tbaa !182
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi i64 [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %1, %if.end16.i ]
  %cmp1 = icmp eq i64 %4, 0
  br i1 %cmp1, label %cleanup, label %if.end3

if.end3:                                          ; preds = %if.end
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %5 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %5, i64 0, i32 15
  %6 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %6, i64 0, i32 1
  %7 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %7() #14
  store i64 0, i64* %device, align 8, !tbaa !182
  store %struct.halide_device_interface_t* null, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  br label %cleanup

cleanup:                                          ; preds = %if.end3, %if.end, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ 0, %if.end3 ], [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.end ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak void @halide_device_and_host_free_as_destructor(i8* %user_context, i8* %obj) local_unnamed_addr #0 {
entry:
  %0 = bitcast i8* %obj to %struct.halide_buffer_t*
  %call = tail call i32 @halide_device_and_host_free(i8* %user_context, %struct.halide_buffer_t* %0) #16
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_device_host_nop_free(i8* %user_context, i8* %obj) local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_default_buffer_copy(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_device_interface_t* %dst_device_interface, %struct.halide_buffer_t* %dst) local_unnamed_addr #2 {
entry:
  ret i32 -39
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_buffer_copy_already_locked(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_device_interface_t* %dst_device_interface, %struct.halide_buffer_t* %dst) local_unnamed_addr #0 {
entry:
  %c = alloca %"struct.Halide::Runtime::Internal::device_copy", align 8
  %tobool.not = icmp eq %struct.halide_device_interface_t* %dst_device_interface, null
  br i1 %tobool.not, label %if.end13, label %land.lhs.true

land.lhs.true:                                    ; preds = %entry
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %tobool1.not = icmp eq %struct.halide_device_interface_t* %0, null
  %cmp.not = icmp eq %struct.halide_device_interface_t* %0, %dst_device_interface
  %or.cond = or i1 %tobool1.not, %cmp.not
  br i1 %or.cond, label %land.lhs.true5, label %if.then

if.then:                                          ; preds = %land.lhs.true
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([64 x i8], [64 x i8]* @.str.41, i64 0, i64 0)) #14
  br label %cleanup143

land.lhs.true5:                                   ; preds = %land.lhs.true
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 0
  %1 = load i64, i64* %device, align 8, !tbaa !182
  %tobool6.not = icmp eq i64 %1, 0
  br i1 %tobool6.not, label %if.then7, label %if.end13

if.then7:                                         ; preds = %land.lhs.true5
  %call = tail call i32 @halide_device_malloc(i8* %user_context, %struct.halide_buffer_t* nonnull %dst, %struct.halide_device_interface_t* nonnull %dst_device_interface) #16
  %tobool10.not = icmp eq i32 %call, 0
  br i1 %tobool10.not, label %if.end13, label %cleanup143

if.end13:                                         ; preds = %if.then7, %land.lhs.true5, %entry
  %device14 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 0
  %2 = load i64, i64* %device14, align 8, !tbaa !182
  %cmp15.not = icmp eq i64 %2, 0
  %host22.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 2
  %.pre = load i8*, i8** %host22.phi.trans.insert, align 8, !tbaa !180
  %cmp23.not = icmp eq i8* %.pre, null
  br i1 %cmp15.not, label %land.end, label %land.rhs

land.rhs:                                         ; preds = %if.end13
  br i1 %cmp23.not, label %land.end32, label %land.end.thread264

land.end.thread264:                               ; preds = %land.rhs
  %flags.i.i243 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 3
  %3 = load i64, i64* %flags.i.i243, align 8, !tbaa !307
  %and.i.i244 = and i64 %3, 1
  %cmp.i.i.not = icmp ne i64 %and.i.i244, 0
  br label %land.rhs26

land.end:                                         ; preds = %if.end13
  br i1 %cmp23.not, label %land.end32, label %land.end.land.rhs26_crit_edge

land.end.land.rhs26_crit_edge:                    ; preds = %land.end
  %flags.i.i247.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 3
  %.pre1 = load i64, i64* %flags.i.i247.phi.trans.insert, align 8, !tbaa !307
  br label %land.rhs26

land.rhs26:                                       ; preds = %land.end.land.rhs26_crit_edge, %land.end.thread264
  %4 = phi i64 [ %3, %land.end.thread264 ], [ %.pre1, %land.end.land.rhs26_crit_edge ]
  %5 = phi i1 [ %cmp.i.i.not, %land.end.thread264 ], [ true, %land.end.land.rhs26_crit_edge ]
  %and.i.i248 = and i64 %4, 2
  %cmp.i.i249.not = icmp eq i64 %and.i.i248, 0
  br i1 %cmp.i.i249.not, label %land.end32, label %lor.rhs28

lor.rhs28:                                        ; preds = %land.rhs26
  %device_interface29 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 1
  %6 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface29, align 8, !tbaa !306
  %cmp30 = icmp ne %struct.halide_device_interface_t* %6, null
  br label %land.end32

land.end32:                                       ; preds = %lor.rhs28, %land.rhs26, %land.end, %land.rhs
  %cmp23.not263 = phi i1 [ true, %land.end ], [ false, %land.rhs26 ], [ false, %lor.rhs28 ], [ true, %land.rhs ]
  %7 = phi i1 [ true, %land.end ], [ %5, %land.rhs26 ], [ %5, %lor.rhs28 ], [ false, %land.rhs ]
  %8 = phi i1 [ true, %land.end ], [ false, %land.rhs26 ], [ %cmp30, %lor.rhs28 ], [ true, %land.rhs ]
  %host34 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 2
  %9 = load i8*, i8** %host34, align 8, !tbaa !180
  %cmp35.not = icmp eq i8* %9, null
  %cmp20.not = xor i1 %tobool.not, true
  %10 = and i1 %tobool.not, %cmp35.not
  br i1 %10, label %cleanup143, label %if.end41

if.end41:                                         ; preds = %land.end32
  %brmerge229 = or i1 %tobool.not, %7
  br i1 %brmerge229, label %if.then51, label %if.end49

if.end49:                                         ; preds = %if.end41
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %dst_device_interface, i64 0, i32 15
  %11 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %buffer_copy = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %11, i64 0, i32 10
  %12 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)** %buffer_copy, align 8, !tbaa !332
  %call48 = tail call i32 %12(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* nonnull %dst_device_interface, %struct.halide_buffer_t* nonnull %dst) #14
  %cmp50 = icmp eq i32 %call48, -42
  br i1 %cmp50, label %if.then51, label %if.end117

if.then51:                                        ; preds = %if.end49, %if.end41
  %brmerge231.demorgan = and i1 %cmp23.not263, %cmp35.not
  br i1 %brmerge231.demorgan, label %cleanup143, label %if.end58

if.end58:                                         ; preds = %if.then51
  %brmerge234 = or i1 %8, %cmp20.not
  br i1 %brmerge234, label %if.else, label %if.end117.thread258

if.end117.thread258:                              ; preds = %if.end58
  %13 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %c to i8*
  call void @llvm.lifetime.start.p0i8(i64 416, i8* nonnull %13) #15
  call void @_ZN6Halide7Runtime8Internal16make_buffer_copyEPK15halide_buffer_tbS4_b(%"struct.Halide::Runtime::Internal::device_copy"* nonnull sret(%"struct.Halide::Runtime::Internal::device_copy") align 8 %c, %struct.halide_buffer_t* nonnull %src, i1 zeroext true, %struct.halide_buffer_t* nonnull %dst, i1 zeroext true) #16
  call void @_ZN6Halide7Runtime8Internal11copy_memoryERKNS1_11device_copyEPv(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %c, i8* %user_context) #16
  call void @llvm.lifetime.end.p0i8(i64 416, i8* nonnull %13) #15
  br label %land.lhs.true126

if.else:                                          ; preds = %if.end58
  %brmerge237 = or i1 %7, %cmp20.not
  br i1 %brmerge237, label %if.else81, label %if.then66

if.then66:                                        ; preds = %if.else
  %device_interface69 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 1
  %14 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface69, align 8, !tbaa !306
  %impl70 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %14, i64 0, i32 15
  %15 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl70, align 8, !tbaa !313
  %buffer_copy71 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %15, i64 0, i32 10
  %16 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)** %buffer_copy71, align 8, !tbaa !332
  %call72 = tail call i32 %16(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* null, %struct.halide_buffer_t* nonnull %dst) #14
  %cmp73 = icmp eq i32 %call72, -42
  br i1 %cmp73, label %if.then74, label %if.end117

if.then74:                                        ; preds = %if.then66
  %call75 = tail call i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* nonnull %src) #16
  %tobool76.not = icmp eq i32 %call75, 0
  br i1 %tobool76.not, label %if.then77, label %cleanup143

if.then77:                                        ; preds = %if.then74
  %call78 = tail call i32 @halide_buffer_copy_already_locked(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* null, %struct.halide_buffer_t* nonnull %dst) #16
  br label %if.end117

if.else81:                                        ; preds = %if.else
  %brmerge239 = or i1 %7, %cmp35.not
  br i1 %brmerge239, label %if.else98, label %if.then85

if.then85:                                        ; preds = %if.else81
  %device_interface90 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 1
  %17 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface90, align 8, !tbaa !306
  %impl91 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %17, i64 0, i32 15
  %18 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl91, align 8, !tbaa !313
  %buffer_copy92 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %18, i64 0, i32 10
  %19 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)** %buffer_copy92, align 8, !tbaa !332
  %call93 = tail call i32 %19(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* null, %struct.halide_buffer_t* nonnull %dst) #14
  %cmp94 = icmp eq i32 %call93, 0
  br i1 %cmp94, label %if.then95, label %cleanup143

if.then95:                                        ; preds = %if.then85
  %flags.i.i245 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 3
  %20 = load i64, i64* %flags.i.i245, align 8, !tbaa !307
  %or.i.i246 = or i64 %20, 1
  store i64 %or.i.i246, i64* %flags.i.i245, align 8, !tbaa !307
  %call96 = tail call i32 @copy_to_device_already_locked(i8* %user_context, %struct.halide_buffer_t* nonnull %dst, %struct.halide_device_interface_t* %dst_device_interface) #16
  br label %if.end117

if.else98:                                        ; preds = %if.else81
  br i1 %tobool.not, label %cleanup143, label %if.then100

if.then100:                                       ; preds = %if.else98
  %call103 = tail call i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* nonnull %src) #16
  %cmp104 = icmp eq i32 %call103, 0
  br i1 %cmp104, label %if.then105, label %cleanup143

if.then105:                                       ; preds = %if.then100
  %impl106 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %dst_device_interface, i64 0, i32 15
  %21 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl106, align 8, !tbaa !313
  %buffer_copy107 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %21, i64 0, i32 10
  %22 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)** %buffer_copy107, align 8, !tbaa !332
  %call108 = tail call i32 %22(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* nonnull %dst_device_interface, %struct.halide_buffer_t* nonnull %dst) #14
  br label %if.end117

if.end117:                                        ; preds = %if.then105, %if.then95, %if.then77, %if.then66, %if.end49
  %err.1 = phi i32 [ %call78, %if.then77 ], [ %call72, %if.then66 ], [ %call96, %if.then95 ], [ %call108, %if.then105 ], [ %call48, %if.end49 ]
  %cond = icmp eq i32 %err.1, 0
  br i1 %cond, label %land.lhs.true126, label %cleanup143

land.lhs.true126:                                 ; preds = %if.end117, %if.end117.thread258
  %cmp127.not.old = icmp eq %struct.halide_buffer_t* %dst, %src
  br i1 %cmp127.not.old, label %cleanup143, label %if.then128

if.then128:                                       ; preds = %land.lhs.true126
  %flags.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 3
  %23 = load i64, i64* %flags.i.i, align 8, !tbaa !307
  %or.i.i = and i64 %23, -4
  br i1 %tobool.not, label %if.else133, label %if.then130

if.then130:                                       ; preds = %if.then128
  %or.i.i242 = or i64 %or.i.i, 2
  store i64 %or.i.i242, i64* %flags.i.i, align 8, !tbaa !307
  br label %cleanup143

if.else133:                                       ; preds = %if.then128
  %and.i.i251 = or i64 %or.i.i, 1
  store i64 %and.i.i251, i64* %flags.i.i, align 8, !tbaa !307
  br label %cleanup143

cleanup143:                                       ; preds = %if.else133, %if.then130, %land.lhs.true126, %if.end117, %if.then100, %if.else98, %if.then85, %if.then74, %if.then51, %land.end32, %if.then7, %if.then
  %retval.1 = phi i32 [ -42, %if.then ], [ %call, %if.then7 ], [ -34, %land.end32 ], [ 0, %if.then130 ], [ 0, %if.else133 ], [ 0, %land.lhs.true126 ], [ -42, %if.then51 ], [ %err.1, %if.end117 ], [ -42, %if.else98 ], [ %call103, %if.then100 ], [ %call93, %if.then85 ], [ %call75, %if.then74 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind
define weak i32 @halide_buffer_copy(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_device_interface_t* %dst_device_interface, %struct.halide_buffer_t* %dst) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %tobool.not = icmp eq %struct.halide_device_interface_t* %dst_device_interface, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %dst_device_interface, i64 0, i32 15
  %0 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %0, i64 0, i32 0
  %1 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %1() #14
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 1
  %2 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %tobool11.not = icmp eq %struct.halide_device_interface_t* %2, null
  br i1 %tobool11.not, label %if.end16, label %if.then12

if.then12:                                        ; preds = %if.end
  %impl14 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %2, i64 0, i32 15
  %3 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl14, align 8, !tbaa !313
  %use_module15 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %3, i64 0, i32 0
  %4 = load void ()*, void ()** %use_module15, align 8, !tbaa !319
  tail call void %4() #14
  br label %if.end16

if.end16:                                         ; preds = %if.then12, %if.end
  %call = tail call i32 @halide_buffer_copy_already_locked(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* %dst_device_interface, %struct.halide_buffer_t* %dst) #16
  br i1 %tobool.not, label %if.end20, label %if.then18

if.then18:                                        ; preds = %if.end16
  %impl19 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %dst_device_interface, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl19, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 1
  %6 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %6() #14
  br label %if.end20

if.end20:                                         ; preds = %if.then18, %if.end16
  %7 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %tobool22.not = icmp eq %struct.halide_device_interface_t* %7, null
  br i1 %tobool22.not, label %if.end27, label %if.then23

if.then23:                                        ; preds = %if.end20
  %impl25 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %7, i64 0, i32 15
  %8 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl25, align 8, !tbaa !313
  %release_module26 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %8, i64 0, i32 1
  %9 = load void ()*, void ()** %release_module26, align 8, !tbaa !321
  tail call void %9() #14
  br label %if.end27

if.end27:                                         ; preds = %if.then23, %if.end20
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_crop(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_buffer_t* %dst) local_unnamed_addr #0 {
entry:
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([44 x i8], [44 x i8]* @.str.58, i64 0, i64 0)) #14
  ret i32 -40
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_slice(i8* %user_context, %struct.halide_buffer_t* %src, i32 %slice_dim, i32 %slice_pos, %struct.halide_buffer_t* %dst) local_unnamed_addr #0 {
entry:
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.59, i64 0, i64 0)) #14
  ret i32 -40
}

; Function Attrs: nounwind
define weak i32 @halide_device_crop(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_buffer_t* %dst) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !182
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %device1 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 0
  %1 = load i64, i64* %device1, align 8, !tbaa !182
  %tobool2.not = icmp eq i64 %1, 0
  br i1 %tobool2.not, label %if.end4, label %if.then3

if.then3:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([52 x i8], [52 x i8]* @.str.60, i64 0, i64 0)) #14
  br label %cleanup

if.end4:                                          ; preds = %if.end
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 5
  %2 = load i32, i32* %dimensions, align 4, !tbaa !183
  %dimensions5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 5
  %3 = load i32, i32* %dimensions5, align 4, !tbaa !183
  %cmp.not = icmp eq i32 %2, %3
  br i1 %cmp.not, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end4
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([48 x i8], [48 x i8]* @.str.61, i64 0, i64 0)) #14
  br label %cleanup

if.end7:                                          ; preds = %if.end4
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 1
  %4 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %impl9 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %7, i64 0, i32 15
  %8 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl9, align 8, !tbaa !313
  %device_crop = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %8, i64 0, i32 11
  %9 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)** %device_crop, align 8, !tbaa !333
  %call = tail call i32 %9(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_buffer_t* nonnull %dst) #14
  br label %cleanup

cleanup:                                          ; preds = %if.end7, %if.then6, %if.then3, %entry
  %retval.0 = phi i32 [ -41, %if.then3 ], [ -41, %if.then6 ], [ %call, %if.end7 ], [ 0, %entry ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %retval.0
}

; Function Attrs: nounwind
define weak i32 @halide_device_slice(i8* %user_context, %struct.halide_buffer_t* %src, i32 %slice_dim, i32 %slice_pos, %struct.halide_buffer_t* %dst) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !182
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %device1 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 0
  %1 = load i64, i64* %device1, align 8, !tbaa !182
  %tobool2.not = icmp eq i64 %1, 0
  br i1 %tobool2.not, label %if.end4, label %if.then3

if.then3:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([52 x i8], [52 x i8]* @.str.60, i64 0, i64 0)) #14
  br label %cleanup

if.end4:                                          ; preds = %if.end
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 5
  %2 = load i32, i32* %dimensions, align 4, !tbaa !183
  %dimensions5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i64 0, i32 5
  %3 = load i32, i32* %dimensions5, align 4, !tbaa !183
  %add = add nsw i32 %3, 1
  %cmp.not = icmp eq i32 %2, %add
  br i1 %cmp.not, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end4
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([52 x i8], [52 x i8]* @.str.64, i64 0, i64 0)) #14
  br label %cleanup

if.end7:                                          ; preds = %if.end4
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i64 0, i32 1
  %4 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i64 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i64 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 8, !tbaa !319
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %impl9 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %7, i64 0, i32 15
  %8 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl9, align 8, !tbaa !313
  %device_slice = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %8, i64 0, i32 12
  %9 = load i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)** %device_slice, align 8, !tbaa !334
  %call = tail call i32 %9(i8* %user_context, %struct.halide_buffer_t* nonnull %src, i32 %slice_dim, i32 %slice_pos, %struct.halide_buffer_t* nonnull %dst) #14
  br label %cleanup

cleanup:                                          ; preds = %if.end7, %if.then6, %if.then3, %entry
  %retval.0 = phi i32 [ -41, %if.then3 ], [ -41, %if.then6 ], [ %call, %if.end7 ], [ 0, %entry ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_release_crop(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !182
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %return, label %if.end

if.end:                                           ; preds = %entry
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([44 x i8], [44 x i8]* @.str.58, i64 0, i64 0)) #14
  br label %return

return:                                           ; preds = %if.end, %entry
  %retval.0 = phi i32 [ -40, %if.end ], [ 0, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind
define weak i32 @halide_device_release_crop(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #4 {
entry:
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !182
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %return, label %if.then

if.then:                                          ; preds = %entry
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i64 0, i32 1
  %1 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %1, i64 0, i32 15
  %2 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %device_release_crop = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %2, i64 0, i32 13
  %3 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_release_crop, align 8, !tbaa !335
  %call = tail call i32 %3(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  store i64 0, i64* %device, align 8, !tbaa !182
  %4 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 8, !tbaa !313
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %4, i64 0, i32 1
  %5 = load void ()*, void ()** %release_module, align 8, !tbaa !321
  tail call void %5() #14
  store %struct.halide_device_interface_t* null, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !306
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  br label %return

return:                                           ; preds = %if.then, %entry
  %retval.0 = phi i32 [ %call, %if.then ], [ 0, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind willreturn mustprogress
define weak float @halide_float16_bits_to_float(i16 zeroext %bits) local_unnamed_addr #2 {
entry:
  %conv = zext i16 %bits to i32
  %and2 = and i32 %conv, 1023
  %and4 = lshr i32 %conv, 10
  %0 = and i32 %and4, 31
  %cmp = icmp eq i32 %0, 0
  %cmp5 = icmp ne i32 %and2, 0
  %or.cond = and i1 %cmp5, %cmp
  br i1 %or.cond, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %1 = tail call i32 @llvm.ctlz.i32(i32 %and2, i1 true), !range !336
  %sub6 = xor i32 %1, 31
  %shl7 = shl nuw i32 1, %sub6
  %neg = xor i32 %shl7, -1
  %and8 = and i32 %and2, %neg
  %sub9 = sub nsw i32 23, %sub6
  %shl10 = shl i32 %and8, %sub9
  %add11.neg = mul nsw i32 %1, -8388608
  %shl12 = add i32 %add11.neg, 1124073472
  br label %if.end28

if.else:                                          ; preds = %entry
  %shl14 = shl nuw nsw i32 %and2, 13
  br i1 %cmp, label %if.end28, label %if.else18

if.else18:                                        ; preds = %if.else
  %cmp19 = icmp eq i32 %0, 31
  br i1 %cmp19, label %if.end28, label %if.else21

if.else21:                                        ; preds = %if.else18
  %add22 = shl nuw nsw i32 %0, 23
  %phi.bo = add nuw nsw i32 %add22, 939524096
  br label %if.end28

if.end28:                                         ; preds = %if.else21, %if.else18, %if.else, %if.then
  %shl14.sink = phi i32 [ %shl12, %if.then ], [ %shl14, %if.else18 ], [ %shl14, %if.else ], [ %shl14, %if.else21 ]
  %reEncodedExponent15.0.sink = phi i32 [ %shl10, %if.then ], [ 2139095040, %if.else18 ], [ 0, %if.else ], [ %phi.bo, %if.else21 ]
  %bits.signext = sext i16 %bits to i32
  %shl = and i32 %bits.signext, -2147483648
  %or25 = or i32 %shl14.sink, %shl
  %or26 = or i32 %or25, %reEncodedExponent15.0.sink
  %result.sroa.0.0 = bitcast i32 %or26 to float
  ret float %result.sroa.0.0
}

; Function Attrs: nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.ctlz.i32(i32, i1 immarg) #7

; Function Attrs: nounwind willreturn mustprogress
define weak double @halide_float16_bits_to_double(i16 zeroext %bits) local_unnamed_addr #2 {
entry:
  %call = tail call float @halide_float16_bits_to_float(i16 zeroext %bits) #16
  %conv = fpext float %call to double
  ret double %conv
}

; Function Attrs: nounwind
define weak i32 @halide_error_bounds_inference_call_failed(i8* %user_context, i8* %extern_stage_name, i32 %result) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i71 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.111, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i72 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.111, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i71, %entry.split ], [ %call.i72, %if.then6.i ]
  %ref.tmp.sroa.16.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i10 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.16.0, i8* %extern_stage_name) #14
  %call.i13 = tail call i8* @halide_string_to_string(i8* %call.i10, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.1.112, i64 0, i64 0)) #14
  %conv.i = sext i32 %result to i64
  %call.i16 = tail call i8* @halide_int64_to_string(i8* %call.i13, i8* %ref.tmp.sroa.16.0, i64 %conv.i, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i16 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 %result
}

; Function Attrs: nounwind
define weak i32 @halide_error_extern_stage_failed(i8* %user_context, i8* %extern_stage_name, i32 %result) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i71 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.2.113, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i72 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.2.113, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i71, %entry.split ], [ %call.i72, %if.then6.i ]
  %ref.tmp.sroa.16.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i10 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.16.0, i8* %extern_stage_name) #14
  %call.i13 = tail call i8* @halide_string_to_string(i8* %call.i10, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.1.112, i64 0, i64 0)) #14
  %conv.i = sext i32 %result to i64
  %call.i16 = tail call i8* @halide_int64_to_string(i8* %call.i13, i8* %ref.tmp.sroa.16.0, i64 %conv.i, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i16 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 %result
}

; Function Attrs: nounwind
define weak i32 @halide_error_explicit_bounds_too_small(i8* %user_context, i8* %func_name, i8* %var_name, i32 %min_bound, i32 %max_bound, i32 %min_required, i32 %max_required) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i151 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.3.114, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i152 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.3.114, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i151, %entry.split ], [ %call.i152, %if.then6.i ]
  %ref.tmp.sroa.34.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i18 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.34.0, i8* %var_name) #14
  %call.i21 = tail call i8* @halide_string_to_string(i8* %call.i18, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.4.115, i64 0, i64 0)) #14
  %call.i24 = tail call i8* @halide_string_to_string(i8* %call.i21, i8* %ref.tmp.sroa.34.0, i8* %func_name) #14
  %call.i27 = tail call i8* @halide_string_to_string(i8* %call.i24, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.5.116, i64 0, i64 0)) #14
  %conv.i = sext i32 %min_bound to i64
  %call.i30 = tail call i8* @halide_int64_to_string(i8* %call.i27, i8* %ref.tmp.sroa.34.0, i64 %conv.i, i32 1) #14
  %call.i33 = tail call i8* @halide_string_to_string(i8* %call.i30, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6.117, i64 0, i64 0)) #14
  %conv.i36 = sext i32 %max_bound to i64
  %call.i37 = tail call i8* @halide_int64_to_string(i8* %call.i33, i8* %ref.tmp.sroa.34.0, i64 %conv.i36, i32 1) #14
  %call.i40 = tail call i8* @halide_string_to_string(i8* %call.i37, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.7.118, i64 0, i64 0)) #14
  %conv.i43 = sext i32 %min_required to i64
  %call.i44 = tail call i8* @halide_int64_to_string(i8* %call.i40, i8* %ref.tmp.sroa.34.0, i64 %conv.i43, i32 1) #14
  %call.i47 = tail call i8* @halide_string_to_string(i8* %call.i44, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6.117, i64 0, i64 0)) #14
  %conv.i50 = sext i32 %max_required to i64
  %call.i51 = tail call i8* @halide_int64_to_string(i8* %call.i47, i8* %ref.tmp.sroa.34.0, i64 %conv.i50, i32 1) #14
  %call.i54 = tail call i8* @halide_string_to_string(i8* %call.i51, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.119, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i54 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -2
}

; Function Attrs: nounwind
define weak i32 @halide_error_bad_type(i8* %user_context, i8* %func_name, i32 %type_given_bits, i32 %correct_type_bits) local_unnamed_addr #4 {
entry:
  %type_given_bits.addr = alloca i32, align 4
  %correct_type_bits.addr = alloca i32, align 4
  %correct_type = alloca %struct.halide_type_t, align 2
  %type_given = alloca %struct.halide_type_t, align 2
  store i32 %type_given_bits, i32* %type_given_bits.addr, align 4, !tbaa !41
  store i32 %correct_type_bits, i32* %correct_type_bits.addr, align 4, !tbaa !41
  %0 = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %correct_type, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %0) #15
  store i8 0, i8* %0, align 2, !tbaa !304
  %bits.i = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %correct_type, i64 0, i32 1
  store i8 0, i8* %bits.i, align 1, !tbaa !144
  %lanes.i = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %correct_type, i64 0, i32 2
  store i16 0, i16* %lanes.i, align 2, !tbaa !305
  %1 = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %type_given, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %1) #15
  store i8 0, i8* %1, align 2, !tbaa !304
  %bits.i8 = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %type_given, i64 0, i32 1
  store i8 0, i8* %bits.i8, align 1, !tbaa !144
  %lanes.i9 = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %type_given, i64 0, i32 2
  store i16 0, i16* %lanes.i9, align 2, !tbaa !305
  %2 = bitcast i32* %correct_type_bits.addr to i8*
  %call = call i8* @memcpy(i8* nonnull %0, i8* nonnull %2, i64 4) #14
  %3 = bitcast i32* %type_given_bits.addr to i8*
  %call1 = call i8* @memcpy(i8* nonnull %1, i8* nonnull %3, i64 4) #14
  %call.i = call i8* @malloc(i64 1024) #14
  %tobool.not.i12 = icmp eq i8* %call.i, null
  br i1 %tobool.not.i12, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i151 = call i8* @halide_string_to_string(i8* null, i8* null, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i152 = call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i151, %entry.split ], [ %call.i152, %if.then6.i ]
  %ref.tmp.sroa.18.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i18 = call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.18.0, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.9.120, i64 0, i64 0)) #14
  %call.i21 = call i8* @halide_type_to_string(i8* %call.i18, i8* %ref.tmp.sroa.18.0, %struct.halide_type_t* nonnull %correct_type) #14
  %call.i24 = call i8* @halide_string_to_string(i8* %call.i21, i8* %ref.tmp.sroa.18.0, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.10.121, i64 0, i64 0)) #14
  %call.i27 = call i8* @halide_type_to_string(i8* %call.i24, i8* %ref.tmp.sroa.18.0, %struct.halide_type_t* nonnull %type_given) #14
  br i1 %tobool.not.i12, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i27 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  call void @free(i8* %call.i) #14
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %1) #15
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %0) #15
  ret i32 -3
}

; Function Attrs: nounwind
define weak i32 @halide_error_bad_dimensions(i8* %user_context, i8* %func_name, i32 %dimensions_given, i32 %correct_dimensions) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.11.122, i64 0, i64 0)) #14
  %conv.i = sext i32 %correct_dimensions to i64
  %call.i14 = tail call i8* @halide_int64_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i64 %conv.i, i32 1) #14
  %call.i17 = tail call i8* @halide_string_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.12.123, i64 0, i64 0)) #14
  %conv.i20 = sext i32 %dimensions_given to i64
  %call.i21 = tail call i8* @halide_int64_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i64 %conv.i20, i32 1) #14
  %call.i24 = tail call i8* @halide_string_to_string(i8* %call.i21, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.13.124, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i24 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -43
}

; Function Attrs: nounwind
define weak i32 @halide_error_access_out_of_bounds(i8* %user_context, i8* %func_name, i32 %dimension, i32 %min_touched, i32 %max_touched, i32 %min_valid, i32 %max_valid) local_unnamed_addr #4 {
entry:
  %cmp = icmp slt i32 %min_touched, %min_valid
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.split, label %if.then6.i

if.then.split:                                    ; preds = %if.then
  %call.i271 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %if.then
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i272 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %if.then.split, %if.then6.i
  %phi.call = phi i8* [ %call.i271, %if.then.split ], [ %call.i272, %if.then6.i ]
  %ref.tmp.sroa.22.0 = phi i8* [ null, %if.then.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i30 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.14.125, i64 0, i64 0)) #14
  %conv.i = sext i32 %min_touched to i64
  %call.i33 = tail call i8* @halide_int64_to_string(i8* %call.i30, i8* %ref.tmp.sroa.22.0, i64 %conv.i, i32 1) #14
  %call.i36 = tail call i8* @halide_string_to_string(i8* %call.i33, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.15.126, i64 0, i64 0)) #14
  %conv.i39 = sext i32 %min_valid to i64
  %call.i40 = tail call i8* @halide_int64_to_string(i8* %call.i36, i8* %ref.tmp.sroa.22.0, i64 %conv.i39, i32 1) #14
  %call.i43 = tail call i8* @halide_string_to_string(i8* %call.i40, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.16.127, i64 0, i64 0)) #14
  %conv.i46 = sext i32 %dimension to i64
  %call.i47 = tail call i8* @halide_int64_to_string(i8* %call.i43, i8* %ref.tmp.sroa.22.0, i64 %conv.i46, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %if.end17.sink.split

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i47 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %if.end17.sink.split

if.else:                                          ; preds = %entry
  %cmp7 = icmp sgt i32 %max_touched, %max_valid
  br i1 %cmp7, label %if.then8, label %if.end17

if.then8:                                         ; preds = %if.else
  %call.i53 = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i56 = icmp eq i8* %call.i53, null
  br i1 %tobool.not.i56, label %if.then8.split, label %if.then6.i59

if.then8.split:                                   ; preds = %if.then8
  %call.i653 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62

if.then6.i59:                                     ; preds = %if.then8
  %add.ptr.i57 = getelementptr inbounds i8, i8* %call.i53, i64 1023
  store i8 0, i8* %add.ptr.i57, align 1, !tbaa !18
  %call.i654 = tail call i8* @halide_string_to_string(i8* nonnull %call.i53, i8* nonnull %add.ptr.i57, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62: ; preds = %if.then8.split, %if.then6.i59
  %phi.call5 = phi i8* [ %call.i653, %if.then8.split ], [ %call.i654, %if.then6.i59 ]
  %ref.tmp9.sroa.22.0 = phi i8* [ null, %if.then8.split ], [ %add.ptr.i57, %if.then6.i59 ]
  %call.i68 = tail call i8* @halide_string_to_string(i8* %phi.call5, i8* %ref.tmp9.sroa.22.0, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.14.125, i64 0, i64 0)) #14
  %conv.i71 = sext i32 %max_touched to i64
  %call.i72 = tail call i8* @halide_int64_to_string(i8* %call.i68, i8* %ref.tmp9.sroa.22.0, i64 %conv.i71, i32 1) #14
  %call.i75 = tail call i8* @halide_string_to_string(i8* %call.i72, i8* %ref.tmp9.sroa.22.0, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.17.128, i64 0, i64 0)) #14
  %conv.i78 = sext i32 %max_valid to i64
  %call.i79 = tail call i8* @halide_int64_to_string(i8* %call.i75, i8* %ref.tmp9.sroa.22.0, i64 %conv.i78, i32 1) #14
  %call.i82 = tail call i8* @halide_string_to_string(i8* %call.i79, i8* %ref.tmp9.sroa.22.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.16.127, i64 0, i64 0)) #14
  %conv.i85 = sext i32 %dimension to i64
  %call.i86 = tail call i8* @halide_int64_to_string(i8* %call.i82, i8* %ref.tmp9.sroa.22.0, i64 %conv.i85, i32 1) #14
  br i1 %tobool.not.i56, label %if.then.i90, label %if.else.i100

if.then.i90:                                      ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %if.end17.sink.split

if.else.i100:                                     ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62
  %sub.ptr.lhs.cast.i.i95 = ptrtoint i8* %call.i86 to i64
  %sub.ptr.rhs.cast.i.i96 = ptrtoint i8* %call.i53 to i64
  %sub.ptr.sub.i.i97 = sub i64 1, %sub.ptr.rhs.cast.i.i96
  %add.i.i98 = add i64 %sub.ptr.sub.i.i97, %sub.ptr.lhs.cast.i.i95
  %call.i.i99 = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i53, i64 %add.i.i98) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i53) #14
  br label %if.end17.sink.split

if.end17.sink.split:                              ; preds = %if.else.i100, %if.then.i90, %if.else.i, %if.then.i
  %call.i53.sink = phi i8* [ %call.i, %if.else.i ], [ null, %if.then.i ], [ %call.i53, %if.else.i100 ], [ null, %if.then.i90 ]
  tail call void @free(i8* %call.i53.sink) #14
  br label %if.end17

if.end17:                                         ; preds = %if.end17.sink.split, %if.else
  ret i32 -4
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_allocation_too_large(i8* %user_context, i8* %buffer_name, i64 %allocation_size, i64 %max_size) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.18.129, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.18.129, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %buffer_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.130, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_uint64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %allocation_size, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.20.131, i64 0, i64 0)) #14
  %call.i23 = tail call i8* @halide_uint64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %max_size, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -5
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_extents_negative(i8* %user_context, i8* %buffer_name, i32 %dimension, i32 %extent) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i91 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.21.132, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i92 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.21.132, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i91, %entry.split ], [ %call.i92, %if.then6.i ]
  %ref.tmp.sroa.22.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i12 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.22.0, i8* %buffer_name) #14
  %call.i15 = tail call i8* @halide_string_to_string(i8* %call.i12, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.22.133, i64 0, i64 0)) #14
  %conv.i = sext i32 %dimension to i64
  %call.i18 = tail call i8* @halide_int64_to_string(i8* %call.i15, i8* %ref.tmp.sroa.22.0, i64 %conv.i, i32 1) #14
  %call.i21 = tail call i8* @halide_string_to_string(i8* %call.i18, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.23.134, i64 0, i64 0)) #14
  %conv.i24 = sext i32 %extent to i64
  %call.i25 = tail call i8* @halide_int64_to_string(i8* %call.i21, i8* %ref.tmp.sroa.22.0, i64 %conv.i24, i32 1) #14
  %call.i28 = tail call i8* @halide_string_to_string(i8* %call.i25, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.119, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i28 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -28
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_extents_too_large(i8* %user_context, i8* %buffer_name, i64 %actual_size, i64 %max_size) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.24.135, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.24.135, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %buffer_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.130, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_int64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %actual_size, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.20.131, i64 0, i64 0)) #14
  %call.i23 = tail call i8* @halide_int64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %max_size, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -6
}

; Function Attrs: nounwind
define weak i32 @halide_error_constraints_make_required_region_smaller(i8* %user_context, i8* %buffer_name, i32 %dimension, i32 %constrained_min, i32 %constrained_extent, i32 %required_min, i32 %required_extent) local_unnamed_addr #4 {
entry:
  %add = add i32 %required_min, -1
  %sub = add i32 %add, %required_extent
  %add1 = add i32 %constrained_min, -1
  %sub2 = add i32 %add1, %constrained_extent
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i231 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.25.136, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i232 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.25.136, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i231, %entry.split ], [ %call.i232, %if.then6.i ]
  %ref.tmp.sroa.38.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i26 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.38.0, i8* %buffer_name) #14
  %call.i29 = tail call i8* @halide_string_to_string(i8* %call.i26, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([54 x i8], [54 x i8]* @.str.26.137, i64 0, i64 0)) #14
  %conv.i = sext i32 %dimension to i64
  %call.i32 = tail call i8* @halide_int64_to_string(i8* %call.i29, i8* %ref.tmp.sroa.38.0, i64 %conv.i, i32 1) #14
  %call.i35 = tail call i8* @halide_string_to_string(i8* %call.i32, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.27.138, i64 0, i64 0)) #14
  %call.i38 = tail call i8* @halide_string_to_string(i8* %call.i35, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.28.139, i64 0, i64 0)) #14
  %conv.i41 = sext i32 %required_min to i64
  %call.i42 = tail call i8* @halide_int64_to_string(i8* %call.i38, i8* %ref.tmp.sroa.38.0, i64 %conv.i41, i32 1) #14
  %call.i45 = tail call i8* @halide_string_to_string(i8* %call.i42, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6.117, i64 0, i64 0)) #14
  %conv.i48 = sext i32 %sub to i64
  %call.i49 = tail call i8* @halide_int64_to_string(i8* %call.i45, i8* %ref.tmp.sroa.38.0, i64 %conv.i48, i32 1) #14
  %call.i52 = tail call i8* @halide_string_to_string(i8* %call.i49, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.27.138, i64 0, i64 0)) #14
  %call.i55 = tail call i8* @halide_string_to_string(i8* %call.i52, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.29.140, i64 0, i64 0)) #14
  %conv.i58 = sext i32 %constrained_min to i64
  %call.i59 = tail call i8* @halide_int64_to_string(i8* %call.i55, i8* %ref.tmp.sroa.38.0, i64 %conv.i58, i32 1) #14
  %call.i62 = tail call i8* @halide_string_to_string(i8* %call.i59, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6.117, i64 0, i64 0)) #14
  %conv.i65 = sext i32 %sub2 to i64
  %call.i66 = tail call i8* @halide_int64_to_string(i8* %call.i62, i8* %ref.tmp.sroa.38.0, i64 %conv.i65, i32 1) #14
  %call.i69 = tail call i8* @halide_string_to_string(i8* %call.i66, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.141, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i69 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -7
}

; Function Attrs: nounwind
define weak i32 @halide_error_constraint_violated(i8* %user_context, i8* %var, i32 %val, i8* %constrained_var, i32 %constrained_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i111 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.31.142, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i112 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.31.142, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i111, %entry.split ], [ %call.i112, %if.then6.i ]
  %ref.tmp.sroa.26.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i14 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.26.0, i8* %var) #14
  %call.i17 = tail call i8* @halide_string_to_string(i8* %call.i14, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.32.143, i64 0, i64 0)) #14
  %conv.i = sext i32 %val to i64
  %call.i20 = tail call i8* @halide_int64_to_string(i8* %call.i17, i8* %ref.tmp.sroa.26.0, i64 %conv.i, i32 1) #14
  %call.i23 = tail call i8* @halide_string_to_string(i8* %call.i20, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.33.144, i64 0, i64 0)) #14
  %call.i26 = tail call i8* @halide_string_to_string(i8* %call.i23, i8* %ref.tmp.sroa.26.0, i8* %constrained_var) #14
  %call.i29 = tail call i8* @halide_string_to_string(i8* %call.i26, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.32.143, i64 0, i64 0)) #14
  %conv.i32 = sext i32 %constrained_val to i64
  %call.i33 = tail call i8* @halide_int64_to_string(i8* %call.i29, i8* %ref.tmp.sroa.26.0, i64 %conv.i32, i32 1) #14
  %call.i36 = tail call i8* @halide_string_to_string(i8* %call.i33, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.119, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i36 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -8
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_small_i64(i8* %user_context, i8* %param_name, i64 %val, i64 %min_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.130, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_int64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.35.146, i64 0, i64 0)) #14
  %call.i23 = tail call i8* @halide_int64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %min_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -9
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_small_u64(i8* %user_context, i8* %param_name, i64 %val, i64 %min_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.130, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_uint64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.35.146, i64 0, i64 0)) #14
  %call.i23 = tail call i8* @halide_uint64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %min_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -9
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_small_f64(i8* %user_context, i8* %param_name, double %val, double %min_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.130, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_double_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, double %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.35.146, i64 0, i64 0)) #14
  %call.i23 = tail call i8* @halide_double_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, double %min_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -9
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_large_i64(i8* %user_context, i8* %param_name, i64 %val, i64 %max_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.130, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_int64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.36, i64 0, i64 0)) #14
  %call.i23 = tail call i8* @halide_int64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %max_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -10
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_large_u64(i8* %user_context, i8* %param_name, i64 %val, i64 %max_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.130, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_uint64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.36, i64 0, i64 0)) #14
  %call.i23 = tail call i8* @halide_uint64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %max_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -10
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_large_f64(i8* %user_context, i8* %param_name, double %val, double %max_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.145, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.130, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_double_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, double %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.36, i64 0, i64 0)) #14
  %call.i23 = tail call i8* @halide_double_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, double %max_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -10
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_error_out_of_memory(i8* %user_context) local_unnamed_addr #0 {
entry:
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([47 x i8], [47 x i8]* @.str.37, i64 0, i64 0)) #14
  ret i32 -11
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_argument_is_null(i8* %user_context, i8* %buffer_name) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i51 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.38, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i52 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.38, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i51, %entry.split ], [ %call.i52, %if.then6.i ]
  %ref.tmp.sroa.14.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i8 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.14.0, i8* %buffer_name) #14
  %call.i11 = tail call i8* @halide_string_to_string(i8* %call.i8, i8* %ref.tmp.sroa.14.0, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.39, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i11 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -12
}

; Function Attrs: nounwind
define weak i32 @halide_error_debug_to_file_failed(i8* %user_context, i8* %func, i8* %filename, i32 %error_code) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.40, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.40, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %func) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.41.147, i64 0, i64 0)) #14
  %call.i17 = tail call i8* @halide_string_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i8* %filename) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.42, i64 0, i64 0)) #14
  %conv.i = sext i32 %error_code to i64
  %call.i23 = tail call i8* @halide_int64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %conv.i, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -13
}

; Function Attrs: nounwind
define weak i32 @halide_error_unaligned_host_ptr(i8* %user_context, i8* %func, i32 %alignment) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i71 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.43, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i72 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.43, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i71, %entry.split ], [ %call.i72, %if.then6.i ]
  %ref.tmp.sroa.18.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i10 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.18.0, i8* %func) #14
  %call.i13 = tail call i8* @halide_string_to_string(i8* %call.i10, i8* %ref.tmp.sroa.18.0, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.44, i64 0, i64 0)) #14
  %conv.i = sext i32 %alignment to i64
  %call.i16 = tail call i8* @halide_int64_to_string(i8* %call.i13, i8* %ref.tmp.sroa.18.0, i64 %conv.i, i32 1) #14
  %call.i19 = tail call i8* @halide_string_to_string(i8* %call.i16, i8* %ref.tmp.sroa.18.0, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.45, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i19 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -24
}

; Function Attrs: nounwind
define weak i32 @halide_error_device_dirty_with_no_device_support(i8* %user_context, i8* %func) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i61 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.46, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i62 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.46, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i61, %entry.split ], [ %call.i62, %if.then6.i ]
  %ref.tmp.sroa.16.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i9 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.16.0, i8* %func) #14
  %call.i12 = tail call i8* @halide_string_to_string(i8* %call.i9, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.47, i64 0, i64 0)) #14
  %call.i15 = tail call i8* @halide_string_to_string(i8* %call.i12, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.48, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i15 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -44
}

; Function Attrs: nounwind
define weak i32 @halide_error_host_is_null(i8* %user_context, i8* %func) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i51 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.43, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i52 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.43, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i51, %entry.split ], [ %call.i52, %if.then6.i ]
  %ref.tmp.sroa.14.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i8 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.14.0, i8* %func) #14
  %call.i11 = tail call i8* @halide_string_to_string(i8* %call.i8, i8* %ref.tmp.sroa.14.0, i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.49, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i11 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -34
}

; Function Attrs: nounwind
define weak i32 @halide_error_bad_fold(i8* %user_context, i8* %func_name, i8* %var_name, i8* %loop_name) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i91 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.50.148, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i92 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.50.148, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i91, %entry.split ], [ %call.i92, %if.then6.i ]
  %ref.tmp.sroa.22.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i12 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.22.0, i8* %var_name) #14
  %call.i15 = tail call i8* @halide_string_to_string(i8* %call.i12, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i64 0, i64 0)) #14
  %call.i18 = tail call i8* @halide_string_to_string(i8* %call.i15, i8* %ref.tmp.sroa.22.0, i8* %func_name) #14
  %call.i21 = tail call i8* @halide_string_to_string(i8* %call.i18, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.52, i64 0, i64 0)) #14
  %call.i24 = tail call i8* @halide_string_to_string(i8* %call.i21, i8* %ref.tmp.sroa.22.0, i8* %loop_name) #14
  %call.i27 = tail call i8* @halide_string_to_string(i8* %call.i24, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.141, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i27 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -25
}

; Function Attrs: nounwind
define weak i32 @halide_error_bad_extern_fold(i8* %user_context, i8* %func_name, i32 %dim, i32 %min, i32 %extent, i32 %valid_min, i32 %fold_factor) local_unnamed_addr #4 {
entry:
  %cmp = icmp slt i32 %min, %valid_min
  br i1 %cmp, label %if.then, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %entry
  %add = add nsw i32 %extent, %min
  %add1 = add nsw i32 %fold_factor, %valid_min
  %cmp2 = icmp sgt i32 %add, %add1
  br i1 %cmp2, label %if.then, label %if.else

if.then:                                          ; preds = %lor.lhs.false, %entry
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.split, label %if.then6.i

if.then.split:                                    ; preds = %if.then
  %call.i521 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.53, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %if.then
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i522 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.53, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %if.then.split, %if.then6.i
  %phi.call = phi i8* [ %call.i521, %if.then.split ], [ %call.i522, %if.then6.i ]
  %ref.tmp.sroa.36.0 = phi i8* [ null, %if.then.split ], [ %add.ptr.i, %if.then6.i ]
  %conv.i = sext i32 %dim to i64
  %call.i55 = tail call i8* @halide_int64_to_string(i8* %phi.call, i8* %ref.tmp.sroa.36.0, i64 %conv.i, i32 1) #14
  %call.i58 = tail call i8* @halide_string_to_string(i8* %call.i55, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i64 0, i64 0)) #14
  %call.i61 = tail call i8* @halide_string_to_string(i8* %call.i58, i8* %ref.tmp.sroa.36.0, i8* %func_name) #14
  %call.i64 = tail call i8* @halide_string_to_string(i8* %call.i61, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.54, i64 0, i64 0)) #14
  %conv.i67 = sext i32 %min to i64
  %call.i68 = tail call i8* @halide_int64_to_string(i8* %call.i64, i8* %ref.tmp.sroa.36.0, i64 %conv.i67, i32 1) #14
  %call.i71 = tail call i8* @halide_string_to_string(i8* %call.i68, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #14
  %add9 = add nsw i32 %extent, %min
  %sub = add nsw i32 %add9, -1
  %conv.i74 = sext i32 %sub to i64
  %call.i75 = tail call i8* @halide_int64_to_string(i8* %call.i71, i8* %ref.tmp.sroa.36.0, i64 %conv.i74, i32 1) #14
  %call.i78 = tail call i8* @halide_string_to_string(i8* %call.i75, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.56, i64 0, i64 0)) #14
  %call.i81 = tail call i8* @halide_string_to_string(i8* %call.i78, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([47 x i8], [47 x i8]* @.str.57, i64 0, i64 0)) #14
  %conv.i84 = sext i32 %valid_min to i64
  %call.i85 = tail call i8* @halide_int64_to_string(i8* %call.i81, i8* %ref.tmp.sroa.36.0, i64 %conv.i84, i32 1) #14
  %call.i88 = tail call i8* @halide_string_to_string(i8* %call.i85, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #14
  %add15 = add nsw i32 %fold_factor, %valid_min
  %sub16 = add nsw i32 %add15, -1
  %conv.i91 = sext i32 %sub16 to i64
  %call.i92 = tail call i8* @halide_int64_to_string(i8* %call.i88, i8* %ref.tmp.sroa.36.0, i64 %conv.i91, i32 1) #14
  %call.i95 = tail call i8* @halide_string_to_string(i8* %call.i92, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.58.149, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %if.end

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i95 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %if.end

if.else:                                          ; preds = %lor.lhs.false
  %call.i101 = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i104 = icmp eq i8* %call.i101, null
  br i1 %tobool.not.i104, label %if.else.split, label %if.then6.i107

if.else.split:                                    ; preds = %if.else
  %call.i1133 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.53, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110

if.then6.i107:                                    ; preds = %if.else
  %add.ptr.i105 = getelementptr inbounds i8, i8* %call.i101, i64 1023
  store i8 0, i8* %add.ptr.i105, align 1, !tbaa !18
  %call.i1134 = tail call i8* @halide_string_to_string(i8* nonnull %call.i101, i8* nonnull %add.ptr.i105, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.53, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110: ; preds = %if.else.split, %if.then6.i107
  %phi.call5 = phi i8* [ %call.i1133, %if.else.split ], [ %call.i1134, %if.then6.i107 ]
  %ref.tmp19.sroa.34.0 = phi i8* [ null, %if.else.split ], [ %add.ptr.i105, %if.then6.i107 ]
  %conv.i116 = sext i32 %dim to i64
  %call.i117 = tail call i8* @halide_int64_to_string(i8* %phi.call5, i8* %ref.tmp19.sroa.34.0, i64 %conv.i116, i32 1) #14
  %call.i120 = tail call i8* @halide_string_to_string(i8* %call.i117, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i64 0, i64 0)) #14
  %call.i123 = tail call i8* @halide_string_to_string(i8* %call.i120, i8* %ref.tmp19.sroa.34.0, i8* %func_name) #14
  %call.i126 = tail call i8* @halide_string_to_string(i8* %call.i123, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.54, i64 0, i64 0)) #14
  %conv.i129 = sext i32 %min to i64
  %call.i130 = tail call i8* @halide_int64_to_string(i8* %call.i126, i8* %ref.tmp19.sroa.34.0, i64 %conv.i129, i32 1) #14
  %call.i133 = tail call i8* @halide_string_to_string(i8* %call.i130, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i64 0, i64 0)) #14
  %sub28 = add nsw i32 %add, -1
  %conv.i136 = sext i32 %sub28 to i64
  %call.i137 = tail call i8* @halide_int64_to_string(i8* %call.i133, i8* %ref.tmp19.sroa.34.0, i64 %conv.i136, i32 1) #14
  %call.i140 = tail call i8* @halide_string_to_string(i8* %call.i137, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.56, i64 0, i64 0)) #14
  %call.i143 = tail call i8* @halide_string_to_string(i8* %call.i140, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([47 x i8], [47 x i8]* @.str.59.150, i64 0, i64 0)) #14
  %call.i146 = tail call i8* @halide_string_to_string(i8* %call.i143, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.60.151, i64 0, i64 0)) #14
  %conv.i149 = sext i32 %fold_factor to i64
  %call.i150 = tail call i8* @halide_int64_to_string(i8* %call.i146, i8* %ref.tmp19.sroa.34.0, i64 %conv.i149, i32 1) #14
  %call.i153 = tail call i8* @halide_string_to_string(i8* %call.i150, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.141, i64 0, i64 0)) #14
  br i1 %tobool.not.i104, label %if.then.i157, label %if.else.i167

if.then.i157:                                     ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %if.end

if.else.i167:                                     ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110
  %sub.ptr.lhs.cast.i.i162 = ptrtoint i8* %call.i153 to i64
  %sub.ptr.rhs.cast.i.i163 = ptrtoint i8* %call.i101 to i64
  %sub.ptr.sub.i.i164 = sub i64 1, %sub.ptr.rhs.cast.i.i163
  %add.i.i165 = add i64 %sub.ptr.sub.i.i164, %sub.ptr.lhs.cast.i.i162
  %call.i.i166 = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i101, i64 %add.i.i165) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i101) #14
  br label %if.end

if.end:                                           ; preds = %if.else.i167, %if.then.i157, %if.else.i, %if.then.i
  %call.i101.sink = phi i8* [ %call.i, %if.else.i ], [ null, %if.then.i ], [ %call.i101, %if.else.i167 ], [ null, %if.then.i157 ]
  tail call void @free(i8* %call.i101.sink) #14
  ret i32 -35
}

; Function Attrs: nounwind
define weak i32 @halide_error_fold_factor_too_small(i8* %user_context, i8* %func_name, i8* %var_name, i32 %fold_factor, i8* %loop_name, i32 %required_extent) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i131 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.61.152, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i132 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.61.152, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i131, %entry.split ], [ %call.i132, %if.then6.i ]
  %ref.tmp.sroa.30.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %conv.i = sext i32 %fold_factor to i64
  %call.i16 = tail call i8* @halide_int64_to_string(i8* %phi.call, i8* %ref.tmp.sroa.30.0, i64 %conv.i, i32 1) #14
  %call.i19 = tail call i8* @halide_string_to_string(i8* %call.i16, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.62, i64 0, i64 0)) #14
  %call.i22 = tail call i8* @halide_string_to_string(i8* %call.i19, i8* %ref.tmp.sroa.30.0, i8* %var_name) #14
  %call.i25 = tail call i8* @halide_string_to_string(i8* %call.i22, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i64 0, i64 0)) #14
  %call.i28 = tail call i8* @halide_string_to_string(i8* %call.i25, i8* %ref.tmp.sroa.30.0, i8* %func_name) #14
  %call.i31 = tail call i8* @halide_string_to_string(i8* %call.i28, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.63, i64 0, i64 0)) #14
  %call.i34 = tail call i8* @halide_string_to_string(i8* %call.i31, i8* %ref.tmp.sroa.30.0, i8* %loop_name) #14
  %call.i37 = tail call i8* @halide_string_to_string(i8* %call.i34, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.32.143, i64 0, i64 0)) #14
  %conv.i40 = sext i32 %required_extent to i64
  %call.i41 = tail call i8* @halide_int64_to_string(i8* %call.i37, i8* %ref.tmp.sroa.30.0, i64 %conv.i40, i32 1) #14
  %call.i44 = tail call i8* @halide_string_to_string(i8* %call.i41, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.64.153, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i44 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -26
}

; Function Attrs: nounwind
define weak i32 @halide_error_requirement_failed(i8* %user_context, i8* %condition, i8* %message) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i61 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.65, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i62 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.65, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i61, %entry.split ], [ %call.i62, %if.then6.i ]
  %ref.tmp.sroa.16.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i9 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.16.0, i8* %condition) #14
  %call.i12 = tail call i8* @halide_string_to_string(i8* %call.i9, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.66, i64 0, i64 0)) #14
  %call.i15 = tail call i8* @halide_string_to_string(i8* %call.i12, i8* %ref.tmp.sroa.16.0, i8* %message) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i15 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -27
}

; Function Attrs: nounwind
define weak i32 @halide_error_specialize_fail(i8* %user_context, i8* %message) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i41 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([59 x i8], [59 x i8]* @.str.67, i64 0, i64 0)) #14
  %call.i75 = tail call i8* @halide_string_to_string(i8* %call.i41, i8* null, i8* %message) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i42 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([59 x i8], [59 x i8]* @.str.67, i64 0, i64 0)) #14
  %call.i7 = tail call i8* @halide_string_to_string(i8* %call.i42, i8* nonnull %add.ptr.i, i8* %message) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i7 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -31
}

; Function Attrs: nounwind
define weak i32 @halide_error_no_device_interface(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i316 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.68, i64 0, i64 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i3 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.68, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i3 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -19
}

; Function Attrs: nounwind
define weak i32 @halide_error_device_interface_no_device(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i316 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.69, i64 0, i64 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i3 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.69, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i3 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -36
}

; Function Attrs: nounwind
define weak i32 @halide_error_host_and_device_dirty(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i316 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.70, i64 0, i64 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i3 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.70, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i3 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -37
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_is_null(i8* %user_context, i8* %routine) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i51 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.71, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i52 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.71, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i51, %entry.split ], [ %call.i52, %if.then6.i ]
  %ref.tmp.sroa.14.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i8 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.14.0, i8* %routine) #14
  %call.i11 = tail call i8* @halide_string_to_string(i8* %call.i8, i8* %ref.tmp.sroa.14.0, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.72, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i11 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -38
}

; Function Attrs: nounwind
define weak i32 @halide_error_storage_bound_too_small(i8* %user_context, i8* %func_name, i8* %var_name, i32 %provided_size, i32 %required_size) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i111 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.73, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i112 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.73, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i111, %entry.split ], [ %call.i112, %if.then6.i ]
  %ref.tmp.sroa.26.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %conv.i = sext i32 %provided_size to i64
  %call.i14 = tail call i8* @halide_int64_to_string(i8* %phi.call, i8* %ref.tmp.sroa.26.0, i64 %conv.i, i32 1) #14
  %call.i17 = tail call i8* @halide_string_to_string(i8* %call.i14, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.62, i64 0, i64 0)) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.26.0, i8* %var_name) #14
  %call.i23 = tail call i8* @halide_string_to_string(i8* %call.i20, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i64 0, i64 0)) #14
  %call.i26 = tail call i8* @halide_string_to_string(i8* %call.i23, i8* %ref.tmp.sroa.26.0, i8* %func_name) #14
  %call.i29 = tail call i8* @halide_string_to_string(i8* %call.i26, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.74, i64 0, i64 0)) #14
  %conv.i32 = sext i32 %required_size to i64
  %call.i33 = tail call i8* @halide_int64_to_string(i8* %call.i29, i8* %ref.tmp.sroa.26.0, i64 %conv.i32, i32 1) #14
  %call.i36 = tail call i8* @halide_string_to_string(i8* %call.i33, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.64.153, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i36 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -45
}

; Function Attrs: nounwind
define weak i32 @halide_error_device_crop_failed(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i316 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([77 x i8], [77 x i8]* @.str.75, i64 0, i64 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  %call.i3 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([77 x i8], [77 x i8]* @.str.75, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i3 to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -41
}

; Function Attrs: nounwind mustprogress
define weak void @halide_profiler_shutdown() #0 {
entry:
  %call = tail call %struct.halide_profiler_state* @halide_profiler_get_state() #16
  %sampling_thread = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 7
  %0 = load %struct.halide_thread*, %struct.halide_thread** %sampling_thread, align 8, !tbaa !337
  %tobool.not = icmp eq %struct.halide_thread* %0, null
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %current_func = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 3
  store i32 -2, i32* %current_func, align 8, !tbaa !339
  tail call void @halide_join_thread(%struct.halide_thread* nonnull %0) #14
  store %struct.halide_thread* null, %struct.halide_thread** %sampling_thread, align 8, !tbaa !337
  store i32 -1, i32* %current_func, align 8, !tbaa !339
  tail call void @halide_profiler_report_unlocked(i8* null, %struct.halide_profiler_state* nonnull %call) #16
  tail call void @halide_profiler_reset_unlocked(%struct.halide_profiler_state* nonnull %call) #16
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak %struct.halide_profiler_state* @halide_profiler_get_state() local_unnamed_addr #2 {
entry:
  ret %struct.halide_profiler_state* @_ZZ25halide_profiler_get_stateE1s
}

; Function Attrs: nounwind
define weak void @halide_profiler_report_unlocked(i8* %user_context, %struct.halide_profiler_state* %s) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i64 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EEC2EPvPc.exit, label %if.then6.i

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i64 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !18
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EEC2EPvPc.exit: ; preds = %if.then6.i, %entry
  %sstr.sroa.125.0 = phi i8* [ %add.ptr.i, %if.then6.i ], [ null, %entry ]
  %pipelines = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %s, i64 0, i32 5
  %p.0624 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %pipelines, align 8, !tbaa !14
  %tobool.not625 = icmp eq %struct.halide_profiler_pipeline_stats* %p.0624, null
  br i1 %tobool.not625, label %for.cond.cleanup, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EEC2EPvPc.exit
  %sub.ptr.rhs.cast.i.i348 = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i349 = sub i64 1, %sub.ptr.rhs.cast.i.i348
  br label %for.body

for.cond.cleanup:                                 ; preds = %cleanup181, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EEC2EPvPc.exit
  %sstr.sroa.19.0.lcssa = phi i8* [ %call.i, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EEC2EPvPc.exit ], [ %sstr.sroa.19.15, %cleanup181 ]
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %for.cond.cleanup
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %for.cond.cleanup
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %sstr.sroa.19.0.lcssa to i64
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i64
  %sub.ptr.sub.i.i = sub i64 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i64 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret void

for.body:                                         ; preds = %cleanup181, %for.body.lr.ph
  %p.0627 = phi %struct.halide_profiler_pipeline_stats* [ %p.0624, %for.body.lr.ph ], [ %p.0, %cleanup181 ]
  %sstr.sroa.19.0626 = phi i8* [ %call.i, %for.body.lr.ph ], [ %sstr.sroa.19.15, %cleanup181 ]
  %time = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 0
  %0 = load i64, i64* %time, align 8, !tbaa !340
  %conv = uitofp i64 %0 to float
  %div = fdiv float %conv, 1.000000e+06
  %runs = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 11
  %1 = load i32, i32* %runs, align 8, !tbaa !342
  %tobool1.not = icmp eq i32 %1, 0
  br i1 %tobool1.not, label %cleanup181, label %if.end

if.end:                                           ; preds = %for.body
  br i1 %tobool.not.i, label %if.end.split, label %if.then.i278

if.end.split:                                     ; preds = %if.end
  %active_threads_numerator1 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 4
  %2 = load i64, i64* %active_threads_numerator1, align 8, !tbaa !343
  %active_threads_denominator2 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 5
  %3 = load i64, i64* %active_threads_denominator2, align 8, !tbaa !344
  %cmp3 = icmp eq i64 %2, %3
  %name4 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 6
  %4 = load i8*, i8** %name4, align 8, !tbaa !345
  %call.i2825 = tail call i8* @halide_string_to_string(i8* null, i8* %sstr.sroa.125.0, i8* %4) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit

if.then.i278:                                     ; preds = %if.end
  store i8 0, i8* %call.i, align 1, !tbaa !18
  %active_threads_numerator6 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 4
  %5 = load i64, i64* %active_threads_numerator6, align 8, !tbaa !343
  %active_threads_denominator7 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 5
  %6 = load i64, i64* %active_threads_denominator7, align 8, !tbaa !344
  %cmp8 = icmp eq i64 %5, %6
  %name9 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 6
  %7 = load i8*, i8** %name9, align 8, !tbaa !345
  %call.i28210 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* %sstr.sroa.125.0, i8* %7) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit: ; preds = %if.end.split, %if.then.i278
  %8 = phi i64 [ %2, %if.end.split ], [ %5, %if.then.i278 ]
  %9 = phi i64 [ %3, %if.end.split ], [ %6, %if.then.i278 ]
  %10 = phi i1 [ %cmp3, %if.end.split ], [ %cmp8, %if.then.i278 ]
  %phi.call = phi i8* [ %call.i2825, %if.end.split ], [ %call.i28210, %if.then.i278 ]
  %call.i285 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.7.164, i64 0, i64 0)) #14
  %call.i288 = tail call i8* @halide_string_to_string(i8* %call.i285, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.8.165, i64 0, i64 0)) #14
  %conv.i = fpext float %div to double
  %call.i291 = tail call i8* @halide_double_to_string(i8* %call.i288, i8* %sstr.sroa.125.0, double %conv.i, i32 0) #14
  %call.i294 = tail call i8* @halide_string_to_string(i8* %call.i291, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.9.166, i64 0, i64 0)) #14
  %call.i297 = tail call i8* @halide_string_to_string(i8* %call.i294, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.10.167, i64 0, i64 0)) #14
  %samples = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 12
  %11 = load i32, i32* %samples, align 4, !tbaa !346
  %conv.i300 = sext i32 %11 to i64
  %call.i301 = tail call i8* @halide_int64_to_string(i8* %call.i297, i8* %sstr.sroa.125.0, i64 %conv.i300, i32 1) #14
  %call.i304 = tail call i8* @halide_string_to_string(i8* %call.i301, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.11.168, i64 0, i64 0)) #14
  %12 = load i32, i32* %runs, align 8, !tbaa !342
  %conv.i307 = sext i32 %12 to i64
  %call.i308 = tail call i8* @halide_int64_to_string(i8* %call.i304, i8* %sstr.sroa.125.0, i64 %conv.i307, i32 1) #14
  %call.i311 = tail call i8* @halide_string_to_string(i8* %call.i308, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.12.169, i64 0, i64 0)) #14
  %13 = load i32, i32* %runs, align 8, !tbaa !342
  %conv19 = sitofp i32 %13 to float
  %div20 = fdiv float %div, %conv19
  %conv.i314 = fpext float %div20 to double
  %call.i315 = tail call i8* @halide_double_to_string(i8* %call.i311, i8* %sstr.sroa.125.0, double %conv.i314, i32 0) #14
  %call.i318 = tail call i8* @halide_string_to_string(i8* %call.i315, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.13.170, i64 0, i64 0)) #14
  br i1 %10, label %if.end28, label %if.then24

if.then24:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit
  %conv3 = uitofp i64 %8 to double
  %conv5 = uitofp i64 %9 to double
  %add = fadd double %conv5, 1.000000e-10
  %div6 = fdiv double %conv3, %add
  %conv7 = fptrunc double %div6 to float
  %call.i321 = tail call i8* @halide_string_to_string(i8* %call.i318, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.14.171, i64 0, i64 0)) #14
  %conv.i324 = fpext float %conv7 to double
  %call.i325 = tail call i8* @halide_double_to_string(i8* %call.i321, i8* %sstr.sroa.125.0, double %conv.i324, i32 0) #14
  %call.i328 = tail call i8* @halide_string_to_string(i8* %call.i325, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.7.164, i64 0, i64 0)) #14
  br label %if.end28

if.end28:                                         ; preds = %if.then24, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit
  %sstr.sroa.19.1 = phi i8* [ %call.i318, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit ], [ %call.i328, %if.then24 ]
  %call.i331 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.1, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.15.172, i64 0, i64 0)) #14
  %num_allocs = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 13
  %14 = load i32, i32* %num_allocs, align 8, !tbaa !347
  %conv.i334 = sext i32 %14 to i64
  %call.i335 = tail call i8* @halide_int64_to_string(i8* %call.i331, i8* %sstr.sroa.125.0, i64 %conv.i334, i32 1) #14
  %call.i338 = tail call i8* @halide_string_to_string(i8* %call.i335, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.16.173, i64 0, i64 0)) #14
  %memory_peak = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 2
  %15 = load i64, i64* %memory_peak, align 8, !tbaa !348
  %call.i341 = tail call i8* @halide_uint64_to_string(i8* %call.i338, i8* %sstr.sroa.125.0, i64 %15, i32 1) #14
  %call.i344 = tail call i8* @halide_string_to_string(i8* %call.i341, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.17.174, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit, label %if.then.i352

if.then.i352:                                     ; preds = %if.end28
  %sub.ptr.lhs.cast.i.i347 = ptrtoint i8* %call.i344 to i64
  %add.i.i350 = add i64 %sub.ptr.sub.i.i349, %sub.ptr.lhs.cast.i.i347
  %call.i.i351 = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i350) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit: ; preds = %if.then.i352, %if.end28
  %retval.0.i = phi i8* [ %call.i, %if.then.i352 ], [ getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0), %if.end28 ]
  tail call void @halide_print(i8* %user_context, i8* nonnull %retval.0.i) #14
  %16 = load i64, i64* %time, align 8, !tbaa !340
  %tobool36.not = icmp eq i64 %16, 0
  br i1 %tobool36.not, label %lor.end, label %for.cond53.preheader

lor.end:                                          ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit
  %memory_total = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 3
  %17 = load i64, i64* %memory_total, align 8, !tbaa !349
  %tobool37.not = icmp eq i64 %17, 0
  br i1 %tobool37.not, label %for.cond41.preheader, label %for.cond53.preheader

for.cond41.preheader:                             ; preds = %lor.end
  %num_funcs = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 9
  %18 = load i32, i32* %num_funcs, align 8, !tbaa !350
  %cmp42589 = icmp sgt i32 %18, 0
  br i1 %cmp42589, label %for.body44.lr.ph, label %cleanup181

for.body44.lr.ph:                                 ; preds = %for.cond41.preheader
  %funcs = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 7
  %19 = load %struct.halide_profiler_func_stats*, %struct.halide_profiler_func_stats** %funcs, align 8, !tbaa !351
  %20 = zext i32 %18 to i64
  br label %for.body44

for.cond41:                                       ; preds = %for.body44
  %exitcond.not = icmp eq i64 %indvars.iv.next, %20
  br i1 %exitcond.not, label %cleanup181, label %for.body44, !llvm.loop !352

for.body44:                                       ; preds = %for.cond41, %for.body44.lr.ph
  %indvars.iv = phi i64 [ 0, %for.body44.lr.ph ], [ %indvars.iv.next, %for.cond41 ]
  %stack_peak = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %19, i64 %indvars.iv, i32 4
  %21 = load i64, i64* %stack_peak, align 8, !tbaa !353
  %tobool45.not = icmp eq i64 %21, 0
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  br i1 %tobool45.not, label %for.cond41, label %for.cond53.preheader

for.cond53.preheader:                             ; preds = %for.body44, %lor.end, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit
  %num_funcs54 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 9
  %22 = load i32, i32* %num_funcs54, align 8, !tbaa !350
  %cmp55621 = icmp sgt i32 %22, 0
  br i1 %cmp55621, label %for.body57.lr.ph, label %cleanup181

for.body57.lr.ph:                                 ; preds = %for.cond53.preheader
  %funcs59 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 7
  br label %for.body57

for.body57:                                       ; preds = %cleanup172, %for.body57.lr.ph
  %indvars.iv630 = phi i64 [ 0, %for.body57.lr.ph ], [ %indvars.iv.next631, %cleanup172 ]
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit358, label %if.then.i356

if.then.i356:                                     ; preds = %for.body57
  store i8 0, i8* %call.i, align 1, !tbaa !18
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit358

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit358: ; preds = %if.then.i356, %for.body57
  %23 = load %struct.halide_profiler_func_stats*, %struct.halide_profiler_func_stats** %funcs59, align 8, !tbaa !351
  %add.ptr61 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %23, i64 %indvars.iv630
  %cmp62 = icmp eq i64 %indvars.iv630, 0
  br i1 %cmp62, label %land.lhs.true, label %if.end66

land.lhs.true:                                    ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit358
  %time63 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %add.ptr61, i64 0, i32 0
  %24 = load i64, i64* %time63, align 8, !tbaa !355
  %cmp64 = icmp eq i64 %24, 0
  br i1 %cmp64, label %cleanup172, label %if.end66

if.end66:                                         ; preds = %land.lhs.true, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5clearEv.exit358
  %call.i361 = tail call i8* @halide_string_to_string(i8* %call.i, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.18.175, i64 0, i64 0)) #14
  %name68 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %23, i64 %indvars.iv630, i32 7
  %25 = load i8*, i8** %name68, align 8, !tbaa !356
  %call.i364 = tail call i8* @halide_string_to_string(i8* %call.i361, i8* %sstr.sroa.125.0, i8* %25) #14
  %call.i367 = tail call i8* @halide_string_to_string(i8* %call.i364, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.19.176, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i591 = ptrtoint i8* %call.i367 to i64
  %sub.ptr.sub.i592 = sub i64 %sub.ptr.lhs.cast.i591, %sub.ptr.rhs.cast.i.i348
  %cmp73593 = icmp ult i64 %sub.ptr.sub.i592, 25
  br i1 %cmp73593, label %while.body, label %while.end

while.body:                                       ; preds = %if.end66, %while.body
  %sstr.sroa.19.3594 = phi i8* [ %call.i384, %while.body ], [ %call.i367, %if.end66 ]
  %call.i384 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.3594, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.20.177, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i = ptrtoint i8* %call.i384 to i64
  %sub.ptr.sub.i = sub i64 %sub.ptr.lhs.cast.i, %sub.ptr.rhs.cast.i.i348
  %cmp73 = icmp ult i64 %sub.ptr.sub.i, 25
  br i1 %cmp73, label %while.body, label %while.end, !llvm.loop !357

while.end:                                        ; preds = %while.body, %if.end66
  %sstr.sroa.19.3.lcssa = phi i8* [ %call.i367, %if.end66 ], [ %call.i384, %while.body ]
  %time75 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %add.ptr61, i64 0, i32 0
  %26 = load i64, i64* %time75, align 8, !tbaa !355
  %conv76 = uitofp i64 %26 to float
  %27 = load i32, i32* %runs, align 8, !tbaa !342
  %conv78 = sitofp i32 %27 to float
  %mul = fmul float %conv78, 1.000000e+06
  %div79 = fdiv float %conv76, %mul
  %conv.i387 = fpext float %div79 to double
  %call.i388 = tail call i8* @halide_double_to_string(i8* %sstr.sroa.19.3.lcssa, i8* %sstr.sroa.125.0, double %conv.i387, i32 0) #14
  %tobool.not.i390 = icmp eq i8* %call.i388, null
  br i1 %tobool.not.i390, label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit, label %if.then.i393

if.then.i393:                                     ; preds = %while.end
  %add.ptr.i391 = getelementptr inbounds i8, i8* %call.i388, i64 -3
  %cmp.i = icmp ult i8* %add.ptr.i391, %call.i
  %spec.store.select.i = select i1 %cmp.i, i8* %call.i, i8* %add.ptr.i391
  store i8 0, i8* %spec.store.select.i, align 1, !tbaa !18
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit: ; preds = %if.then.i393, %while.end
  %sstr.sroa.19.4 = phi i8* [ null, %while.end ], [ %spec.store.select.i, %if.then.i393 ]
  %call.i399 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.4, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.21.178, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i400596 = ptrtoint i8* %call.i399 to i64
  %sub.ptr.sub.i402597 = sub i64 %sub.ptr.lhs.cast.i400596, %sub.ptr.rhs.cast.i.i348
  %cmp85598 = icmp ult i64 %sub.ptr.sub.i402597, 35
  br i1 %cmp85598, label %while.body86, label %while.end88

while.body86:                                     ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit, %while.body86
  %sstr.sroa.19.5599 = phi i8* [ %call.i408, %while.body86 ], [ %call.i399, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit ]
  %call.i408 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.5599, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.20.177, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i400 = ptrtoint i8* %call.i408 to i64
  %sub.ptr.sub.i402 = sub i64 %sub.ptr.lhs.cast.i400, %sub.ptr.rhs.cast.i.i348
  %cmp85 = icmp ult i64 %sub.ptr.sub.i402, 35
  br i1 %cmp85, label %while.body86, label %while.end88, !llvm.loop !358

while.end88:                                      ; preds = %while.body86, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit
  %sstr.sroa.19.5.lcssa = phi i8* [ %call.i399, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit ], [ %call.i408, %while.body86 ]
  %28 = load i64, i64* %time, align 8, !tbaa !340
  %cmp90.not = icmp eq i64 %28, 0
  br i1 %cmp90.not, label %if.end97, label %if.then91

if.then91:                                        ; preds = %while.end88
  %29 = load i64, i64* %time75, align 8, !tbaa !355
  %mul93 = mul i64 %29, 100
  %div95 = udiv i64 %mul93, %28
  br label %if.end97

if.end97:                                         ; preds = %if.then91, %while.end88
  %percent.0 = phi i64 [ %div95, %if.then91 ], [ 0, %while.end88 ]
  %call.i411 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.5.lcssa, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.22.179, i64 0, i64 0)) #14
  %sext = shl i64 %percent.0, 32
  %conv.i414 = ashr exact i64 %sext, 32
  %call.i415 = tail call i8* @halide_int64_to_string(i8* %call.i411, i8* %sstr.sroa.125.0, i64 %conv.i414, i32 1) #14
  %call.i418 = tail call i8* @halide_string_to_string(i8* %call.i415, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.23.180, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i419601 = ptrtoint i8* %call.i418 to i64
  %sub.ptr.sub.i421602 = sub i64 %sub.ptr.lhs.cast.i419601, %sub.ptr.rhs.cast.i.i348
  %cmp104603 = icmp ult i64 %sub.ptr.sub.i421602, 43
  br i1 %cmp104603, label %while.body105, label %while.end107

while.body105:                                    ; preds = %if.end97, %while.body105
  %sstr.sroa.19.6604 = phi i8* [ %call.i427, %while.body105 ], [ %call.i418, %if.end97 ]
  %call.i427 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.6604, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.20.177, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i419 = ptrtoint i8* %call.i427 to i64
  %sub.ptr.sub.i421 = sub i64 %sub.ptr.lhs.cast.i419, %sub.ptr.rhs.cast.i.i348
  %cmp104 = icmp ult i64 %sub.ptr.sub.i421, 43
  br i1 %cmp104, label %while.body105, label %while.end107, !llvm.loop !359

while.end107:                                     ; preds = %while.body105, %if.end97
  %sstr.sroa.19.6.lcssa = phi i8* [ %call.i418, %if.end97 ], [ %call.i427, %while.body105 ]
  br i1 %10, label %if.end127, label %if.then109

if.then109:                                       ; preds = %while.end107
  %active_threads_numerator111 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %23, i64 %indvars.iv630, i32 5
  %30 = load i64, i64* %active_threads_numerator111, align 8, !tbaa !360
  %conv112 = uitofp i64 %30 to double
  %active_threads_denominator113 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %23, i64 %indvars.iv630, i32 6
  %31 = load i64, i64* %active_threads_denominator113, align 8, !tbaa !361
  %conv114 = uitofp i64 %31 to double
  %add115 = fadd double %conv114, 1.000000e-10
  %div116 = fdiv double %conv112, %add115
  %conv117 = fptrunc double %div116 to float
  %call.i430 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.6.lcssa, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.24.181, i64 0, i64 0)) #14
  %conv.i433 = fpext float %conv117 to double
  %call.i434 = tail call i8* @halide_double_to_string(i8* %call.i430, i8* %sstr.sroa.125.0, double %conv.i433, i32 0) #14
  %tobool.not.i436 = icmp eq i8* %call.i434, null
  br i1 %tobool.not.i436, label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit442, label %if.then.i441

if.then.i441:                                     ; preds = %if.then109
  %add.ptr.i437 = getelementptr inbounds i8, i8* %call.i434, i64 -3
  %cmp.i439 = icmp ult i8* %add.ptr.i437, %call.i
  %spec.store.select.i440 = select i1 %cmp.i439, i8* %call.i, i8* %add.ptr.i437
  store i8 0, i8* %spec.store.select.i440, align 1, !tbaa !18
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit442

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit442: ; preds = %if.then.i441, %if.then109
  %sstr.sroa.19.7 = phi i8* [ null, %if.then109 ], [ %spec.store.select.i440, %if.then.i441 ]
  %sub.ptr.lhs.cast.i447606 = ptrtoint i8* %sstr.sroa.19.7 to i64
  %sub.ptr.sub.i449607 = sub i64 %sub.ptr.lhs.cast.i447606, %sub.ptr.rhs.cast.i.i348
  %cmp123608 = icmp ult i64 %sub.ptr.sub.i449607, 58
  br i1 %cmp123608, label %while.body124, label %if.end127

while.body124:                                    ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit442, %while.body124
  %sstr.sroa.19.8609 = phi i8* [ %call.i455, %while.body124 ], [ %sstr.sroa.19.7, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit442 ]
  %call.i455 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.8609, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.20.177, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i447 = ptrtoint i8* %call.i455 to i64
  %sub.ptr.sub.i449 = sub i64 %sub.ptr.lhs.cast.i447, %sub.ptr.rhs.cast.i.i348
  %cmp123 = icmp ult i64 %sub.ptr.sub.i449, 58
  br i1 %cmp123, label %while.body124, label %if.end127, !llvm.loop !362

if.end127:                                        ; preds = %while.body124, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit442, %while.end107
  %sstr.sroa.19.9 = phi i8* [ %sstr.sroa.19.6.lcssa, %while.end107 ], [ %sstr.sroa.19.7, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit442 ], [ %call.i455, %while.body124 ]
  %cursor.0 = phi i64 [ 58, %while.end107 ], [ 73, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE5eraseEi.exit442 ], [ 73, %while.body124 ]
  %memory_peak128 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %23, i64 %indvars.iv630, i32 2
  %32 = load i64, i64* %memory_peak128, align 8, !tbaa !363
  %tobool129.not = icmp eq i64 %32, 0
  br i1 %tobool129.not, label %if.end162, label %if.then130

if.then130:                                       ; preds = %if.end127
  %call.i458 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.9, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.25.182, i64 0, i64 0)) #14
  %33 = load i64, i64* %memory_peak128, align 8, !tbaa !363
  %call.i461 = tail call i8* @halide_uint64_to_string(i8* %call.i458, i8* %sstr.sroa.125.0, i64 %33, i32 1) #14
  %sub.ptr.lhs.cast.i462611 = ptrtoint i8* %call.i461 to i64
  %sub.ptr.sub.i464612 = sub i64 %sub.ptr.lhs.cast.i462611, %sub.ptr.rhs.cast.i.i348
  %cmp137613 = icmp ult i64 %sub.ptr.sub.i464612, %cursor.0
  br i1 %cmp137613, label %while.body138, label %while.end140

while.body138:                                    ; preds = %if.then130, %while.body138
  %sstr.sroa.19.10614 = phi i8* [ %call.i470, %while.body138 ], [ %call.i461, %if.then130 ]
  %call.i470 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.10614, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.20.177, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i462 = ptrtoint i8* %call.i470 to i64
  %sub.ptr.sub.i464 = sub i64 %sub.ptr.lhs.cast.i462, %sub.ptr.rhs.cast.i.i348
  %cmp137 = icmp ult i64 %sub.ptr.sub.i464, %cursor.0
  br i1 %cmp137, label %while.body138, label %while.end140, !llvm.loop !364

while.end140:                                     ; preds = %while.body138, %if.then130
  %sstr.sroa.19.10.lcssa = phi i8* [ %call.i461, %if.then130 ], [ %call.i470, %while.body138 ]
  %call.i473 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.10.lcssa, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.26.183, i64 0, i64 0)) #14
  %num_allocs142 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %23, i64 %indvars.iv630, i32 8
  %34 = load i32, i32* %num_allocs142, align 8, !tbaa !365
  %conv.i476 = sext i32 %34 to i64
  %call.i477 = tail call i8* @halide_int64_to_string(i8* %call.i473, i8* %sstr.sroa.125.0, i64 %conv.i476, i32 1) #14
  %add144 = add nuw nsw i64 %cursor.0, 15
  %sub.ptr.lhs.cast.i478616 = ptrtoint i8* %call.i477 to i64
  %sub.ptr.sub.i480617 = sub i64 %sub.ptr.lhs.cast.i478616, %sub.ptr.rhs.cast.i.i348
  %cmp147618 = icmp ult i64 %sub.ptr.sub.i480617, %add144
  br i1 %cmp147618, label %while.body148, label %while.end150

while.body148:                                    ; preds = %while.end140, %while.body148
  %sstr.sroa.19.11619 = phi i8* [ %call.i467, %while.body148 ], [ %call.i477, %while.end140 ]
  %call.i467 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.11619, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.20.177, i64 0, i64 0)) #14
  %sub.ptr.lhs.cast.i478 = ptrtoint i8* %call.i467 to i64
  %sub.ptr.sub.i480 = sub i64 %sub.ptr.lhs.cast.i478, %sub.ptr.rhs.cast.i.i348
  %cmp147 = icmp ult i64 %sub.ptr.sub.i480, %add144
  br i1 %cmp147, label %while.body148, label %while.end150, !llvm.loop !366

while.end150:                                     ; preds = %while.body148, %while.end140
  %sstr.sroa.19.11.lcssa = phi i8* [ %call.i477, %while.end140 ], [ %call.i467, %while.body148 ]
  %35 = load i32, i32* %num_allocs142, align 8, !tbaa !365
  %cmp152.not = icmp eq i32 %35, 0
  br i1 %cmp152.not, label %if.end159, label %if.then153

if.then153:                                       ; preds = %while.end150
  %memory_total154 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %23, i64 %indvars.iv630, i32 3
  %36 = load i64, i64* %memory_total154, align 8, !tbaa !367
  %conv156 = sext i32 %35 to i64
  %div157 = udiv i64 %36, %conv156
  br label %if.end159

if.end159:                                        ; preds = %if.then153, %while.end150
  %alloc_avg.0 = phi i64 [ %div157, %if.then153 ], [ 0, %while.end150 ]
  %call.i452 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.11.lcssa, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.27.184, i64 0, i64 0)) #14
  %sext586 = shl i64 %alloc_avg.0, 32
  %conv.i445 = ashr exact i64 %sext586, 32
  %call.i446 = tail call i8* @halide_int64_to_string(i8* %call.i452, i8* %sstr.sroa.125.0, i64 %conv.i445, i32 1) #14
  br label %if.end162

if.end162:                                        ; preds = %if.end159, %if.end127
  %sstr.sroa.19.12 = phi i8* [ %sstr.sroa.19.9, %if.end127 ], [ %call.i446, %if.end159 ]
  %stack_peak163 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %23, i64 %indvars.iv630, i32 4
  %37 = load i64, i64* %stack_peak163, align 8, !tbaa !353
  %cmp164.not = icmp eq i64 %37, 0
  br i1 %cmp164.not, label %if.end169, label %if.then165

if.then165:                                       ; preds = %if.end162
  %call.i424 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.12, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.28.185, i64 0, i64 0)) #14
  %38 = load i64, i64* %stack_peak163, align 8, !tbaa !353
  %call.i405 = tail call i8* @halide_uint64_to_string(i8* %call.i424, i8* %sstr.sroa.125.0, i64 %38, i32 1) #14
  br label %if.end169

if.end169:                                        ; preds = %if.then165, %if.end162
  %sstr.sroa.19.13 = phi i8* [ %sstr.sroa.19.12, %if.end162 ], [ %call.i405, %if.then165 ]
  %call.i396 = tail call i8* @halide_string_to_string(i8* %sstr.sroa.19.13, i8* %sstr.sroa.125.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.7.164, i64 0, i64 0)) #14
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit381, label %if.then.i379

if.then.i379:                                     ; preds = %if.end169
  %sub.ptr.lhs.cast.i.i374 = ptrtoint i8* %call.i396 to i64
  %add.i.i377 = add i64 %sub.ptr.sub.i.i349, %sub.ptr.lhs.cast.i.i374
  %call.i.i378 = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %add.i.i377) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit381

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit381: ; preds = %if.then.i379, %if.end169
  %retval.0.i380 = phi i8* [ %call.i, %if.then.i379 ], [ getelementptr inbounds ([35 x i8], [35 x i8]* @.str.29.163, i64 0, i64 0), %if.end169 ]
  tail call void @halide_print(i8* %user_context, i8* nonnull %retval.0.i380) #14
  br label %cleanup172

cleanup172:                                       ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit381, %land.lhs.true
  %sstr.sroa.19.14 = phi i8* [ %call.i, %land.lhs.true ], [ %call.i396, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE2ELy1024EE3strEv.exit381 ]
  %indvars.iv.next631 = add nuw nsw i64 %indvars.iv630, 1
  %39 = load i32, i32* %num_funcs54, align 8, !tbaa !350
  %40 = sext i32 %39 to i64
  %cmp55 = icmp slt i64 %indvars.iv.next631, %40
  br i1 %cmp55, label %for.body57, label %cleanup181, !llvm.loop !368

cleanup181:                                       ; preds = %for.cond41, %cleanup172, %for.cond53.preheader, %for.cond41.preheader, %for.body
  %sstr.sroa.19.15 = phi i8* [ %sstr.sroa.19.0626, %for.body ], [ %call.i344, %for.cond53.preheader ], [ %call.i344, %for.cond41.preheader ], [ %sstr.sroa.19.14, %cleanup172 ], [ %call.i344, %for.cond41 ]
  %next = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0627, i64 0, i32 8
  %41 = bitcast i8** %next to %struct.halide_profiler_pipeline_stats**
  %p.0 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %41, align 8, !tbaa !14
  %tobool.not = icmp eq %struct.halide_profiler_pipeline_stats* %p.0, null
  br i1 %tobool.not, label %for.cond.cleanup, label %for.body, !llvm.loop !369
}

; Function Attrs: nounwind mustprogress
define weak void @halide_profiler_reset_unlocked(%struct.halide_profiler_state* %s) local_unnamed_addr #0 {
entry:
  %pipelines = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %s, i64 0, i32 5
  %0 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %pipelines, align 8, !tbaa !370
  %tobool.not9 = icmp eq %struct.halide_profiler_pipeline_stats* %0, null
  br i1 %tobool.not9, label %while.end, label %while.body

while.body:                                       ; preds = %entry, %while.body
  %1 = phi %struct.halide_profiler_pipeline_stats* [ %7, %while.body ], [ %0, %entry ]
  %next = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %1, i64 0, i32 8
  %2 = bitcast i8** %next to %struct.halide_profiler_pipeline_stats**
  %3 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %2, align 8, !tbaa !371
  store %struct.halide_profiler_pipeline_stats* %3, %struct.halide_profiler_pipeline_stats** %pipelines, align 8, !tbaa !370
  %funcs = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %1, i64 0, i32 7
  %4 = bitcast %struct.halide_profiler_func_stats** %funcs to i8**
  %5 = load i8*, i8** %4, align 8, !tbaa !351
  tail call void @free(i8* %5) #14
  %6 = bitcast %struct.halide_profiler_pipeline_stats* %1 to i8*
  tail call void @free(i8* nonnull %6) #14
  %7 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %pipelines, align 8, !tbaa !370
  %tobool.not = icmp eq %struct.halide_profiler_pipeline_stats* %7, null
  br i1 %tobool.not, label %while.end, label %while.body, !llvm.loop !372

while.end:                                        ; preds = %while.body, %entry
  %first_free_id = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %s, i64 0, i32 2
  store i32 0, i32* %first_free_id, align 4, !tbaa !373
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce %struct.halide_profiler_pipeline_stats* @_ZN6Halide7Runtime8Internal23find_or_create_pipelineEPKciPKy(i8* %pipeline_name, i32 %num_funcs, i64* %func_names) local_unnamed_addr #0 {
entry:
  %call = tail call %struct.halide_profiler_state* @halide_profiler_get_state() #16
  %pipelines = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 5
  %p.0121 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %pipelines, align 8, !tbaa !14
  %tobool.not122 = icmp eq %struct.halide_profiler_pipeline_stats* %p.0121, null
  br i1 %tobool.not122, label %for.end, label %for.body

for.body:                                         ; preds = %entry, %for.inc
  %p.0123 = phi %struct.halide_profiler_pipeline_stats* [ %p.0, %for.inc ], [ %p.0121, %entry ]
  %name = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0123, i64 0, i32 6
  %0 = load i8*, i8** %name, align 8, !tbaa !345
  %cmp = icmp eq i8* %0, %pipeline_name
  br i1 %cmp, label %land.lhs.true, label %for.inc

land.lhs.true:                                    ; preds = %for.body
  %num_funcs1 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0123, i64 0, i32 9
  %1 = load i32, i32* %num_funcs1, align 8, !tbaa !350
  %cmp2 = icmp eq i32 %1, %num_funcs
  br i1 %cmp2, label %cleanup62, label %for.inc

for.inc:                                          ; preds = %land.lhs.true, %for.body
  %next = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.0123, i64 0, i32 8
  %2 = bitcast i8** %next to %struct.halide_profiler_pipeline_stats**
  %p.0 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %2, align 8, !tbaa !14
  %tobool.not = icmp eq %struct.halide_profiler_pipeline_stats* %p.0, null
  br i1 %tobool.not, label %for.end, label %for.body, !llvm.loop !374

for.end:                                          ; preds = %for.inc, %entry
  %call4 = tail call i8* @malloc(i64 96) #14
  %3 = bitcast i8* %call4 to %struct.halide_profiler_pipeline_stats*
  %tobool5.not = icmp eq i8* %call4, null
  br i1 %tobool5.not, label %cleanup62, label %if.end7

if.end7:                                          ; preds = %for.end
  %4 = bitcast %struct.halide_profiler_pipeline_stats** %pipelines to i8**
  %5 = load i8*, i8** %4, align 8, !tbaa !370
  %next9 = getelementptr inbounds i8, i8* %call4, i64 64
  %6 = bitcast i8* %next9 to i8**
  store i8* %5, i8** %6, align 8, !tbaa !371
  %name10 = getelementptr inbounds i8, i8* %call4, i64 48
  %7 = bitcast i8* %name10 to i8**
  store i8* %pipeline_name, i8** %7, align 8, !tbaa !345
  %first_free_id = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 2
  %8 = load i32, i32* %first_free_id, align 4, !tbaa !373
  %first_func_id = getelementptr inbounds i8, i8* %call4, i64 76
  %9 = bitcast i8* %first_func_id to i32*
  store i32 %8, i32* %9, align 4, !tbaa !375
  %num_funcs11 = getelementptr inbounds i8, i8* %call4, i64 72
  %10 = bitcast i8* %num_funcs11 to i32*
  store i32 %num_funcs, i32* %10, align 8, !tbaa !350
  %runs = getelementptr inbounds i8, i8* %call4, i64 80
  %11 = bitcast i8* %runs to <2 x i32>*
  store <2 x i32> zeroinitializer, <2 x i32>* %11, align 8, !tbaa !41
  %12 = bitcast i8* %call4 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %12, align 8, !tbaa !22
  %memory_peak = getelementptr inbounds i8, i8* %call4, i64 16
  %13 = bitcast i8* %memory_peak to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %13, align 8, !tbaa !22
  %num_allocs = getelementptr inbounds i8, i8* %call4, i64 88
  %14 = bitcast i8* %num_allocs to i32*
  store i32 0, i32* %14, align 8, !tbaa !347
  %active_threads_numerator = getelementptr inbounds i8, i8* %call4, i64 32
  %15 = bitcast i8* %active_threads_numerator to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %15, align 8, !tbaa !22
  %conv = sext i32 %num_funcs to i64
  %mul = mul nsw i64 %conv, 72
  %call12 = tail call i8* @malloc(i64 %mul) #14
  %funcs = getelementptr inbounds i8, i8* %call4, i64 56
  %16 = bitcast i8* %funcs to i8**
  store i8* %call12, i8** %16, align 8, !tbaa !351
  %tobool14.not = icmp eq i8* %call12, null
  %17 = bitcast i8* %call12 to %struct.halide_profiler_func_stats*
  br i1 %tobool14.not, label %if.then15, label %for.cond17.preheader

for.cond17.preheader:                             ; preds = %if.end7
  %cmp18119 = icmp sgt i32 %num_funcs, 0
  br i1 %cmp18119, label %for.body20.lr.ph, label %for.cond.cleanup19

for.body20.lr.ph:                                 ; preds = %for.cond17.preheader
  %wide.trip.count = zext i32 %num_funcs to i64
  br label %for.body20

if.then15:                                        ; preds = %if.end7
  tail call void @free(i8* nonnull %call4) #14
  br label %cleanup62

for.cond.cleanup19:                               ; preds = %for.body20, %for.cond17.preheader
  %18 = load i32, i32* %first_free_id, align 4, !tbaa !373
  %add = add nsw i32 %18, %num_funcs
  store i32 %add, i32* %first_free_id, align 4, !tbaa !373
  store i8* %call4, i8** %4, align 8, !tbaa !370
  br label %cleanup62

for.body20:                                       ; preds = %for.body20, %for.body20.lr.ph
  %indvars.iv = phi i64 [ 0, %for.body20.lr.ph ], [ %indvars.iv.next, %for.body20 ]
  %time22 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %17, i64 %indvars.iv, i32 0
  store i64 0, i64* %time22, align 8, !tbaa !355
  %arrayidx24 = getelementptr inbounds i64, i64* %func_names, i64 %indvars.iv
  %19 = load i64, i64* %arrayidx24, align 8, !tbaa !22
  %20 = inttoptr i64 %19 to i8*
  %name28 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %17, i64 %indvars.iv, i32 7
  store i8* %20, i8** %name28, align 8, !tbaa !356
  %memory_current32 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %17, i64 %indvars.iv, i32 1
  %21 = bitcast i64* %memory_current32 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %21, align 8, !tbaa !22
  %memory_total40 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %17, i64 %indvars.iv, i32 3
  %num_allocs44 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %17, i64 %indvars.iv, i32 8
  store i32 0, i32* %num_allocs44, align 8, !tbaa !365
  %22 = bitcast i64* %memory_total40 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %22, align 8, !tbaa !22
  %active_threads_numerator51 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %17, i64 %indvars.iv, i32 5
  %23 = bitcast i64* %active_threads_numerator51 to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %23, align 8, !tbaa !22
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond.not, label %for.cond.cleanup19, label %for.body20, !llvm.loop !376

cleanup62:                                        ; preds = %land.lhs.true, %for.cond.cleanup19, %if.then15, %for.end
  %retval.2 = phi %struct.halide_profiler_pipeline_stats* [ %3, %for.cond.cleanup19 ], [ null, %if.then15 ], [ null, %for.end ], [ %p.0123, %land.lhs.true ]
  ret %struct.halide_profiler_pipeline_stats* %retval.2
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal9bill_funcEP21halide_profiler_stateiyi(%struct.halide_profiler_state* %s, i32 %func_id, i64 %time, i32 %active_threads) local_unnamed_addr #0 {
entry:
  %pipelines = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %s, i64 0, i32 5
  %p.055 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %pipelines, align 8, !tbaa !14
  %tobool.not56 = icmp eq %struct.halide_profiler_pipeline_stats* %p.055, null
  br i1 %tobool.not56, label %cleanup25, label %for.body

for.body:                                         ; preds = %entry, %if.end23
  %p.058 = phi %struct.halide_profiler_pipeline_stats* [ %p.0, %if.end23 ], [ %p.055, %entry ]
  %p_prev.057 = phi %struct.halide_profiler_pipeline_stats* [ %p.058, %if.end23 ], [ null, %entry ]
  %first_func_id = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 10
  %0 = load i32, i32* %first_func_id, align 4, !tbaa !375
  %cmp.not = icmp sgt i32 %0, %func_id
  br i1 %cmp.not, label %if.end23, label %land.lhs.true

land.lhs.true:                                    ; preds = %for.body
  %num_funcs = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 9
  %1 = load i32, i32* %num_funcs, align 8, !tbaa !350
  %add = add nsw i32 %1, %0
  %cmp2 = icmp sgt i32 %add, %func_id
  br i1 %cmp2, label %if.then, label %if.end23

if.then:                                          ; preds = %land.lhs.true
  %tobool3.not = icmp eq %struct.halide_profiler_pipeline_stats* %p_prev.057, null
  br i1 %tobool3.not, label %if.end, label %if.then4

if.then4:                                         ; preds = %if.then
  %next = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 8
  %2 = load i8*, i8** %next, align 8, !tbaa !371
  %next5 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p_prev.057, i64 0, i32 8
  store i8* %2, i8** %next5, align 8, !tbaa !371
  %3 = bitcast i8** %next to %struct.halide_profiler_pipeline_stats**
  store %struct.halide_profiler_pipeline_stats* %p.055, %struct.halide_profiler_pipeline_stats** %3, align 8, !tbaa !371
  store %struct.halide_profiler_pipeline_stats* %p.058, %struct.halide_profiler_pipeline_stats** %pipelines, align 8, !tbaa !370
  br label %if.end

if.end:                                           ; preds = %if.then4, %if.then
  %funcs = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 7
  %4 = load %struct.halide_profiler_func_stats*, %struct.halide_profiler_func_stats** %funcs, align 8, !tbaa !351
  %idx.ext = sext i32 %func_id to i64
  %add.ptr = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %4, i64 %idx.ext
  %idx.ext10 = sext i32 %0 to i64
  %idx.neg = sub nsw i64 0, %idx.ext10
  %add.ptr11 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %add.ptr, i64 %idx.neg
  %time12 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %add.ptr11, i64 0, i32 0
  %5 = load i64, i64* %time12, align 8, !tbaa !355
  %add13 = add i64 %5, %time
  store i64 %add13, i64* %time12, align 8, !tbaa !355
  %conv = sext i32 %active_threads to i64
  %active_threads_numerator = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %add.ptr11, i64 0, i32 5
  %6 = load i64, i64* %active_threads_numerator, align 8, !tbaa !360
  %add14 = add i64 %6, %conv
  store i64 %add14, i64* %active_threads_numerator, align 8, !tbaa !360
  %active_threads_denominator = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %add.ptr11, i64 0, i32 6
  %7 = load i64, i64* %active_threads_denominator, align 8, !tbaa !361
  %add15 = add i64 %7, 1
  store i64 %add15, i64* %active_threads_denominator, align 8, !tbaa !361
  %time16 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 0
  %8 = load i64, i64* %time16, align 8, !tbaa !340
  %add17 = add i64 %8, %time
  store i64 %add17, i64* %time16, align 8, !tbaa !340
  %samples = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 12
  %9 = load i32, i32* %samples, align 4, !tbaa !346
  %inc = add nsw i32 %9, 1
  store i32 %inc, i32* %samples, align 4, !tbaa !346
  %active_threads_numerator19 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 4
  %10 = load i64, i64* %active_threads_numerator19, align 8, !tbaa !343
  %add20 = add i64 %10, %conv
  store i64 %add20, i64* %active_threads_numerator19, align 8, !tbaa !343
  %active_threads_denominator21 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 5
  %11 = load i64, i64* %active_threads_denominator21, align 8, !tbaa !344
  %add22 = add i64 %11, 1
  store i64 %add22, i64* %active_threads_denominator21, align 8, !tbaa !344
  ret void

if.end23:                                         ; preds = %land.lhs.true, %for.body
  %next24 = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.058, i64 0, i32 8
  %12 = bitcast i8** %next24 to %struct.halide_profiler_pipeline_stats**
  %p.0 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %12, align 8, !tbaa !14
  %tobool.not = icmp eq %struct.halide_profiler_pipeline_stats* %p.0, null
  br i1 %tobool.not, label %cleanup25, label %for.body, !llvm.loop !377

cleanup25:                                        ; preds = %if.end23, %entry
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_profiler_sample(%struct.halide_profiler_state* %s, i64* %prev_t) local_unnamed_addr #0 {
entry:
  %func = alloca i32, align 4
  %active_threads = alloca i32, align 4
  %0 = bitcast i32* %func to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %0) #15
  %1 = bitcast i32* %active_threads to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %1) #15
  %get_remote_profiler_state = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %s, i64 0, i32 6
  %2 = load void (i32*, i32*)*, void (i32*, i32*)** %get_remote_profiler_state, align 8, !tbaa !378
  %tobool.not = icmp eq void (i32*, i32*)* %2, null
  br i1 %tobool.not, label %if.else, label %if.then

if.then:                                          ; preds = %entry
  call void %2(i32* nonnull %func, i32* nonnull %active_threads) #14
  br label %if.end

if.else:                                          ; preds = %entry
  %current_func = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %s, i64 0, i32 3
  %3 = load i32, i32* %current_func, align 8, !tbaa !339
  store i32 %3, i32* %func, align 4, !tbaa !41
  %active_threads2 = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %s, i64 0, i32 4
  %4 = load i32, i32* %active_threads2, align 4, !tbaa !379
  store i32 %4, i32* %active_threads, align 4, !tbaa !41
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then
  %call = call i64 @halide_current_time_ns(i8* null) #14
  %5 = load i32, i32* %func, align 4, !tbaa !41
  %cmp = icmp eq i32 %5, -2
  br i1 %cmp, label %cleanup, label %if.else4

if.else4:                                         ; preds = %if.end
  %cmp5 = icmp sgt i32 %5, -1
  br i1 %cmp5, label %if.then6, label %if.end8

if.then6:                                         ; preds = %if.else4
  %6 = load i64, i64* %prev_t, align 8, !tbaa !22
  %sub = sub i64 %call, %6
  %7 = load i32, i32* %active_threads, align 4, !tbaa !41
  call void @_ZN6Halide7Runtime8Internal9bill_funcEP21halide_profiler_stateiyi(%struct.halide_profiler_state* nonnull %s, i32 %5, i64 %sub, i32 %7) #16
  br label %if.end8

if.end8:                                          ; preds = %if.then6, %if.else4
  store i64 %call, i64* %prev_t, align 8, !tbaa !22
  %sleep_time = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %s, i64 0, i32 1
  %8 = load i32, i32* %sleep_time, align 8, !tbaa !380
  br label %cleanup

cleanup:                                          ; preds = %if.end8, %if.end
  %retval.0 = phi i32 [ %8, %if.end8 ], [ -1, %if.end ]
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %1) #15
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %0) #15
  ret i32 %retval.0
}

; Function Attrs: nounwind
define linkonce void @_ZN6Halide7Runtime8Internal24sampling_profiler_threadEPv(i8* %0) #4 {
entry:
  %t = alloca i64, align 8
  %call = tail call %struct.halide_profiler_state* @halide_profiler_get_state() #16
  %lock = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 0
  tail call void @halide_mutex_lock(%struct.halide_mutex* %lock) #14
  %current_func = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 3
  %1 = load i32, i32* %current_func, align 8, !tbaa !339
  %cmp.not23 = icmp eq i32 %1, -2
  br i1 %cmp.not23, label %while.end8, label %while.body.lr.ph

while.body.lr.ph:                                 ; preds = %entry
  %2 = bitcast i64* %t to i8*
  br label %while.body

while.body:                                       ; preds = %while.end, %while.body.lr.ph
  %call1 = call i64 @halide_current_time_ns(i8* null) #14
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %2) #15
  store i64 %call1, i64* %t, align 8, !tbaa !22
  %call420 = call i32 @halide_profiler_sample(%struct.halide_profiler_state* nonnull %call, i64* nonnull %t) #16
  %cmp521 = icmp slt i32 %call420, 0
  br i1 %cmp521, label %while.end, label %if.end

if.end:                                           ; preds = %while.body, %if.end
  %call422 = phi i32 [ %call4, %if.end ], [ %call420, %while.body ]
  call void @halide_mutex_unlock(%struct.halide_mutex* %lock) #14
  call void @halide_sleep_ms(i8* null, i32 %call422) #14
  call void @halide_mutex_lock(%struct.halide_mutex* %lock) #14
  %call4 = call i32 @halide_profiler_sample(%struct.halide_profiler_state* %call, i64* nonnull %t) #16
  %cmp5 = icmp slt i32 %call4, 0
  br i1 %cmp5, label %while.end, label %if.end

while.end:                                        ; preds = %if.end, %while.body
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %2) #15
  %3 = load i32, i32* %current_func, align 8, !tbaa !339
  %cmp.not = icmp eq i32 %3, -2
  br i1 %cmp.not, label %while.end8, label %while.body, !llvm.loop !381

while.end8:                                       ; preds = %while.end, %entry
  call void @halide_mutex_unlock(%struct.halide_mutex* nonnull %lock) #14
  ret void
}

; Function Attrs: nounwind
define weak %struct.halide_profiler_pipeline_stats* @halide_profiler_get_pipeline_state(i8* %pipeline_name) local_unnamed_addr #4 {
entry:
  %call = tail call %struct.halide_profiler_state* @halide_profiler_get_state() #16
  %lock.i = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 0
  tail call void @halide_mutex_lock(%struct.halide_mutex* %lock.i) #14
  %pipelines = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 5
  %p.013 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %pipelines, align 8, !tbaa !14
  %tobool.not14 = icmp eq %struct.halide_profiler_pipeline_stats* %p.013, null
  br i1 %tobool.not14, label %cleanup, label %for.body

for.body:                                         ; preds = %entry, %for.inc
  %p.015 = phi %struct.halide_profiler_pipeline_stats* [ %p.0, %for.inc ], [ %p.013, %entry ]
  %name = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.015, i64 0, i32 6
  %0 = load i8*, i8** %name, align 8, !tbaa !345
  %cmp = icmp eq i8* %0, %pipeline_name
  br i1 %cmp, label %cleanup, label %for.inc

for.inc:                                          ; preds = %for.body
  %next = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %p.015, i64 0, i32 8
  %1 = bitcast i8** %next to %struct.halide_profiler_pipeline_stats**
  %p.0 = load %struct.halide_profiler_pipeline_stats*, %struct.halide_profiler_pipeline_stats** %1, align 8, !tbaa !14
  %tobool.not = icmp eq %struct.halide_profiler_pipeline_stats* %p.0, null
  br i1 %tobool.not, label %cleanup, label %for.body, !llvm.loop !382

cleanup:                                          ; preds = %for.inc, %for.body, %entry
  %p.0.lcssa = phi %struct.halide_profiler_pipeline_stats* [ null, %entry ], [ null, %for.inc ], [ %p.015, %for.body ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* %lock.i) #14
  ret %struct.halide_profiler_pipeline_stats* %p.0.lcssa
}

; Function Attrs: nounwind
define weak i32 @halide_profiler_pipeline_start(i8* %user_context, i8* %pipeline_name, i32 %num_funcs, i64* %func_names) local_unnamed_addr #4 {
entry:
  %call = tail call %struct.halide_profiler_state* @halide_profiler_get_state() #16
  %lock.i = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 0
  tail call void @halide_mutex_lock(%struct.halide_mutex* %lock.i) #14
  %sampling_thread = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 7
  %0 = load %struct.halide_thread*, %struct.halide_thread** %sampling_thread, align 8, !tbaa !337
  %tobool.not = icmp eq %struct.halide_thread* %0, null
  br i1 %tobool.not, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %call1 = tail call i32 @halide_start_clock(i8* %user_context) #14
  %call2 = tail call %struct.halide_thread* @halide_spawn_thread(void (i8*)* nonnull @_ZN6Halide7Runtime8Internal24sampling_profiler_threadEPv, i8* null) #14
  store %struct.halide_thread* %call2, %struct.halide_thread** %sampling_thread, align 8, !tbaa !337
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %call4 = tail call %struct.halide_profiler_pipeline_stats* @_ZN6Halide7Runtime8Internal23find_or_create_pipelineEPKciPKy(i8* %pipeline_name, i32 %num_funcs, i64* %func_names) #16
  %tobool5.not = icmp eq %struct.halide_profiler_pipeline_stats* %call4, null
  br i1 %tobool5.not, label %if.then6, label %if.end8

if.then6:                                         ; preds = %if.end
  %call7 = tail call i32 @halide_error_out_of_memory(i8* %user_context) #14
  br label %cleanup

if.end8:                                          ; preds = %if.end
  %runs = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %call4, i64 0, i32 11
  %1 = load i32, i32* %runs, align 8, !tbaa !342
  %inc = add nsw i32 %1, 1
  store i32 %inc, i32* %runs, align 8, !tbaa !342
  %first_func_id = getelementptr inbounds %struct.halide_profiler_pipeline_stats, %struct.halide_profiler_pipeline_stats* %call4, i64 0, i32 10
  %2 = load i32, i32* %first_func_id, align 4, !tbaa !375
  br label %cleanup

cleanup:                                          ; preds = %if.end8, %if.then6
  %retval.0 = phi i32 [ %2, %if.end8 ], [ %call7, %if.then6 ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull %lock.i) #14
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak void @halide_profiler_stack_peak_update(i8* %user_context, i8* %pipeline_state, i64* %f_values) local_unnamed_addr #0 {
entry:
  %cmp.not = icmp eq i8* %pipeline_state, null
  br i1 %cmp.not, label %if.then, label %do.end

if.then:                                          ; preds = %entry
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([128 x i8], [128 x i8]* @.str.186, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then, %entry
  %num_funcs = getelementptr inbounds i8, i8* %pipeline_state, i64 72
  %0 = bitcast i8* %num_funcs to i32*
  %1 = load i32, i32* %0, align 8, !tbaa !350
  %cmp118 = icmp sgt i32 %1, 0
  br i1 %cmp118, label %for.body.lr.ph, label %for.cond.cleanup

for.body.lr.ph:                                   ; preds = %do.end
  %funcs = getelementptr inbounds i8, i8* %pipeline_state, i64 56
  %2 = bitcast i8* %funcs to %struct.halide_profiler_func_stats**
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.inc, %do.end
  ret void

for.body:                                         ; preds = %for.inc, %for.body.lr.ph
  %3 = phi i32 [ %1, %for.body.lr.ph ], [ %9, %for.inc ]
  %indvars.iv = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next, %for.inc ]
  %arrayidx = getelementptr inbounds i64, i64* %f_values, i64 %indvars.iv
  %4 = load i64, i64* %arrayidx, align 8, !tbaa !22
  %cmp2.not = icmp eq i64 %4, 0
  br i1 %cmp2.not, label %for.inc, label %if.then3

if.then3:                                         ; preds = %for.body
  %5 = load %struct.halide_profiler_func_stats*, %struct.halide_profiler_func_stats** %2, align 8, !tbaa !351
  %stack_peak = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %5, i64 %indvars.iv, i32 4
  %6 = load i64, i64* %stack_peak, align 8, !tbaa !22
  br label %while.cond.i

while.cond.i:                                     ; preds = %while.body.i, %if.then3
  %old_val.0.i = phi i64 [ %6, %if.then3 ], [ %8, %while.body.i ]
  %cmp.i = icmp ult i64 %old_val.0.i, %4
  br i1 %cmp.i, label %while.body.i, label %for.inc.loopexit

while.body.i:                                     ; preds = %while.cond.i
  %7 = cmpxchg i64* %stack_peak, i64 %old_val.0.i, i64 %4 seq_cst seq_cst
  %8 = extractvalue { i64, i1 } %7, 0
  %cmp1.i = icmp eq i64 %old_val.0.i, %8
  br i1 %cmp1.i, label %for.inc.loopexit, label %while.cond.i, !llvm.loop !383

for.inc.loopexit:                                 ; preds = %while.body.i, %while.cond.i
  %.pre = load i32, i32* %0, align 8, !tbaa !350
  br label %for.inc

for.inc:                                          ; preds = %for.inc.loopexit, %for.body
  %9 = phi i32 [ %.pre, %for.inc.loopexit ], [ %3, %for.body ]
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %10 = sext i32 %9 to i64
  %cmp1 = icmp slt i64 %indvars.iv.next, %10
  br i1 %cmp1, label %for.body, label %for.cond.cleanup, !llvm.loop !384
}

; Function Attrs: nounwind mustprogress
define weak void @halide_profiler_memory_allocate(i8* %user_context, i8* %pipeline_state, i32 %func_id, i64 %incr) local_unnamed_addr #0 {
entry:
  %cmp = icmp eq i64 %incr, 0
  br i1 %cmp, label %return, label %if.end

if.end:                                           ; preds = %entry
  %cmp1.not = icmp eq i8* %pipeline_state, null
  br i1 %cmp1.not, label %if.then2, label %do.body4

if.then2:                                         ; preds = %if.end
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([128 x i8], [128 x i8]* @.str.1.187, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.body4

do.body4:                                         ; preds = %if.then2, %if.end
  %cmp5 = icmp sgt i32 %func_id, -1
  br i1 %cmp5, label %do.body10, label %if.then6

if.then6:                                         ; preds = %do.body4
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([122 x i8], [122 x i8]* @.str.2.188, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.body10

do.body10:                                        ; preds = %if.then6, %do.body4
  %num_funcs = getelementptr inbounds i8, i8* %pipeline_state, i64 72
  %0 = bitcast i8* %num_funcs to i32*
  %1 = load i32, i32* %0, align 8, !tbaa !350
  %cmp11 = icmp sgt i32 %1, %func_id
  br i1 %cmp11, label %do.end15, label %if.then12

if.then12:                                        ; preds = %do.body10
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([138 x i8], [138 x i8]* @.str.3.189, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end15

do.end15:                                         ; preds = %if.then12, %do.body10
  %funcs = getelementptr inbounds i8, i8* %pipeline_state, i64 56
  %2 = bitcast i8* %funcs to %struct.halide_profiler_func_stats**
  %3 = load %struct.halide_profiler_func_stats*, %struct.halide_profiler_func_stats** %2, align 8, !tbaa !351
  %idxprom = sext i32 %func_id to i64
  %num_allocs = getelementptr inbounds i8, i8* %pipeline_state, i64 88
  %4 = bitcast i8* %num_allocs to i32*
  %5 = atomicrmw add i32* %4, i32 1 seq_cst
  %memory_total = getelementptr inbounds i8, i8* %pipeline_state, i64 24
  %6 = bitcast i8* %memory_total to i64*
  %7 = atomicrmw add i64* %6, i64 %incr seq_cst
  %memory_current = getelementptr inbounds i8, i8* %pipeline_state, i64 8
  %8 = bitcast i8* %memory_current to i64*
  %9 = atomicrmw add i64* %8, i64 %incr seq_cst
  %10 = add i64 %9, %incr
  %memory_peak = getelementptr inbounds i8, i8* %pipeline_state, i64 16
  %11 = bitcast i8* %memory_peak to i64*
  %12 = load i64, i64* %11, align 8, !tbaa !22
  br label %while.cond.i

while.cond.i:                                     ; preds = %while.body.i, %do.end15
  %old_val.0.i = phi i64 [ %12, %do.end15 ], [ %14, %while.body.i ]
  %cmp.i = icmp ult i64 %old_val.0.i, %10
  br i1 %cmp.i, label %while.body.i, label %_ZN12_GLOBAL__N_125sync_compare_max_and_swapIyEEvPT_S1_.exit

while.body.i:                                     ; preds = %while.cond.i
  %13 = cmpxchg i64* %11, i64 %old_val.0.i, i64 %10 seq_cst seq_cst
  %14 = extractvalue { i64, i1 } %13, 0
  %cmp1.i = icmp eq i64 %old_val.0.i, %14
  br i1 %cmp1.i, label %_ZN12_GLOBAL__N_125sync_compare_max_and_swapIyEEvPT_S1_.exit, label %while.cond.i, !llvm.loop !383

_ZN12_GLOBAL__N_125sync_compare_max_and_swapIyEEvPT_S1_.exit: ; preds = %while.body.i, %while.cond.i
  %num_allocs16 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %3, i64 %idxprom, i32 8
  %15 = atomicrmw add i32* %num_allocs16, i32 1 seq_cst
  %memory_total17 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %3, i64 %idxprom, i32 3
  %16 = atomicrmw add i64* %memory_total17, i64 %incr seq_cst
  %memory_current18 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %3, i64 %idxprom, i32 1
  %17 = atomicrmw add i64* %memory_current18, i64 %incr seq_cst
  %18 = add i64 %17, %incr
  %memory_peak19 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %3, i64 %idxprom, i32 2
  %19 = load i64, i64* %memory_peak19, align 8, !tbaa !22
  br label %while.cond.i43

while.cond.i43:                                   ; preds = %while.body.i45, %_ZN12_GLOBAL__N_125sync_compare_max_and_swapIyEEvPT_S1_.exit
  %old_val.0.i41 = phi i64 [ %19, %_ZN12_GLOBAL__N_125sync_compare_max_and_swapIyEEvPT_S1_.exit ], [ %21, %while.body.i45 ]
  %cmp.i42 = icmp ult i64 %old_val.0.i41, %18
  br i1 %cmp.i42, label %while.body.i45, label %return

while.body.i45:                                   ; preds = %while.cond.i43
  %20 = cmpxchg i64* %memory_peak19, i64 %old_val.0.i41, i64 %18 seq_cst seq_cst
  %21 = extractvalue { i64, i1 } %20, 0
  %cmp1.i44 = icmp eq i64 %old_val.0.i41, %21
  br i1 %cmp1.i44, label %return, label %while.cond.i43, !llvm.loop !383

return:                                           ; preds = %while.body.i45, %while.cond.i43, %entry
  ret void
}

; Function Attrs: nounwind mustprogress
define weak void @halide_profiler_memory_free(i8* %user_context, i8* %pipeline_state, i32 %func_id, i64 %decr) local_unnamed_addr #0 {
entry:
  %cmp = icmp eq i64 %decr, 0
  br i1 %cmp, label %return, label %if.end

if.end:                                           ; preds = %entry
  %cmp1.not = icmp eq i8* %pipeline_state, null
  br i1 %cmp1.not, label %if.then2, label %do.body4

if.then2:                                         ; preds = %if.end
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([128 x i8], [128 x i8]* @.str.4.190, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.body4

do.body4:                                         ; preds = %if.then2, %if.end
  %cmp5 = icmp sgt i32 %func_id, -1
  br i1 %cmp5, label %do.body10, label %if.then6

if.then6:                                         ; preds = %do.body4
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([122 x i8], [122 x i8]* @.str.5.191, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.body10

do.body10:                                        ; preds = %if.then6, %do.body4
  %num_funcs = getelementptr inbounds i8, i8* %pipeline_state, i64 72
  %0 = bitcast i8* %num_funcs to i32*
  %1 = load i32, i32* %0, align 8, !tbaa !350
  %cmp11 = icmp sgt i32 %1, %func_id
  br i1 %cmp11, label %do.end15, label %if.then12

if.then12:                                        ; preds = %do.body10
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([138 x i8], [138 x i8]* @.str.6.192, i64 0, i64 0)) #14
  tail call void @abort() #14
  br label %do.end15

do.end15:                                         ; preds = %if.then12, %do.body10
  %funcs = getelementptr inbounds i8, i8* %pipeline_state, i64 56
  %2 = bitcast i8* %funcs to %struct.halide_profiler_func_stats**
  %3 = load %struct.halide_profiler_func_stats*, %struct.halide_profiler_func_stats** %2, align 8, !tbaa !351
  %idxprom = sext i32 %func_id to i64
  %memory_current = getelementptr inbounds i8, i8* %pipeline_state, i64 8
  %4 = bitcast i8* %memory_current to i64*
  %5 = atomicrmw sub i64* %4, i64 %decr seq_cst
  %memory_current16 = getelementptr inbounds %struct.halide_profiler_func_stats, %struct.halide_profiler_func_stats* %3, i64 %idxprom, i32 1
  %6 = atomicrmw sub i64* %memory_current16, i64 %decr seq_cst
  br label %return

return:                                           ; preds = %do.end15, %entry
  ret void
}

; Function Attrs: nounwind
define weak void @halide_profiler_report(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call = tail call %struct.halide_profiler_state* @halide_profiler_get_state() #16
  %lock.i = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 0
  tail call void @halide_mutex_lock(%struct.halide_mutex* %lock.i) #14
  tail call void @halide_profiler_report_unlocked(i8* %user_context, %struct.halide_profiler_state* %call) #16
  tail call void @halide_mutex_unlock(%struct.halide_mutex* %lock.i) #14
  ret void
}

; Function Attrs: nounwind
define weak void @halide_profiler_reset() local_unnamed_addr #4 {
entry:
  %call = tail call %struct.halide_profiler_state* @halide_profiler_get_state() #16
  %lock.i = getelementptr inbounds %struct.halide_profiler_state, %struct.halide_profiler_state* %call, i64 0, i32 0
  tail call void @halide_mutex_lock(%struct.halide_mutex* %lock.i) #14
  tail call void @halide_profiler_reset_unlocked(%struct.halide_profiler_state* %call) #16
  tail call void @halide_mutex_unlock(%struct.halide_mutex* %lock.i) #14
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_profiler_pipeline_end(i8* %user_context, i8* %state) local_unnamed_addr #2 {
entry:
  %current_func = getelementptr inbounds i8, i8* %state, i64 16
  %0 = bitcast i8* %current_func to i32*
  store i32 -1, i32* %0, align 8, !tbaa !339
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* %ptr, i64 %len) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_msan_check_memory_is_initialized(i8* %user_context, i8* %ptr, i64 %len, i8* %name) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_msan_check_buffer_is_initialized(i8* %user_context, %struct.halide_buffer_t* %b, i8* %buf_name) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_msan_annotate_buffer_is_initialized(i8* %user_context, %struct.halide_buffer_t* %b) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_msan_annotate_buffer_is_initialized_as_destructor(i8* %user_context, i8* %b) local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind
define weak i32 @halide_default_can_use_target_features(i32 %count, i64* %features) #4 {
entry:
  %tmp = alloca %"struct.Halide::Runtime::Internal::CpuFeatures", align 8
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal36halide_cpu_features_initialized_lockE) #14
  %0 = load i8, i8* @_ZN6Halide7Runtime8Internal31halide_cpu_features_initializedE, align 1, !tbaa !19, !range !21
  %tobool.not = icmp eq i8 %0, 0
  br i1 %tobool.not, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %1 = bitcast %"struct.Halide::Runtime::Internal::CpuFeatures"* %tmp to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1) #15
  call void @_ZN6Halide7Runtime8Internal23halide_get_cpu_featuresEv(%"struct.Halide::Runtime::Internal::CpuFeatures"* nonnull sret(%"struct.Halide::Runtime::Internal::CpuFeatures") align 8 %tmp) #14
  %call = call i8* @memcpy(i8* bitcast ([4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE to i8*), i8* nonnull %1, i64 32) #14
  store i8 1, i8* @_ZN6Halide7Runtime8Internal31halide_cpu_features_initializedE, align 1, !tbaa !19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1) #15
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal36halide_cpu_features_initialized_lockE) #14
  %cmp.not = icmp eq i32 %count, 2
  br i1 %cmp.not, label %if.end2, label %if.then1

if.then1:                                         ; preds = %if.end
  call void @halide_error(i8* null, i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.197, i64 0, i64 0)) #14
  br label %if.end2

if.end2:                                          ; preds = %if.then1, %if.end
  %2 = load i64, i64* %features, align 8, !tbaa !22
  %3 = load i64, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE, i64 0, i64 0), align 8, !tbaa !22
  %and = and i64 %3, %2
  %cmp6.not = icmp eq i64 %and, 0
  br i1 %cmp6.not, label %for.inc.critedge, label %if.then7

if.then7:                                         ; preds = %if.end2
  %4 = load i64, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE, i64 0, i64 2), align 8, !tbaa !22
  %and10 = and i64 %4, %and
  %cmp11.not = icmp eq i64 %and10, %and
  br i1 %cmp11.not, label %for.inc.critedge, label %cleanup15

for.inc.critedge:                                 ; preds = %if.then7, %if.end2
  %arrayidx.1 = getelementptr inbounds i64, i64* %features, i64 1
  %5 = load i64, i64* %arrayidx.1, align 8, !tbaa !22
  %6 = load i64, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE, i64 0, i64 1), align 8, !tbaa !22
  %and.1 = and i64 %6, %5
  %cmp6.not.1 = icmp eq i64 %and.1, 0
  br i1 %cmp6.not.1, label %for.inc.critedge.1, label %if.then7.1

cleanup15:                                        ; preds = %for.inc.critedge.1, %if.then7.1, %if.then7
  %cmp3.lcssa = phi i32 [ 0, %if.then7 ], [ 0, %if.then7.1 ], [ 1, %for.inc.critedge.1 ]
  ret i32 %cmp3.lcssa

if.then7.1:                                       ; preds = %for.inc.critedge
  %7 = load i64, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE, i64 0, i64 3), align 8, !tbaa !22
  %and10.1 = and i64 %7, %and.1
  %cmp11.not.1 = icmp eq i64 %and10.1, %and.1
  br i1 %cmp11.not.1, label %for.inc.critedge.1, label %cleanup15

for.inc.critedge.1:                               ; preds = %if.then7.1, %for.inc.critedge
  br label %cleanup15
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 (i32, i64*)* @halide_set_custom_can_use_target_features(i32 (i32, i64*)* %fn) local_unnamed_addr #2 {
entry:
  %0 = load i32 (i32, i64*)*, i32 (i32, i64*)** @_ZN6Halide7Runtime8Internal30custom_can_use_target_featuresE, align 8, !tbaa !14
  store i32 (i32, i64*)* %fn, i32 (i32, i64*)** @_ZN6Halide7Runtime8Internal30custom_can_use_target_featuresE, align 8, !tbaa !14
  ret i32 (i32, i64*)* %0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_can_use_target_features(i32 %count, i64* %features) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i32, i64*)*, i32 (i32, i64*)** @_ZN6Halide7Runtime8Internal30custom_can_use_target_featuresE, align 8, !tbaa !14
  %call = tail call i32 %0(i32 %count, i64* %features) #14
  ret i32 %call
}

; Function Attrs: nounwind willreturn
define linkonce void @_ZN6Halide7Runtime8Internal23halide_get_cpu_featuresEv(%"struct.Halide::Runtime::Internal::CpuFeatures"* noalias sret(%"struct.Halide::Runtime::Internal::CpuFeatures") align 8 %agg.result) local_unnamed_addr #8 {
entry:
  %arrayidx3.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::CpuFeatures", %"struct.Halide::Runtime::Internal::CpuFeatures"* %agg.result, i64 0, i32 1, i64 0
  %0 = bitcast %"struct.Halide::Runtime::Internal::CpuFeatures"* %agg.result to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %0, align 8, !tbaa !22
  %1 = bitcast i64* %arrayidx3.i to <2 x i64>*
  store <2 x i64> zeroinitializer, <2 x i64>* %1, align 8, !tbaa !22
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_use_jit_module() local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_release_jit_module() local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16>, <4 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <4 x i16> @llvm.aarch64.neon.sqadd.v4i16(<4 x i16>, <4 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16>, <8 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <2 x i32> @llvm.aarch64.neon.sqadd.v2i32(<2 x i32>, <2 x i32>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16>, <4 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16>, <8 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16>, <8 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32>, <2 x i32>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <4 x i16> @llvm.aarch64.neon.sshl.v4i16(<4 x i16>, <4 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16>, <8 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16>, <8 x i16>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <2 x i32> @llvm.aarch64.neon.sshl.v2i32(<2 x i32>, <2 x i32>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16>, <8 x i16>) #9

; Function Attrs: nofree nounwind
define i32 @softmax(%struct.halide_buffer_t* noalias nocapture readonly %input.buffer, i16 %beta_multiplier, i16 %beta_shift, i8 %output_zero, i16 %output_multiplier, i16 %output_shift, %struct.halide_buffer_t* noalias nocapture readonly %output.buffer) local_unnamed_addr #10 {
entry:
  %inv_sum_exp_row170 = alloca <4 x i16>, align 16
  %sum_exp_row171 = alloca [4 x i32], align 16
  %sum_exp_row1714465 = bitcast [4 x i32]* %sum_exp_row171 to i8*
  %max_x172 = alloca i32, align 16
  %tmpcast = bitcast i32* %max_x172 to [4 x i8]*
  %max_x172.sub = bitcast i32* %max_x172 to i8*
  %host.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %input.buffer, i64 0, i32 2
  %0 = load i8*, i8** %host.i, align 8, !tbaa !180
  %dim.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %input.buffer, i64 0, i32 6
  %1 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i, align 8, !tbaa !184
  %min.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %1, i64 0, i32 0
  %2 = load i32, i32* %min.i, align 4, !tbaa !221
  %extent.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %1, i64 0, i32 1
  %3 = load i32, i32* %extent.i, align 4, !tbaa !189
  %min.i4378 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %1, i64 1, i32 0
  %4 = load i32, i32* %min.i4378, align 4, !tbaa !221
  %stride.i4380 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %1, i64 1, i32 2
  %5 = load i32, i32* %stride.i4380, align 4, !tbaa !185
  %host.i4381 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %output.buffer, i64 0, i32 2
  %6 = load i8*, i8** %host.i4381, align 8, !tbaa !180
  %dim.i4382 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %output.buffer, i64 0, i32 6
  %7 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i4382, align 8, !tbaa !184
  %min.i4383 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %7, i64 0, i32 0
  %8 = load i32, i32* %min.i4383, align 4, !tbaa !221
  %extent.i4385 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %7, i64 0, i32 1
  %9 = load i32, i32* %extent.i4385, align 4, !tbaa !189
  %min.i4389 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %7, i64 1, i32 0
  %10 = load i32, i32* %min.i4389, align 4, !tbaa !221
  %extent.i4391 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %7, i64 1, i32 1
  %11 = load i32, i32* %extent.i4391, align 4, !tbaa !189
  %stride.i4393 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %7, i64 1, i32 2
  %12 = load i32, i32* %stride.i4393, align 4, !tbaa !185
  %a0 = ashr i32 %3, 6
  %13 = icmp sgt i32 %3, 63
  %t305 = select i1 %13, i32 %a0, i32 0
  %14 = add nsw i32 %3, 63
  %15 = ashr i32 %14, 6
  %a1 = sub nsw i32 %15, %t305
  %16 = icmp sgt i32 %a1, 0
  %t303 = sub nsw i32 %10, %4
  %17 = mul nsw i32 %5, %4
  %t301 = sub i16 15, %beta_shift
  %18 = mul nsw i32 %12, %10
  %t304 = add nsw i32 %18, %8
  %19 = icmp sgt i32 %11, 0
  br i1 %19, label %"for output.s0.y.y.preheader", label %destructor_block, !prof !385

"for output.s0.y.y.preheader":                    ; preds = %entry
  %20 = add nsw i32 %9, 127
  %t302 = ashr i32 %20, 7
  %21 = add nsw i32 %11, 3
  %t297 = ashr i32 %21, 2
  %t300 = select i1 %16, i32 %a1, i32 0
  %22 = insertelement <64 x i16> undef, i16 %beta_multiplier, i32 0
  %23 = shufflevector <64 x i16> %22, <64 x i16> undef, <8 x i32> zeroinitializer
  %24 = insertelement <64 x i16> undef, i16 %beta_shift, i32 0
  %25 = shufflevector <64 x i16> %24, <64 x i16> undef, <64 x i32> zeroinitializer
  %26 = insertelement <64 x i16> undef, i16 %t301, i32 0
  %27 = shufflevector <64 x i16> %26, <64 x i16> undef, <8 x i32> zeroinitializer
  %28 = insertelement <4 x i16> undef, i16 %beta_multiplier, i32 0
  %29 = insertelement <4 x i16> undef, i16 %t301, i32 0
  %30 = icmp sgt i32 %9, 0
  %31 = insertelement <64 x i16> undef, i16 %output_multiplier, i32 0
  %32 = shufflevector <64 x i16> %31, <64 x i16> undef, <8 x i32> zeroinitializer
  %33 = sub i16 0, %output_shift
  %34 = insertelement <64 x i16> undef, i16 %33, i32 0
  %35 = shufflevector <64 x i16> %34, <64 x i16> undef, <8 x i32> zeroinitializer
  %36 = zext i8 %output_zero to i16
  %37 = insertelement <64 x i16> undef, i16 %36, i32 0
  %38 = shufflevector <64 x i16> %37, <64 x i16> undef, <8 x i32> zeroinitializer
  %39 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 1
  %40 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 1
  %41 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 2
  %42 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 2
  %43 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 3
  %44 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 3
  %45 = zext i32 %t305 to i64
  %46 = zext i32 %t300 to i64
  %47 = zext i32 %t302 to i64
  %48 = sext i32 %8 to i64
  %49 = zext i32 %t297 to i64
  %.neg4597 = mul i32 %t305, -64
  %50 = add i32 %.neg4597, %3
  br label %"for output.s0.y.y"

"for output.s0.y.y":                              ; preds = %"for output.s0.y.y.preheader", %"end for output.s0.x.x"
  %indvars.iv4493 = phi i64 [ 0, %"for output.s0.y.y.preheader" ], [ %indvars.iv.next4494, %"end for output.s0.x.x" ]
  store i32 0, i32* %max_x172, align 16
  %51 = trunc i64 %indvars.iv4493 to i32
  %52 = shl nsw i32 %51, 2
  %t306 = add nsw i32 %52, %10
  br label %"for max_x.s1.y.rebased"

"end for output.s0.y.y":                          ; preds = %"end for output.s0.x.x"
  %.pre = load i32, i32* %min.i, align 4, !tbaa !221
  %.pre4533 = load i32, i32* %extent.i, align 4, !tbaa !189
  %.pre4534 = load i32, i32* %min.i4378, align 4, !tbaa !221
  %.pre4535 = load i32, i32* %stride.i4380, align 4, !tbaa !185
  %.pre4536 = load i32, i32* %min.i4383, align 4, !tbaa !221
  %.pre4537 = load i32, i32* %extent.i4385, align 4, !tbaa !189
  %.pre4538 = load i32, i32* %min.i4389, align 4, !tbaa !221
  %.pre4539 = load i32, i32* %extent.i4391, align 4, !tbaa !189
  %.pre4540 = load i32, i32* %stride.i4393, align 4, !tbaa !185
  %.pre4541 = ashr i32 %.pre4533, 6
  %.pre4542 = add nsw i32 %.pre4533, 63
  %.pre4543 = ashr i32 %.pre4542, 6
  %.pre4551 = mul nsw i32 %.pre4535, %.pre4534
  %53 = icmp sgt i32 %.pre4533, 63
  %t30525 = select i1 %53, i32 %.pre4541, i32 0
  %a47 = sub nsw i32 %.pre4543, %t30525
  %54 = icmp sgt i32 %a47, 0
  %55 = icmp sgt i32 %.pre4539, 0
  br i1 %55, label %"for output.s0.y.y33.preheader", label %destructor_block, !prof !385

"for output.s0.y.y33.preheader":                  ; preds = %"end for output.s0.y.y"
  %.pre4548 = add nsw i32 %.pre4537, 127
  %.pre4550 = ashr i32 %.pre4548, 7
  %.pre4545 = add nsw i32 %.pre4539, 3
  %.pre4547 = ashr i32 %.pre4545, 2
  %t30026 = select i1 %54, i32 %a47, i32 0
  %56 = mul nsw i32 %.pre4540, %.pre4538
  %57 = insertelement <8 x i16> undef, i16 %beta_multiplier, i32 0
  %58 = shufflevector <8 x i16> %57, <8 x i16> undef, <8 x i32> zeroinitializer
  %59 = sub i16 0, %beta_shift
  %60 = insertelement <64 x i16> undef, i16 %59, i32 0
  %61 = shufflevector <64 x i16> %60, <64 x i16> undef, <64 x i32> zeroinitializer
  %.scalar = shl i16 -1, %beta_shift
  %.scalar4599 = xor i16 %.scalar, -1
  %62 = insertelement <64 x i16> poison, i16 %.scalar4599, i64 0
  %.not4333 = shufflevector <64 x i16> %62, <64 x i16> undef, <64 x i32> zeroinitializer
  %63 = insertelement <64 x i16> undef, i16 %t301, i32 0
  %64 = shufflevector <64 x i16> %63, <64 x i16> undef, <8 x i32> zeroinitializer
  %65 = insertelement <4 x i16> undef, i16 %beta_multiplier, i32 0
  %66 = insertelement <4 x i16> undef, i16 %t301, i32 0
  %67 = sub nsw i32 %.pre4538, %.pre4534
  %68 = add nsw i32 %56, %.pre4536
  %69 = icmp sgt i32 %.pre4537, 0
  %t379 = shl nuw i16 1, %output_shift
  %70 = insertelement <8 x i16> undef, i16 %output_multiplier, i32 0
  %71 = shufflevector <8 x i16> %70, <8 x i16> undef, <8 x i32> zeroinitializer
  %72 = ashr i16 %t379, 1
  %73 = insertelement <8 x i16> undef, i16 %72, i32 0
  %74 = shufflevector <8 x i16> %73, <8 x i16> undef, <8 x i32> zeroinitializer
  %75 = sub i16 0, %output_shift
  %76 = insertelement <8 x i16> undef, i16 %75, i32 0
  %77 = shufflevector <8 x i16> %76, <8 x i16> undef, <8 x i32> zeroinitializer
  %78 = zext i8 %output_zero to i16
  %79 = insertelement <8 x i16> undef, i16 %78, i32 0
  %80 = shufflevector <8 x i16> %79, <8 x i16> undef, <8 x i32> zeroinitializer
  %81 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 1
  %82 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 1
  %83 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 2
  %84 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 2
  %85 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 3
  %86 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 3
  %87 = zext i32 %t30525 to i64
  %88 = zext i32 %t30026 to i64
  %89 = zext i32 %.pre4550 to i64
  %90 = sext i32 %.pre4536 to i64
  %91 = zext i32 %.pre4547 to i64
  %.neg4598 = mul i32 %t30525, -64
  %92 = add i32 %.neg4598, %.pre4533
  br label %"for output.s0.y.y33"

"for max_x.s1.y.rebased":                         ; preds = %"for output.s0.y.y", %"end for max_x.s1.r6$x.r6$x.rebased"
  %indvars.iv4463 = phi i64 [ 0, %"for output.s0.y.y" ], [ %indvars.iv.next4464, %"end for max_x.s1.r6$x.r6$x.rebased" ]
  %93 = trunc i64 %indvars.iv4463 to i32
  %94 = add i32 %t306, %93
  %95 = mul i32 %94, %5
  %t307 = sub i32 %95, %17
  br i1 %13, label %"for max_x.s1.r6$x.r6$x.preheader", label %"end for max_x.s1.r6$x.r6$x", !prof !385

"for max_x.s1.r6$x.r6$x.preheader":               ; preds = %"for max_x.s1.y.rebased"
  %96 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 %indvars.iv4463
  %97 = sext i32 %t307 to i64
  %.promoted = load i8, i8* %96, align 1, !tbaa !386
  br label %"for max_x.s1.r6$x.r6$x"

"for max_x.s1.r6$x.r6$x":                         ; preds = %"for max_x.s1.r6$x.r6$x.preheader", %"for max_x.s1.r6$x.r6$x"
  %indvars.iv = phi i64 [ 0, %"for max_x.s1.r6$x.r6$x.preheader" ], [ %indvars.iv.next, %"for max_x.s1.r6$x.r6$x" ]
  %a24432 = phi i8 [ %.promoted, %"for max_x.s1.r6$x.r6$x.preheader" ], [ %116, %"for max_x.s1.r6$x.r6$x" ]
  %98 = shl nuw nsw i64 %indvars.iv, 6
  %99 = add nsw i64 %98, %97
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  %101 = bitcast i8* %100 to <16 x i8>*
  %102 = load <16 x i8>, <16 x i8>* %101, align 1, !tbaa !389
  %103 = getelementptr inbounds i8, i8* %100, i64 16
  %104 = bitcast i8* %103 to <16 x i8>*
  %105 = load <16 x i8>, <16 x i8>* %104, align 1, !tbaa !389
  %106 = getelementptr inbounds i8, i8* %100, i64 32
  %107 = bitcast i8* %106 to <16 x i8>*
  %108 = load <16 x i8>, <16 x i8>* %107, align 1, !tbaa !389
  %109 = getelementptr inbounds i8, i8* %100, i64 48
  %110 = bitcast i8* %109 to <16 x i8>*
  %111 = load <16 x i8>, <16 x i8>* %110, align 1, !tbaa !389
  %112 = shufflevector <16 x i8> %102, <16 x i8> %105, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %113 = shufflevector <16 x i8> %108, <16 x i8> %111, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %114 = shufflevector <32 x i8> %112, <32 x i8> %113, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %b4 = tail call i8 @llvm.vector.reduce.umax.v64i8(<64 x i8> %114) #17
  %115 = icmp ugt i8 %a24432, %b4
  %116 = select i1 %115, i8 %a24432, i8 %b4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %.not4374 = icmp eq i64 %indvars.iv.next, %45
  br i1 %.not4374, label %"end for max_x.s1.r6$x.r6$x.loopexit", label %"for max_x.s1.r6$x.r6$x"

"end for max_x.s1.r6$x.r6$x.loopexit":            ; preds = %"for max_x.s1.r6$x.r6$x"
  store i8 %116, i8* %96, align 1, !tbaa !386
  br label %"end for max_x.s1.r6$x.r6$x"

"end for max_x.s1.r6$x.r6$x":                     ; preds = %"end for max_x.s1.r6$x.r6$x.loopexit", %"for max_x.s1.y.rebased"
  br i1 %16, label %"for max_x.s1.r6$x.r6$x.rebased.preheader", label %"end for max_x.s1.r6$x.r6$x.rebased", !prof !385

"for max_x.s1.r6$x.r6$x.rebased.preheader":       ; preds = %"end for max_x.s1.r6$x.r6$x"
  %117 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 %indvars.iv4463
  br label %"for max_x.s1.r6$x.r6$x.rebased"

"for max_x.s1.r6$x.r6$x.rebased":                 ; preds = %"for max_x.s1.r6$x.r6$x.rebased.preheader", %"end for max_x.s1.r6$x.r34"
  %indvars.iv4461 = phi i64 [ 0, %"for max_x.s1.r6$x.r6$x.rebased.preheader" ], [ %indvars.iv.next4462, %"end for max_x.s1.r6$x.r34" ]
  %118 = trunc i64 %indvars.iv4461 to i32
  %119 = mul i32 %118, -64
  %120 = add i32 %119, %50
  %121 = icmp slt i32 %120, 64
  %smin = select i1 %121, i32 %120, i32 64
  %122 = zext i32 %smin to i64
  %123 = trunc i64 %indvars.iv4461 to i32
  %124 = add i32 %t305, %123
  %125 = shl nsw i32 %124, 6
  %a3 = sub nsw i32 %3, %125
  %126 = icmp sgt i32 %a3, 0
  br i1 %126, label %"for max_x.s1.r6$x.r34.preheader", label %"end for max_x.s1.r6$x.r34", !prof !385

"for max_x.s1.r6$x.r34.preheader":                ; preds = %"for max_x.s1.r6$x.r6$x.rebased"
  %127 = icmp slt i32 %a3, 64
  %t309 = select i1 %127, i32 %a3, i32 64
  %t310 = add nsw i32 %125, %t307
  %128 = sext i32 %t310 to i64
  %.promoted4434 = load i8, i8* %117, align 1, !tbaa !386
  %129 = zext i32 %t309 to i64
  %min.iters.check = icmp ult i32 %smin, 32
  br i1 %min.iters.check, label %"for max_x.s1.r6$x.r34.preheader4607", label %vector.ph

vector.ph:                                        ; preds = %"for max_x.s1.r6$x.r34.preheader"
  %n.vec = and i64 %122, 4294967264
  %minmax.ident.splatinsert = insertelement <16 x i8> poison, i8 %.promoted4434, i32 0
  %minmax.ident.splat = shufflevector <16 x i8> %minmax.ident.splatinsert, <16 x i8> poison, <16 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vec.phi = phi <16 x i8> [ %minmax.ident.splat, %vector.ph ], [ %137, %vector.body ]
  %vec.phi4574 = phi <16 x i8> [ %minmax.ident.splat, %vector.ph ], [ %138, %vector.body ]
  %130 = add nsw i64 %index, %128
  %131 = getelementptr inbounds i8, i8* %0, i64 %130
  %132 = bitcast i8* %131 to <16 x i8>*
  %wide.load = load <16 x i8>, <16 x i8>* %132, align 1, !tbaa !389
  %133 = getelementptr inbounds i8, i8* %131, i64 16
  %134 = bitcast i8* %133 to <16 x i8>*
  %wide.load4575 = load <16 x i8>, <16 x i8>* %134, align 1, !tbaa !389
  %135 = icmp ugt <16 x i8> %vec.phi, %wide.load
  %136 = icmp ugt <16 x i8> %vec.phi4574, %wide.load4575
  %137 = select <16 x i1> %135, <16 x i8> %vec.phi, <16 x i8> %wide.load
  %138 = select <16 x i1> %136, <16 x i8> %vec.phi4574, <16 x i8> %wide.load4575
  %index.next = add i64 %index, 32
  %139 = icmp eq i64 %index.next, %n.vec
  br i1 %139, label %middle.block, label %vector.body, !llvm.loop !391

middle.block:                                     ; preds = %vector.body
  %rdx.minmax.cmp = icmp ugt <16 x i8> %137, %138
  %rdx.minmax.select = select <16 x i1> %rdx.minmax.cmp, <16 x i8> %137, <16 x i8> %138
  %140 = call i8 @llvm.vector.reduce.umax.v16i8(<16 x i8> %rdx.minmax.select)
  %cmp.n = icmp eq i64 %n.vec, %122
  br i1 %cmp.n, label %"end for max_x.s1.r6$x.r34.loopexit", label %"for max_x.s1.r6$x.r34.preheader4607"

"for max_x.s1.r6$x.r34.preheader4607":            ; preds = %"for max_x.s1.r6$x.r34.preheader", %middle.block
  %indvars.iv4459.ph = phi i64 [ 0, %"for max_x.s1.r6$x.r34.preheader" ], [ %n.vec, %middle.block ]
  %a44435.ph = phi i8 [ %.promoted4434, %"for max_x.s1.r6$x.r34.preheader" ], [ %140, %middle.block ]
  br label %"for max_x.s1.r6$x.r34"

"end for max_x.s1.r6$x.r6$x.rebased":             ; preds = %"end for max_x.s1.r6$x.r34", %"end for max_x.s1.r6$x.r6$x"
  %indvars.iv.next4464 = add nuw nsw i64 %indvars.iv4463, 1
  %.not4355 = icmp eq i64 %indvars.iv.next4464, 4
  br i1 %.not4355, label %"for sum_exp_row.s0.y.rebased.preheader", label %"for max_x.s1.y.rebased"

"for sum_exp_row.s0.y.rebased.preheader":         ; preds = %"end for max_x.s1.r6$x.r6$x.rebased"
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 dereferenceable(16) %sum_exp_row1714465, i8 0, i64 16, i1 false)
  br label %"for sum_exp_row.s1.y.rebased"

"for max_x.s1.r6$x.r34":                          ; preds = %"for max_x.s1.r6$x.r34.preheader4607", %"for max_x.s1.r6$x.r34"
  %indvars.iv4459 = phi i64 [ %indvars.iv.next4460, %"for max_x.s1.r6$x.r34" ], [ %indvars.iv4459.ph, %"for max_x.s1.r6$x.r34.preheader4607" ]
  %a44435 = phi i8 [ %144, %"for max_x.s1.r6$x.r34" ], [ %a44435.ph, %"for max_x.s1.r6$x.r34.preheader4607" ]
  %141 = add nsw i64 %indvars.iv4459, %128
  %142 = getelementptr inbounds i8, i8* %0, i64 %141
  %b6 = load i8, i8* %142, align 1, !tbaa !389
  %143 = icmp ugt i8 %a44435, %b6
  %144 = select i1 %143, i8 %a44435, i8 %b6
  %indvars.iv.next4460 = add nuw nsw i64 %indvars.iv4459, 1
  %.not4373 = icmp eq i64 %indvars.iv.next4460, %129
  br i1 %.not4373, label %"end for max_x.s1.r6$x.r34.loopexit", label %"for max_x.s1.r6$x.r34", !llvm.loop !392

"end for max_x.s1.r6$x.r34.loopexit":             ; preds = %"for max_x.s1.r6$x.r34", %middle.block
  %.lcssa4571 = phi i8 [ %140, %middle.block ], [ %144, %"for max_x.s1.r6$x.r34" ]
  store i8 %.lcssa4571, i8* %117, align 1, !tbaa !386
  br label %"end for max_x.s1.r6$x.r34"

"end for max_x.s1.r6$x.r34":                      ; preds = %"end for max_x.s1.r6$x.r34.loopexit", %"for max_x.s1.r6$x.r6$x.rebased"
  %indvars.iv.next4462 = add nuw nsw i64 %indvars.iv4461, 1
  %.not4372 = icmp eq i64 %indvars.iv.next4462, %46
  br i1 %.not4372, label %"end for max_x.s1.r6$x.r6$x.rebased", label %"for max_x.s1.r6$x.r6$x.rebased"

"for sum_exp_row.s1.y.rebased":                   ; preds = %"for sum_exp_row.s0.y.rebased.preheader", %"end for sum_exp_row.s1.r6$x.r6$x.rebased"
  %indvars.iv4474 = phi i64 [ 0, %"for sum_exp_row.s0.y.rebased.preheader" ], [ %indvars.iv.next4475, %"end for sum_exp_row.s1.r6$x.r6$x.rebased" ]
  %145 = trunc i64 %indvars.iv4474 to i32
  %146 = add i32 %t306, %145
  %147 = mul i32 %146, %5
  %t313 = sub i32 %147, %17
  br i1 %13, label %"for sum_exp_row.s1.r6$x.r6$x.preheader", label %"end for sum_exp_row.s1.r6$x.r6$x", !prof !385

"for sum_exp_row.s1.r6$x.r6$x.preheader":         ; preds = %"for sum_exp_row.s1.y.rebased"
  %148 = sext i32 %t313 to i64
  %149 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 %indvars.iv4474
  %150 = load i8, i8* %149, align 1, !tbaa !386
  %151 = zext i8 %150 to i16
  %152 = mul nsw i16 %151, -64
  %153 = insertelement <64 x i16> undef, i16 %152, i32 0
  %154 = shufflevector <64 x i16> %153, <64 x i16> undef, <64 x i32> zeroinitializer
  %155 = getelementptr inbounds [4 x i32], [4 x i32]* %sum_exp_row171, i64 0, i64 %indvars.iv4474
  %.promoted4437 = load i32, i32* %155, align 4, !tbaa !393
  br label %"for sum_exp_row.s1.r6$x.r6$x"

"for sum_exp_row.s1.r6$x.r6$x":                   ; preds = %"for sum_exp_row.s1.r6$x.r6$x.preheader", %"for sum_exp_row.s1.r6$x.r6$x"
  %indvars.iv4468 = phi i64 [ 0, %"for sum_exp_row.s1.r6$x.r6$x.preheader" ], [ %indvars.iv.next4469, %"for sum_exp_row.s1.r6$x.r6$x" ]
  %156 = phi i32 [ %.promoted4437, %"for sum_exp_row.s1.r6$x.r6$x.preheader" ], [ %336, %"for sum_exp_row.s1.r6$x.r6$x" ]
  %157 = shl nuw nsw i64 %indvars.iv4468, 6
  %158 = add nsw i64 %157, %148
  %159 = getelementptr inbounds i8, i8* %0, i64 %158
  %160 = bitcast i8* %159 to <16 x i8>*
  %161 = load <16 x i8>, <16 x i8>* %160, align 1, !tbaa !389
  %162 = getelementptr inbounds i8, i8* %159, i64 16
  %163 = bitcast i8* %162 to <16 x i8>*
  %164 = load <16 x i8>, <16 x i8>* %163, align 1, !tbaa !389
  %165 = getelementptr inbounds i8, i8* %159, i64 32
  %166 = bitcast i8* %165 to <16 x i8>*
  %167 = load <16 x i8>, <16 x i8>* %166, align 1, !tbaa !389
  %168 = getelementptr inbounds i8, i8* %159, i64 48
  %169 = bitcast i8* %168 to <16 x i8>*
  %170 = load <16 x i8>, <16 x i8>* %169, align 1, !tbaa !389
  %171 = shufflevector <16 x i8> %161, <16 x i8> %164, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %172 = shufflevector <16 x i8> %167, <16 x i8> %170, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %173 = shufflevector <32 x i8> %171, <32 x i8> %172, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %174 = zext <64 x i8> %173 to <64 x i16>
  %175 = shl nuw nsw <64 x i16> %174, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %176 = add <64 x i16> %154, %175
  %177 = shufflevector <64 x i16> %176, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %178 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %177, <8 x i16> %23)
  %179 = shufflevector <64 x i16> %176, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %180 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %179, <8 x i16> %23)
  %181 = shufflevector <64 x i16> %176, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %182 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %181, <8 x i16> %23)
  %183 = shufflevector <64 x i16> %176, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %184 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %183, <8 x i16> %23)
  %185 = shufflevector <64 x i16> %176, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %186 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %185, <8 x i16> %23)
  %187 = shufflevector <64 x i16> %176, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %188 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %187, <8 x i16> %23)
  %189 = shufflevector <64 x i16> %176, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %190 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %189, <8 x i16> %23)
  %191 = shufflevector <64 x i16> %176, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %192 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %191, <8 x i16> %23)
  %193 = shufflevector <8 x i16> %178, <8 x i16> %180, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %194 = shufflevector <8 x i16> %182, <8 x i16> %184, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %195 = shufflevector <8 x i16> %186, <8 x i16> %188, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %196 = shufflevector <8 x i16> %190, <8 x i16> %192, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %197 = shufflevector <16 x i16> %193, <16 x i16> %194, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %198 = shufflevector <16 x i16> %195, <16 x i16> %196, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %"t101.widened.sum_exp_row.s1.r6$x.r32" = shufflevector <32 x i16> %197, <32 x i16> %198, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %"t102.widened.sum_exp_row.s1.r6$x.r32" = ashr <64 x i16> %"t101.widened.sum_exp_row.s1.r6$x.r32", %25
  %199 = add <64 x i16> %"t102.widened.sum_exp_row.s1.r6$x.r32", <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %200 = shufflevector <64 x i16> %199, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %201 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %200)
  %202 = shufflevector <64 x i16> %199, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %203 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %202)
  %204 = shufflevector <64 x i16> %199, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %205 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %204)
  %206 = shufflevector <64 x i16> %199, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %207 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %206)
  %208 = shufflevector <64 x i16> %199, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %209 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %208)
  %210 = shufflevector <64 x i16> %199, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %211 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %210)
  %212 = shufflevector <64 x i16> %199, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %213 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %212)
  %214 = shufflevector <64 x i16> %199, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %215 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %214)
  %216 = shufflevector <8 x i16> %215, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %217 = shufflevector <16 x i16> %216, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %"t103.widened.sum_exp_row.s1.r6$x.r32" = shufflevector <32 x i16> %217, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %218 = shl <64 x i16> %"t102.widened.sum_exp_row.s1.r6$x.r32", %25
  %219 = sub <64 x i16> %"t101.widened.sum_exp_row.s1.r6$x.r32", %218
  %220 = shufflevector <64 x i16> %219, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %221 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %220, <8 x i16> %27)
  %222 = shufflevector <64 x i16> %219, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %223 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %222, <8 x i16> %27)
  %224 = shufflevector <64 x i16> %219, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %225 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %224, <8 x i16> %27)
  %226 = shufflevector <64 x i16> %219, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %227 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %226, <8 x i16> %27)
  %228 = shufflevector <64 x i16> %219, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %229 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %228, <8 x i16> %27)
  %230 = shufflevector <64 x i16> %219, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %231 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %230, <8 x i16> %27)
  %232 = shufflevector <64 x i16> %219, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %233 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %232, <8 x i16> %27)
  %234 = shufflevector <64 x i16> %219, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %235 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %234, <8 x i16> %27)
  %236 = shufflevector <8 x i16> %235, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %237 = shufflevector <16 x i16> %236, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %"t104.widened.sum_exp_row.s1.r6$x.r32" = shufflevector <32 x i16> %237, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %238 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %221, <8 x i16> %221)
  %239 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %223, <8 x i16> %223)
  %240 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %225, <8 x i16> %225)
  %241 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %227, <8 x i16> %227)
  %242 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %229, <8 x i16> %229)
  %243 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %231, <8 x i16> %231)
  %244 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %233, <8 x i16> %233)
  %245 = shufflevector <64 x i16> %"t104.widened.sum_exp_row.s1.r6$x.r32", <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %246 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %245, <8 x i16> %245)
  %247 = shufflevector <8 x i16> %246, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %248 = shufflevector <16 x i16> %247, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %"t105.widened.sum_exp_row.s1.r6$x.r32" = shufflevector <32 x i16> %248, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %249 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %238)
  %250 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %239)
  %251 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %240)
  %252 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %241)
  %253 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %242)
  %254 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %243)
  %255 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %244)
  %256 = shufflevector <64 x i16> %"t105.widened.sum_exp_row.s1.r6$x.r32", <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %257 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %256)
  %258 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %221)
  %259 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %223)
  %260 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %225)
  %261 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %227)
  %262 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %229)
  %263 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %231)
  %264 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %233)
  %265 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %245)
  %266 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %238, <8 x i16> %221)
  %267 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %239, <8 x i16> %223)
  %268 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %240, <8 x i16> %225)
  %269 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %241, <8 x i16> %227)
  %270 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %242, <8 x i16> %229)
  %271 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %243, <8 x i16> %231)
  %272 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %244, <8 x i16> %233)
  %273 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %256, <8 x i16> %245)
  %274 = shufflevector <8 x i16> %273, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %275 = shufflevector <16 x i16> %274, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %276 = shufflevector <32 x i16> %275, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %277 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %266)
  %278 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %267)
  %279 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %268)
  %280 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %269)
  %281 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %270)
  %282 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %271)
  %283 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %272)
  %284 = shufflevector <64 x i16> %276, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %285 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %284)
  %286 = add <8 x i16> %258, %249
  %287 = add <8 x i16> %286, %277
  %288 = add <8 x i16> %259, %250
  %289 = add <8 x i16> %288, %278
  %290 = add <8 x i16> %260, %251
  %291 = add <8 x i16> %290, %279
  %292 = add <8 x i16> %261, %252
  %293 = add <8 x i16> %292, %280
  %294 = add <8 x i16> %262, %253
  %295 = add <8 x i16> %294, %281
  %296 = add <8 x i16> %263, %254
  %297 = add <8 x i16> %296, %282
  %298 = add <8 x i16> %264, %255
  %299 = add <8 x i16> %298, %283
  %300 = add <8 x i16> %265, %257
  %301 = add <8 x i16> %300, %285
  %302 = shufflevector <8 x i16> %301, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %303 = shufflevector <16 x i16> %302, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %304 = shufflevector <32 x i16> %303, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %305 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %201, <8 x i16> %287)
  %306 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %203, <8 x i16> %289)
  %307 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %205, <8 x i16> %291)
  %308 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %207, <8 x i16> %293)
  %309 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %209, <8 x i16> %295)
  %310 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %211, <8 x i16> %297)
  %311 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %213, <8 x i16> %299)
  %312 = shufflevector <64 x i16> %"t103.widened.sum_exp_row.s1.r6$x.r32", <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %313 = shufflevector <64 x i16> %304, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %314 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %312, <8 x i16> %313)
  %315 = shufflevector <8 x i16> %314, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %316 = shufflevector <16 x i16> %315, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %317 = shufflevector <32 x i16> %316, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %318 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %201, <8 x i16> %305)
  %319 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %203, <8 x i16> %306)
  %320 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %205, <8 x i16> %307)
  %321 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %207, <8 x i16> %308)
  %322 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %209, <8 x i16> %309)
  %323 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %211, <8 x i16> %310)
  %324 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %213, <8 x i16> %311)
  %325 = shufflevector <64 x i16> %317, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %326 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %312, <8 x i16> %325)
  %327 = shufflevector <8 x i16> %318, <8 x i16> %319, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %328 = shufflevector <8 x i16> %320, <8 x i16> %321, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %329 = shufflevector <8 x i16> %322, <8 x i16> %323, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %330 = shufflevector <8 x i16> %324, <8 x i16> %326, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %331 = shufflevector <16 x i16> %327, <16 x i16> %328, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %332 = shufflevector <16 x i16> %329, <16 x i16> %330, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %333 = shufflevector <32 x i16> %331, <32 x i16> %332, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %334 = sext <64 x i16> %333 to <64 x i32>
  %335 = tail call i32 @llvm.vector.reduce.add.v64i32(<64 x i32> %334) #17
  %336 = add nsw i32 %335, %156
  %indvars.iv.next4469 = add nuw nsw i64 %indvars.iv4468, 1
  %.not4371 = icmp eq i64 %indvars.iv.next4469, %45
  br i1 %.not4371, label %"end for sum_exp_row.s1.r6$x.r6$x.loopexit", label %"for sum_exp_row.s1.r6$x.r6$x"

"end for sum_exp_row.s1.r6$x.r6$x.loopexit":      ; preds = %"for sum_exp_row.s1.r6$x.r6$x"
  store i32 %336, i32* %155, align 4, !tbaa !393
  br label %"end for sum_exp_row.s1.r6$x.r6$x"

"end for sum_exp_row.s1.r6$x.r6$x":               ; preds = %"end for sum_exp_row.s1.r6$x.r6$x.loopexit", %"for sum_exp_row.s1.y.rebased"
  br i1 %16, label %"for sum_exp_row.s1.r6$x.r6$x.rebased.preheader", label %"end for sum_exp_row.s1.r6$x.r6$x.rebased", !prof !385

"for sum_exp_row.s1.r6$x.r6$x.rebased.preheader": ; preds = %"end for sum_exp_row.s1.r6$x.r6$x"
  %337 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 %indvars.iv4474
  %338 = getelementptr inbounds [4 x i32], [4 x i32]* %sum_exp_row171, i64 0, i64 %indvars.iv4474
  br label %"for sum_exp_row.s1.r6$x.r6$x.rebased"

"for sum_exp_row.s1.r6$x.r6$x.rebased":           ; preds = %"for sum_exp_row.s1.r6$x.r6$x.rebased.preheader", %"end for sum_exp_row.s1.r6$x.r32"
  %indvars.iv4472 = phi i64 [ 0, %"for sum_exp_row.s1.r6$x.r6$x.rebased.preheader" ], [ %indvars.iv.next4473, %"end for sum_exp_row.s1.r6$x.r32" ]
  %339 = trunc i64 %indvars.iv4472 to i32
  %340 = add i32 %t305, %339
  %341 = shl nsw i32 %340, 6
  %a5 = sub nsw i32 %3, %341
  %342 = icmp sgt i32 %a5, 0
  br i1 %342, label %"for sum_exp_row.s1.r6$x.r32.preheader", label %"end for sum_exp_row.s1.r6$x.r32", !prof !385

"for sum_exp_row.s1.r6$x.r32.preheader":          ; preds = %"for sum_exp_row.s1.r6$x.r6$x.rebased"
  %343 = icmp slt i32 %a5, 64
  %t317 = select i1 %343, i32 %a5, i32 64
  %t318 = add nsw i32 %341, %t313
  %344 = sext i32 %t318 to i64
  %345 = load i8, i8* %337, align 1, !tbaa !386
  %346 = zext i8 %345 to i16
  %.promoted4439 = load i32, i32* %338, align 4, !tbaa !393
  %347 = zext i32 %t317 to i64
  br label %"for sum_exp_row.s1.r6$x.r32"

"end for sum_exp_row.s1.r6$x.r6$x.rebased":       ; preds = %"end for sum_exp_row.s1.r6$x.r32", %"end for sum_exp_row.s1.r6$x.r6$x"
  %indvars.iv.next4475 = add nuw nsw i64 %indvars.iv4474, 1
  %.not4357 = icmp eq i64 %indvars.iv.next4475, 4
  br i1 %.not4357, label %"end for sum_exp_row.s1.r6$x.r6$x.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge", label %"for sum_exp_row.s1.y.rebased"

"end for sum_exp_row.s1.r6$x.r6$x.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge": ; preds = %"end for sum_exp_row.s1.r6$x.r6$x.rebased"
  %.1 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 0
  %.14626 = getelementptr inbounds [4 x i32], [4 x i32]* %sum_exp_row171, i64 0, i64 0
  %indvars.iv.next4477.1 = add nuw nsw i64 0, 1
  br label %"for inv_sum_exp_row.s0.y.rebased"

"for sum_exp_row.s1.r6$x.r32":                    ; preds = %"for sum_exp_row.s1.r6$x.r32.preheader", %"for sum_exp_row.s1.r6$x.r32"
  %indvars.iv4470 = phi i64 [ 0, %"for sum_exp_row.s1.r6$x.r32.preheader" ], [ %indvars.iv.next4471, %"for sum_exp_row.s1.r6$x.r32" ]
  %348 = phi i32 [ %.promoted4439, %"for sum_exp_row.s1.r6$x.r32.preheader" ], [ %424, %"for sum_exp_row.s1.r6$x.r32" ]
  %349 = add nsw i64 %indvars.iv4470, %344
  %350 = getelementptr inbounds i8, i8* %0, i64 %349
  %351 = load i8, i8* %350, align 1, !tbaa !389
  %352 = zext i8 %351 to i16
  %353 = sub nsw i16 %352, %346
  %354 = shl nsw i16 %353, 6
  %355 = insertelement <4 x i16> undef, i16 %354, i32 0
  %356 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %355, <4 x i16> %28)
  %357 = shufflevector <4 x i32> %356, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %358 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %357, <2 x i32> <i32 -15, i32 undef>)
  %a7 = extractelement <2 x i32> %358, i64 0
  %359 = icmp slt i32 %a7, 32767
  %a6 = select i1 %359, i32 %a7, i32 32767
  %360 = icmp sgt i32 %a6, -32768
  %361 = select i1 %360, i32 %a6, i32 -32768
  %t101 = trunc i32 %361 to i16
  %t102 = ashr i16 %t101, %beta_shift
  %362 = add i16 %t102, 15
  %363 = sext i16 %362 to i32
  %364 = insertelement <2 x i32> undef, i32 %363, i32 0
  %365 = tail call <2 x i32> @llvm.aarch64.neon.sshl.v2i32(<2 x i32> <i32 1, i32 undef>, <2 x i32> %364)
  %a9 = extractelement <2 x i32> %365, i64 0
  %366 = icmp slt i32 %a9, 32767
  %a8 = select i1 %366, i32 %a9, i32 32767
  %367 = icmp sgt i32 %a8, -32768
  %368 = select i1 %367, i32 %a8, i32 -32768
  %t103 = trunc i32 %368 to i16
  %369 = shl i16 %t102, %beta_shift
  %370 = sub i16 %t101, %369
  %371 = insertelement <4 x i16> undef, i16 %370, i32 0
  %372 = tail call <4 x i16> @llvm.aarch64.neon.sshl.v4i16(<4 x i16> %371, <4 x i16> %29)
  %373 = shufflevector <4 x i16> %372, <4 x i16> undef, <4 x i32> <i32 0, i32 undef, i32 undef, i32 undef>
  %374 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %373, <4 x i16> %373)
  %375 = shufflevector <4 x i32> %374, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %376 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %375, <2 x i32> <i32 -15, i32 undef>)
  %a11 = extractelement <2 x i32> %376, i64 0
  %377 = icmp slt i32 %a11, 32767
  %a10 = select i1 %377, i32 %a11, i32 32767
  %378 = icmp sgt i32 %a10, -32768
  %379 = select i1 %378, i32 %a10, i32 -32768
  %t105 = trunc i32 %379 to i16
  %380 = insertelement <4 x i16> undef, i16 %t105, i32 0
  %381 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 7363, i16 undef, i16 undef, i16 undef>, <4 x i16> %380)
  %382 = shufflevector <4 x i32> %381, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %383 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %382, <2 x i32> <i32 -15, i32 undef>)
  %a15 = extractelement <2 x i32> %383, i64 0
  %384 = icmp slt i32 %a15, 32767
  %a14 = select i1 %384, i32 %a15, i32 32767
  %385 = icmp sgt i32 %a14, -32768
  %386 = select i1 %385, i32 %a14, i32 -32768
  %387 = trunc i32 %386 to i16
  %388 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 22812, i16 undef, i16 undef, i16 undef>, <4 x i16> %373)
  %389 = shufflevector <4 x i32> %388, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %390 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %389, <2 x i32> <i32 -15, i32 undef>)
  %a17 = extractelement <2 x i32> %390, i64 0
  %391 = icmp slt i32 %a17, 32767
  %a16 = select i1 %391, i32 %a17, i32 32767
  %392 = icmp sgt i32 %a16, -32768
  %393 = select i1 %392, i32 %a16, i32 -32768
  %394 = trunc i32 %393 to i16
  %395 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %380, <4 x i16> %373)
  %396 = shufflevector <4 x i32> %395, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %397 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %396, <2 x i32> <i32 -15, i32 undef>)
  %a21 = extractelement <2 x i32> %397, i64 0
  %398 = icmp slt i32 %a21, 32767
  %a20 = select i1 %398, i32 %a21, i32 32767
  %399 = icmp sgt i32 %a20, -32768
  %400 = select i1 %399, i32 %a20, i32 -32768
  %401 = trunc i32 %400 to i16
  %402 = insertelement <4 x i16> undef, i16 %401, i32 0
  %403 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 2592, i16 undef, i16 undef, i16 undef>, <4 x i16> %402)
  %404 = shufflevector <4 x i32> %403, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %405 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %404, <2 x i32> <i32 -15, i32 undef>)
  %a19 = extractelement <2 x i32> %405, i64 0
  %406 = icmp slt i32 %a19, 32767
  %a18 = select i1 %406, i32 %a19, i32 32767
  %407 = icmp sgt i32 %a18, -32768
  %408 = select i1 %407, i32 %a18, i32 -32768
  %409 = trunc i32 %408 to i16
  %410 = add i16 %394, %387
  %411 = add i16 %410, %409
  %412 = insertelement <4 x i16> undef, i16 %t103, i32 0
  %413 = insertelement <4 x i16> undef, i16 %411, i32 0
  %414 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %412, <4 x i16> %413)
  %415 = shufflevector <4 x i32> %414, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %416 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %415, <2 x i32> <i32 -15, i32 undef>)
  %a13 = extractelement <2 x i32> %416, i64 0
  %417 = icmp slt i32 %a13, 32767
  %a12 = select i1 %417, i32 %a13, i32 32767
  %418 = icmp sgt i32 %a12, -32768
  %419 = select i1 %418, i32 %a12, i32 -32768
  %420 = trunc i32 %419 to i16
  %421 = insertelement <4 x i16> undef, i16 %420, i32 0
  %422 = tail call <4 x i16> @llvm.aarch64.neon.sqadd.v4i16(<4 x i16> %412, <4 x i16> %421)
  %t204.s = extractelement <4 x i16> %422, i64 0
  %423 = sext i16 %t204.s to i32
  %424 = add nsw i32 %348, %423
  %indvars.iv.next4471 = add nuw nsw i64 %indvars.iv4470, 1
  %.not4370 = icmp eq i64 %indvars.iv.next4471, %347
  br i1 %.not4370, label %"end for sum_exp_row.s1.r6$x.r32.loopexit", label %"for sum_exp_row.s1.r6$x.r32"

"end for sum_exp_row.s1.r6$x.r32.loopexit":       ; preds = %"for sum_exp_row.s1.r6$x.r32"
  store i32 %424, i32* %338, align 4, !tbaa !393
  br label %"end for sum_exp_row.s1.r6$x.r32"

"end for sum_exp_row.s1.r6$x.r32":                ; preds = %"end for sum_exp_row.s1.r6$x.r32.loopexit", %"for sum_exp_row.s1.r6$x.r6$x.rebased"
  %indvars.iv.next4473 = add nuw nsw i64 %indvars.iv4472, 1
  %.not4369 = icmp eq i64 %indvars.iv.next4473, %46
  br i1 %.not4369, label %"end for sum_exp_row.s1.r6$x.r6$x.rebased", label %"for sum_exp_row.s1.r6$x.r6$x.rebased"

"for inv_sum_exp_row.s0.y.rebased":               ; preds = %"end for sum_exp_row.s1.r6$x.r6$x.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge", %"for inv_sum_exp_row.s0.y.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge"
  %indvars.iv.next4477.phi = phi i64 [ %indvars.iv.next4477.0, %"for inv_sum_exp_row.s0.y.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge" ], [ %indvars.iv.next4477.1, %"end for sum_exp_row.s1.r6$x.r6$x.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge" ]
  %.phi = phi i32* [ %.04625, %"for inv_sum_exp_row.s0.y.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge" ], [ %.14626, %"end for sum_exp_row.s1.r6$x.r6$x.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge" ]
  %.phi4627 = phi i16* [ %.0, %"for inv_sum_exp_row.s0.y.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge" ], [ %.1, %"end for sum_exp_row.s1.r6$x.r6$x.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge" ]
  %t261 = load i32, i32* %.phi, align 4, !tbaa !393
  %425 = tail call i32 @llvm.ctlz.i32(i32 %t261, i1 false), !range !395
  %426 = add nsw i32 %425, -16
  %427 = insertelement <2 x i32> undef, i32 %t261, i32 0
  %428 = insertelement <2 x i32> undef, i32 %426, i32 0
  %429 = tail call <2 x i32> @llvm.aarch64.neon.sshl.v2i32(<2 x i32> %427, <2 x i32> %428)
  %430 = bitcast <2 x i32> %429 to <4 x i16>
  %431 = extractelement <4 x i16> %430, i32 0
  %t263 = and i16 %431, 32767
  %432 = insertelement <4 x i16> undef, i16 %t263, i32 0
  %433 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %432, <4 x i16> %432)
  %434 = shufflevector <4 x i32> %433, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %435 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %434, <2 x i32> <i32 -15, i32 undef>)
  %a23 = extractelement <2 x i32> %435, i64 0
  %436 = icmp slt i32 %a23, 32767
  %a22 = select i1 %436, i32 %a23, i32 32767
  %437 = icmp sgt i32 %a22, -32768
  %438 = select i1 %437, i32 %a22, i32 -32768
  %t264 = trunc i32 %438 to i16
  %.neg4358 = mul nsw i32 %425, -32768
  %439 = add nsw i32 %.neg4358, 1015808
  %440 = insertelement <4 x i16> undef, i16 %t264, i32 0
  %441 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 -9421, i16 undef, i16 undef, i16 undef>, <4 x i16> %440)
  %442 = shufflevector <4 x i32> %441, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %443 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %442, <2 x i32> <i32 -15, i32 undef>)
  %a25 = extractelement <2 x i32> %443, i64 0
  %444 = icmp slt i32 %a25, 32767
  %a24 = select i1 %444, i32 %a25, i32 32767
  %445 = icmp sgt i32 %a24, -32768
  %446 = select i1 %445, i32 %a24, i32 -32768
  %447 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %440, <4 x i16> %432)
  %448 = shufflevector <4 x i32> %447, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %449 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %448, <2 x i32> <i32 -15, i32 undef>)
  %a29 = extractelement <2 x i32> %449, i64 0
  %450 = icmp slt i32 %a29, 32767
  %a28 = select i1 %450, i32 %a29, i32 32767
  %451 = icmp sgt i32 %a28, -32768
  %452 = select i1 %451, i32 %a28, i32 -32768
  %453 = trunc i32 %452 to i16
  %454 = insertelement <4 x i16> undef, i16 %453, i32 0
  %455 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 2555, i16 undef, i16 undef, i16 undef>, <4 x i16> %454)
  %456 = shufflevector <4 x i32> %455, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %457 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %456, <2 x i32> <i32 -15, i32 undef>)
  %a27 = extractelement <2 x i32> %457, i64 0
  %458 = icmp slt i32 %a27, 32767
  %a26 = select i1 %458, i32 %a27, i32 32767
  %459 = icmp sgt i32 %a26, -32768
  %460 = select i1 %459, i32 %a26, i32 -32768
  %461 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 23249, i16 undef, i16 undef, i16 undef>, <4 x i16> %432)
  %462 = shufflevector <4 x i32> %461, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %463 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %462, <2 x i32> <i32 -15, i32 undef>)
  %a31 = extractelement <2 x i32> %463, i64 0
  %464 = icmp slt i32 %a31, 32767
  %a30 = select i1 %464, i32 %a31, i32 32767
  %465 = icmp sgt i32 %a30, -32768
  %466 = select i1 %465, i32 %a30, i32 -32768
  %467 = add nsw i32 %460, %446
  %468 = add nsw i32 %467, %466
  %469 = shl i32 %468, 16
  %sext4359 = add i32 %469, 327680
  %470 = ashr exact i32 %sext4359, 15
  %471 = insertelement <2 x i32> undef, i32 %439, i32 0
  %472 = insertelement <2 x i32> undef, i32 %470, i32 0
  %473 = tail call <2 x i32> @llvm.aarch64.neon.sqadd.v2i32(<2 x i32> %471, <2 x i32> %472)
  %t265 = extractelement <2 x i32> %473, i64 0
  %474 = sub nsw i32 0, %t265
  %475 = shl i32 %474, 1
  %476 = add i32 %475, 1966080
  %sext4360 = ashr i32 %476, 16
  %477 = insertelement <2 x i32> undef, i32 %sext4360, i32 0
  %478 = tail call <2 x i32> @llvm.aarch64.neon.sshl.v2i32(<2 x i32> <i32 1, i32 undef>, <2 x i32> %477)
  %a33 = extractelement <2 x i32> %478, i64 0
  %479 = icmp slt i32 %a33, 32767
  %a32 = select i1 %479, i32 %a33, i32 32767
  %480 = icmp sgt i32 %a32, -32768
  %481 = select i1 %480, i32 %a32, i32 -32768
  %t266 = trunc i32 %481 to i16
  %482 = trunc i32 %474 to i16
  %t267 = and i16 %482, 32767
  %483 = insertelement <4 x i16> undef, i16 %t267, i32 0
  %484 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %483, <4 x i16> %483)
  %485 = shufflevector <4 x i32> %484, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %486 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %485, <2 x i32> <i32 -15, i32 undef>)
  %a35 = extractelement <2 x i32> %486, i64 0
  %487 = icmp slt i32 %a35, 32767
  %a34 = select i1 %487, i32 %a35, i32 32767
  %488 = icmp sgt i32 %a34, -32768
  %489 = select i1 %488, i32 %a34, i32 -32768
  %t268 = trunc i32 %489 to i16
  %490 = insertelement <4 x i16> undef, i16 %t268, i32 0
  %491 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 7363, i16 undef, i16 undef, i16 undef>, <4 x i16> %490)
  %492 = shufflevector <4 x i32> %491, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %493 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %492, <2 x i32> <i32 -15, i32 undef>)
  %a39 = extractelement <2 x i32> %493, i64 0
  %494 = icmp slt i32 %a39, 32767
  %a38 = select i1 %494, i32 %a39, i32 32767
  %495 = icmp sgt i32 %a38, -32768
  %496 = select i1 %495, i32 %a38, i32 -32768
  %497 = trunc i32 %496 to i16
  %498 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 22812, i16 undef, i16 undef, i16 undef>, <4 x i16> %483)
  %499 = shufflevector <4 x i32> %498, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %500 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %499, <2 x i32> <i32 -15, i32 undef>)
  %a41 = extractelement <2 x i32> %500, i64 0
  %501 = icmp slt i32 %a41, 32767
  %a40 = select i1 %501, i32 %a41, i32 32767
  %502 = icmp sgt i32 %a40, -32768
  %503 = select i1 %502, i32 %a40, i32 -32768
  %504 = trunc i32 %503 to i16
  %505 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %490, <4 x i16> %483)
  %506 = shufflevector <4 x i32> %505, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %507 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %506, <2 x i32> <i32 -15, i32 undef>)
  %a45 = extractelement <2 x i32> %507, i64 0
  %508 = icmp slt i32 %a45, 32767
  %a44 = select i1 %508, i32 %a45, i32 32767
  %509 = icmp sgt i32 %a44, -32768
  %510 = select i1 %509, i32 %a44, i32 -32768
  %511 = trunc i32 %510 to i16
  %512 = insertelement <4 x i16> undef, i16 %511, i32 0
  %513 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 2592, i16 undef, i16 undef, i16 undef>, <4 x i16> %512)
  %514 = shufflevector <4 x i32> %513, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %515 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %514, <2 x i32> <i32 -15, i32 undef>)
  %a43 = extractelement <2 x i32> %515, i64 0
  %516 = icmp slt i32 %a43, 32767
  %a42 = select i1 %516, i32 %a43, i32 32767
  %517 = icmp sgt i32 %a42, -32768
  %518 = select i1 %517, i32 %a42, i32 -32768
  %519 = trunc i32 %518 to i16
  %520 = add i16 %504, %497
  %521 = add i16 %520, %519
  %522 = insertelement <4 x i16> undef, i16 %t266, i32 0
  %523 = insertelement <4 x i16> undef, i16 %521, i32 0
  %524 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %522, <4 x i16> %523)
  %525 = shufflevector <4 x i32> %524, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %526 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %525, <2 x i32> <i32 -15, i32 undef>)
  %a37 = extractelement <2 x i32> %526, i64 0
  %527 = icmp slt i32 %a37, 32767
  %a36 = select i1 %527, i32 %a37, i32 32767
  %528 = icmp sgt i32 %a36, -32768
  %529 = select i1 %528, i32 %a36, i32 -32768
  %530 = trunc i32 %529 to i16
  %531 = insertelement <4 x i16> undef, i16 %530, i32 0
  %532 = tail call <4 x i16> @llvm.aarch64.neon.sqadd.v4i16(<4 x i16> %522, <4 x i16> %531)
  %533 = extractelement <4 x i16> %532, i64 0
  store i16 %533, i16* %.phi4627, align 2, !tbaa !396
  %.not4362 = icmp eq i64 %indvars.iv.next4477.phi, 4
  br i1 %.not4362, label %"consume max_x1", label %"for inv_sum_exp_row.s0.y.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge"

"for inv_sum_exp_row.s0.y.rebased.for inv_sum_exp_row.s0.y.rebased_crit_edge": ; preds = %"for inv_sum_exp_row.s0.y.rebased"
  %.0 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 %indvars.iv.next4477.phi
  %.04625 = getelementptr inbounds [4 x i32], [4 x i32]* %sum_exp_row171, i64 0, i64 %indvars.iv.next4477.phi
  %indvars.iv.next4477.0 = add nuw nsw i64 %indvars.iv.next4477.phi, 1
  br label %"for inv_sum_exp_row.s0.y.rebased"

"consume max_x1":                                 ; preds = %"for inv_sum_exp_row.s0.y.rebased"
  %t329 = add nsw i32 %52, %t303
  br i1 %30, label %"for output.s0.x.x.preheader", label %"end for output.s0.x.x", !prof !385

"for output.s0.x.x.preheader":                    ; preds = %"consume max_x1"
  %534 = add nsw i32 %t306, 1
  %535 = mul nsw i32 %534, %12
  %t322 = sub nsw i32 %535, %t304
  %536 = add nsw i32 %t306, 2
  %537 = mul nsw i32 %536, %12
  %t324 = sub nsw i32 %537, %t304
  %538 = add nsw i32 %t306, 3
  %539 = mul nsw i32 %538, %12
  %t326 = sub nsw i32 %539, %t304
  %540 = add nsw i32 %t329, 1
  %541 = mul nsw i32 %540, %5
  %t321 = sub nsw i32 %541, %2
  %542 = add nsw i32 %t329, 2
  %543 = mul nsw i32 %542, %5
  %t323 = sub nsw i32 %543, %2
  %544 = add nsw i32 %t329, 3
  %545 = mul nsw i32 %544, %5
  %t325 = sub nsw i32 %545, %2
  %546 = mul nsw i32 %t306, %12
  %t320 = sub nsw i32 %546, %t304
  %547 = mul nsw i32 %t329, %5
  %t319 = sub nsw i32 %547, %2
  %548 = sext i32 %t319 to i64
  %549 = load i8, i8* %max_x172.sub, align 16, !tbaa !398
  %550 = zext i8 %549 to i16
  %551 = mul nsw i16 %550, -64
  %552 = insertelement <64 x i16> undef, i16 %551, i32 0
  %553 = shufflevector <64 x i16> %552, <64 x i16> undef, <64 x i32> zeroinitializer
  %554 = load <4 x i16>, <4 x i16>* %inv_sum_exp_row170, align 16
  %555 = shufflevector <4 x i16> %554, <4 x i16> poison, <8 x i32> zeroinitializer
  %556 = sext i32 %t320 to i64
  %557 = sext i32 %t321 to i64
  %558 = load i8, i8* %39, align 1, !tbaa !410
  %559 = zext i8 %558 to i16
  %560 = mul nsw i16 %559, -64
  %561 = insertelement <64 x i16> undef, i16 %560, i32 0
  %562 = shufflevector <64 x i16> %561, <64 x i16> undef, <64 x i32> zeroinitializer
  %563 = load i16, i16* %40, align 2, !tbaa !412
  %564 = insertelement <64 x i16> undef, i16 %563, i32 0
  %565 = shufflevector <64 x i16> %564, <64 x i16> undef, <8 x i32> zeroinitializer
  %566 = sext i32 %t322 to i64
  %567 = sext i32 %t323 to i64
  %568 = load i8, i8* %41, align 2, !tbaa !424
  %569 = zext i8 %568 to i16
  %570 = mul nsw i16 %569, -64
  %571 = insertelement <64 x i16> undef, i16 %570, i32 0
  %572 = shufflevector <64 x i16> %571, <64 x i16> undef, <64 x i32> zeroinitializer
  %573 = load i16, i16* %42, align 4, !tbaa !427
  %574 = insertelement <64 x i16> undef, i16 %573, i32 0
  %575 = shufflevector <64 x i16> %574, <64 x i16> undef, <8 x i32> zeroinitializer
  %576 = sext i32 %t324 to i64
  %577 = sext i32 %t325 to i64
  %578 = load i8, i8* %43, align 1, !tbaa !430
  %579 = zext i8 %578 to i16
  %580 = mul nsw i16 %579, -64
  %581 = insertelement <64 x i16> undef, i16 %580, i32 0
  %582 = shufflevector <64 x i16> %581, <64 x i16> undef, <64 x i32> zeroinitializer
  %583 = load i16, i16* %44, align 2, !tbaa !432
  %584 = insertelement <64 x i16> undef, i16 %583, i32 0
  %585 = shufflevector <64 x i16> %584, <64 x i16> undef, <8 x i32> zeroinitializer
  %586 = sext i32 %t326 to i64
  br label %"for output.s0.x.x"

"for output.s0.x.x":                              ; preds = %"for output.s0.x.x.preheader", %"end for output.s0.x.xi.xi9"
  %indvars.iv4490 = phi i64 [ 0, %"for output.s0.x.x.preheader" ], [ %indvars.iv.next4491, %"end for output.s0.x.xi.xi9" ]
  %587 = shl nsw i64 %indvars.iv4490, 7
  %588 = add nsw i64 %587, %48
  br label %"for output.s0.x.xi.xi"

"end for output.s0.x.x":                          ; preds = %"end for output.s0.x.xi.xi9", %"consume max_x1"
  %indvars.iv.next4494 = add nuw nsw i64 %indvars.iv4493, 1
  %.not4363 = icmp eq i64 %indvars.iv.next4494, %49
  br i1 %.not4363, label %"end for output.s0.y.y", label %"for output.s0.y.y"

"for output.s0.x.xi.xi":                          ; preds = %"for output.s0.x.x", %"for output.s0.x.xi.xi"
  %indvars.iv4478 = phi i64 [ 0, %"for output.s0.x.x" ], [ %indvars.iv.next4479, %"for output.s0.x.xi.xi" ]
  %589 = shl nsw i64 %indvars.iv4478, 6
  %590 = add nsw i64 %589, %588
  %591 = add nsw i64 %590, %548
  %592 = getelementptr inbounds i8, i8* %0, i64 %591
  %593 = bitcast i8* %592 to <16 x i8>*
  %594 = load <16 x i8>, <16 x i8>* %593, align 1, !tbaa !389
  %595 = getelementptr inbounds i8, i8* %592, i64 16
  %596 = bitcast i8* %595 to <16 x i8>*
  %597 = load <16 x i8>, <16 x i8>* %596, align 1, !tbaa !389
  %598 = getelementptr inbounds i8, i8* %592, i64 32
  %599 = bitcast i8* %598 to <16 x i8>*
  %600 = load <16 x i8>, <16 x i8>* %599, align 1, !tbaa !389
  %601 = getelementptr inbounds i8, i8* %592, i64 48
  %602 = bitcast i8* %601 to <16 x i8>*
  %603 = load <16 x i8>, <16 x i8>* %602, align 1, !tbaa !389
  %604 = shufflevector <16 x i8> %594, <16 x i8> %597, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %605 = shufflevector <16 x i8> %600, <16 x i8> %603, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %606 = shufflevector <32 x i8> %604, <32 x i8> %605, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %607 = zext <64 x i8> %606 to <64 x i16>
  %608 = shl nuw nsw <64 x i16> %607, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %609 = add <64 x i16> %553, %608
  %610 = shufflevector <64 x i16> %609, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %611 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %610, <8 x i16> %23)
  %612 = shufflevector <64 x i16> %609, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %613 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %612, <8 x i16> %23)
  %614 = shufflevector <64 x i16> %609, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %615 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %614, <8 x i16> %23)
  %616 = shufflevector <64 x i16> %609, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %617 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %616, <8 x i16> %23)
  %618 = shufflevector <64 x i16> %609, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %619 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %618, <8 x i16> %23)
  %620 = shufflevector <64 x i16> %609, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %621 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %620, <8 x i16> %23)
  %622 = shufflevector <64 x i16> %609, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %623 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %622, <8 x i16> %23)
  %624 = shufflevector <64 x i16> %609, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %625 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %624, <8 x i16> %23)
  %626 = shufflevector <8 x i16> %611, <8 x i16> %613, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %627 = shufflevector <8 x i16> %615, <8 x i16> %617, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %628 = shufflevector <8 x i16> %619, <8 x i16> %621, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %629 = shufflevector <8 x i16> %623, <8 x i16> %625, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %630 = shufflevector <16 x i16> %626, <16 x i16> %627, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %631 = shufflevector <16 x i16> %628, <16 x i16> %629, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t271 = shufflevector <32 x i16> %630, <32 x i16> %631, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t272 = ashr <64 x i16> %t271, %25
  %632 = add <64 x i16> %t272, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %633 = shufflevector <64 x i16> %632, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %634 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %633)
  %635 = shufflevector <64 x i16> %632, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %636 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %635)
  %637 = shufflevector <64 x i16> %632, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %638 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %637)
  %639 = shufflevector <64 x i16> %632, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %640 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %639)
  %641 = shufflevector <64 x i16> %632, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %642 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %641)
  %643 = shufflevector <64 x i16> %632, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %644 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %643)
  %645 = shufflevector <64 x i16> %632, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %646 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %645)
  %647 = shufflevector <64 x i16> %632, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %648 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %647)
  %649 = shufflevector <8 x i16> %648, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %650 = shufflevector <16 x i16> %649, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t273 = shufflevector <32 x i16> %650, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %651 = shl <64 x i16> %t272, %25
  %652 = sub <64 x i16> %t271, %651
  %653 = shufflevector <64 x i16> %652, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %654 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %653, <8 x i16> %27)
  %655 = shufflevector <64 x i16> %652, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %656 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %655, <8 x i16> %27)
  %657 = shufflevector <64 x i16> %652, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %658 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %657, <8 x i16> %27)
  %659 = shufflevector <64 x i16> %652, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %660 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %659, <8 x i16> %27)
  %661 = shufflevector <64 x i16> %652, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %662 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %661, <8 x i16> %27)
  %663 = shufflevector <64 x i16> %652, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %664 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %663, <8 x i16> %27)
  %665 = shufflevector <64 x i16> %652, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %666 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %665, <8 x i16> %27)
  %667 = shufflevector <64 x i16> %652, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %668 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %667, <8 x i16> %27)
  %669 = shufflevector <8 x i16> %668, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %670 = shufflevector <16 x i16> %669, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t274 = shufflevector <32 x i16> %670, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %671 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %654, <8 x i16> %654)
  %672 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %656, <8 x i16> %656)
  %673 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %658, <8 x i16> %658)
  %674 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %660, <8 x i16> %660)
  %675 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %662, <8 x i16> %662)
  %676 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %664, <8 x i16> %664)
  %677 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %666, <8 x i16> %666)
  %678 = shufflevector <64 x i16> %t274, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %679 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %678, <8 x i16> %678)
  %680 = shufflevector <8 x i16> %679, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %681 = shufflevector <16 x i16> %680, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t275 = shufflevector <32 x i16> %681, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %682 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %671)
  %683 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %672)
  %684 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %673)
  %685 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %674)
  %686 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %675)
  %687 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %676)
  %688 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %677)
  %689 = shufflevector <64 x i16> %t275, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %690 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %689)
  %691 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %654)
  %692 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %656)
  %693 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %658)
  %694 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %660)
  %695 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %662)
  %696 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %664)
  %697 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %666)
  %698 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %678)
  %699 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %671, <8 x i16> %654)
  %700 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %672, <8 x i16> %656)
  %701 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %673, <8 x i16> %658)
  %702 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %674, <8 x i16> %660)
  %703 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %675, <8 x i16> %662)
  %704 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %676, <8 x i16> %664)
  %705 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %677, <8 x i16> %666)
  %706 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %689, <8 x i16> %678)
  %707 = shufflevector <8 x i16> %706, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %708 = shufflevector <16 x i16> %707, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %709 = shufflevector <32 x i16> %708, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %710 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %699)
  %711 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %700)
  %712 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %701)
  %713 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %702)
  %714 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %703)
  %715 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %704)
  %716 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %705)
  %717 = shufflevector <64 x i16> %709, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %718 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %717)
  %719 = add <8 x i16> %691, %682
  %720 = add <8 x i16> %719, %710
  %721 = add <8 x i16> %692, %683
  %722 = add <8 x i16> %721, %711
  %723 = add <8 x i16> %693, %684
  %724 = add <8 x i16> %723, %712
  %725 = add <8 x i16> %694, %685
  %726 = add <8 x i16> %725, %713
  %727 = add <8 x i16> %695, %686
  %728 = add <8 x i16> %727, %714
  %729 = add <8 x i16> %696, %687
  %730 = add <8 x i16> %729, %715
  %731 = add <8 x i16> %697, %688
  %732 = add <8 x i16> %731, %716
  %733 = add <8 x i16> %698, %690
  %734 = add <8 x i16> %733, %718
  %735 = shufflevector <8 x i16> %734, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %736 = shufflevector <16 x i16> %735, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %737 = shufflevector <32 x i16> %736, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %738 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %634, <8 x i16> %720)
  %739 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %636, <8 x i16> %722)
  %740 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %638, <8 x i16> %724)
  %741 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %640, <8 x i16> %726)
  %742 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %642, <8 x i16> %728)
  %743 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %644, <8 x i16> %730)
  %744 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %646, <8 x i16> %732)
  %745 = shufflevector <64 x i16> %t273, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %746 = shufflevector <64 x i16> %737, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %747 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %745, <8 x i16> %746)
  %748 = shufflevector <8 x i16> %747, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %749 = shufflevector <16 x i16> %748, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %750 = shufflevector <32 x i16> %749, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %751 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %634, <8 x i16> %738)
  %752 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %636, <8 x i16> %739)
  %753 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %638, <8 x i16> %740)
  %754 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %640, <8 x i16> %741)
  %755 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %642, <8 x i16> %742)
  %756 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %644, <8 x i16> %743)
  %757 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %646, <8 x i16> %744)
  %758 = shufflevector <64 x i16> %750, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %759 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %745, <8 x i16> %758)
  %760 = shufflevector <8 x i16> %759, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %761 = shufflevector <16 x i16> %760, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %762 = shufflevector <32 x i16> %761, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %763 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %751, <8 x i16> %555)
  %764 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %752, <8 x i16> %555)
  %765 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %753, <8 x i16> %555)
  %766 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %754, <8 x i16> %555)
  %767 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %755, <8 x i16> %555)
  %768 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %756, <8 x i16> %555)
  %769 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %757, <8 x i16> %555)
  %770 = shufflevector <64 x i16> %762, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %771 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %770, <8 x i16> %555)
  %772 = shufflevector <8 x i16> %771, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %773 = shufflevector <16 x i16> %772, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %774 = shufflevector <32 x i16> %773, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %775 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %763, <8 x i16> %32)
  %776 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %764, <8 x i16> %32)
  %777 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %765, <8 x i16> %32)
  %778 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %766, <8 x i16> %32)
  %779 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %767, <8 x i16> %32)
  %780 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %768, <8 x i16> %32)
  %781 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %769, <8 x i16> %32)
  %782 = shufflevector <64 x i16> %774, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %783 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %782, <8 x i16> %32)
  %784 = shufflevector <8 x i16> %783, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %785 = shufflevector <16 x i16> %784, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %786 = shufflevector <32 x i16> %785, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %787 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %775, <8 x i16> %35)
  %788 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %776, <8 x i16> %35)
  %789 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %777, <8 x i16> %35)
  %790 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %778, <8 x i16> %35)
  %791 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %779, <8 x i16> %35)
  %792 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %780, <8 x i16> %35)
  %793 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %781, <8 x i16> %35)
  %794 = shufflevector <64 x i16> %786, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %795 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %794, <8 x i16> %35)
  %796 = shufflevector <8 x i16> %795, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %797 = shufflevector <16 x i16> %796, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %798 = shufflevector <32 x i16> %797, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %799 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %787, <8 x i16> %38)
  %800 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %788, <8 x i16> %38)
  %801 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %789, <8 x i16> %38)
  %802 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %790, <8 x i16> %38)
  %803 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %791, <8 x i16> %38)
  %804 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %792, <8 x i16> %38)
  %805 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %793, <8 x i16> %38)
  %806 = shufflevector <64 x i16> %798, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %807 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %806, <8 x i16> %38)
  %808 = shufflevector <8 x i16> %807, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %809 = shufflevector <16 x i16> %808, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %810 = shufflevector <32 x i16> %809, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %811 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %799)
  %812 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %800)
  %813 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %801)
  %814 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %802)
  %815 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %803)
  %816 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %804)
  %817 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %805)
  %818 = shufflevector <64 x i16> %810, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %819 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %818)
  %820 = shufflevector <8 x i8> %811, <8 x i8> %812, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %821 = shufflevector <8 x i8> %813, <8 x i8> %814, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %822 = shufflevector <8 x i8> %815, <8 x i8> %816, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %823 = shufflevector <8 x i8> %817, <8 x i8> %819, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %824 = shufflevector <32 x i8> %823, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %825 = add nsw i64 %590, %556
  %826 = getelementptr inbounds i8, i8* %6, i64 %825
  %827 = bitcast i8* %826 to <16 x i8>*
  store <16 x i8> %820, <16 x i8>* %827, align 1, !tbaa !434
  %828 = getelementptr inbounds i8, i8* %826, i64 16
  %829 = bitcast i8* %828 to <16 x i8>*
  store <16 x i8> %821, <16 x i8>* %829, align 1, !tbaa !434
  %830 = getelementptr inbounds i8, i8* %826, i64 32
  %831 = bitcast i8* %830 to <16 x i8>*
  store <16 x i8> %822, <16 x i8>* %831, align 1, !tbaa !434
  %832 = shufflevector <64 x i8> %824, <64 x i8> undef, <16 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %833 = getelementptr inbounds i8, i8* %826, i64 48
  %834 = bitcast i8* %833 to <16 x i8>*
  store <16 x i8> %832, <16 x i8>* %834, align 1, !tbaa !434
  %indvars.iv.next4479 = add nuw nsw i64 %indvars.iv4478, 1
  %.not4364 = icmp eq i64 %indvars.iv.next4479, 2
  br i1 %.not4364, label %"for output.s0.x.xi.xi2", label %"for output.s0.x.xi.xi"

"for output.s0.x.xi.xi2":                         ; preds = %"for output.s0.x.xi.xi", %"for output.s0.x.xi.xi2"
  %indvars.iv4481 = phi i64 [ %indvars.iv.next4482, %"for output.s0.x.xi.xi2" ], [ 0, %"for output.s0.x.xi.xi" ]
  %835 = shl nsw i64 %indvars.iv4481, 6
  %836 = add nsw i64 %835, %588
  %837 = add nsw i64 %836, %557
  %838 = getelementptr inbounds i8, i8* %0, i64 %837
  %839 = bitcast i8* %838 to <16 x i8>*
  %840 = load <16 x i8>, <16 x i8>* %839, align 1, !tbaa !389
  %841 = getelementptr inbounds i8, i8* %838, i64 16
  %842 = bitcast i8* %841 to <16 x i8>*
  %843 = load <16 x i8>, <16 x i8>* %842, align 1, !tbaa !389
  %844 = getelementptr inbounds i8, i8* %838, i64 32
  %845 = bitcast i8* %844 to <16 x i8>*
  %846 = load <16 x i8>, <16 x i8>* %845, align 1, !tbaa !389
  %847 = getelementptr inbounds i8, i8* %838, i64 48
  %848 = bitcast i8* %847 to <16 x i8>*
  %849 = load <16 x i8>, <16 x i8>* %848, align 1, !tbaa !389
  %850 = shufflevector <16 x i8> %840, <16 x i8> %843, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %851 = shufflevector <16 x i8> %846, <16 x i8> %849, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %852 = shufflevector <32 x i8> %850, <32 x i8> %851, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %853 = zext <64 x i8> %852 to <64 x i16>
  %854 = shl nuw nsw <64 x i16> %853, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %855 = add <64 x i16> %562, %854
  %856 = shufflevector <64 x i16> %855, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %857 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %856, <8 x i16> %23)
  %858 = shufflevector <64 x i16> %855, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %859 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %858, <8 x i16> %23)
  %860 = shufflevector <64 x i16> %855, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %861 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %860, <8 x i16> %23)
  %862 = shufflevector <64 x i16> %855, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %863 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %862, <8 x i16> %23)
  %864 = shufflevector <64 x i16> %855, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %865 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %864, <8 x i16> %23)
  %866 = shufflevector <64 x i16> %855, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %867 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %866, <8 x i16> %23)
  %868 = shufflevector <64 x i16> %855, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %869 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %868, <8 x i16> %23)
  %870 = shufflevector <64 x i16> %855, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %871 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %870, <8 x i16> %23)
  %872 = shufflevector <8 x i16> %857, <8 x i16> %859, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %873 = shufflevector <8 x i16> %861, <8 x i16> %863, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %874 = shufflevector <8 x i16> %865, <8 x i16> %867, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %875 = shufflevector <8 x i16> %869, <8 x i16> %871, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %876 = shufflevector <16 x i16> %872, <16 x i16> %873, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %877 = shufflevector <16 x i16> %874, <16 x i16> %875, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t278 = shufflevector <32 x i16> %876, <32 x i16> %877, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t279 = ashr <64 x i16> %t278, %25
  %878 = add <64 x i16> %t279, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %879 = shufflevector <64 x i16> %878, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %880 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %879)
  %881 = shufflevector <64 x i16> %878, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %882 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %881)
  %883 = shufflevector <64 x i16> %878, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %884 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %883)
  %885 = shufflevector <64 x i16> %878, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %886 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %885)
  %887 = shufflevector <64 x i16> %878, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %888 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %887)
  %889 = shufflevector <64 x i16> %878, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %890 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %889)
  %891 = shufflevector <64 x i16> %878, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %892 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %891)
  %893 = shufflevector <64 x i16> %878, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %894 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %893)
  %895 = shufflevector <8 x i16> %894, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %896 = shufflevector <16 x i16> %895, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t280 = shufflevector <32 x i16> %896, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %897 = shl <64 x i16> %t279, %25
  %898 = sub <64 x i16> %t278, %897
  %899 = shufflevector <64 x i16> %898, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %900 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %899, <8 x i16> %27)
  %901 = shufflevector <64 x i16> %898, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %902 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %901, <8 x i16> %27)
  %903 = shufflevector <64 x i16> %898, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %904 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %903, <8 x i16> %27)
  %905 = shufflevector <64 x i16> %898, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %906 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %905, <8 x i16> %27)
  %907 = shufflevector <64 x i16> %898, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %908 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %907, <8 x i16> %27)
  %909 = shufflevector <64 x i16> %898, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %910 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %909, <8 x i16> %27)
  %911 = shufflevector <64 x i16> %898, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %912 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %911, <8 x i16> %27)
  %913 = shufflevector <64 x i16> %898, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %914 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %913, <8 x i16> %27)
  %915 = shufflevector <8 x i16> %914, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %916 = shufflevector <16 x i16> %915, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t281 = shufflevector <32 x i16> %916, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %917 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %900, <8 x i16> %900)
  %918 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %902, <8 x i16> %902)
  %919 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %904, <8 x i16> %904)
  %920 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %906, <8 x i16> %906)
  %921 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %908, <8 x i16> %908)
  %922 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %910, <8 x i16> %910)
  %923 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %912, <8 x i16> %912)
  %924 = shufflevector <64 x i16> %t281, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %925 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %924, <8 x i16> %924)
  %926 = shufflevector <8 x i16> %925, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %927 = shufflevector <16 x i16> %926, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t282 = shufflevector <32 x i16> %927, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %928 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %917)
  %929 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %918)
  %930 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %919)
  %931 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %920)
  %932 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %921)
  %933 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %922)
  %934 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %923)
  %935 = shufflevector <64 x i16> %t282, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %936 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %935)
  %937 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %900)
  %938 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %902)
  %939 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %904)
  %940 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %906)
  %941 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %908)
  %942 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %910)
  %943 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %912)
  %944 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %924)
  %945 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %917, <8 x i16> %900)
  %946 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %918, <8 x i16> %902)
  %947 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %919, <8 x i16> %904)
  %948 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %920, <8 x i16> %906)
  %949 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %921, <8 x i16> %908)
  %950 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %922, <8 x i16> %910)
  %951 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %923, <8 x i16> %912)
  %952 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %935, <8 x i16> %924)
  %953 = shufflevector <8 x i16> %952, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %954 = shufflevector <16 x i16> %953, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %955 = shufflevector <32 x i16> %954, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %956 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %945)
  %957 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %946)
  %958 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %947)
  %959 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %948)
  %960 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %949)
  %961 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %950)
  %962 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %951)
  %963 = shufflevector <64 x i16> %955, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %964 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %963)
  %965 = add <8 x i16> %937, %928
  %966 = add <8 x i16> %965, %956
  %967 = add <8 x i16> %938, %929
  %968 = add <8 x i16> %967, %957
  %969 = add <8 x i16> %939, %930
  %970 = add <8 x i16> %969, %958
  %971 = add <8 x i16> %940, %931
  %972 = add <8 x i16> %971, %959
  %973 = add <8 x i16> %941, %932
  %974 = add <8 x i16> %973, %960
  %975 = add <8 x i16> %942, %933
  %976 = add <8 x i16> %975, %961
  %977 = add <8 x i16> %943, %934
  %978 = add <8 x i16> %977, %962
  %979 = add <8 x i16> %944, %936
  %980 = add <8 x i16> %979, %964
  %981 = shufflevector <8 x i16> %980, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %982 = shufflevector <16 x i16> %981, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %983 = shufflevector <32 x i16> %982, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %984 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %880, <8 x i16> %966)
  %985 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %882, <8 x i16> %968)
  %986 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %884, <8 x i16> %970)
  %987 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %886, <8 x i16> %972)
  %988 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %888, <8 x i16> %974)
  %989 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %890, <8 x i16> %976)
  %990 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %892, <8 x i16> %978)
  %991 = shufflevector <64 x i16> %t280, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %992 = shufflevector <64 x i16> %983, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %993 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %991, <8 x i16> %992)
  %994 = shufflevector <8 x i16> %993, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %995 = shufflevector <16 x i16> %994, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %996 = shufflevector <32 x i16> %995, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %997 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %880, <8 x i16> %984)
  %998 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %882, <8 x i16> %985)
  %999 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %884, <8 x i16> %986)
  %1000 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %886, <8 x i16> %987)
  %1001 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %888, <8 x i16> %988)
  %1002 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %890, <8 x i16> %989)
  %1003 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %892, <8 x i16> %990)
  %1004 = shufflevector <64 x i16> %996, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1005 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %991, <8 x i16> %1004)
  %1006 = shufflevector <8 x i16> %1005, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1007 = shufflevector <16 x i16> %1006, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1008 = shufflevector <32 x i16> %1007, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1009 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %997, <8 x i16> %565)
  %1010 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %998, <8 x i16> %565)
  %1011 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %999, <8 x i16> %565)
  %1012 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1000, <8 x i16> %565)
  %1013 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1001, <8 x i16> %565)
  %1014 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1002, <8 x i16> %565)
  %1015 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1003, <8 x i16> %565)
  %1016 = shufflevector <64 x i16> %1008, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1017 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1016, <8 x i16> %565)
  %1018 = shufflevector <8 x i16> %1017, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1019 = shufflevector <16 x i16> %1018, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1020 = shufflevector <32 x i16> %1019, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1021 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1009, <8 x i16> %32)
  %1022 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1010, <8 x i16> %32)
  %1023 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1011, <8 x i16> %32)
  %1024 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1012, <8 x i16> %32)
  %1025 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1013, <8 x i16> %32)
  %1026 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1014, <8 x i16> %32)
  %1027 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1015, <8 x i16> %32)
  %1028 = shufflevector <64 x i16> %1020, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1029 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1028, <8 x i16> %32)
  %1030 = shufflevector <8 x i16> %1029, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1031 = shufflevector <16 x i16> %1030, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1032 = shufflevector <32 x i16> %1031, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1033 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1021, <8 x i16> %35)
  %1034 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1022, <8 x i16> %35)
  %1035 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1023, <8 x i16> %35)
  %1036 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1024, <8 x i16> %35)
  %1037 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1025, <8 x i16> %35)
  %1038 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1026, <8 x i16> %35)
  %1039 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1027, <8 x i16> %35)
  %1040 = shufflevector <64 x i16> %1032, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1041 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1040, <8 x i16> %35)
  %1042 = shufflevector <8 x i16> %1041, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1043 = shufflevector <16 x i16> %1042, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1044 = shufflevector <32 x i16> %1043, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1045 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1033, <8 x i16> %38)
  %1046 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1034, <8 x i16> %38)
  %1047 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1035, <8 x i16> %38)
  %1048 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1036, <8 x i16> %38)
  %1049 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1037, <8 x i16> %38)
  %1050 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1038, <8 x i16> %38)
  %1051 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1039, <8 x i16> %38)
  %1052 = shufflevector <64 x i16> %1044, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1053 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1052, <8 x i16> %38)
  %1054 = shufflevector <8 x i16> %1053, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1055 = shufflevector <16 x i16> %1054, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1056 = shufflevector <32 x i16> %1055, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1057 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1045)
  %1058 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1046)
  %1059 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1047)
  %1060 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1048)
  %1061 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1049)
  %1062 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1050)
  %1063 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1051)
  %1064 = shufflevector <64 x i16> %1056, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1065 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1064)
  %1066 = shufflevector <8 x i8> %1057, <8 x i8> %1058, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1067 = shufflevector <8 x i8> %1059, <8 x i8> %1060, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1068 = shufflevector <8 x i8> %1061, <8 x i8> %1062, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1069 = shufflevector <8 x i8> %1063, <8 x i8> %1065, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1070 = shufflevector <32 x i8> %1069, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1071 = add nsw i64 %836, %566
  %1072 = getelementptr inbounds i8, i8* %6, i64 %1071
  %1073 = bitcast i8* %1072 to <16 x i8>*
  store <16 x i8> %1066, <16 x i8>* %1073, align 1, !tbaa !434
  %1074 = getelementptr inbounds i8, i8* %1072, i64 16
  %1075 = bitcast i8* %1074 to <16 x i8>*
  store <16 x i8> %1067, <16 x i8>* %1075, align 1, !tbaa !434
  %1076 = getelementptr inbounds i8, i8* %1072, i64 32
  %1077 = bitcast i8* %1076 to <16 x i8>*
  store <16 x i8> %1068, <16 x i8>* %1077, align 1, !tbaa !434
  %1078 = shufflevector <64 x i8> %1070, <64 x i8> undef, <16 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1079 = getelementptr inbounds i8, i8* %1072, i64 48
  %1080 = bitcast i8* %1079 to <16 x i8>*
  store <16 x i8> %1078, <16 x i8>* %1080, align 1, !tbaa !434
  %indvars.iv.next4482 = add nuw nsw i64 %indvars.iv4481, 1
  %.not4365 = icmp eq i64 %indvars.iv.next4482, 2
  br i1 %.not4365, label %"for output.s0.x.xi.xi5", label %"for output.s0.x.xi.xi2"

"for output.s0.x.xi.xi5":                         ; preds = %"for output.s0.x.xi.xi2", %"for output.s0.x.xi.xi5"
  %indvars.iv4484 = phi i64 [ %indvars.iv.next4485, %"for output.s0.x.xi.xi5" ], [ 0, %"for output.s0.x.xi.xi2" ]
  %1081 = shl nsw i64 %indvars.iv4484, 6
  %1082 = add nsw i64 %1081, %588
  %1083 = add nsw i64 %1082, %567
  %1084 = getelementptr inbounds i8, i8* %0, i64 %1083
  %1085 = bitcast i8* %1084 to <16 x i8>*
  %1086 = load <16 x i8>, <16 x i8>* %1085, align 1, !tbaa !389
  %1087 = getelementptr inbounds i8, i8* %1084, i64 16
  %1088 = bitcast i8* %1087 to <16 x i8>*
  %1089 = load <16 x i8>, <16 x i8>* %1088, align 1, !tbaa !389
  %1090 = getelementptr inbounds i8, i8* %1084, i64 32
  %1091 = bitcast i8* %1090 to <16 x i8>*
  %1092 = load <16 x i8>, <16 x i8>* %1091, align 1, !tbaa !389
  %1093 = getelementptr inbounds i8, i8* %1084, i64 48
  %1094 = bitcast i8* %1093 to <16 x i8>*
  %1095 = load <16 x i8>, <16 x i8>* %1094, align 1, !tbaa !389
  %1096 = shufflevector <16 x i8> %1086, <16 x i8> %1089, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1097 = shufflevector <16 x i8> %1092, <16 x i8> %1095, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1098 = shufflevector <32 x i8> %1096, <32 x i8> %1097, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1099 = zext <64 x i8> %1098 to <64 x i16>
  %1100 = shl nuw nsw <64 x i16> %1099, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1101 = add <64 x i16> %572, %1100
  %1102 = shufflevector <64 x i16> %1101, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1103 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1102, <8 x i16> %23)
  %1104 = shufflevector <64 x i16> %1101, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1105 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1104, <8 x i16> %23)
  %1106 = shufflevector <64 x i16> %1101, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1107 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1106, <8 x i16> %23)
  %1108 = shufflevector <64 x i16> %1101, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1109 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1108, <8 x i16> %23)
  %1110 = shufflevector <64 x i16> %1101, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %1111 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1110, <8 x i16> %23)
  %1112 = shufflevector <64 x i16> %1101, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %1113 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1112, <8 x i16> %23)
  %1114 = shufflevector <64 x i16> %1101, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %1115 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1114, <8 x i16> %23)
  %1116 = shufflevector <64 x i16> %1101, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1117 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1116, <8 x i16> %23)
  %1118 = shufflevector <8 x i16> %1103, <8 x i16> %1105, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1119 = shufflevector <8 x i16> %1107, <8 x i16> %1109, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1120 = shufflevector <8 x i16> %1111, <8 x i16> %1113, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1121 = shufflevector <8 x i16> %1115, <8 x i16> %1117, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1122 = shufflevector <16 x i16> %1118, <16 x i16> %1119, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1123 = shufflevector <16 x i16> %1120, <16 x i16> %1121, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t285 = shufflevector <32 x i16> %1122, <32 x i16> %1123, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t286 = ashr <64 x i16> %t285, %25
  %1124 = add <64 x i16> %t286, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %1125 = shufflevector <64 x i16> %1124, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1126 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1125)
  %1127 = shufflevector <64 x i16> %1124, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1128 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1127)
  %1129 = shufflevector <64 x i16> %1124, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1130 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1129)
  %1131 = shufflevector <64 x i16> %1124, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1132 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1131)
  %1133 = shufflevector <64 x i16> %1124, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %1134 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1133)
  %1135 = shufflevector <64 x i16> %1124, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %1136 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1135)
  %1137 = shufflevector <64 x i16> %1124, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %1138 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1137)
  %1139 = shufflevector <64 x i16> %1124, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1140 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1139)
  %1141 = shufflevector <8 x i16> %1140, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1142 = shufflevector <16 x i16> %1141, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t287 = shufflevector <32 x i16> %1142, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1143 = shl <64 x i16> %t286, %25
  %1144 = sub <64 x i16> %t285, %1143
  %1145 = shufflevector <64 x i16> %1144, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1146 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1145, <8 x i16> %27)
  %1147 = shufflevector <64 x i16> %1144, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1148 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1147, <8 x i16> %27)
  %1149 = shufflevector <64 x i16> %1144, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1150 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1149, <8 x i16> %27)
  %1151 = shufflevector <64 x i16> %1144, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1152 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1151, <8 x i16> %27)
  %1153 = shufflevector <64 x i16> %1144, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %1154 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1153, <8 x i16> %27)
  %1155 = shufflevector <64 x i16> %1144, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %1156 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1155, <8 x i16> %27)
  %1157 = shufflevector <64 x i16> %1144, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %1158 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1157, <8 x i16> %27)
  %1159 = shufflevector <64 x i16> %1144, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1160 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1159, <8 x i16> %27)
  %1161 = shufflevector <8 x i16> %1160, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1162 = shufflevector <16 x i16> %1161, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t288 = shufflevector <32 x i16> %1162, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1163 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1146, <8 x i16> %1146)
  %1164 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1148, <8 x i16> %1148)
  %1165 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1150, <8 x i16> %1150)
  %1166 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1152, <8 x i16> %1152)
  %1167 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1154, <8 x i16> %1154)
  %1168 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1156, <8 x i16> %1156)
  %1169 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1158, <8 x i16> %1158)
  %1170 = shufflevector <64 x i16> %t288, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1171 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1170, <8 x i16> %1170)
  %1172 = shufflevector <8 x i16> %1171, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1173 = shufflevector <16 x i16> %1172, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t289 = shufflevector <32 x i16> %1173, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1174 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1163)
  %1175 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1164)
  %1176 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1165)
  %1177 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1166)
  %1178 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1167)
  %1179 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1168)
  %1180 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1169)
  %1181 = shufflevector <64 x i16> %t289, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1182 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1181)
  %1183 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1146)
  %1184 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1148)
  %1185 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1150)
  %1186 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1152)
  %1187 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1154)
  %1188 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1156)
  %1189 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1158)
  %1190 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1170)
  %1191 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1163, <8 x i16> %1146)
  %1192 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1164, <8 x i16> %1148)
  %1193 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1165, <8 x i16> %1150)
  %1194 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1166, <8 x i16> %1152)
  %1195 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1167, <8 x i16> %1154)
  %1196 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1168, <8 x i16> %1156)
  %1197 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1169, <8 x i16> %1158)
  %1198 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1181, <8 x i16> %1170)
  %1199 = shufflevector <8 x i16> %1198, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1200 = shufflevector <16 x i16> %1199, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1201 = shufflevector <32 x i16> %1200, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1202 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1191)
  %1203 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1192)
  %1204 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1193)
  %1205 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1194)
  %1206 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1195)
  %1207 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1196)
  %1208 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1197)
  %1209 = shufflevector <64 x i16> %1201, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1210 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1209)
  %1211 = add <8 x i16> %1183, %1174
  %1212 = add <8 x i16> %1211, %1202
  %1213 = add <8 x i16> %1184, %1175
  %1214 = add <8 x i16> %1213, %1203
  %1215 = add <8 x i16> %1185, %1176
  %1216 = add <8 x i16> %1215, %1204
  %1217 = add <8 x i16> %1186, %1177
  %1218 = add <8 x i16> %1217, %1205
  %1219 = add <8 x i16> %1187, %1178
  %1220 = add <8 x i16> %1219, %1206
  %1221 = add <8 x i16> %1188, %1179
  %1222 = add <8 x i16> %1221, %1207
  %1223 = add <8 x i16> %1189, %1180
  %1224 = add <8 x i16> %1223, %1208
  %1225 = add <8 x i16> %1190, %1182
  %1226 = add <8 x i16> %1225, %1210
  %1227 = shufflevector <8 x i16> %1226, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1228 = shufflevector <16 x i16> %1227, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1229 = shufflevector <32 x i16> %1228, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1230 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1126, <8 x i16> %1212)
  %1231 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1128, <8 x i16> %1214)
  %1232 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1130, <8 x i16> %1216)
  %1233 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1132, <8 x i16> %1218)
  %1234 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1134, <8 x i16> %1220)
  %1235 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1136, <8 x i16> %1222)
  %1236 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1138, <8 x i16> %1224)
  %1237 = shufflevector <64 x i16> %t287, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1238 = shufflevector <64 x i16> %1229, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1239 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1237, <8 x i16> %1238)
  %1240 = shufflevector <8 x i16> %1239, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1241 = shufflevector <16 x i16> %1240, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1242 = shufflevector <32 x i16> %1241, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1243 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1126, <8 x i16> %1230)
  %1244 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1128, <8 x i16> %1231)
  %1245 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1130, <8 x i16> %1232)
  %1246 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1132, <8 x i16> %1233)
  %1247 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1134, <8 x i16> %1234)
  %1248 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1136, <8 x i16> %1235)
  %1249 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1138, <8 x i16> %1236)
  %1250 = shufflevector <64 x i16> %1242, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1251 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1237, <8 x i16> %1250)
  %1252 = shufflevector <8 x i16> %1251, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1253 = shufflevector <16 x i16> %1252, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1254 = shufflevector <32 x i16> %1253, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1255 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1243, <8 x i16> %575)
  %1256 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1244, <8 x i16> %575)
  %1257 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1245, <8 x i16> %575)
  %1258 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1246, <8 x i16> %575)
  %1259 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1247, <8 x i16> %575)
  %1260 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1248, <8 x i16> %575)
  %1261 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1249, <8 x i16> %575)
  %1262 = shufflevector <64 x i16> %1254, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1263 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1262, <8 x i16> %575)
  %1264 = shufflevector <8 x i16> %1263, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1265 = shufflevector <16 x i16> %1264, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1266 = shufflevector <32 x i16> %1265, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1267 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1255, <8 x i16> %32)
  %1268 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1256, <8 x i16> %32)
  %1269 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1257, <8 x i16> %32)
  %1270 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1258, <8 x i16> %32)
  %1271 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1259, <8 x i16> %32)
  %1272 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1260, <8 x i16> %32)
  %1273 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1261, <8 x i16> %32)
  %1274 = shufflevector <64 x i16> %1266, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1275 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1274, <8 x i16> %32)
  %1276 = shufflevector <8 x i16> %1275, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1277 = shufflevector <16 x i16> %1276, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1278 = shufflevector <32 x i16> %1277, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1279 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1267, <8 x i16> %35)
  %1280 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1268, <8 x i16> %35)
  %1281 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1269, <8 x i16> %35)
  %1282 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1270, <8 x i16> %35)
  %1283 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1271, <8 x i16> %35)
  %1284 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1272, <8 x i16> %35)
  %1285 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1273, <8 x i16> %35)
  %1286 = shufflevector <64 x i16> %1278, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1287 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1286, <8 x i16> %35)
  %1288 = shufflevector <8 x i16> %1287, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1289 = shufflevector <16 x i16> %1288, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1290 = shufflevector <32 x i16> %1289, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1291 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1279, <8 x i16> %38)
  %1292 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1280, <8 x i16> %38)
  %1293 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1281, <8 x i16> %38)
  %1294 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1282, <8 x i16> %38)
  %1295 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1283, <8 x i16> %38)
  %1296 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1284, <8 x i16> %38)
  %1297 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1285, <8 x i16> %38)
  %1298 = shufflevector <64 x i16> %1290, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1299 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1298, <8 x i16> %38)
  %1300 = shufflevector <8 x i16> %1299, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1301 = shufflevector <16 x i16> %1300, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1302 = shufflevector <32 x i16> %1301, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1303 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1291)
  %1304 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1292)
  %1305 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1293)
  %1306 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1294)
  %1307 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1295)
  %1308 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1296)
  %1309 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1297)
  %1310 = shufflevector <64 x i16> %1302, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1311 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1310)
  %1312 = shufflevector <8 x i8> %1303, <8 x i8> %1304, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1313 = shufflevector <8 x i8> %1305, <8 x i8> %1306, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1314 = shufflevector <8 x i8> %1307, <8 x i8> %1308, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1315 = shufflevector <8 x i8> %1309, <8 x i8> %1311, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1316 = shufflevector <32 x i8> %1315, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1317 = add nsw i64 %1082, %576
  %1318 = getelementptr inbounds i8, i8* %6, i64 %1317
  %1319 = bitcast i8* %1318 to <16 x i8>*
  store <16 x i8> %1312, <16 x i8>* %1319, align 1, !tbaa !434
  %1320 = getelementptr inbounds i8, i8* %1318, i64 16
  %1321 = bitcast i8* %1320 to <16 x i8>*
  store <16 x i8> %1313, <16 x i8>* %1321, align 1, !tbaa !434
  %1322 = getelementptr inbounds i8, i8* %1318, i64 32
  %1323 = bitcast i8* %1322 to <16 x i8>*
  store <16 x i8> %1314, <16 x i8>* %1323, align 1, !tbaa !434
  %1324 = shufflevector <64 x i8> %1316, <64 x i8> undef, <16 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1325 = getelementptr inbounds i8, i8* %1318, i64 48
  %1326 = bitcast i8* %1325 to <16 x i8>*
  store <16 x i8> %1324, <16 x i8>* %1326, align 1, !tbaa !434
  %indvars.iv.next4485 = add nuw nsw i64 %indvars.iv4484, 1
  %.not4366 = icmp eq i64 %indvars.iv.next4485, 2
  br i1 %.not4366, label %"for output.s0.x.xi.xi8", label %"for output.s0.x.xi.xi5"

"for output.s0.x.xi.xi8":                         ; preds = %"for output.s0.x.xi.xi5", %"for output.s0.x.xi.xi8"
  %indvars.iv4487 = phi i64 [ %indvars.iv.next4488, %"for output.s0.x.xi.xi8" ], [ 0, %"for output.s0.x.xi.xi5" ]
  %1327 = shl nsw i64 %indvars.iv4487, 6
  %1328 = add nsw i64 %1327, %588
  %1329 = add nsw i64 %1328, %577
  %1330 = getelementptr inbounds i8, i8* %0, i64 %1329
  %1331 = bitcast i8* %1330 to <16 x i8>*
  %1332 = load <16 x i8>, <16 x i8>* %1331, align 1, !tbaa !389
  %1333 = getelementptr inbounds i8, i8* %1330, i64 16
  %1334 = bitcast i8* %1333 to <16 x i8>*
  %1335 = load <16 x i8>, <16 x i8>* %1334, align 1, !tbaa !389
  %1336 = getelementptr inbounds i8, i8* %1330, i64 32
  %1337 = bitcast i8* %1336 to <16 x i8>*
  %1338 = load <16 x i8>, <16 x i8>* %1337, align 1, !tbaa !389
  %1339 = getelementptr inbounds i8, i8* %1330, i64 48
  %1340 = bitcast i8* %1339 to <16 x i8>*
  %1341 = load <16 x i8>, <16 x i8>* %1340, align 1, !tbaa !389
  %1342 = shufflevector <16 x i8> %1332, <16 x i8> %1335, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1343 = shufflevector <16 x i8> %1338, <16 x i8> %1341, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1344 = shufflevector <32 x i8> %1342, <32 x i8> %1343, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1345 = zext <64 x i8> %1344 to <64 x i16>
  %1346 = shl nuw nsw <64 x i16> %1345, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1347 = add <64 x i16> %582, %1346
  %1348 = shufflevector <64 x i16> %1347, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1349 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1348, <8 x i16> %23)
  %1350 = shufflevector <64 x i16> %1347, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1351 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1350, <8 x i16> %23)
  %1352 = shufflevector <64 x i16> %1347, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1353 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1352, <8 x i16> %23)
  %1354 = shufflevector <64 x i16> %1347, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1355 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1354, <8 x i16> %23)
  %1356 = shufflevector <64 x i16> %1347, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %1357 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1356, <8 x i16> %23)
  %1358 = shufflevector <64 x i16> %1347, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %1359 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1358, <8 x i16> %23)
  %1360 = shufflevector <64 x i16> %1347, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %1361 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1360, <8 x i16> %23)
  %1362 = shufflevector <64 x i16> %1347, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1363 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1362, <8 x i16> %23)
  %1364 = shufflevector <8 x i16> %1349, <8 x i16> %1351, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1365 = shufflevector <8 x i16> %1353, <8 x i16> %1355, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1366 = shufflevector <8 x i16> %1357, <8 x i16> %1359, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1367 = shufflevector <8 x i16> %1361, <8 x i16> %1363, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1368 = shufflevector <16 x i16> %1364, <16 x i16> %1365, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1369 = shufflevector <16 x i16> %1366, <16 x i16> %1367, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t292 = shufflevector <32 x i16> %1368, <32 x i16> %1369, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t293 = ashr <64 x i16> %t292, %25
  %1370 = add <64 x i16> %t293, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %1371 = shufflevector <64 x i16> %1370, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1372 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1371)
  %1373 = shufflevector <64 x i16> %1370, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1374 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1373)
  %1375 = shufflevector <64 x i16> %1370, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1376 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1375)
  %1377 = shufflevector <64 x i16> %1370, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1378 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1377)
  %1379 = shufflevector <64 x i16> %1370, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %1380 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1379)
  %1381 = shufflevector <64 x i16> %1370, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %1382 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1381)
  %1383 = shufflevector <64 x i16> %1370, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %1384 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1383)
  %1385 = shufflevector <64 x i16> %1370, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1386 = tail call <8 x i16> @llvm.aarch64.neon.sqshl.v8i16(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, <8 x i16> %1385)
  %1387 = shufflevector <8 x i16> %1386, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1388 = shufflevector <16 x i16> %1387, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t294 = shufflevector <32 x i16> %1388, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1389 = shl <64 x i16> %t293, %25
  %1390 = sub <64 x i16> %t292, %1389
  %1391 = shufflevector <64 x i16> %1390, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1392 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1391, <8 x i16> %27)
  %1393 = shufflevector <64 x i16> %1390, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1394 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1393, <8 x i16> %27)
  %1395 = shufflevector <64 x i16> %1390, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1396 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1395, <8 x i16> %27)
  %1397 = shufflevector <64 x i16> %1390, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1398 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1397, <8 x i16> %27)
  %1399 = shufflevector <64 x i16> %1390, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %1400 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1399, <8 x i16> %27)
  %1401 = shufflevector <64 x i16> %1390, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %1402 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1401, <8 x i16> %27)
  %1403 = shufflevector <64 x i16> %1390, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %1404 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1403, <8 x i16> %27)
  %1405 = shufflevector <64 x i16> %1390, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1406 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1405, <8 x i16> %27)
  %1407 = shufflevector <8 x i16> %1406, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1408 = shufflevector <16 x i16> %1407, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t295 = shufflevector <32 x i16> %1408, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1409 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1392, <8 x i16> %1392)
  %1410 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1394, <8 x i16> %1394)
  %1411 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1396, <8 x i16> %1396)
  %1412 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1398, <8 x i16> %1398)
  %1413 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1400, <8 x i16> %1400)
  %1414 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1402, <8 x i16> %1402)
  %1415 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1404, <8 x i16> %1404)
  %1416 = shufflevector <64 x i16> %t295, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1417 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1416, <8 x i16> %1416)
  %1418 = shufflevector <8 x i16> %1417, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1419 = shufflevector <16 x i16> %1418, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t296 = shufflevector <32 x i16> %1419, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1420 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1409)
  %1421 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1410)
  %1422 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1411)
  %1423 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1412)
  %1424 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1413)
  %1425 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1414)
  %1426 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1415)
  %1427 = shufflevector <64 x i16> %t296, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1428 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1427)
  %1429 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1392)
  %1430 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1394)
  %1431 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1396)
  %1432 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1398)
  %1433 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1400)
  %1434 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1402)
  %1435 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1404)
  %1436 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1416)
  %1437 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1409, <8 x i16> %1392)
  %1438 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1410, <8 x i16> %1394)
  %1439 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1411, <8 x i16> %1396)
  %1440 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1412, <8 x i16> %1398)
  %1441 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1413, <8 x i16> %1400)
  %1442 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1414, <8 x i16> %1402)
  %1443 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1415, <8 x i16> %1404)
  %1444 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1427, <8 x i16> %1416)
  %1445 = shufflevector <8 x i16> %1444, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1446 = shufflevector <16 x i16> %1445, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1447 = shufflevector <32 x i16> %1446, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1448 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1437)
  %1449 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1438)
  %1450 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1439)
  %1451 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1440)
  %1452 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1441)
  %1453 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1442)
  %1454 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1443)
  %1455 = shufflevector <64 x i16> %1447, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1456 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1455)
  %1457 = add <8 x i16> %1429, %1420
  %1458 = add <8 x i16> %1457, %1448
  %1459 = add <8 x i16> %1430, %1421
  %1460 = add <8 x i16> %1459, %1449
  %1461 = add <8 x i16> %1431, %1422
  %1462 = add <8 x i16> %1461, %1450
  %1463 = add <8 x i16> %1432, %1423
  %1464 = add <8 x i16> %1463, %1451
  %1465 = add <8 x i16> %1433, %1424
  %1466 = add <8 x i16> %1465, %1452
  %1467 = add <8 x i16> %1434, %1425
  %1468 = add <8 x i16> %1467, %1453
  %1469 = add <8 x i16> %1435, %1426
  %1470 = add <8 x i16> %1469, %1454
  %1471 = add <8 x i16> %1436, %1428
  %1472 = add <8 x i16> %1471, %1456
  %1473 = shufflevector <8 x i16> %1472, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1474 = shufflevector <16 x i16> %1473, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1475 = shufflevector <32 x i16> %1474, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1476 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1372, <8 x i16> %1458)
  %1477 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1374, <8 x i16> %1460)
  %1478 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1376, <8 x i16> %1462)
  %1479 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1378, <8 x i16> %1464)
  %1480 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1380, <8 x i16> %1466)
  %1481 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1382, <8 x i16> %1468)
  %1482 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1384, <8 x i16> %1470)
  %1483 = shufflevector <64 x i16> %t294, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1484 = shufflevector <64 x i16> %1475, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1485 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1483, <8 x i16> %1484)
  %1486 = shufflevector <8 x i16> %1485, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1487 = shufflevector <16 x i16> %1486, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1488 = shufflevector <32 x i16> %1487, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1489 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1372, <8 x i16> %1476)
  %1490 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1374, <8 x i16> %1477)
  %1491 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1376, <8 x i16> %1478)
  %1492 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1378, <8 x i16> %1479)
  %1493 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1380, <8 x i16> %1480)
  %1494 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1382, <8 x i16> %1481)
  %1495 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1384, <8 x i16> %1482)
  %1496 = shufflevector <64 x i16> %1488, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1497 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1483, <8 x i16> %1496)
  %1498 = shufflevector <8 x i16> %1497, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1499 = shufflevector <16 x i16> %1498, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1500 = shufflevector <32 x i16> %1499, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1501 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1489, <8 x i16> %585)
  %1502 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1490, <8 x i16> %585)
  %1503 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1491, <8 x i16> %585)
  %1504 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1492, <8 x i16> %585)
  %1505 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1493, <8 x i16> %585)
  %1506 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1494, <8 x i16> %585)
  %1507 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1495, <8 x i16> %585)
  %1508 = shufflevector <64 x i16> %1500, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1509 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1508, <8 x i16> %585)
  %1510 = shufflevector <8 x i16> %1509, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1511 = shufflevector <16 x i16> %1510, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1512 = shufflevector <32 x i16> %1511, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1513 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1501, <8 x i16> %32)
  %1514 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1502, <8 x i16> %32)
  %1515 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1503, <8 x i16> %32)
  %1516 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1504, <8 x i16> %32)
  %1517 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1505, <8 x i16> %32)
  %1518 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1506, <8 x i16> %32)
  %1519 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1507, <8 x i16> %32)
  %1520 = shufflevector <64 x i16> %1512, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1521 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1520, <8 x i16> %32)
  %1522 = shufflevector <8 x i16> %1521, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1523 = shufflevector <16 x i16> %1522, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1524 = shufflevector <32 x i16> %1523, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1525 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1513, <8 x i16> %35)
  %1526 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1514, <8 x i16> %35)
  %1527 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1515, <8 x i16> %35)
  %1528 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1516, <8 x i16> %35)
  %1529 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1517, <8 x i16> %35)
  %1530 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1518, <8 x i16> %35)
  %1531 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1519, <8 x i16> %35)
  %1532 = shufflevector <64 x i16> %1524, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1533 = tail call <8 x i16> @llvm.aarch64.neon.srshl.v8i16(<8 x i16> %1532, <8 x i16> %35)
  %1534 = shufflevector <8 x i16> %1533, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1535 = shufflevector <16 x i16> %1534, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1536 = shufflevector <32 x i16> %1535, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1537 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1525, <8 x i16> %38)
  %1538 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1526, <8 x i16> %38)
  %1539 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1527, <8 x i16> %38)
  %1540 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1528, <8 x i16> %38)
  %1541 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1529, <8 x i16> %38)
  %1542 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1530, <8 x i16> %38)
  %1543 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1531, <8 x i16> %38)
  %1544 = shufflevector <64 x i16> %1536, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1545 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1544, <8 x i16> %38)
  %1546 = shufflevector <8 x i16> %1545, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1547 = shufflevector <16 x i16> %1546, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1548 = shufflevector <32 x i16> %1547, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1549 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1537)
  %1550 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1538)
  %1551 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1539)
  %1552 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1540)
  %1553 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1541)
  %1554 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1542)
  %1555 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1543)
  %1556 = shufflevector <64 x i16> %1548, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1557 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %1556)
  %1558 = shufflevector <8 x i8> %1549, <8 x i8> %1550, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1559 = shufflevector <8 x i8> %1551, <8 x i8> %1552, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1560 = shufflevector <8 x i8> %1553, <8 x i8> %1554, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1561 = shufflevector <8 x i8> %1555, <8 x i8> %1557, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1562 = shufflevector <32 x i8> %1561, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1563 = add nsw i64 %1328, %586
  %1564 = getelementptr inbounds i8, i8* %6, i64 %1563
  %1565 = bitcast i8* %1564 to <16 x i8>*
  store <16 x i8> %1558, <16 x i8>* %1565, align 1, !tbaa !434
  %1566 = getelementptr inbounds i8, i8* %1564, i64 16
  %1567 = bitcast i8* %1566 to <16 x i8>*
  store <16 x i8> %1559, <16 x i8>* %1567, align 1, !tbaa !434
  %1568 = getelementptr inbounds i8, i8* %1564, i64 32
  %1569 = bitcast i8* %1568 to <16 x i8>*
  store <16 x i8> %1560, <16 x i8>* %1569, align 1, !tbaa !434
  %1570 = shufflevector <64 x i8> %1562, <64 x i8> undef, <16 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1571 = getelementptr inbounds i8, i8* %1564, i64 48
  %1572 = bitcast i8* %1571 to <16 x i8>*
  store <16 x i8> %1570, <16 x i8>* %1572, align 1, !tbaa !434
  %indvars.iv.next4488 = add nuw nsw i64 %indvars.iv4487, 1
  %.not4367 = icmp eq i64 %indvars.iv.next4488, 2
  br i1 %.not4367, label %"end for output.s0.x.xi.xi9", label %"for output.s0.x.xi.xi8"

"end for output.s0.x.xi.xi9":                     ; preds = %"for output.s0.x.xi.xi8"
  %indvars.iv.next4491 = add nuw nsw i64 %indvars.iv4490, 1
  %.not4368 = icmp eq i64 %indvars.iv.next4491, %47
  br i1 %.not4368, label %"end for output.s0.x.x", label %"for output.s0.x.x"

"for output.s0.y.y33":                            ; preds = %"for output.s0.y.y33.preheader", %"end for output.s0.x.x117"
  %indvars.iv4531 = phi i64 [ 0, %"for output.s0.y.y33.preheader" ], [ %indvars.iv.next4532, %"end for output.s0.x.x117" ]
  store i32 0, i32* %max_x172, align 16
  %1573 = trunc i64 %indvars.iv4531 to i32
  %1574 = shl nsw i32 %1573, 2
  %1575 = add nsw i32 %1574, %.pre4538
  br label %"for max_x.s1.y.rebased41"

"for max_x.s1.y.rebased41":                       ; preds = %"for output.s0.y.y33", %"end for max_x.s1.r6$x.r6$x.rebased50"
  %indvars.iv4503 = phi i64 [ 0, %"for output.s0.y.y33" ], [ %indvars.iv.next4504, %"end for max_x.s1.r6$x.r6$x.rebased50" ]
  %1576 = trunc i64 %indvars.iv4503 to i32
  %1577 = add i32 %1575, %1576
  %1578 = mul i32 %1577, %.pre4535
  %t30744 = sub i32 %1578, %.pre4551
  br i1 %53, label %"for max_x.s1.r6$x.r6$x45.preheader", label %"end for max_x.s1.r6$x.r6$x46", !prof !385

"for max_x.s1.r6$x.r6$x45.preheader":             ; preds = %"for max_x.s1.y.rebased41"
  %1579 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 %indvars.iv4503
  %1580 = sext i32 %t30744 to i64
  %.promoted4441 = load i8, i8* %1579, align 1, !tbaa !386
  br label %"for max_x.s1.r6$x.r6$x45"

"for max_x.s1.r6$x.r6$x45":                       ; preds = %"for max_x.s1.r6$x.r6$x45.preheader", %"for max_x.s1.r6$x.r6$x45"
  %indvars.iv4497 = phi i64 [ 0, %"for max_x.s1.r6$x.r6$x45.preheader" ], [ %indvars.iv.next4498, %"for max_x.s1.r6$x.r6$x45" ]
  %a494442 = phi i8 [ %.promoted4441, %"for max_x.s1.r6$x.r6$x45.preheader" ], [ %1599, %"for max_x.s1.r6$x.r6$x45" ]
  %1581 = shl nuw nsw i64 %indvars.iv4497, 6
  %1582 = add nsw i64 %1581, %1580
  %1583 = getelementptr inbounds i8, i8* %0, i64 %1582
  %1584 = bitcast i8* %1583 to <16 x i8>*
  %1585 = load <16 x i8>, <16 x i8>* %1584, align 1, !tbaa !389
  %1586 = getelementptr inbounds i8, i8* %1583, i64 16
  %1587 = bitcast i8* %1586 to <16 x i8>*
  %1588 = load <16 x i8>, <16 x i8>* %1587, align 1, !tbaa !389
  %1589 = getelementptr inbounds i8, i8* %1583, i64 32
  %1590 = bitcast i8* %1589 to <16 x i8>*
  %1591 = load <16 x i8>, <16 x i8>* %1590, align 1, !tbaa !389
  %1592 = getelementptr inbounds i8, i8* %1583, i64 48
  %1593 = bitcast i8* %1592 to <16 x i8>*
  %1594 = load <16 x i8>, <16 x i8>* %1593, align 1, !tbaa !389
  %1595 = shufflevector <16 x i8> %1585, <16 x i8> %1588, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1596 = shufflevector <16 x i8> %1591, <16 x i8> %1594, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1597 = shufflevector <32 x i8> %1595, <32 x i8> %1596, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %b51 = tail call i8 @llvm.vector.reduce.umax.v64i8(<64 x i8> %1597) #17
  %1598 = icmp ugt i8 %a494442, %b51
  %1599 = select i1 %1598, i8 %a494442, i8 %b51
  %indvars.iv.next4498 = add nuw nsw i64 %indvars.iv4497, 1
  %.not4353 = icmp eq i64 %indvars.iv.next4498, %87
  br i1 %.not4353, label %"end for max_x.s1.r6$x.r6$x46.loopexit", label %"for max_x.s1.r6$x.r6$x45"

"end for max_x.s1.r6$x.r6$x46.loopexit":          ; preds = %"for max_x.s1.r6$x.r6$x45"
  store i8 %1599, i8* %1579, align 1, !tbaa !386
  br label %"end for max_x.s1.r6$x.r6$x46"

"end for max_x.s1.r6$x.r6$x46":                   ; preds = %"end for max_x.s1.r6$x.r6$x46.loopexit", %"for max_x.s1.y.rebased41"
  br i1 %54, label %"for max_x.s1.r6$x.r6$x.rebased49.preheader", label %"end for max_x.s1.r6$x.r6$x.rebased50", !prof !385

"for max_x.s1.r6$x.r6$x.rebased49.preheader":     ; preds = %"end for max_x.s1.r6$x.r6$x46"
  %1600 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 %indvars.iv4503
  br label %"for max_x.s1.r6$x.r6$x.rebased49"

"for max_x.s1.r6$x.r6$x.rebased49":               ; preds = %"for max_x.s1.r6$x.r6$x.rebased49.preheader", %"end for max_x.s1.r6$x.r3455"
  %indvars.iv4501 = phi i64 [ 0, %"for max_x.s1.r6$x.r6$x.rebased49.preheader" ], [ %indvars.iv.next4502, %"end for max_x.s1.r6$x.r3455" ]
  %1601 = trunc i64 %indvars.iv4501 to i32
  %1602 = mul i32 %1601, -64
  %1603 = add i32 %1602, %92
  %1604 = icmp slt i32 %1603, 64
  %smin4579 = select i1 %1604, i32 %1603, i32 64
  %1605 = zext i32 %smin4579 to i64
  %1606 = trunc i64 %indvars.iv4501 to i32
  %1607 = add i32 %t30525, %1606
  %1608 = shl nsw i32 %1607, 6
  %a51 = sub nsw i32 %.pre4533, %1608
  %1609 = icmp sgt i32 %a51, 0
  br i1 %1609, label %"for max_x.s1.r6$x.r3454.preheader", label %"end for max_x.s1.r6$x.r3455", !prof !385

"for max_x.s1.r6$x.r3454.preheader":              ; preds = %"for max_x.s1.r6$x.r6$x.rebased49"
  %1610 = icmp slt i32 %a51, 64
  %t30952 = select i1 %1610, i32 %a51, i32 64
  %t31053 = add nsw i32 %1608, %t30744
  %1611 = sext i32 %t31053 to i64
  %.promoted4444 = load i8, i8* %1600, align 1, !tbaa !386
  %1612 = zext i32 %t30952 to i64
  %min.iters.check4580 = icmp ult i32 %smin4579, 32
  br i1 %min.iters.check4580, label %"for max_x.s1.r6$x.r3454.preheader4601", label %vector.ph4581

vector.ph4581:                                    ; preds = %"for max_x.s1.r6$x.r3454.preheader"
  %n.vec4583 = and i64 %1605, 4294967264
  %minmax.ident.splatinsert4588 = insertelement <16 x i8> poison, i8 %.promoted4444, i32 0
  %minmax.ident.splat4589 = shufflevector <16 x i8> %minmax.ident.splatinsert4588, <16 x i8> poison, <16 x i32> zeroinitializer
  br label %vector.body4578

vector.body4578:                                  ; preds = %vector.body4578, %vector.ph4581
  %index4584 = phi i64 [ 0, %vector.ph4581 ], [ %index.next4585, %vector.body4578 ]
  %vec.phi4590 = phi <16 x i8> [ %minmax.ident.splat4589, %vector.ph4581 ], [ %1620, %vector.body4578 ]
  %vec.phi4591 = phi <16 x i8> [ %minmax.ident.splat4589, %vector.ph4581 ], [ %1621, %vector.body4578 ]
  %1613 = add nsw i64 %index4584, %1611
  %1614 = getelementptr inbounds i8, i8* %0, i64 %1613
  %1615 = bitcast i8* %1614 to <16 x i8>*
  %wide.load4592 = load <16 x i8>, <16 x i8>* %1615, align 1, !tbaa !389
  %1616 = getelementptr inbounds i8, i8* %1614, i64 16
  %1617 = bitcast i8* %1616 to <16 x i8>*
  %wide.load4593 = load <16 x i8>, <16 x i8>* %1617, align 1, !tbaa !389
  %1618 = icmp ugt <16 x i8> %vec.phi4590, %wide.load4592
  %1619 = icmp ugt <16 x i8> %vec.phi4591, %wide.load4593
  %1620 = select <16 x i1> %1618, <16 x i8> %vec.phi4590, <16 x i8> %wide.load4592
  %1621 = select <16 x i1> %1619, <16 x i8> %vec.phi4591, <16 x i8> %wide.load4593
  %index.next4585 = add i64 %index4584, 32
  %1622 = icmp eq i64 %index.next4585, %n.vec4583
  br i1 %1622, label %middle.block4576, label %vector.body4578, !llvm.loop !436

middle.block4576:                                 ; preds = %vector.body4578
  %rdx.minmax.cmp4594 = icmp ugt <16 x i8> %1620, %1621
  %rdx.minmax.select4595 = select <16 x i1> %rdx.minmax.cmp4594, <16 x i8> %1620, <16 x i8> %1621
  %1623 = call i8 @llvm.vector.reduce.umax.v16i8(<16 x i8> %rdx.minmax.select4595)
  %cmp.n4587 = icmp eq i64 %n.vec4583, %1605
  br i1 %cmp.n4587, label %"end for max_x.s1.r6$x.r3455.loopexit", label %"for max_x.s1.r6$x.r3454.preheader4601"

"for max_x.s1.r6$x.r3454.preheader4601":          ; preds = %"for max_x.s1.r6$x.r3454.preheader", %middle.block4576
  %indvars.iv4499.ph = phi i64 [ 0, %"for max_x.s1.r6$x.r3454.preheader" ], [ %n.vec4583, %middle.block4576 ]
  %a544445.ph = phi i8 [ %.promoted4444, %"for max_x.s1.r6$x.r3454.preheader" ], [ %1623, %middle.block4576 ]
  br label %"for max_x.s1.r6$x.r3454"

"end for max_x.s1.r6$x.r6$x.rebased50":           ; preds = %"end for max_x.s1.r6$x.r3455", %"end for max_x.s1.r6$x.r6$x46"
  %indvars.iv.next4504 = add nuw nsw i64 %indvars.iv4503, 1
  %.not173 = icmp eq i64 %indvars.iv.next4504, 4
  br i1 %.not173, label %"for sum_exp_row.s0.y.rebased58.preheader", label %"for max_x.s1.y.rebased41"

"for sum_exp_row.s0.y.rebased58.preheader":       ; preds = %"end for max_x.s1.r6$x.r6$x.rebased50"
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 dereferenceable(16) %sum_exp_row1714465, i8 0, i64 16, i1 false)
  br label %"for sum_exp_row.s1.y.rebased63"

"for max_x.s1.r6$x.r3454":                        ; preds = %"for max_x.s1.r6$x.r3454.preheader4601", %"for max_x.s1.r6$x.r3454"
  %indvars.iv4499 = phi i64 [ %indvars.iv.next4500, %"for max_x.s1.r6$x.r3454" ], [ %indvars.iv4499.ph, %"for max_x.s1.r6$x.r3454.preheader4601" ]
  %a544445 = phi i8 [ %1627, %"for max_x.s1.r6$x.r3454" ], [ %a544445.ph, %"for max_x.s1.r6$x.r3454.preheader4601" ]
  %1624 = add nsw i64 %indvars.iv4499, %1611
  %1625 = getelementptr inbounds i8, i8* %0, i64 %1624
  %b56 = load i8, i8* %1625, align 1, !tbaa !389
  %1626 = icmp ugt i8 %a544445, %b56
  %1627 = select i1 %1626, i8 %a544445, i8 %b56
  %indvars.iv.next4500 = add nuw nsw i64 %indvars.iv4499, 1
  %.not4352 = icmp eq i64 %indvars.iv.next4500, %1612
  br i1 %.not4352, label %"end for max_x.s1.r6$x.r3455.loopexit", label %"for max_x.s1.r6$x.r3454", !llvm.loop !437

"end for max_x.s1.r6$x.r3455.loopexit":           ; preds = %"for max_x.s1.r6$x.r3454", %middle.block4576
  %.lcssa4567 = phi i8 [ %1623, %middle.block4576 ], [ %1627, %"for max_x.s1.r6$x.r3454" ]
  store i8 %.lcssa4567, i8* %1600, align 1, !tbaa !386
  br label %"end for max_x.s1.r6$x.r3455"

"end for max_x.s1.r6$x.r3455":                    ; preds = %"end for max_x.s1.r6$x.r3455.loopexit", %"for max_x.s1.r6$x.r6$x.rebased49"
  %indvars.iv.next4502 = add nuw nsw i64 %indvars.iv4501, 1
  %.not4351 = icmp eq i64 %indvars.iv.next4502, %88
  br i1 %.not4351, label %"end for max_x.s1.r6$x.r6$x.rebased50", label %"for max_x.s1.r6$x.r6$x.rebased49"

"for sum_exp_row.s1.y.rebased63":                 ; preds = %"for sum_exp_row.s0.y.rebased58.preheader", %"end for sum_exp_row.s1.r6$x.r6$x.rebased77"
  %indvars.iv4513 = phi i64 [ 0, %"for sum_exp_row.s0.y.rebased58.preheader" ], [ %indvars.iv.next4514, %"end for sum_exp_row.s1.r6$x.r6$x.rebased77" ]
  %1628 = trunc i64 %indvars.iv4513 to i32
  %1629 = add i32 %1575, %1628
  %1630 = mul i32 %1629, %.pre4535
  %t31366 = sub i32 %1630, %.pre4551
  br i1 %53, label %"for sum_exp_row.s1.r6$x.r6$x67.preheader", label %"end for sum_exp_row.s1.r6$x.r6$x68", !prof !385

"for sum_exp_row.s1.r6$x.r6$x67.preheader":       ; preds = %"for sum_exp_row.s1.y.rebased63"
  %1631 = sext i32 %t31366 to i64
  %1632 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 %indvars.iv4513
  %1633 = load i8, i8* %1632, align 1, !tbaa !386
  %t335 = zext i8 %1633 to i16
  %1634 = mul nsw i16 %t335, -64
  %1635 = insertelement <8 x i16> undef, i16 %1634, i32 0
  %1636 = shufflevector <8 x i16> %1635, <8 x i16> undef, <8 x i32> zeroinitializer
  %1637 = getelementptr inbounds [4 x i32], [4 x i32]* %sum_exp_row171, i64 0, i64 %indvars.iv4513
  %.promoted4447 = load i32, i32* %1637, align 4, !tbaa !393
  br label %"for sum_exp_row.s1.r6$x.r6$x67"

"for sum_exp_row.s1.r6$x.r6$x67":                 ; preds = %"for sum_exp_row.s1.r6$x.r6$x67.preheader", %"for sum_exp_row.s1.r6$x.r6$x67"
  %indvars.iv4507 = phi i64 [ 0, %"for sum_exp_row.s1.r6$x.r6$x67.preheader" ], [ %indvars.iv.next4508, %"for sum_exp_row.s1.r6$x.r6$x67" ]
  %1638 = phi i32 [ %.promoted4447, %"for sum_exp_row.s1.r6$x.r6$x67.preheader" ], [ %1923, %"for sum_exp_row.s1.r6$x.r6$x67" ]
  %1639 = shl nuw nsw i64 %indvars.iv4507, 6
  %1640 = add nsw i64 %1639, %1631
  %1641 = getelementptr inbounds i8, i8* %0, i64 %1640
  %1642 = bitcast i8* %1641 to <16 x i8>*
  %1643 = load <16 x i8>, <16 x i8>* %1642, align 1, !tbaa !389
  %1644 = getelementptr inbounds i8, i8* %1641, i64 16
  %1645 = bitcast i8* %1644 to <16 x i8>*
  %1646 = load <16 x i8>, <16 x i8>* %1645, align 1, !tbaa !389
  %1647 = getelementptr inbounds i8, i8* %1641, i64 32
  %1648 = bitcast i8* %1647 to <16 x i8>*
  %1649 = load <16 x i8>, <16 x i8>* %1648, align 1, !tbaa !389
  %1650 = getelementptr inbounds i8, i8* %1641, i64 48
  %1651 = bitcast i8* %1650 to <16 x i8>*
  %1652 = load <16 x i8>, <16 x i8>* %1651, align 1, !tbaa !389
  %1653 = shufflevector <16 x i8> %1643, <16 x i8> %1646, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1654 = shufflevector <16 x i8> %1649, <16 x i8> %1652, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1655 = shufflevector <32 x i8> %1653, <32 x i8> %1654, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t334 = zext <64 x i8> %1655 to <64 x i16>
  %1656 = shl nuw nsw <64 x i16> %t334, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1657 = bitcast <64 x i16> %1656 to <16 x i64>
  %1658 = shufflevector <16 x i64> %1657, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %1659 = bitcast <2 x i64> %1658 to <8 x i16>
  %1660 = add <8 x i16> %1636, %1659
  %1661 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1660, <8 x i16> %58) #15
  %1662 = shufflevector <16 x i64> %1657, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %1663 = bitcast <2 x i64> %1662 to <8 x i16>
  %1664 = add <8 x i16> %1636, %1663
  %1665 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1664, <8 x i16> %58) #15
  %1666 = shufflevector <16 x i64> %1657, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %1667 = bitcast <2 x i64> %1666 to <8 x i16>
  %1668 = add <8 x i16> %1636, %1667
  %1669 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1668, <8 x i16> %58) #15
  %1670 = shufflevector <16 x i64> %1657, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %1671 = bitcast <2 x i64> %1670 to <8 x i16>
  %1672 = add <8 x i16> %1636, %1671
  %1673 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1672, <8 x i16> %58) #15
  %1674 = shufflevector <16 x i64> %1657, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %1675 = bitcast <2 x i64> %1674 to <8 x i16>
  %1676 = add <8 x i16> %1636, %1675
  %1677 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1676, <8 x i16> %58) #15
  %1678 = shufflevector <16 x i64> %1657, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %1679 = bitcast <2 x i64> %1678 to <8 x i16>
  %1680 = add <8 x i16> %1636, %1679
  %1681 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1680, <8 x i16> %58) #15
  %1682 = shufflevector <16 x i64> %1657, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %1683 = bitcast <2 x i64> %1682 to <8 x i16>
  %1684 = add <8 x i16> %1636, %1683
  %1685 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1684, <8 x i16> %58) #15
  %1686 = shufflevector <16 x i64> %1657, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %1687 = bitcast <2 x i64> %1686 to <8 x i16>
  %1688 = add <8 x i16> %1636, %1687
  %1689 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1688, <8 x i16> %58) #15
  %1690 = shufflevector <8 x i16> %1661, <8 x i16> %1665, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1691 = shufflevector <8 x i16> %1669, <8 x i16> %1673, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1692 = shufflevector <8 x i16> %1677, <8 x i16> %1681, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1693 = shufflevector <8 x i16> %1685, <8 x i16> %1689, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1694 = shufflevector <16 x i16> %1690, <16 x i16> %1691, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1695 = shufflevector <16 x i16> %1692, <16 x i16> %1693, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %"t101.widened.sum_exp_row.s1.r6$x.r3270" = shufflevector <32 x i16> %1694, <32 x i16> %1695, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t336 = shl <64 x i16> %"t101.widened.sum_exp_row.s1.r6$x.r3270", %61
  %1696 = bitcast <64 x i16> %t336 to <16 x i64>
  %1697 = shufflevector <16 x i64> %1696, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %1698 = shufflevector <16 x i64> %1696, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %1699 = shufflevector <16 x i64> %1696, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %1700 = shufflevector <16 x i64> %1696, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %1701 = shufflevector <16 x i64> %1696, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %1702 = shufflevector <16 x i64> %1696, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %1703 = shufflevector <16 x i64> %1696, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %1704 = shufflevector <16 x i64> %1696, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %.cast4302 = bitcast <2 x i64> %1697 to <8 x i16>
  %1705 = add <8 x i16> %.cast4302, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %1706 = bitcast <8 x i16> %1705 to <2 x i64>
  %1707 = shufflevector <2 x i64> %1706, <2 x i64> undef, <1 x i32> zeroinitializer
  %1708 = bitcast <1 x i64> %1707 to <4 x i16>
  %1709 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1708) #15
  %1710 = add <8 x i16> %.cast4302, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %1711 = bitcast <8 x i16> %1710 to <2 x i64>
  %1712 = shufflevector <2 x i64> %1711, <2 x i64> undef, <1 x i32> <i32 1>
  %1713 = bitcast <1 x i64> %1712 to <4 x i16>
  %1714 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1713) #15
  %.cast4306 = bitcast <2 x i64> %1698 to <8 x i16>
  %1715 = add <8 x i16> %.cast4306, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %1716 = bitcast <8 x i16> %1715 to <2 x i64>
  %1717 = shufflevector <2 x i64> %1716, <2 x i64> undef, <1 x i32> zeroinitializer
  %1718 = bitcast <1 x i64> %1717 to <4 x i16>
  %1719 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1718) #15
  %1720 = add <8 x i16> %.cast4306, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %1721 = bitcast <8 x i16> %1720 to <2 x i64>
  %1722 = shufflevector <2 x i64> %1721, <2 x i64> undef, <1 x i32> <i32 1>
  %1723 = bitcast <1 x i64> %1722 to <4 x i16>
  %1724 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1723) #15
  %.cast4310 = bitcast <2 x i64> %1699 to <8 x i16>
  %1725 = add <8 x i16> %.cast4310, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %1726 = bitcast <8 x i16> %1725 to <2 x i64>
  %1727 = shufflevector <2 x i64> %1726, <2 x i64> undef, <1 x i32> zeroinitializer
  %1728 = bitcast <1 x i64> %1727 to <4 x i16>
  %1729 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1728) #15
  %1730 = add <8 x i16> %.cast4310, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %1731 = bitcast <8 x i16> %1730 to <2 x i64>
  %1732 = shufflevector <2 x i64> %1731, <2 x i64> undef, <1 x i32> <i32 1>
  %1733 = bitcast <1 x i64> %1732 to <4 x i16>
  %1734 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1733) #15
  %.cast4314 = bitcast <2 x i64> %1700 to <8 x i16>
  %1735 = add <8 x i16> %.cast4314, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %1736 = bitcast <8 x i16> %1735 to <2 x i64>
  %1737 = shufflevector <2 x i64> %1736, <2 x i64> undef, <1 x i32> zeroinitializer
  %1738 = bitcast <1 x i64> %1737 to <4 x i16>
  %1739 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1738) #15
  %1740 = add <8 x i16> %.cast4314, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %1741 = bitcast <8 x i16> %1740 to <2 x i64>
  %1742 = shufflevector <2 x i64> %1741, <2 x i64> undef, <1 x i32> <i32 1>
  %1743 = bitcast <1 x i64> %1742 to <4 x i16>
  %1744 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1743) #15
  %.cast4318 = bitcast <2 x i64> %1701 to <8 x i16>
  %1745 = add <8 x i16> %.cast4318, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %1746 = bitcast <8 x i16> %1745 to <2 x i64>
  %1747 = shufflevector <2 x i64> %1746, <2 x i64> undef, <1 x i32> zeroinitializer
  %1748 = bitcast <1 x i64> %1747 to <4 x i16>
  %1749 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1748) #15
  %1750 = add <8 x i16> %.cast4318, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %1751 = bitcast <8 x i16> %1750 to <2 x i64>
  %1752 = shufflevector <2 x i64> %1751, <2 x i64> undef, <1 x i32> <i32 1>
  %1753 = bitcast <1 x i64> %1752 to <4 x i16>
  %1754 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1753) #15
  %.cast4322 = bitcast <2 x i64> %1702 to <8 x i16>
  %1755 = add <8 x i16> %.cast4322, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %1756 = bitcast <8 x i16> %1755 to <2 x i64>
  %1757 = shufflevector <2 x i64> %1756, <2 x i64> undef, <1 x i32> zeroinitializer
  %1758 = bitcast <1 x i64> %1757 to <4 x i16>
  %1759 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1758) #15
  %1760 = add <8 x i16> %.cast4322, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %1761 = bitcast <8 x i16> %1760 to <2 x i64>
  %1762 = shufflevector <2 x i64> %1761, <2 x i64> undef, <1 x i32> <i32 1>
  %1763 = bitcast <1 x i64> %1762 to <4 x i16>
  %1764 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1763) #15
  %.cast4326 = bitcast <2 x i64> %1703 to <8 x i16>
  %1765 = add <8 x i16> %.cast4326, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %1766 = bitcast <8 x i16> %1765 to <2 x i64>
  %1767 = shufflevector <2 x i64> %1766, <2 x i64> undef, <1 x i32> zeroinitializer
  %1768 = bitcast <1 x i64> %1767 to <4 x i16>
  %1769 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1768) #15
  %1770 = add <8 x i16> %.cast4326, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %1771 = bitcast <8 x i16> %1770 to <2 x i64>
  %1772 = shufflevector <2 x i64> %1771, <2 x i64> undef, <1 x i32> <i32 1>
  %1773 = bitcast <1 x i64> %1772 to <4 x i16>
  %1774 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1773) #15
  %.cast4330 = bitcast <2 x i64> %1704 to <8 x i16>
  %1775 = add <8 x i16> %.cast4330, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %1776 = bitcast <8 x i16> %1775 to <2 x i64>
  %1777 = shufflevector <2 x i64> %1776, <2 x i64> undef, <1 x i32> zeroinitializer
  %1778 = bitcast <1 x i64> %1777 to <4 x i16>
  %1779 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1778) #15
  %1780 = add <8 x i16> %.cast4330, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %1781 = bitcast <8 x i16> %1780 to <2 x i64>
  %1782 = shufflevector <2 x i64> %1781, <2 x i64> undef, <1 x i32> <i32 1>
  %1783 = bitcast <1 x i64> %1782 to <4 x i16>
  %1784 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %1783) #15
  %1785 = shufflevector <4 x i16> %1709, <4 x i16> %1714, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1786 = shufflevector <4 x i16> %1719, <4 x i16> %1724, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1787 = shufflevector <4 x i16> %1729, <4 x i16> %1734, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1788 = shufflevector <4 x i16> %1739, <4 x i16> %1744, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1789 = shufflevector <4 x i16> %1749, <4 x i16> %1754, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1790 = shufflevector <4 x i16> %1759, <4 x i16> %1764, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1791 = shufflevector <4 x i16> %1769, <4 x i16> %1774, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1792 = shufflevector <4 x i16> %1779, <4 x i16> %1784, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1793 = shufflevector <16 x i16> %1792, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %"t103.widened.sum_exp_row.s1.r6$x.r3272" = shufflevector <32 x i16> %1793, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1794 = and <64 x i16> %"t101.widened.sum_exp_row.s1.r6$x.r3270", %.not4333
  %1795 = shufflevector <64 x i16> %1794, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1796 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1795, <8 x i16> %64)
  %1797 = shufflevector <64 x i16> %1794, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1798 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1797, <8 x i16> %64)
  %1799 = shufflevector <64 x i16> %1794, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1800 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1799, <8 x i16> %64)
  %1801 = shufflevector <64 x i16> %1794, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1802 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1801, <8 x i16> %64)
  %1803 = shufflevector <64 x i16> %1794, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %1804 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1803, <8 x i16> %64)
  %1805 = shufflevector <64 x i16> %1794, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %1806 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1805, <8 x i16> %64)
  %1807 = shufflevector <64 x i16> %1794, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %1808 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1807, <8 x i16> %64)
  %1809 = shufflevector <64 x i16> %1794, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1810 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %1809, <8 x i16> %64)
  %1811 = shufflevector <8 x i16> %1796, <8 x i16> %1798, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1812 = shufflevector <8 x i16> %1800, <8 x i16> %1802, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1813 = shufflevector <8 x i16> %1804, <8 x i16> %1806, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1814 = shufflevector <8 x i16> %1808, <8 x i16> %1810, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1815 = shufflevector <16 x i16> %1811, <16 x i16> %1812, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1816 = shufflevector <16 x i16> %1813, <16 x i16> %1814, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %"t104.widened.sum_exp_row.s1.r6$x.r3273" = shufflevector <32 x i16> %1815, <32 x i16> %1816, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1817 = bitcast <64 x i16> %"t104.widened.sum_exp_row.s1.r6$x.r3273" to <16 x i64>
  %1818 = shufflevector <16 x i64> %1817, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %t346 = bitcast <2 x i64> %1818 to <8 x i16>
  %1819 = shufflevector <16 x i64> %1817, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %t347 = bitcast <2 x i64> %1819 to <8 x i16>
  %1820 = shufflevector <16 x i64> %1817, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %t348 = bitcast <2 x i64> %1820 to <8 x i16>
  %1821 = shufflevector <16 x i64> %1817, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %t349 = bitcast <2 x i64> %1821 to <8 x i16>
  %1822 = shufflevector <16 x i64> %1817, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %t350 = bitcast <2 x i64> %1822 to <8 x i16>
  %1823 = shufflevector <16 x i64> %1817, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %t351 = bitcast <2 x i64> %1823 to <8 x i16>
  %1824 = shufflevector <16 x i64> %1817, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %t352 = bitcast <2 x i64> %1824 to <8 x i16>
  %1825 = shufflevector <16 x i64> %1817, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %t353 = bitcast <2 x i64> %1825 to <8 x i16>
  %1826 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t346, <8 x i16> %t346) #15
  %1827 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t347, <8 x i16> %t347) #15
  %1828 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t348, <8 x i16> %t348) #15
  %1829 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t349, <8 x i16> %t349) #15
  %1830 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t350, <8 x i16> %t350) #15
  %1831 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t351, <8 x i16> %t351) #15
  %1832 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t352, <8 x i16> %t352) #15
  %1833 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t353, <8 x i16> %t353) #15
  %1834 = shufflevector <8 x i16> %1833, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1835 = shufflevector <16 x i16> %1834, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %"t105.widened.sum_exp_row.s1.r6$x.r3274" = shufflevector <32 x i16> %1835, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1836 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1826)
  %1837 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1827)
  %1838 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1828)
  %1839 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1829)
  %1840 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1830)
  %1841 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1831)
  %1842 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1832)
  %1843 = shufflevector <64 x i16> %"t105.widened.sum_exp_row.s1.r6$x.r3274", <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1844 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>, <8 x i16> %1843)
  %1845 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1796)
  %1846 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1798)
  %1847 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1800)
  %1848 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1802)
  %1849 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1804)
  %1850 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1806)
  %1851 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1808)
  %1852 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>, <8 x i16> %1810)
  %1853 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1826, <8 x i16> %1796)
  %1854 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1827, <8 x i16> %1798)
  %1855 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1828, <8 x i16> %1800)
  %1856 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1829, <8 x i16> %1802)
  %1857 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1830, <8 x i16> %1804)
  %1858 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1831, <8 x i16> %1806)
  %1859 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1832, <8 x i16> %1808)
  %1860 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1843, <8 x i16> %1810)
  %1861 = shufflevector <8 x i16> %1860, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1862 = shufflevector <16 x i16> %1861, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1863 = shufflevector <32 x i16> %1862, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1864 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1853)
  %1865 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1854)
  %1866 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1855)
  %1867 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1856)
  %1868 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1857)
  %1869 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1858)
  %1870 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1859)
  %1871 = shufflevector <64 x i16> %1863, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1872 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1871)
  %1873 = add <8 x i16> %1845, %1836
  %1874 = add <8 x i16> %1873, %1864
  %1875 = add <8 x i16> %1846, %1837
  %1876 = add <8 x i16> %1875, %1865
  %1877 = add <8 x i16> %1847, %1838
  %1878 = add <8 x i16> %1877, %1866
  %1879 = add <8 x i16> %1848, %1839
  %1880 = add <8 x i16> %1879, %1867
  %1881 = add <8 x i16> %1849, %1840
  %1882 = add <8 x i16> %1881, %1868
  %1883 = add <8 x i16> %1850, %1841
  %1884 = add <8 x i16> %1883, %1869
  %1885 = add <8 x i16> %1851, %1842
  %1886 = add <8 x i16> %1885, %1870
  %1887 = add <8 x i16> %1852, %1844
  %1888 = add <8 x i16> %1887, %1872
  %1889 = shufflevector <8 x i16> %1888, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1890 = shufflevector <16 x i16> %1889, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1891 = shufflevector <32 x i16> %1890, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1892 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1785, <8 x i16> %1874)
  %1893 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1786, <8 x i16> %1876)
  %1894 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1787, <8 x i16> %1878)
  %1895 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1788, <8 x i16> %1880)
  %1896 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1789, <8 x i16> %1882)
  %1897 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1790, <8 x i16> %1884)
  %1898 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1791, <8 x i16> %1886)
  %1899 = shufflevector <64 x i16> %"t103.widened.sum_exp_row.s1.r6$x.r3272", <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1900 = shufflevector <64 x i16> %1891, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1901 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %1899, <8 x i16> %1900)
  %1902 = shufflevector <8 x i16> %1901, <8 x i16> poison, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1903 = shufflevector <16 x i16> %1902, <16 x i16> poison, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1904 = shufflevector <32 x i16> %1903, <32 x i16> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1905 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1785, <8 x i16> %1892)
  %1906 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1786, <8 x i16> %1893)
  %1907 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1787, <8 x i16> %1894)
  %1908 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1788, <8 x i16> %1895)
  %1909 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1789, <8 x i16> %1896)
  %1910 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1790, <8 x i16> %1897)
  %1911 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1791, <8 x i16> %1898)
  %1912 = shufflevector <64 x i16> %1904, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1913 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %1899, <8 x i16> %1912)
  %1914 = shufflevector <8 x i16> %1905, <8 x i16> %1906, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1915 = shufflevector <8 x i16> %1907, <8 x i16> %1908, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1916 = shufflevector <8 x i16> %1909, <8 x i16> %1910, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1917 = shufflevector <8 x i16> %1911, <8 x i16> %1913, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %1918 = shufflevector <16 x i16> %1914, <16 x i16> %1915, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1919 = shufflevector <16 x i16> %1916, <16 x i16> %1917, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1920 = shufflevector <32 x i16> %1918, <32 x i16> %1919, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1921 = sext <64 x i16> %1920 to <64 x i32>
  %1922 = tail call i32 @llvm.vector.reduce.add.v64i32(<64 x i32> %1921) #17
  %1923 = add nsw i32 %1922, %1638
  %indvars.iv.next4508 = add nuw nsw i64 %indvars.iv4507, 1
  %.not4350 = icmp eq i64 %indvars.iv.next4508, %87
  br i1 %.not4350, label %"end for sum_exp_row.s1.r6$x.r6$x68.loopexit", label %"for sum_exp_row.s1.r6$x.r6$x67"

"end for sum_exp_row.s1.r6$x.r6$x68.loopexit":    ; preds = %"for sum_exp_row.s1.r6$x.r6$x67"
  store i32 %1923, i32* %1637, align 4, !tbaa !393
  br label %"end for sum_exp_row.s1.r6$x.r6$x68"

"end for sum_exp_row.s1.r6$x.r6$x68":             ; preds = %"end for sum_exp_row.s1.r6$x.r6$x68.loopexit", %"for sum_exp_row.s1.y.rebased63"
  br i1 %54, label %"for sum_exp_row.s1.r6$x.r6$x.rebased76.preheader", label %"end for sum_exp_row.s1.r6$x.r6$x.rebased77", !prof !385

"for sum_exp_row.s1.r6$x.r6$x.rebased76.preheader": ; preds = %"end for sum_exp_row.s1.r6$x.r6$x68"
  %1924 = getelementptr inbounds [4 x i8], [4 x i8]* %tmpcast, i64 0, i64 %indvars.iv4513
  %1925 = getelementptr inbounds [4 x i32], [4 x i32]* %sum_exp_row171, i64 0, i64 %indvars.iv4513
  br label %"for sum_exp_row.s1.r6$x.r6$x.rebased76"

"for sum_exp_row.s1.r6$x.r6$x.rebased76":         ; preds = %"for sum_exp_row.s1.r6$x.r6$x.rebased76.preheader", %"end for sum_exp_row.s1.r6$x.r3282"
  %indvars.iv4511 = phi i64 [ 0, %"for sum_exp_row.s1.r6$x.r6$x.rebased76.preheader" ], [ %indvars.iv.next4512, %"end for sum_exp_row.s1.r6$x.r3282" ]
  %1926 = trunc i64 %indvars.iv4511 to i32
  %1927 = add i32 %t30525, %1926
  %1928 = shl nsw i32 %1927, 6
  %a56 = sub nsw i32 %.pre4533, %1928
  %1929 = icmp sgt i32 %a56, 0
  br i1 %1929, label %"for sum_exp_row.s1.r6$x.r3281.preheader", label %"end for sum_exp_row.s1.r6$x.r3282", !prof !385

"for sum_exp_row.s1.r6$x.r3281.preheader":        ; preds = %"for sum_exp_row.s1.r6$x.r6$x.rebased76"
  %1930 = icmp slt i32 %a56, 64
  %t31779 = select i1 %1930, i32 %a56, i32 64
  %t31880 = add nsw i32 %1928, %t31366
  %1931 = sext i32 %t31880 to i64
  %1932 = load i8, i8* %1924, align 1, !tbaa !386
  %1933 = zext i8 %1932 to i16
  %.promoted4449 = load i32, i32* %1925, align 4, !tbaa !393
  %1934 = zext i32 %t31779 to i64
  br label %"for sum_exp_row.s1.r6$x.r3281"

"end for sum_exp_row.s1.r6$x.r6$x.rebased77":     ; preds = %"end for sum_exp_row.s1.r6$x.r3282", %"end for sum_exp_row.s1.r6$x.r6$x68"
  %indvars.iv.next4514 = add nuw nsw i64 %indvars.iv4513, 1
  %.not175 = icmp eq i64 %indvars.iv.next4514, 4
  br i1 %.not175, label %"end for sum_exp_row.s1.r6$x.r6$x.rebased77.for inv_sum_exp_row.s0.y.rebased92_crit_edge", label %"for sum_exp_row.s1.y.rebased63"

"end for sum_exp_row.s1.r6$x.r6$x.rebased77.for inv_sum_exp_row.s0.y.rebased92_crit_edge": ; preds = %"end for sum_exp_row.s1.r6$x.r6$x.rebased77"
  %.14630 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 0
  %.14631 = getelementptr inbounds [4 x i32], [4 x i32]* %sum_exp_row171, i64 0, i64 0
  %indvars.iv.next4516.1 = add nuw nsw i64 0, 1
  br label %"for inv_sum_exp_row.s0.y.rebased92"

"for sum_exp_row.s1.r6$x.r3281":                  ; preds = %"for sum_exp_row.s1.r6$x.r3281.preheader", %"for sum_exp_row.s1.r6$x.r3281"
  %indvars.iv4509 = phi i64 [ 0, %"for sum_exp_row.s1.r6$x.r3281.preheader" ], [ %indvars.iv.next4510, %"for sum_exp_row.s1.r6$x.r3281" ]
  %1935 = phi i32 [ %.promoted4449, %"for sum_exp_row.s1.r6$x.r3281.preheader" ], [ %2011, %"for sum_exp_row.s1.r6$x.r3281" ]
  %1936 = add nsw i64 %indvars.iv4509, %1931
  %1937 = getelementptr inbounds i8, i8* %0, i64 %1936
  %1938 = load i8, i8* %1937, align 1, !tbaa !389
  %1939 = zext i8 %1938 to i16
  %1940 = sub nsw i16 %1939, %1933
  %1941 = shl nsw i16 %1940, 6
  %1942 = insertelement <4 x i16> undef, i16 %1941, i32 0
  %1943 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %1942, <4 x i16> %65)
  %1944 = shufflevector <4 x i32> %1943, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %1945 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %1944, <2 x i32> <i32 -15, i32 undef>)
  %a60 = extractelement <2 x i32> %1945, i64 0
  %1946 = icmp slt i32 %a60, 32767
  %a59 = select i1 %1946, i32 %a60, i32 32767
  %1947 = icmp sgt i32 %a59, -32768
  %1948 = select i1 %1947, i32 %a59, i32 -32768
  %t10184 = trunc i32 %1948 to i16
  %t10285 = ashr i16 %t10184, %beta_shift
  %1949 = add i16 %t10285, 15
  %1950 = sext i16 %1949 to i32
  %1951 = insertelement <2 x i32> undef, i32 %1950, i32 0
  %1952 = tail call <2 x i32> @llvm.aarch64.neon.sshl.v2i32(<2 x i32> <i32 1, i32 undef>, <2 x i32> %1951)
  %a62 = extractelement <2 x i32> %1952, i64 0
  %1953 = icmp slt i32 %a62, 32767
  %a61 = select i1 %1953, i32 %a62, i32 32767
  %1954 = icmp sgt i32 %a61, -32768
  %1955 = select i1 %1954, i32 %a61, i32 -32768
  %t10386 = trunc i32 %1955 to i16
  %1956 = shl i16 %t10285, %beta_shift
  %1957 = sub i16 %t10184, %1956
  %1958 = insertelement <4 x i16> undef, i16 %1957, i32 0
  %1959 = tail call <4 x i16> @llvm.aarch64.neon.sshl.v4i16(<4 x i16> %1958, <4 x i16> %66)
  %1960 = shufflevector <4 x i16> %1959, <4 x i16> undef, <4 x i32> <i32 0, i32 undef, i32 undef, i32 undef>
  %1961 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %1960, <4 x i16> %1960)
  %1962 = shufflevector <4 x i32> %1961, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %1963 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %1962, <2 x i32> <i32 -15, i32 undef>)
  %a64 = extractelement <2 x i32> %1963, i64 0
  %1964 = icmp slt i32 %a64, 32767
  %a63 = select i1 %1964, i32 %a64, i32 32767
  %1965 = icmp sgt i32 %a63, -32768
  %1966 = select i1 %1965, i32 %a63, i32 -32768
  %t10588 = trunc i32 %1966 to i16
  %1967 = insertelement <4 x i16> undef, i16 %t10588, i32 0
  %1968 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 7363, i16 undef, i16 undef, i16 undef>, <4 x i16> %1967)
  %1969 = shufflevector <4 x i32> %1968, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %1970 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %1969, <2 x i32> <i32 -15, i32 undef>)
  %a68 = extractelement <2 x i32> %1970, i64 0
  %1971 = icmp slt i32 %a68, 32767
  %a67 = select i1 %1971, i32 %a68, i32 32767
  %1972 = icmp sgt i32 %a67, -32768
  %1973 = select i1 %1972, i32 %a67, i32 -32768
  %1974 = trunc i32 %1973 to i16
  %1975 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 22812, i16 undef, i16 undef, i16 undef>, <4 x i16> %1960)
  %1976 = shufflevector <4 x i32> %1975, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %1977 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %1976, <2 x i32> <i32 -15, i32 undef>)
  %a70 = extractelement <2 x i32> %1977, i64 0
  %1978 = icmp slt i32 %a70, 32767
  %a69 = select i1 %1978, i32 %a70, i32 32767
  %1979 = icmp sgt i32 %a69, -32768
  %1980 = select i1 %1979, i32 %a69, i32 -32768
  %1981 = trunc i32 %1980 to i16
  %1982 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %1967, <4 x i16> %1960)
  %1983 = shufflevector <4 x i32> %1982, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %1984 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %1983, <2 x i32> <i32 -15, i32 undef>)
  %a74 = extractelement <2 x i32> %1984, i64 0
  %1985 = icmp slt i32 %a74, 32767
  %a73 = select i1 %1985, i32 %a74, i32 32767
  %1986 = icmp sgt i32 %a73, -32768
  %1987 = select i1 %1986, i32 %a73, i32 -32768
  %1988 = trunc i32 %1987 to i16
  %1989 = insertelement <4 x i16> undef, i16 %1988, i32 0
  %1990 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 2592, i16 undef, i16 undef, i16 undef>, <4 x i16> %1989)
  %1991 = shufflevector <4 x i32> %1990, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %1992 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %1991, <2 x i32> <i32 -15, i32 undef>)
  %a72 = extractelement <2 x i32> %1992, i64 0
  %1993 = icmp slt i32 %a72, 32767
  %a71 = select i1 %1993, i32 %a72, i32 32767
  %1994 = icmp sgt i32 %a71, -32768
  %1995 = select i1 %1994, i32 %a71, i32 -32768
  %1996 = trunc i32 %1995 to i16
  %1997 = add i16 %1981, %1974
  %1998 = add i16 %1997, %1996
  %1999 = insertelement <4 x i16> undef, i16 %t10386, i32 0
  %2000 = insertelement <4 x i16> undef, i16 %1998, i32 0
  %2001 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %1999, <4 x i16> %2000)
  %2002 = shufflevector <4 x i32> %2001, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2003 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2002, <2 x i32> <i32 -15, i32 undef>)
  %a66 = extractelement <2 x i32> %2003, i64 0
  %2004 = icmp slt i32 %a66, 32767
  %a65 = select i1 %2004, i32 %a66, i32 32767
  %2005 = icmp sgt i32 %a65, -32768
  %2006 = select i1 %2005, i32 %a65, i32 -32768
  %2007 = trunc i32 %2006 to i16
  %2008 = insertelement <4 x i16> undef, i16 %2007, i32 0
  %2009 = tail call <4 x i16> @llvm.aarch64.neon.sqadd.v4i16(<4 x i16> %1999, <4 x i16> %2008)
  %t204.s89 = extractelement <4 x i16> %2009, i64 0
  %2010 = sext i16 %t204.s89 to i32
  %2011 = add nsw i32 %1935, %2010
  %indvars.iv.next4510 = add nuw nsw i64 %indvars.iv4509, 1
  %.not4300 = icmp eq i64 %indvars.iv.next4510, %1934
  br i1 %.not4300, label %"end for sum_exp_row.s1.r6$x.r3282.loopexit", label %"for sum_exp_row.s1.r6$x.r3281"

"end for sum_exp_row.s1.r6$x.r3282.loopexit":     ; preds = %"for sum_exp_row.s1.r6$x.r3281"
  store i32 %2011, i32* %1925, align 4, !tbaa !393
  br label %"end for sum_exp_row.s1.r6$x.r3282"

"end for sum_exp_row.s1.r6$x.r3282":              ; preds = %"end for sum_exp_row.s1.r6$x.r3282.loopexit", %"for sum_exp_row.s1.r6$x.r6$x.rebased76"
  %indvars.iv.next4512 = add nuw nsw i64 %indvars.iv4511, 1
  %.not4299 = icmp eq i64 %indvars.iv.next4512, %88
  br i1 %.not4299, label %"end for sum_exp_row.s1.r6$x.r6$x.rebased77", label %"for sum_exp_row.s1.r6$x.r6$x.rebased76"

"for inv_sum_exp_row.s0.y.rebased92":             ; preds = %"end for sum_exp_row.s1.r6$x.r6$x.rebased77.for inv_sum_exp_row.s0.y.rebased92_crit_edge", %"for inv_sum_exp_row.s0.y.rebased92.for inv_sum_exp_row.s0.y.rebased92_crit_edge"
  %indvars.iv.next4516.phi = phi i64 [ %indvars.iv.next4516.0, %"for inv_sum_exp_row.s0.y.rebased92.for inv_sum_exp_row.s0.y.rebased92_crit_edge" ], [ %indvars.iv.next4516.1, %"end for sum_exp_row.s1.r6$x.r6$x.rebased77.for inv_sum_exp_row.s0.y.rebased92_crit_edge" ]
  %.phi4632 = phi i32* [ %.04629, %"for inv_sum_exp_row.s0.y.rebased92.for inv_sum_exp_row.s0.y.rebased92_crit_edge" ], [ %.14631, %"end for sum_exp_row.s1.r6$x.r6$x.rebased77.for inv_sum_exp_row.s0.y.rebased92_crit_edge" ]
  %.phi4633 = phi i16* [ %.04628, %"for inv_sum_exp_row.s0.y.rebased92.for inv_sum_exp_row.s0.y.rebased92_crit_edge" ], [ %.14630, %"end for sum_exp_row.s1.r6$x.r6$x.rebased77.for inv_sum_exp_row.s0.y.rebased92_crit_edge" ]
  %t26195 = load i32, i32* %.phi4632, align 4, !tbaa !393
  %2012 = tail call i32 @llvm.ctlz.i32(i32 %t26195, i1 false), !range !395
  %2013 = add nsw i32 %2012, -16
  %2014 = insertelement <2 x i32> undef, i32 %t26195, i32 0
  %2015 = insertelement <2 x i32> undef, i32 %2013, i32 0
  %2016 = tail call <2 x i32> @llvm.aarch64.neon.sshl.v2i32(<2 x i32> %2014, <2 x i32> %2015)
  %2017 = bitcast <2 x i32> %2016 to <4 x i16>
  %2018 = extractelement <4 x i16> %2017, i32 0
  %t26397 = and i16 %2018, 32767
  %2019 = insertelement <4 x i16> undef, i16 %t26397, i32 0
  %2020 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %2019, <4 x i16> %2019)
  %2021 = shufflevector <4 x i32> %2020, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2022 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2021, <2 x i32> <i32 -15, i32 undef>)
  %a76 = extractelement <2 x i32> %2022, i64 0
  %2023 = icmp slt i32 %a76, 32767
  %a75 = select i1 %2023, i32 %a76, i32 32767
  %2024 = icmp sgt i32 %a75, -32768
  %2025 = select i1 %2024, i32 %a75, i32 -32768
  %t26498 = trunc i32 %2025 to i16
  %.neg = mul nsw i32 %2012, -32768
  %2026 = add nsw i32 %.neg, 1015808
  %2027 = insertelement <4 x i16> undef, i16 %t26498, i32 0
  %2028 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 -9421, i16 undef, i16 undef, i16 undef>, <4 x i16> %2027)
  %2029 = shufflevector <4 x i32> %2028, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2030 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2029, <2 x i32> <i32 -15, i32 undef>)
  %a78 = extractelement <2 x i32> %2030, i64 0
  %2031 = icmp slt i32 %a78, 32767
  %a77 = select i1 %2031, i32 %a78, i32 32767
  %2032 = icmp sgt i32 %a77, -32768
  %2033 = select i1 %2032, i32 %a77, i32 -32768
  %2034 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %2027, <4 x i16> %2019)
  %2035 = shufflevector <4 x i32> %2034, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2036 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2035, <2 x i32> <i32 -15, i32 undef>)
  %a82 = extractelement <2 x i32> %2036, i64 0
  %2037 = icmp slt i32 %a82, 32767
  %a81 = select i1 %2037, i32 %a82, i32 32767
  %2038 = icmp sgt i32 %a81, -32768
  %2039 = select i1 %2038, i32 %a81, i32 -32768
  %2040 = trunc i32 %2039 to i16
  %2041 = insertelement <4 x i16> undef, i16 %2040, i32 0
  %2042 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 2555, i16 undef, i16 undef, i16 undef>, <4 x i16> %2041)
  %2043 = shufflevector <4 x i32> %2042, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2044 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2043, <2 x i32> <i32 -15, i32 undef>)
  %a80 = extractelement <2 x i32> %2044, i64 0
  %2045 = icmp slt i32 %a80, 32767
  %a79 = select i1 %2045, i32 %a80, i32 32767
  %2046 = icmp sgt i32 %a79, -32768
  %2047 = select i1 %2046, i32 %a79, i32 -32768
  %2048 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 23249, i16 undef, i16 undef, i16 undef>, <4 x i16> %2019)
  %2049 = shufflevector <4 x i32> %2048, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2050 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2049, <2 x i32> <i32 -15, i32 undef>)
  %a84 = extractelement <2 x i32> %2050, i64 0
  %2051 = icmp slt i32 %a84, 32767
  %a83 = select i1 %2051, i32 %a84, i32 32767
  %2052 = icmp sgt i32 %a83, -32768
  %2053 = select i1 %2052, i32 %a83, i32 -32768
  %2054 = add nsw i32 %2047, %2033
  %2055 = add nsw i32 %2054, %2053
  %2056 = shl i32 %2055, 16
  %sext = add i32 %2056, 327680
  %2057 = ashr exact i32 %sext, 15
  %2058 = insertelement <2 x i32> undef, i32 %2026, i32 0
  %2059 = insertelement <2 x i32> undef, i32 %2057, i32 0
  %2060 = tail call <2 x i32> @llvm.aarch64.neon.sqadd.v2i32(<2 x i32> %2058, <2 x i32> %2059)
  %t26599 = extractelement <2 x i32> %2060, i64 0
  %2061 = sub nsw i32 0, %t26599
  %2062 = shl i32 %2061, 1
  %2063 = add i32 %2062, 1966080
  %sext176 = ashr i32 %2063, 16
  %2064 = insertelement <2 x i32> undef, i32 %sext176, i32 0
  %2065 = tail call <2 x i32> @llvm.aarch64.neon.sshl.v2i32(<2 x i32> <i32 1, i32 undef>, <2 x i32> %2064)
  %a86 = extractelement <2 x i32> %2065, i64 0
  %2066 = icmp slt i32 %a86, 32767
  %a85 = select i1 %2066, i32 %a86, i32 32767
  %2067 = icmp sgt i32 %a85, -32768
  %2068 = select i1 %2067, i32 %a85, i32 -32768
  %t266100 = trunc i32 %2068 to i16
  %2069 = trunc i32 %2061 to i16
  %t267101 = and i16 %2069, 32767
  %2070 = insertelement <4 x i16> undef, i16 %t267101, i32 0
  %2071 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %2070, <4 x i16> %2070)
  %2072 = shufflevector <4 x i32> %2071, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2073 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2072, <2 x i32> <i32 -15, i32 undef>)
  %a88 = extractelement <2 x i32> %2073, i64 0
  %2074 = icmp slt i32 %a88, 32767
  %a87 = select i1 %2074, i32 %a88, i32 32767
  %2075 = icmp sgt i32 %a87, -32768
  %2076 = select i1 %2075, i32 %a87, i32 -32768
  %t268102 = trunc i32 %2076 to i16
  %2077 = insertelement <4 x i16> undef, i16 %t268102, i32 0
  %2078 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 7363, i16 undef, i16 undef, i16 undef>, <4 x i16> %2077)
  %2079 = shufflevector <4 x i32> %2078, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2080 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2079, <2 x i32> <i32 -15, i32 undef>)
  %a92 = extractelement <2 x i32> %2080, i64 0
  %2081 = icmp slt i32 %a92, 32767
  %a91 = select i1 %2081, i32 %a92, i32 32767
  %2082 = icmp sgt i32 %a91, -32768
  %2083 = select i1 %2082, i32 %a91, i32 -32768
  %2084 = trunc i32 %2083 to i16
  %2085 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 22812, i16 undef, i16 undef, i16 undef>, <4 x i16> %2070)
  %2086 = shufflevector <4 x i32> %2085, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2087 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2086, <2 x i32> <i32 -15, i32 undef>)
  %a94 = extractelement <2 x i32> %2087, i64 0
  %2088 = icmp slt i32 %a94, 32767
  %a93 = select i1 %2088, i32 %a94, i32 32767
  %2089 = icmp sgt i32 %a93, -32768
  %2090 = select i1 %2089, i32 %a93, i32 -32768
  %2091 = trunc i32 %2090 to i16
  %2092 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %2077, <4 x i16> %2070)
  %2093 = shufflevector <4 x i32> %2092, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2094 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2093, <2 x i32> <i32 -15, i32 undef>)
  %a98 = extractelement <2 x i32> %2094, i64 0
  %2095 = icmp slt i32 %a98, 32767
  %a97 = select i1 %2095, i32 %a98, i32 32767
  %2096 = icmp sgt i32 %a97, -32768
  %2097 = select i1 %2096, i32 %a97, i32 -32768
  %2098 = trunc i32 %2097 to i16
  %2099 = insertelement <4 x i16> undef, i16 %2098, i32 0
  %2100 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> <i16 2592, i16 undef, i16 undef, i16 undef>, <4 x i16> %2099)
  %2101 = shufflevector <4 x i32> %2100, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2102 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2101, <2 x i32> <i32 -15, i32 undef>)
  %a96 = extractelement <2 x i32> %2102, i64 0
  %2103 = icmp slt i32 %a96, 32767
  %a95 = select i1 %2103, i32 %a96, i32 32767
  %2104 = icmp sgt i32 %a95, -32768
  %2105 = select i1 %2104, i32 %a95, i32 -32768
  %2106 = trunc i32 %2105 to i16
  %2107 = add i16 %2091, %2084
  %2108 = add i16 %2107, %2106
  %2109 = insertelement <4 x i16> undef, i16 %t266100, i32 0
  %2110 = insertelement <4 x i16> undef, i16 %2108, i32 0
  %2111 = tail call <4 x i32> @llvm.aarch64.neon.smull.v4i32(<4 x i16> %2109, <4 x i16> %2110)
  %2112 = shufflevector <4 x i32> %2111, <4 x i32> undef, <2 x i32> <i32 0, i32 undef>
  %2113 = tail call <2 x i32> @llvm.aarch64.neon.srshl.v2i32(<2 x i32> %2112, <2 x i32> <i32 -15, i32 undef>)
  %a90 = extractelement <2 x i32> %2113, i64 0
  %2114 = icmp slt i32 %a90, 32767
  %a89 = select i1 %2114, i32 %a90, i32 32767
  %2115 = icmp sgt i32 %a89, -32768
  %2116 = select i1 %2115, i32 %a89, i32 -32768
  %2117 = trunc i32 %2116 to i16
  %2118 = insertelement <4 x i16> undef, i16 %2117, i32 0
  %2119 = tail call <4 x i16> @llvm.aarch64.neon.sqadd.v4i16(<4 x i16> %2109, <4 x i16> %2118)
  %2120 = extractelement <4 x i16> %2119, i64 0
  store i16 %2120, i16* %.phi4633, align 2, !tbaa !396
  %.not178 = icmp eq i64 %indvars.iv.next4516.phi, 4
  br i1 %.not178, label %"consume max_x104", label %"for inv_sum_exp_row.s0.y.rebased92.for inv_sum_exp_row.s0.y.rebased92_crit_edge"

"for inv_sum_exp_row.s0.y.rebased92.for inv_sum_exp_row.s0.y.rebased92_crit_edge": ; preds = %"for inv_sum_exp_row.s0.y.rebased92"
  %.04628 = getelementptr inbounds <4 x i16>, <4 x i16>* %inv_sum_exp_row170, i64 0, i64 %indvars.iv.next4516.phi
  %.04629 = getelementptr inbounds [4 x i32], [4 x i32]* %sum_exp_row171, i64 0, i64 %indvars.iv.next4516.phi
  %indvars.iv.next4516.0 = add nuw nsw i64 %indvars.iv.next4516.phi, 1
  br label %"for inv_sum_exp_row.s0.y.rebased92"

"consume max_x104":                               ; preds = %"for inv_sum_exp_row.s0.y.rebased92"
  %2121 = add nsw i32 %1574, %67
  br i1 %69, label %"for output.s0.x.x116.preheader", label %"end for output.s0.x.x117", !prof !385

"for output.s0.x.x116.preheader":                 ; preds = %"consume max_x104"
  %2122 = add nsw i32 %1575, 1
  %2123 = mul nsw i32 %2122, %.pre4540
  %t322115 = sub nsw i32 %2123, %68
  %2124 = add nsw i32 %1575, 2
  %2125 = mul nsw i32 %2124, %.pre4540
  %t324114 = sub nsw i32 %2125, %68
  %2126 = add nsw i32 %1575, 3
  %2127 = mul nsw i32 %2126, %.pre4540
  %t326113 = sub nsw i32 %2127, %68
  %2128 = add nsw i32 %2121, 1
  %2129 = mul nsw i32 %2128, %.pre4535
  %t321112 = sub nsw i32 %2129, %.pre
  %2130 = add nsw i32 %2121, 2
  %2131 = mul nsw i32 %2130, %.pre4535
  %t323111 = sub nsw i32 %2131, %.pre
  %2132 = add nsw i32 %2121, 3
  %2133 = mul nsw i32 %2132, %.pre4535
  %t325110 = sub nsw i32 %2133, %.pre
  %2134 = mul nsw i32 %1575, %.pre4540
  %t320109 = sub nsw i32 %2134, %68
  %2135 = mul nsw i32 %2121, %.pre4535
  %t319108 = sub nsw i32 %2135, %.pre
  %2136 = sext i32 %t319108 to i64
  %2137 = load i8, i8* %max_x172.sub, align 16, !tbaa !398
  %t355 = zext i8 %2137 to i16
  %2138 = mul nsw i16 %t355, -64
  %2139 = insertelement <8 x i16> undef, i16 %2138, i32 0
  %2140 = shufflevector <8 x i16> %2139, <8 x i16> undef, <8 x i32> zeroinitializer
  %2141 = load <4 x i16>, <4 x i16>* %inv_sum_exp_row170, align 16
  %t378 = shufflevector <4 x i16> %2141, <4 x i16> poison, <8 x i32> zeroinitializer
  %2142 = sext i32 %t320109 to i64
  %2143 = sext i32 %t321112 to i64
  %2144 = load i8, i8* %81, align 1, !tbaa !410
  %t395 = zext i8 %2144 to i16
  %2145 = mul nsw i16 %t395, -64
  %2146 = insertelement <8 x i16> undef, i16 %2145, i32 0
  %2147 = shufflevector <8 x i16> %2146, <8 x i16> undef, <8 x i32> zeroinitializer
  %2148 = load i16, i16* %82, align 2, !tbaa !412
  %2149 = insertelement <8 x i16> undef, i16 %2148, i32 0
  %t418 = shufflevector <8 x i16> %2149, <8 x i16> undef, <8 x i32> zeroinitializer
  %2150 = sext i32 %t322115 to i64
  %2151 = sext i32 %t323111 to i64
  %2152 = load i8, i8* %83, align 2, !tbaa !424
  %t435 = zext i8 %2152 to i16
  %2153 = mul nsw i16 %t435, -64
  %2154 = insertelement <8 x i16> undef, i16 %2153, i32 0
  %2155 = shufflevector <8 x i16> %2154, <8 x i16> undef, <8 x i32> zeroinitializer
  %2156 = load i16, i16* %84, align 4, !tbaa !427
  %2157 = insertelement <8 x i16> undef, i16 %2156, i32 0
  %t458 = shufflevector <8 x i16> %2157, <8 x i16> undef, <8 x i32> zeroinitializer
  %2158 = sext i32 %t324114 to i64
  %2159 = sext i32 %t325110 to i64
  %2160 = load i8, i8* %85, align 1, !tbaa !430
  %t475 = zext i8 %2160 to i16
  %2161 = mul nsw i16 %t475, -64
  %2162 = insertelement <8 x i16> undef, i16 %2161, i32 0
  %2163 = shufflevector <8 x i16> %2162, <8 x i16> undef, <8 x i32> zeroinitializer
  %2164 = load i16, i16* %86, align 2, !tbaa !432
  %2165 = insertelement <8 x i16> undef, i16 %2164, i32 0
  %t498 = shufflevector <8 x i16> %2165, <8 x i16> undef, <8 x i32> zeroinitializer
  %2166 = sext i32 %t326113 to i64
  br label %"for output.s0.x.x116"

"for output.s0.x.x116":                           ; preds = %"for output.s0.x.x116.preheader", %"end for output.s0.x.xi.xi151"
  %indvars.iv4529 = phi i64 [ 0, %"for output.s0.x.x116.preheader" ], [ %indvars.iv.next4530, %"end for output.s0.x.xi.xi151" ]
  %2167 = shl nsw i64 %indvars.iv4529, 7
  %2168 = add nsw i64 %2167, %90
  br label %"for output.s0.x.xi.xi120"

"end for output.s0.x.x117":                       ; preds = %"end for output.s0.x.xi.xi151", %"consume max_x104"
  %indvars.iv.next4532 = add nuw nsw i64 %indvars.iv4531, 1
  %.not179 = icmp eq i64 %indvars.iv.next4532, %91
  br i1 %.not179, label %destructor_block, label %"for output.s0.y.y33"

"for output.s0.x.xi.xi120":                       ; preds = %"for output.s0.x.x116", %"for output.s0.x.xi.xi120"
  %indvars.iv4517 = phi i64 [ 0, %"for output.s0.x.x116" ], [ %indvars.iv.next4518, %"for output.s0.x.xi.xi120" ]
  %2169 = shl nsw i64 %indvars.iv4517, 6
  %2170 = add nsw i64 %2169, %2168
  %2171 = add nsw i64 %2170, %2136
  %2172 = getelementptr inbounds i8, i8* %0, i64 %2171
  %2173 = bitcast i8* %2172 to <16 x i8>*
  %2174 = load <16 x i8>, <16 x i8>* %2173, align 1, !tbaa !389
  %2175 = getelementptr inbounds i8, i8* %2172, i64 16
  %2176 = bitcast i8* %2175 to <16 x i8>*
  %2177 = load <16 x i8>, <16 x i8>* %2176, align 1, !tbaa !389
  %2178 = getelementptr inbounds i8, i8* %2172, i64 32
  %2179 = bitcast i8* %2178 to <16 x i8>*
  %2180 = load <16 x i8>, <16 x i8>* %2179, align 1, !tbaa !389
  %2181 = getelementptr inbounds i8, i8* %2172, i64 48
  %2182 = bitcast i8* %2181 to <16 x i8>*
  %2183 = load <16 x i8>, <16 x i8>* %2182, align 1, !tbaa !389
  %2184 = shufflevector <16 x i8> %2174, <16 x i8> %2177, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2185 = shufflevector <16 x i8> %2180, <16 x i8> %2183, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2186 = shufflevector <32 x i8> %2184, <32 x i8> %2185, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t354 = zext <64 x i8> %2186 to <64 x i16>
  %2187 = shl nuw nsw <64 x i16> %t354, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %2188 = bitcast <64 x i16> %2187 to <16 x i64>
  %2189 = shufflevector <16 x i64> %2188, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %2190 = bitcast <2 x i64> %2189 to <8 x i16>
  %2191 = add <8 x i16> %2140, %2190
  %2192 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2191, <8 x i16> %58) #15
  %2193 = shufflevector <16 x i64> %2188, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %2194 = bitcast <2 x i64> %2193 to <8 x i16>
  %2195 = add <8 x i16> %2140, %2194
  %2196 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2195, <8 x i16> %58) #15
  %2197 = shufflevector <16 x i64> %2188, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %2198 = bitcast <2 x i64> %2197 to <8 x i16>
  %2199 = add <8 x i16> %2140, %2198
  %2200 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2199, <8 x i16> %58) #15
  %2201 = shufflevector <16 x i64> %2188, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %2202 = bitcast <2 x i64> %2201 to <8 x i16>
  %2203 = add <8 x i16> %2140, %2202
  %2204 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2203, <8 x i16> %58) #15
  %2205 = shufflevector <16 x i64> %2188, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %2206 = bitcast <2 x i64> %2205 to <8 x i16>
  %2207 = add <8 x i16> %2140, %2206
  %2208 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2207, <8 x i16> %58) #15
  %2209 = shufflevector <16 x i64> %2188, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %2210 = bitcast <2 x i64> %2209 to <8 x i16>
  %2211 = add <8 x i16> %2140, %2210
  %2212 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2211, <8 x i16> %58) #15
  %2213 = shufflevector <16 x i64> %2188, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %2214 = bitcast <2 x i64> %2213 to <8 x i16>
  %2215 = add <8 x i16> %2140, %2214
  %2216 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2215, <8 x i16> %58) #15
  %2217 = shufflevector <16 x i64> %2188, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %2218 = bitcast <2 x i64> %2217 to <8 x i16>
  %2219 = add <8 x i16> %2140, %2218
  %2220 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2219, <8 x i16> %58) #15
  %2221 = shufflevector <8 x i16> %2192, <8 x i16> %2196, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2222 = shufflevector <8 x i16> %2200, <8 x i16> %2204, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2223 = shufflevector <8 x i16> %2208, <8 x i16> %2212, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2224 = shufflevector <8 x i16> %2216, <8 x i16> %2220, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2225 = shufflevector <16 x i16> %2221, <16 x i16> %2222, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2226 = shufflevector <16 x i16> %2223, <16 x i16> %2224, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t271124 = shufflevector <32 x i16> %2225, <32 x i16> %2226, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t356 = shl <64 x i16> %t271124, %61
  %2227 = bitcast <64 x i16> %t356 to <16 x i64>
  %2228 = shufflevector <16 x i64> %2227, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %2229 = shufflevector <16 x i64> %2227, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %2230 = shufflevector <16 x i64> %2227, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %2231 = shufflevector <16 x i64> %2227, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %2232 = shufflevector <16 x i64> %2227, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %2233 = shufflevector <16 x i64> %2227, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %2234 = shufflevector <16 x i64> %2227, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %2235 = shufflevector <16 x i64> %2227, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %2236 = and <64 x i16> %t271124, %.not4333
  %2237 = shufflevector <64 x i16> %2236, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2238 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2237, <8 x i16> %64)
  %2239 = shufflevector <64 x i16> %2236, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2240 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2239, <8 x i16> %64)
  %2241 = shufflevector <64 x i16> %2236, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2242 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2241, <8 x i16> %64)
  %2243 = shufflevector <64 x i16> %2236, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2244 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2243, <8 x i16> %64)
  %2245 = shufflevector <64 x i16> %2236, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %2246 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2245, <8 x i16> %64)
  %2247 = shufflevector <64 x i16> %2236, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %2248 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2247, <8 x i16> %64)
  %2249 = shufflevector <64 x i16> %2236, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %2250 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2249, <8 x i16> %64)
  %2251 = shufflevector <64 x i16> %2236, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %2252 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2251, <8 x i16> %64)
  %2253 = shufflevector <8 x i16> %2238, <8 x i16> %2240, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2254 = shufflevector <8 x i16> %2242, <8 x i16> %2244, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2255 = shufflevector <8 x i16> %2246, <8 x i16> %2248, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2256 = shufflevector <8 x i16> %2250, <8 x i16> %2252, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2257 = shufflevector <16 x i16> %2253, <16 x i16> %2254, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2258 = shufflevector <16 x i16> %2255, <16 x i16> %2256, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t365 = shufflevector <32 x i16> %2257, <32 x i16> %2258, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %2259 = bitcast <64 x i16> %t365 to <16 x i64>
  %2260 = shufflevector <16 x i64> %2259, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %t366 = bitcast <2 x i64> %2260 to <8 x i16>
  %2261 = shufflevector <16 x i64> %2259, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %t367 = bitcast <2 x i64> %2261 to <8 x i16>
  %2262 = shufflevector <16 x i64> %2259, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %t368 = bitcast <2 x i64> %2262 to <8 x i16>
  %2263 = shufflevector <16 x i64> %2259, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %t369 = bitcast <2 x i64> %2263 to <8 x i16>
  %2264 = shufflevector <16 x i64> %2259, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %t370 = bitcast <2 x i64> %2264 to <8 x i16>
  %2265 = shufflevector <16 x i64> %2259, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %t371 = bitcast <2 x i64> %2265 to <8 x i16>
  %2266 = shufflevector <16 x i64> %2259, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %t372 = bitcast <2 x i64> %2266 to <8 x i16>
  %2267 = shufflevector <16 x i64> %2259, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %t373 = bitcast <2 x i64> %2267 to <8 x i16>
  %.cast = bitcast <2 x i64> %2228 to <8 x i16>
  %2268 = add <8 x i16> %.cast, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2269 = bitcast <8 x i16> %2268 to <2 x i64>
  %2270 = shufflevector <2 x i64> %2269, <2 x i64> undef, <1 x i32> zeroinitializer
  %2271 = bitcast <1 x i64> %2270 to <4 x i16>
  %2272 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2271) #15
  %2273 = add <8 x i16> %.cast, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2274 = bitcast <8 x i16> %2273 to <2 x i64>
  %2275 = shufflevector <2 x i64> %2274, <2 x i64> undef, <1 x i32> <i32 1>
  %2276 = bitcast <1 x i64> %2275 to <4 x i16>
  %2277 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2276) #15
  %2278 = shufflevector <4 x i16> %2272, <4 x i16> %2277, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2279 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t366, <8 x i16> %t366) #15
  %2280 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2279, <8 x i16> %t366) #15
  %2281 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2280) #15
  %2282 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t366, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2283 = add <8 x i16> %2282, %2281
  %2284 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2279, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2285 = add <8 x i16> %2283, %2284
  %2286 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2278, <8 x i16> %2285) #15
  %2287 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2286, <8 x i16> %2278) #15
  %2288 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2287, <8 x i16> %t378) #15
  %2289 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2288, <8 x i16> %71) #15
  %2290 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2289) #15
  %2291 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2290, <8 x i16> %77) #15
  %2292 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2291, <8 x i16> %80) #15
  %2293 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2292) #15
  %.cast290 = bitcast <2 x i64> %2229 to <8 x i16>
  %2294 = add <8 x i16> %.cast290, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2295 = bitcast <8 x i16> %2294 to <2 x i64>
  %2296 = shufflevector <2 x i64> %2295, <2 x i64> undef, <1 x i32> zeroinitializer
  %2297 = bitcast <1 x i64> %2296 to <4 x i16>
  %2298 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2297) #15
  %2299 = add <8 x i16> %.cast290, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2300 = bitcast <8 x i16> %2299 to <2 x i64>
  %2301 = shufflevector <2 x i64> %2300, <2 x i64> undef, <1 x i32> <i32 1>
  %2302 = bitcast <1 x i64> %2301 to <4 x i16>
  %2303 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2302) #15
  %2304 = shufflevector <4 x i16> %2298, <4 x i16> %2303, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2305 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t367, <8 x i16> %t367) #15
  %2306 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2305, <8 x i16> %t367) #15
  %2307 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2306) #15
  %2308 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t367, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2309 = add <8 x i16> %2308, %2307
  %2310 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2305, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2311 = add <8 x i16> %2309, %2310
  %2312 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2304, <8 x i16> %2311) #15
  %2313 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2312, <8 x i16> %2304) #15
  %2314 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2313, <8 x i16> %t378) #15
  %2315 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2314, <8 x i16> %71) #15
  %2316 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2315) #15
  %2317 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2316, <8 x i16> %77) #15
  %2318 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2317, <8 x i16> %80) #15
  %2319 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2318) #15
  %2320 = shufflevector <8 x i8> %2293, <8 x i8> %2319, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2321 = bitcast <64 x i8> %2320 to <8 x i64>
  %2322 = shufflevector <8 x i64> %2321, <8 x i64> undef, <2 x i32> <i32 0, i32 1>
  %.cast640 = bitcast <2 x i64> %2230 to <8 x i16>
  %2323 = add <8 x i16> %.cast640, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2324 = bitcast <8 x i16> %2323 to <2 x i64>
  %2325 = shufflevector <2 x i64> %2324, <2 x i64> undef, <1 x i32> zeroinitializer
  %2326 = bitcast <1 x i64> %2325 to <4 x i16>
  %2327 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2326) #15
  %2328 = add <8 x i16> %.cast640, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2329 = bitcast <8 x i16> %2328 to <2 x i64>
  %2330 = shufflevector <2 x i64> %2329, <2 x i64> undef, <1 x i32> <i32 1>
  %2331 = bitcast <1 x i64> %2330 to <4 x i16>
  %2332 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2331) #15
  %2333 = shufflevector <4 x i16> %2327, <4 x i16> %2332, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2334 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t368, <8 x i16> %t368) #15
  %2335 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2334, <8 x i16> %t368) #15
  %2336 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2335) #15
  %2337 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t368, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2338 = add <8 x i16> %2337, %2336
  %2339 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2334, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2340 = add <8 x i16> %2338, %2339
  %2341 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2333, <8 x i16> %2340) #15
  %2342 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2341, <8 x i16> %2333) #15
  %2343 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2342, <8 x i16> %t378) #15
  %2344 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2343, <8 x i16> %71) #15
  %2345 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2344) #15
  %2346 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2345, <8 x i16> %77) #15
  %2347 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2346, <8 x i16> %80) #15
  %2348 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2347) #15
  %.cast654 = bitcast <2 x i64> %2231 to <8 x i16>
  %2349 = add <8 x i16> %.cast654, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2350 = bitcast <8 x i16> %2349 to <2 x i64>
  %2351 = shufflevector <2 x i64> %2350, <2 x i64> undef, <1 x i32> zeroinitializer
  %2352 = bitcast <1 x i64> %2351 to <4 x i16>
  %2353 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2352) #15
  %2354 = add <8 x i16> %.cast654, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2355 = bitcast <8 x i16> %2354 to <2 x i64>
  %2356 = shufflevector <2 x i64> %2355, <2 x i64> undef, <1 x i32> <i32 1>
  %2357 = bitcast <1 x i64> %2356 to <4 x i16>
  %2358 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2357) #15
  %2359 = shufflevector <4 x i16> %2353, <4 x i16> %2358, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2360 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t369, <8 x i16> %t369) #15
  %2361 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2360, <8 x i16> %t369) #15
  %2362 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2361) #15
  %2363 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t369, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2364 = add <8 x i16> %2363, %2362
  %2365 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2360, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2366 = add <8 x i16> %2364, %2365
  %2367 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2359, <8 x i16> %2366) #15
  %2368 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2367, <8 x i16> %2359) #15
  %2369 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2368, <8 x i16> %t378) #15
  %2370 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2369, <8 x i16> %71) #15
  %2371 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2370) #15
  %2372 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2371, <8 x i16> %77) #15
  %2373 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2372, <8 x i16> %80) #15
  %2374 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2373) #15
  %2375 = shufflevector <8 x i8> %2348, <8 x i8> %2374, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2376 = shufflevector <32 x i8> %2375, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2377 = bitcast <64 x i8> %2376 to <8 x i64>
  %2378 = shufflevector <8 x i64> %2377, <8 x i64> undef, <2 x i32> <i32 2, i32 3>
  %.cast892 = bitcast <2 x i64> %2232 to <8 x i16>
  %2379 = add <8 x i16> %.cast892, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2380 = bitcast <8 x i16> %2379 to <2 x i64>
  %2381 = shufflevector <2 x i64> %2380, <2 x i64> undef, <1 x i32> zeroinitializer
  %2382 = bitcast <1 x i64> %2381 to <4 x i16>
  %2383 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2382) #15
  %2384 = add <8 x i16> %.cast892, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2385 = bitcast <8 x i16> %2384 to <2 x i64>
  %2386 = shufflevector <2 x i64> %2385, <2 x i64> undef, <1 x i32> <i32 1>
  %2387 = bitcast <1 x i64> %2386 to <4 x i16>
  %2388 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2387) #15
  %2389 = shufflevector <4 x i16> %2383, <4 x i16> %2388, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2390 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t370, <8 x i16> %t370) #15
  %2391 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2390, <8 x i16> %t370) #15
  %2392 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2391) #15
  %2393 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t370, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2394 = add <8 x i16> %2393, %2392
  %2395 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2390, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2396 = add <8 x i16> %2394, %2395
  %2397 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2389, <8 x i16> %2396) #15
  %2398 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2397, <8 x i16> %2389) #15
  %2399 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2398, <8 x i16> %t378) #15
  %2400 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2399, <8 x i16> %71) #15
  %2401 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2400) #15
  %2402 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2401, <8 x i16> %77) #15
  %2403 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2402, <8 x i16> %80) #15
  %2404 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2403) #15
  %.cast906 = bitcast <2 x i64> %2233 to <8 x i16>
  %2405 = add <8 x i16> %.cast906, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2406 = bitcast <8 x i16> %2405 to <2 x i64>
  %2407 = shufflevector <2 x i64> %2406, <2 x i64> undef, <1 x i32> zeroinitializer
  %2408 = bitcast <1 x i64> %2407 to <4 x i16>
  %2409 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2408) #15
  %2410 = add <8 x i16> %.cast906, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2411 = bitcast <8 x i16> %2410 to <2 x i64>
  %2412 = shufflevector <2 x i64> %2411, <2 x i64> undef, <1 x i32> <i32 1>
  %2413 = bitcast <1 x i64> %2412 to <4 x i16>
  %2414 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2413) #15
  %2415 = shufflevector <4 x i16> %2409, <4 x i16> %2414, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2416 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t371, <8 x i16> %t371) #15
  %2417 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2416, <8 x i16> %t371) #15
  %2418 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2417) #15
  %2419 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t371, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2420 = add <8 x i16> %2419, %2418
  %2421 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2416, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2422 = add <8 x i16> %2420, %2421
  %2423 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2415, <8 x i16> %2422) #15
  %2424 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2423, <8 x i16> %2415) #15
  %2425 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2424, <8 x i16> %t378) #15
  %2426 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2425, <8 x i16> %71) #15
  %2427 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2426) #15
  %2428 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2427, <8 x i16> %77) #15
  %2429 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2428, <8 x i16> %80) #15
  %2430 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2429) #15
  %2431 = shufflevector <8 x i8> %2404, <8 x i8> %2430, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2432 = bitcast <64 x i8> %2431 to <8 x i64>
  %2433 = shufflevector <8 x i64> %2432, <8 x i64> undef, <2 x i32> <i32 4, i32 5>
  %.cast1144 = bitcast <2 x i64> %2234 to <8 x i16>
  %2434 = add <8 x i16> %.cast1144, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2435 = bitcast <8 x i16> %2434 to <2 x i64>
  %2436 = shufflevector <2 x i64> %2435, <2 x i64> undef, <1 x i32> zeroinitializer
  %2437 = bitcast <1 x i64> %2436 to <4 x i16>
  %2438 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2437) #15
  %2439 = add <8 x i16> %.cast1144, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2440 = bitcast <8 x i16> %2439 to <2 x i64>
  %2441 = shufflevector <2 x i64> %2440, <2 x i64> undef, <1 x i32> <i32 1>
  %2442 = bitcast <1 x i64> %2441 to <4 x i16>
  %2443 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2442) #15
  %2444 = shufflevector <4 x i16> %2438, <4 x i16> %2443, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2445 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t372, <8 x i16> %t372) #15
  %2446 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2445, <8 x i16> %t372) #15
  %2447 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2446) #15
  %2448 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t372, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2449 = add <8 x i16> %2448, %2447
  %2450 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2445, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2451 = add <8 x i16> %2449, %2450
  %2452 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2444, <8 x i16> %2451) #15
  %2453 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2452, <8 x i16> %2444) #15
  %2454 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2453, <8 x i16> %t378) #15
  %2455 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2454, <8 x i16> %71) #15
  %2456 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2455) #15
  %2457 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2456, <8 x i16> %77) #15
  %2458 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2457, <8 x i16> %80) #15
  %2459 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2458) #15
  %.cast1158 = bitcast <2 x i64> %2235 to <8 x i16>
  %2460 = add <8 x i16> %.cast1158, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2461 = bitcast <8 x i16> %2460 to <2 x i64>
  %2462 = shufflevector <2 x i64> %2461, <2 x i64> undef, <1 x i32> zeroinitializer
  %2463 = bitcast <1 x i64> %2462 to <4 x i16>
  %2464 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2463) #15
  %2465 = add <8 x i16> %.cast1158, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2466 = bitcast <8 x i16> %2465 to <2 x i64>
  %2467 = shufflevector <2 x i64> %2466, <2 x i64> undef, <1 x i32> <i32 1>
  %2468 = bitcast <1 x i64> %2467 to <4 x i16>
  %2469 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2468) #15
  %2470 = shufflevector <4 x i16> %2464, <4 x i16> %2469, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2471 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t373, <8 x i16> %t373) #15
  %2472 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2471, <8 x i16> %t373) #15
  %2473 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2472) #15
  %2474 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t373, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2475 = add <8 x i16> %2474, %2473
  %2476 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2471, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2477 = add <8 x i16> %2475, %2476
  %2478 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2470, <8 x i16> %2477) #15
  %2479 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2478, <8 x i16> %2470) #15
  %2480 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2479, <8 x i16> %t378) #15
  %2481 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2480, <8 x i16> %71) #15
  %2482 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2481) #15
  %2483 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2482, <8 x i16> %77) #15
  %2484 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2483, <8 x i16> %80) #15
  %2485 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2484) #15
  %2486 = shufflevector <8 x i8> %2459, <8 x i8> %2485, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2487 = shufflevector <32 x i8> %2486, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2488 = bitcast <64 x i8> %2487 to <8 x i64>
  %2489 = shufflevector <8 x i64> %2488, <8 x i64> undef, <2 x i32> <i32 6, i32 7>
  %2490 = add nsw i64 %2170, %2142
  %2491 = getelementptr inbounds i8, i8* %6, i64 %2490
  %2492 = bitcast i8* %2491 to <2 x i64>*
  store <2 x i64> %2322, <2 x i64>* %2492, align 1, !tbaa !434
  %2493 = getelementptr inbounds i8, i8* %2491, i64 16
  %2494 = bitcast i8* %2493 to <2 x i64>*
  store <2 x i64> %2378, <2 x i64>* %2494, align 1, !tbaa !434
  %2495 = getelementptr inbounds i8, i8* %2491, i64 32
  %2496 = bitcast i8* %2495 to <2 x i64>*
  store <2 x i64> %2433, <2 x i64>* %2496, align 1, !tbaa !434
  %2497 = getelementptr inbounds i8, i8* %2491, i64 48
  %2498 = bitcast i8* %2497 to <2 x i64>*
  store <2 x i64> %2489, <2 x i64>* %2498, align 1, !tbaa !434
  %indvars.iv.next4518 = add nuw nsw i64 %indvars.iv4517, 1
  %.not1171 = icmp eq i64 %indvars.iv.next4518, 2
  br i1 %.not1171, label %"for output.s0.x.xi.xi130", label %"for output.s0.x.xi.xi120"

"for output.s0.x.xi.xi130":                       ; preds = %"for output.s0.x.xi.xi120", %"for output.s0.x.xi.xi130"
  %indvars.iv4520 = phi i64 [ %indvars.iv.next4521, %"for output.s0.x.xi.xi130" ], [ 0, %"for output.s0.x.xi.xi120" ]
  %2499 = shl nsw i64 %indvars.iv4520, 6
  %2500 = add nsw i64 %2499, %2168
  %2501 = add nsw i64 %2500, %2143
  %2502 = getelementptr inbounds i8, i8* %0, i64 %2501
  %2503 = bitcast i8* %2502 to <16 x i8>*
  %2504 = load <16 x i8>, <16 x i8>* %2503, align 1, !tbaa !389
  %2505 = getelementptr inbounds i8, i8* %2502, i64 16
  %2506 = bitcast i8* %2505 to <16 x i8>*
  %2507 = load <16 x i8>, <16 x i8>* %2506, align 1, !tbaa !389
  %2508 = getelementptr inbounds i8, i8* %2502, i64 32
  %2509 = bitcast i8* %2508 to <16 x i8>*
  %2510 = load <16 x i8>, <16 x i8>* %2509, align 1, !tbaa !389
  %2511 = getelementptr inbounds i8, i8* %2502, i64 48
  %2512 = bitcast i8* %2511 to <16 x i8>*
  %2513 = load <16 x i8>, <16 x i8>* %2512, align 1, !tbaa !389
  %2514 = shufflevector <16 x i8> %2504, <16 x i8> %2507, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2515 = shufflevector <16 x i8> %2510, <16 x i8> %2513, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2516 = shufflevector <32 x i8> %2514, <32 x i8> %2515, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t394 = zext <64 x i8> %2516 to <64 x i16>
  %2517 = shl nuw nsw <64 x i16> %t394, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %2518 = bitcast <64 x i16> %2517 to <16 x i64>
  %2519 = shufflevector <16 x i64> %2518, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %2520 = bitcast <2 x i64> %2519 to <8 x i16>
  %2521 = add <8 x i16> %2147, %2520
  %2522 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2521, <8 x i16> %58) #15
  %2523 = shufflevector <16 x i64> %2518, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %2524 = bitcast <2 x i64> %2523 to <8 x i16>
  %2525 = add <8 x i16> %2147, %2524
  %2526 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2525, <8 x i16> %58) #15
  %2527 = shufflevector <16 x i64> %2518, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %2528 = bitcast <2 x i64> %2527 to <8 x i16>
  %2529 = add <8 x i16> %2147, %2528
  %2530 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2529, <8 x i16> %58) #15
  %2531 = shufflevector <16 x i64> %2518, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %2532 = bitcast <2 x i64> %2531 to <8 x i16>
  %2533 = add <8 x i16> %2147, %2532
  %2534 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2533, <8 x i16> %58) #15
  %2535 = shufflevector <16 x i64> %2518, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %2536 = bitcast <2 x i64> %2535 to <8 x i16>
  %2537 = add <8 x i16> %2147, %2536
  %2538 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2537, <8 x i16> %58) #15
  %2539 = shufflevector <16 x i64> %2518, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %2540 = bitcast <2 x i64> %2539 to <8 x i16>
  %2541 = add <8 x i16> %2147, %2540
  %2542 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2541, <8 x i16> %58) #15
  %2543 = shufflevector <16 x i64> %2518, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %2544 = bitcast <2 x i64> %2543 to <8 x i16>
  %2545 = add <8 x i16> %2147, %2544
  %2546 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2545, <8 x i16> %58) #15
  %2547 = shufflevector <16 x i64> %2518, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %2548 = bitcast <2 x i64> %2547 to <8 x i16>
  %2549 = add <8 x i16> %2147, %2548
  %2550 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2549, <8 x i16> %58) #15
  %2551 = shufflevector <8 x i16> %2522, <8 x i16> %2526, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2552 = shufflevector <8 x i16> %2530, <8 x i16> %2534, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2553 = shufflevector <8 x i16> %2538, <8 x i16> %2542, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2554 = shufflevector <8 x i16> %2546, <8 x i16> %2550, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2555 = shufflevector <16 x i16> %2551, <16 x i16> %2552, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2556 = shufflevector <16 x i16> %2553, <16 x i16> %2554, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t278134 = shufflevector <32 x i16> %2555, <32 x i16> %2556, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t396 = shl <64 x i16> %t278134, %61
  %2557 = bitcast <64 x i16> %t396 to <16 x i64>
  %2558 = shufflevector <16 x i64> %2557, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %2559 = shufflevector <16 x i64> %2557, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %2560 = shufflevector <16 x i64> %2557, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %2561 = shufflevector <16 x i64> %2557, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %2562 = shufflevector <16 x i64> %2557, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %2563 = shufflevector <16 x i64> %2557, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %2564 = shufflevector <16 x i64> %2557, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %2565 = shufflevector <16 x i64> %2557, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %2566 = and <64 x i16> %t278134, %.not4333
  %2567 = shufflevector <64 x i16> %2566, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2568 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2567, <8 x i16> %64)
  %2569 = shufflevector <64 x i16> %2566, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2570 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2569, <8 x i16> %64)
  %2571 = shufflevector <64 x i16> %2566, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2572 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2571, <8 x i16> %64)
  %2573 = shufflevector <64 x i16> %2566, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2574 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2573, <8 x i16> %64)
  %2575 = shufflevector <64 x i16> %2566, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %2576 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2575, <8 x i16> %64)
  %2577 = shufflevector <64 x i16> %2566, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %2578 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2577, <8 x i16> %64)
  %2579 = shufflevector <64 x i16> %2566, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %2580 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2579, <8 x i16> %64)
  %2581 = shufflevector <64 x i16> %2566, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %2582 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2581, <8 x i16> %64)
  %2583 = shufflevector <8 x i16> %2568, <8 x i16> %2570, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2584 = shufflevector <8 x i16> %2572, <8 x i16> %2574, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2585 = shufflevector <8 x i16> %2576, <8 x i16> %2578, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2586 = shufflevector <8 x i16> %2580, <8 x i16> %2582, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2587 = shufflevector <16 x i16> %2583, <16 x i16> %2584, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2588 = shufflevector <16 x i16> %2585, <16 x i16> %2586, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t405 = shufflevector <32 x i16> %2587, <32 x i16> %2588, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %2589 = bitcast <64 x i16> %t405 to <16 x i64>
  %2590 = shufflevector <16 x i64> %2589, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %t406 = bitcast <2 x i64> %2590 to <8 x i16>
  %2591 = shufflevector <16 x i64> %2589, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %t407 = bitcast <2 x i64> %2591 to <8 x i16>
  %2592 = shufflevector <16 x i64> %2589, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %t408 = bitcast <2 x i64> %2592 to <8 x i16>
  %2593 = shufflevector <16 x i64> %2589, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %t409 = bitcast <2 x i64> %2593 to <8 x i16>
  %2594 = shufflevector <16 x i64> %2589, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %t410 = bitcast <2 x i64> %2594 to <8 x i16>
  %2595 = shufflevector <16 x i64> %2589, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %t411 = bitcast <2 x i64> %2595 to <8 x i16>
  %2596 = shufflevector <16 x i64> %2589, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %t412 = bitcast <2 x i64> %2596 to <8 x i16>
  %2597 = shufflevector <16 x i64> %2589, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %t413 = bitcast <2 x i64> %2597 to <8 x i16>
  %.cast1318 = bitcast <2 x i64> %2558 to <8 x i16>
  %2598 = add <8 x i16> %.cast1318, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2599 = bitcast <8 x i16> %2598 to <2 x i64>
  %2600 = shufflevector <2 x i64> %2599, <2 x i64> undef, <1 x i32> zeroinitializer
  %2601 = bitcast <1 x i64> %2600 to <4 x i16>
  %2602 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2601) #15
  %2603 = add <8 x i16> %.cast1318, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2604 = bitcast <8 x i16> %2603 to <2 x i64>
  %2605 = shufflevector <2 x i64> %2604, <2 x i64> undef, <1 x i32> <i32 1>
  %2606 = bitcast <1 x i64> %2605 to <4 x i16>
  %2607 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2606) #15
  %2608 = shufflevector <4 x i16> %2602, <4 x i16> %2607, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2609 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t406, <8 x i16> %t406) #15
  %2610 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2609, <8 x i16> %t406) #15
  %2611 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2610) #15
  %2612 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t406, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2613 = add <8 x i16> %2612, %2611
  %2614 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2609, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2615 = add <8 x i16> %2613, %2614
  %2616 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2608, <8 x i16> %2615) #15
  %2617 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2616, <8 x i16> %2608) #15
  %2618 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2617, <8 x i16> %t418) #15
  %2619 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2618, <8 x i16> %71) #15
  %2620 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2619) #15
  %2621 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2620, <8 x i16> %77) #15
  %2622 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2621, <8 x i16> %80) #15
  %2623 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2622) #15
  %.cast1332 = bitcast <2 x i64> %2559 to <8 x i16>
  %2624 = add <8 x i16> %.cast1332, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2625 = bitcast <8 x i16> %2624 to <2 x i64>
  %2626 = shufflevector <2 x i64> %2625, <2 x i64> undef, <1 x i32> zeroinitializer
  %2627 = bitcast <1 x i64> %2626 to <4 x i16>
  %2628 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2627) #15
  %2629 = add <8 x i16> %.cast1332, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2630 = bitcast <8 x i16> %2629 to <2 x i64>
  %2631 = shufflevector <2 x i64> %2630, <2 x i64> undef, <1 x i32> <i32 1>
  %2632 = bitcast <1 x i64> %2631 to <4 x i16>
  %2633 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2632) #15
  %2634 = shufflevector <4 x i16> %2628, <4 x i16> %2633, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2635 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t407, <8 x i16> %t407) #15
  %2636 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2635, <8 x i16> %t407) #15
  %2637 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2636) #15
  %2638 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t407, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2639 = add <8 x i16> %2638, %2637
  %2640 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2635, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2641 = add <8 x i16> %2639, %2640
  %2642 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2634, <8 x i16> %2641) #15
  %2643 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2642, <8 x i16> %2634) #15
  %2644 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2643, <8 x i16> %t418) #15
  %2645 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2644, <8 x i16> %71) #15
  %2646 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2645) #15
  %2647 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2646, <8 x i16> %77) #15
  %2648 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2647, <8 x i16> %80) #15
  %2649 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2648) #15
  %2650 = shufflevector <8 x i8> %2623, <8 x i8> %2649, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2651 = bitcast <64 x i8> %2650 to <8 x i64>
  %2652 = shufflevector <8 x i64> %2651, <8 x i64> undef, <2 x i32> <i32 0, i32 1>
  %.cast1682 = bitcast <2 x i64> %2560 to <8 x i16>
  %2653 = add <8 x i16> %.cast1682, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2654 = bitcast <8 x i16> %2653 to <2 x i64>
  %2655 = shufflevector <2 x i64> %2654, <2 x i64> undef, <1 x i32> zeroinitializer
  %2656 = bitcast <1 x i64> %2655 to <4 x i16>
  %2657 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2656) #15
  %2658 = add <8 x i16> %.cast1682, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2659 = bitcast <8 x i16> %2658 to <2 x i64>
  %2660 = shufflevector <2 x i64> %2659, <2 x i64> undef, <1 x i32> <i32 1>
  %2661 = bitcast <1 x i64> %2660 to <4 x i16>
  %2662 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2661) #15
  %2663 = shufflevector <4 x i16> %2657, <4 x i16> %2662, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2664 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t408, <8 x i16> %t408) #15
  %2665 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2664, <8 x i16> %t408) #15
  %2666 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2665) #15
  %2667 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t408, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2668 = add <8 x i16> %2667, %2666
  %2669 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2664, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2670 = add <8 x i16> %2668, %2669
  %2671 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2663, <8 x i16> %2670) #15
  %2672 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2671, <8 x i16> %2663) #15
  %2673 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2672, <8 x i16> %t418) #15
  %2674 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2673, <8 x i16> %71) #15
  %2675 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2674) #15
  %2676 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2675, <8 x i16> %77) #15
  %2677 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2676, <8 x i16> %80) #15
  %2678 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2677) #15
  %.cast1696 = bitcast <2 x i64> %2561 to <8 x i16>
  %2679 = add <8 x i16> %.cast1696, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2680 = bitcast <8 x i16> %2679 to <2 x i64>
  %2681 = shufflevector <2 x i64> %2680, <2 x i64> undef, <1 x i32> zeroinitializer
  %2682 = bitcast <1 x i64> %2681 to <4 x i16>
  %2683 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2682) #15
  %2684 = add <8 x i16> %.cast1696, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2685 = bitcast <8 x i16> %2684 to <2 x i64>
  %2686 = shufflevector <2 x i64> %2685, <2 x i64> undef, <1 x i32> <i32 1>
  %2687 = bitcast <1 x i64> %2686 to <4 x i16>
  %2688 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2687) #15
  %2689 = shufflevector <4 x i16> %2683, <4 x i16> %2688, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2690 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t409, <8 x i16> %t409) #15
  %2691 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2690, <8 x i16> %t409) #15
  %2692 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2691) #15
  %2693 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t409, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2694 = add <8 x i16> %2693, %2692
  %2695 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2690, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2696 = add <8 x i16> %2694, %2695
  %2697 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2689, <8 x i16> %2696) #15
  %2698 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2697, <8 x i16> %2689) #15
  %2699 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2698, <8 x i16> %t418) #15
  %2700 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2699, <8 x i16> %71) #15
  %2701 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2700) #15
  %2702 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2701, <8 x i16> %77) #15
  %2703 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2702, <8 x i16> %80) #15
  %2704 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2703) #15
  %2705 = shufflevector <8 x i8> %2678, <8 x i8> %2704, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2706 = shufflevector <32 x i8> %2705, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2707 = bitcast <64 x i8> %2706 to <8 x i64>
  %2708 = shufflevector <8 x i64> %2707, <8 x i64> undef, <2 x i32> <i32 2, i32 3>
  %.cast1934 = bitcast <2 x i64> %2562 to <8 x i16>
  %2709 = add <8 x i16> %.cast1934, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2710 = bitcast <8 x i16> %2709 to <2 x i64>
  %2711 = shufflevector <2 x i64> %2710, <2 x i64> undef, <1 x i32> zeroinitializer
  %2712 = bitcast <1 x i64> %2711 to <4 x i16>
  %2713 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2712) #15
  %2714 = add <8 x i16> %.cast1934, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2715 = bitcast <8 x i16> %2714 to <2 x i64>
  %2716 = shufflevector <2 x i64> %2715, <2 x i64> undef, <1 x i32> <i32 1>
  %2717 = bitcast <1 x i64> %2716 to <4 x i16>
  %2718 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2717) #15
  %2719 = shufflevector <4 x i16> %2713, <4 x i16> %2718, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2720 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t410, <8 x i16> %t410) #15
  %2721 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2720, <8 x i16> %t410) #15
  %2722 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2721) #15
  %2723 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t410, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2724 = add <8 x i16> %2723, %2722
  %2725 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2720, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2726 = add <8 x i16> %2724, %2725
  %2727 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2719, <8 x i16> %2726) #15
  %2728 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2727, <8 x i16> %2719) #15
  %2729 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2728, <8 x i16> %t418) #15
  %2730 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2729, <8 x i16> %71) #15
  %2731 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2730) #15
  %2732 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2731, <8 x i16> %77) #15
  %2733 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2732, <8 x i16> %80) #15
  %2734 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2733) #15
  %.cast1948 = bitcast <2 x i64> %2563 to <8 x i16>
  %2735 = add <8 x i16> %.cast1948, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2736 = bitcast <8 x i16> %2735 to <2 x i64>
  %2737 = shufflevector <2 x i64> %2736, <2 x i64> undef, <1 x i32> zeroinitializer
  %2738 = bitcast <1 x i64> %2737 to <4 x i16>
  %2739 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2738) #15
  %2740 = add <8 x i16> %.cast1948, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2741 = bitcast <8 x i16> %2740 to <2 x i64>
  %2742 = shufflevector <2 x i64> %2741, <2 x i64> undef, <1 x i32> <i32 1>
  %2743 = bitcast <1 x i64> %2742 to <4 x i16>
  %2744 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2743) #15
  %2745 = shufflevector <4 x i16> %2739, <4 x i16> %2744, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2746 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t411, <8 x i16> %t411) #15
  %2747 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2746, <8 x i16> %t411) #15
  %2748 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2747) #15
  %2749 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t411, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2750 = add <8 x i16> %2749, %2748
  %2751 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2746, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2752 = add <8 x i16> %2750, %2751
  %2753 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2745, <8 x i16> %2752) #15
  %2754 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2753, <8 x i16> %2745) #15
  %2755 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2754, <8 x i16> %t418) #15
  %2756 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2755, <8 x i16> %71) #15
  %2757 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2756) #15
  %2758 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2757, <8 x i16> %77) #15
  %2759 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2758, <8 x i16> %80) #15
  %2760 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2759) #15
  %2761 = shufflevector <8 x i8> %2734, <8 x i8> %2760, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2762 = bitcast <64 x i8> %2761 to <8 x i64>
  %2763 = shufflevector <8 x i64> %2762, <8 x i64> undef, <2 x i32> <i32 4, i32 5>
  %.cast2186 = bitcast <2 x i64> %2564 to <8 x i16>
  %2764 = add <8 x i16> %.cast2186, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2765 = bitcast <8 x i16> %2764 to <2 x i64>
  %2766 = shufflevector <2 x i64> %2765, <2 x i64> undef, <1 x i32> zeroinitializer
  %2767 = bitcast <1 x i64> %2766 to <4 x i16>
  %2768 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2767) #15
  %2769 = add <8 x i16> %.cast2186, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2770 = bitcast <8 x i16> %2769 to <2 x i64>
  %2771 = shufflevector <2 x i64> %2770, <2 x i64> undef, <1 x i32> <i32 1>
  %2772 = bitcast <1 x i64> %2771 to <4 x i16>
  %2773 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2772) #15
  %2774 = shufflevector <4 x i16> %2768, <4 x i16> %2773, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2775 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t412, <8 x i16> %t412) #15
  %2776 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2775, <8 x i16> %t412) #15
  %2777 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2776) #15
  %2778 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t412, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2779 = add <8 x i16> %2778, %2777
  %2780 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2775, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2781 = add <8 x i16> %2779, %2780
  %2782 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2774, <8 x i16> %2781) #15
  %2783 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2782, <8 x i16> %2774) #15
  %2784 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2783, <8 x i16> %t418) #15
  %2785 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2784, <8 x i16> %71) #15
  %2786 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2785) #15
  %2787 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2786, <8 x i16> %77) #15
  %2788 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2787, <8 x i16> %80) #15
  %2789 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2788) #15
  %.cast2200 = bitcast <2 x i64> %2565 to <8 x i16>
  %2790 = add <8 x i16> %.cast2200, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2791 = bitcast <8 x i16> %2790 to <2 x i64>
  %2792 = shufflevector <2 x i64> %2791, <2 x i64> undef, <1 x i32> zeroinitializer
  %2793 = bitcast <1 x i64> %2792 to <4 x i16>
  %2794 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2793) #15
  %2795 = add <8 x i16> %.cast2200, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2796 = bitcast <8 x i16> %2795 to <2 x i64>
  %2797 = shufflevector <2 x i64> %2796, <2 x i64> undef, <1 x i32> <i32 1>
  %2798 = bitcast <1 x i64> %2797 to <4 x i16>
  %2799 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2798) #15
  %2800 = shufflevector <4 x i16> %2794, <4 x i16> %2799, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2801 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t413, <8 x i16> %t413) #15
  %2802 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2801, <8 x i16> %t413) #15
  %2803 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2802) #15
  %2804 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t413, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2805 = add <8 x i16> %2804, %2803
  %2806 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2801, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2807 = add <8 x i16> %2805, %2806
  %2808 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2800, <8 x i16> %2807) #15
  %2809 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2808, <8 x i16> %2800) #15
  %2810 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2809, <8 x i16> %t418) #15
  %2811 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2810, <8 x i16> %71) #15
  %2812 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2811) #15
  %2813 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2812, <8 x i16> %77) #15
  %2814 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2813, <8 x i16> %80) #15
  %2815 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2814) #15
  %2816 = shufflevector <8 x i8> %2789, <8 x i8> %2815, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2817 = shufflevector <32 x i8> %2816, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2818 = bitcast <64 x i8> %2817 to <8 x i64>
  %2819 = shufflevector <8 x i64> %2818, <8 x i64> undef, <2 x i32> <i32 6, i32 7>
  %2820 = add nsw i64 %2500, %2150
  %2821 = getelementptr inbounds i8, i8* %6, i64 %2820
  %2822 = bitcast i8* %2821 to <2 x i64>*
  store <2 x i64> %2652, <2 x i64>* %2822, align 1, !tbaa !434
  %2823 = getelementptr inbounds i8, i8* %2821, i64 16
  %2824 = bitcast i8* %2823 to <2 x i64>*
  store <2 x i64> %2708, <2 x i64>* %2824, align 1, !tbaa !434
  %2825 = getelementptr inbounds i8, i8* %2821, i64 32
  %2826 = bitcast i8* %2825 to <2 x i64>*
  store <2 x i64> %2763, <2 x i64>* %2826, align 1, !tbaa !434
  %2827 = getelementptr inbounds i8, i8* %2821, i64 48
  %2828 = bitcast i8* %2827 to <2 x i64>*
  store <2 x i64> %2819, <2 x i64>* %2828, align 1, !tbaa !434
  %indvars.iv.next4521 = add nuw nsw i64 %indvars.iv4520, 1
  %.not2213 = icmp eq i64 %indvars.iv.next4521, 2
  br i1 %.not2213, label %"for output.s0.x.xi.xi140", label %"for output.s0.x.xi.xi130"

"for output.s0.x.xi.xi140":                       ; preds = %"for output.s0.x.xi.xi130", %"for output.s0.x.xi.xi140"
  %indvars.iv4523 = phi i64 [ %indvars.iv.next4524, %"for output.s0.x.xi.xi140" ], [ 0, %"for output.s0.x.xi.xi130" ]
  %2829 = shl nsw i64 %indvars.iv4523, 6
  %2830 = add nsw i64 %2829, %2168
  %2831 = add nsw i64 %2830, %2151
  %2832 = getelementptr inbounds i8, i8* %0, i64 %2831
  %2833 = bitcast i8* %2832 to <16 x i8>*
  %2834 = load <16 x i8>, <16 x i8>* %2833, align 1, !tbaa !389
  %2835 = getelementptr inbounds i8, i8* %2832, i64 16
  %2836 = bitcast i8* %2835 to <16 x i8>*
  %2837 = load <16 x i8>, <16 x i8>* %2836, align 1, !tbaa !389
  %2838 = getelementptr inbounds i8, i8* %2832, i64 32
  %2839 = bitcast i8* %2838 to <16 x i8>*
  %2840 = load <16 x i8>, <16 x i8>* %2839, align 1, !tbaa !389
  %2841 = getelementptr inbounds i8, i8* %2832, i64 48
  %2842 = bitcast i8* %2841 to <16 x i8>*
  %2843 = load <16 x i8>, <16 x i8>* %2842, align 1, !tbaa !389
  %2844 = shufflevector <16 x i8> %2834, <16 x i8> %2837, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2845 = shufflevector <16 x i8> %2840, <16 x i8> %2843, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2846 = shufflevector <32 x i8> %2844, <32 x i8> %2845, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t434 = zext <64 x i8> %2846 to <64 x i16>
  %2847 = shl nuw nsw <64 x i16> %t434, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %2848 = bitcast <64 x i16> %2847 to <16 x i64>
  %2849 = shufflevector <16 x i64> %2848, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %2850 = bitcast <2 x i64> %2849 to <8 x i16>
  %2851 = add <8 x i16> %2155, %2850
  %2852 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2851, <8 x i16> %58) #15
  %2853 = shufflevector <16 x i64> %2848, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %2854 = bitcast <2 x i64> %2853 to <8 x i16>
  %2855 = add <8 x i16> %2155, %2854
  %2856 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2855, <8 x i16> %58) #15
  %2857 = shufflevector <16 x i64> %2848, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %2858 = bitcast <2 x i64> %2857 to <8 x i16>
  %2859 = add <8 x i16> %2155, %2858
  %2860 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2859, <8 x i16> %58) #15
  %2861 = shufflevector <16 x i64> %2848, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %2862 = bitcast <2 x i64> %2861 to <8 x i16>
  %2863 = add <8 x i16> %2155, %2862
  %2864 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2863, <8 x i16> %58) #15
  %2865 = shufflevector <16 x i64> %2848, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %2866 = bitcast <2 x i64> %2865 to <8 x i16>
  %2867 = add <8 x i16> %2155, %2866
  %2868 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2867, <8 x i16> %58) #15
  %2869 = shufflevector <16 x i64> %2848, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %2870 = bitcast <2 x i64> %2869 to <8 x i16>
  %2871 = add <8 x i16> %2155, %2870
  %2872 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2871, <8 x i16> %58) #15
  %2873 = shufflevector <16 x i64> %2848, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %2874 = bitcast <2 x i64> %2873 to <8 x i16>
  %2875 = add <8 x i16> %2155, %2874
  %2876 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2875, <8 x i16> %58) #15
  %2877 = shufflevector <16 x i64> %2848, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %2878 = bitcast <2 x i64> %2877 to <8 x i16>
  %2879 = add <8 x i16> %2155, %2878
  %2880 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2879, <8 x i16> %58) #15
  %2881 = shufflevector <8 x i16> %2852, <8 x i16> %2856, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2882 = shufflevector <8 x i16> %2860, <8 x i16> %2864, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2883 = shufflevector <8 x i16> %2868, <8 x i16> %2872, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2884 = shufflevector <8 x i16> %2876, <8 x i16> %2880, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2885 = shufflevector <16 x i16> %2881, <16 x i16> %2882, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2886 = shufflevector <16 x i16> %2883, <16 x i16> %2884, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t285144 = shufflevector <32 x i16> %2885, <32 x i16> %2886, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t436 = shl <64 x i16> %t285144, %61
  %2887 = bitcast <64 x i16> %t436 to <16 x i64>
  %2888 = shufflevector <16 x i64> %2887, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %2889 = shufflevector <16 x i64> %2887, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %2890 = shufflevector <16 x i64> %2887, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %2891 = shufflevector <16 x i64> %2887, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %2892 = shufflevector <16 x i64> %2887, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %2893 = shufflevector <16 x i64> %2887, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %2894 = shufflevector <16 x i64> %2887, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %2895 = shufflevector <16 x i64> %2887, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %2896 = and <64 x i16> %t285144, %.not4333
  %2897 = shufflevector <64 x i16> %2896, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2898 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2897, <8 x i16> %64)
  %2899 = shufflevector <64 x i16> %2896, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2900 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2899, <8 x i16> %64)
  %2901 = shufflevector <64 x i16> %2896, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2902 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2901, <8 x i16> %64)
  %2903 = shufflevector <64 x i16> %2896, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2904 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2903, <8 x i16> %64)
  %2905 = shufflevector <64 x i16> %2896, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %2906 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2905, <8 x i16> %64)
  %2907 = shufflevector <64 x i16> %2896, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %2908 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2907, <8 x i16> %64)
  %2909 = shufflevector <64 x i16> %2896, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %2910 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2909, <8 x i16> %64)
  %2911 = shufflevector <64 x i16> %2896, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %2912 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %2911, <8 x i16> %64)
  %2913 = shufflevector <8 x i16> %2898, <8 x i16> %2900, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2914 = shufflevector <8 x i16> %2902, <8 x i16> %2904, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2915 = shufflevector <8 x i16> %2906, <8 x i16> %2908, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2916 = shufflevector <8 x i16> %2910, <8 x i16> %2912, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2917 = shufflevector <16 x i16> %2913, <16 x i16> %2914, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2918 = shufflevector <16 x i16> %2915, <16 x i16> %2916, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t445 = shufflevector <32 x i16> %2917, <32 x i16> %2918, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %2919 = bitcast <64 x i16> %t445 to <16 x i64>
  %2920 = shufflevector <16 x i64> %2919, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %t446 = bitcast <2 x i64> %2920 to <8 x i16>
  %2921 = shufflevector <16 x i64> %2919, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %t447 = bitcast <2 x i64> %2921 to <8 x i16>
  %2922 = shufflevector <16 x i64> %2919, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %t448 = bitcast <2 x i64> %2922 to <8 x i16>
  %2923 = shufflevector <16 x i64> %2919, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %t449 = bitcast <2 x i64> %2923 to <8 x i16>
  %2924 = shufflevector <16 x i64> %2919, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %t450 = bitcast <2 x i64> %2924 to <8 x i16>
  %2925 = shufflevector <16 x i64> %2919, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %t451 = bitcast <2 x i64> %2925 to <8 x i16>
  %2926 = shufflevector <16 x i64> %2919, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %t452 = bitcast <2 x i64> %2926 to <8 x i16>
  %2927 = shufflevector <16 x i64> %2919, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %t453 = bitcast <2 x i64> %2927 to <8 x i16>
  %.cast2360 = bitcast <2 x i64> %2888 to <8 x i16>
  %2928 = add <8 x i16> %.cast2360, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2929 = bitcast <8 x i16> %2928 to <2 x i64>
  %2930 = shufflevector <2 x i64> %2929, <2 x i64> undef, <1 x i32> zeroinitializer
  %2931 = bitcast <1 x i64> %2930 to <4 x i16>
  %2932 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2931) #15
  %2933 = add <8 x i16> %.cast2360, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2934 = bitcast <8 x i16> %2933 to <2 x i64>
  %2935 = shufflevector <2 x i64> %2934, <2 x i64> undef, <1 x i32> <i32 1>
  %2936 = bitcast <1 x i64> %2935 to <4 x i16>
  %2937 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2936) #15
  %2938 = shufflevector <4 x i16> %2932, <4 x i16> %2937, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2939 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t446, <8 x i16> %t446) #15
  %2940 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2939, <8 x i16> %t446) #15
  %2941 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2940) #15
  %2942 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t446, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2943 = add <8 x i16> %2942, %2941
  %2944 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2939, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2945 = add <8 x i16> %2943, %2944
  %2946 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2938, <8 x i16> %2945) #15
  %2947 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2946, <8 x i16> %2938) #15
  %2948 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2947, <8 x i16> %t458) #15
  %2949 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2948, <8 x i16> %71) #15
  %2950 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2949) #15
  %2951 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2950, <8 x i16> %77) #15
  %2952 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2951, <8 x i16> %80) #15
  %2953 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2952) #15
  %.cast2374 = bitcast <2 x i64> %2889 to <8 x i16>
  %2954 = add <8 x i16> %.cast2374, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2955 = bitcast <8 x i16> %2954 to <2 x i64>
  %2956 = shufflevector <2 x i64> %2955, <2 x i64> undef, <1 x i32> zeroinitializer
  %2957 = bitcast <1 x i64> %2956 to <4 x i16>
  %2958 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2957) #15
  %2959 = add <8 x i16> %.cast2374, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2960 = bitcast <8 x i16> %2959 to <2 x i64>
  %2961 = shufflevector <2 x i64> %2960, <2 x i64> undef, <1 x i32> <i32 1>
  %2962 = bitcast <1 x i64> %2961 to <4 x i16>
  %2963 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2962) #15
  %2964 = shufflevector <4 x i16> %2958, <4 x i16> %2963, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2965 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t447, <8 x i16> %t447) #15
  %2966 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2965, <8 x i16> %t447) #15
  %2967 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2966) #15
  %2968 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t447, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2969 = add <8 x i16> %2968, %2967
  %2970 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2965, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %2971 = add <8 x i16> %2969, %2970
  %2972 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2964, <8 x i16> %2971) #15
  %2973 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2972, <8 x i16> %2964) #15
  %2974 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2973, <8 x i16> %t458) #15
  %2975 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2974, <8 x i16> %71) #15
  %2976 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %2975) #15
  %2977 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %2976, <8 x i16> %77) #15
  %2978 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %2977, <8 x i16> %80) #15
  %2979 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %2978) #15
  %2980 = shufflevector <8 x i8> %2953, <8 x i8> %2979, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2981 = bitcast <64 x i8> %2980 to <8 x i64>
  %2982 = shufflevector <8 x i64> %2981, <8 x i64> undef, <2 x i32> <i32 0, i32 1>
  %.cast2724 = bitcast <2 x i64> %2890 to <8 x i16>
  %2983 = add <8 x i16> %.cast2724, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %2984 = bitcast <8 x i16> %2983 to <2 x i64>
  %2985 = shufflevector <2 x i64> %2984, <2 x i64> undef, <1 x i32> zeroinitializer
  %2986 = bitcast <1 x i64> %2985 to <4 x i16>
  %2987 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2986) #15
  %2988 = add <8 x i16> %.cast2724, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %2989 = bitcast <8 x i16> %2988 to <2 x i64>
  %2990 = shufflevector <2 x i64> %2989, <2 x i64> undef, <1 x i32> <i32 1>
  %2991 = bitcast <1 x i64> %2990 to <4 x i16>
  %2992 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %2991) #15
  %2993 = shufflevector <4 x i16> %2987, <4 x i16> %2992, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2994 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t448, <8 x i16> %t448) #15
  %2995 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2994, <8 x i16> %t448) #15
  %2996 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %2995) #15
  %2997 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t448, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %2998 = add <8 x i16> %2997, %2996
  %2999 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2994, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3000 = add <8 x i16> %2998, %2999
  %3001 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %2993, <8 x i16> %3000) #15
  %3002 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3001, <8 x i16> %2993) #15
  %3003 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3002, <8 x i16> %t458) #15
  %3004 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3003, <8 x i16> %71) #15
  %3005 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3004) #15
  %3006 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3005, <8 x i16> %77) #15
  %3007 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3006, <8 x i16> %80) #15
  %3008 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3007) #15
  %.cast2738 = bitcast <2 x i64> %2891 to <8 x i16>
  %3009 = add <8 x i16> %.cast2738, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3010 = bitcast <8 x i16> %3009 to <2 x i64>
  %3011 = shufflevector <2 x i64> %3010, <2 x i64> undef, <1 x i32> zeroinitializer
  %3012 = bitcast <1 x i64> %3011 to <4 x i16>
  %3013 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3012) #15
  %3014 = add <8 x i16> %.cast2738, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3015 = bitcast <8 x i16> %3014 to <2 x i64>
  %3016 = shufflevector <2 x i64> %3015, <2 x i64> undef, <1 x i32> <i32 1>
  %3017 = bitcast <1 x i64> %3016 to <4 x i16>
  %3018 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3017) #15
  %3019 = shufflevector <4 x i16> %3013, <4 x i16> %3018, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3020 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t449, <8 x i16> %t449) #15
  %3021 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3020, <8 x i16> %t449) #15
  %3022 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3021) #15
  %3023 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t449, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3024 = add <8 x i16> %3023, %3022
  %3025 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3020, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3026 = add <8 x i16> %3024, %3025
  %3027 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3019, <8 x i16> %3026) #15
  %3028 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3027, <8 x i16> %3019) #15
  %3029 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3028, <8 x i16> %t458) #15
  %3030 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3029, <8 x i16> %71) #15
  %3031 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3030) #15
  %3032 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3031, <8 x i16> %77) #15
  %3033 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3032, <8 x i16> %80) #15
  %3034 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3033) #15
  %3035 = shufflevector <8 x i8> %3008, <8 x i8> %3034, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3036 = shufflevector <32 x i8> %3035, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3037 = bitcast <64 x i8> %3036 to <8 x i64>
  %3038 = shufflevector <8 x i64> %3037, <8 x i64> undef, <2 x i32> <i32 2, i32 3>
  %.cast2976 = bitcast <2 x i64> %2892 to <8 x i16>
  %3039 = add <8 x i16> %.cast2976, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3040 = bitcast <8 x i16> %3039 to <2 x i64>
  %3041 = shufflevector <2 x i64> %3040, <2 x i64> undef, <1 x i32> zeroinitializer
  %3042 = bitcast <1 x i64> %3041 to <4 x i16>
  %3043 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3042) #15
  %3044 = add <8 x i16> %.cast2976, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3045 = bitcast <8 x i16> %3044 to <2 x i64>
  %3046 = shufflevector <2 x i64> %3045, <2 x i64> undef, <1 x i32> <i32 1>
  %3047 = bitcast <1 x i64> %3046 to <4 x i16>
  %3048 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3047) #15
  %3049 = shufflevector <4 x i16> %3043, <4 x i16> %3048, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3050 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t450, <8 x i16> %t450) #15
  %3051 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3050, <8 x i16> %t450) #15
  %3052 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3051) #15
  %3053 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t450, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3054 = add <8 x i16> %3053, %3052
  %3055 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3050, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3056 = add <8 x i16> %3054, %3055
  %3057 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3049, <8 x i16> %3056) #15
  %3058 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3057, <8 x i16> %3049) #15
  %3059 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3058, <8 x i16> %t458) #15
  %3060 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3059, <8 x i16> %71) #15
  %3061 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3060) #15
  %3062 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3061, <8 x i16> %77) #15
  %3063 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3062, <8 x i16> %80) #15
  %3064 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3063) #15
  %.cast2990 = bitcast <2 x i64> %2893 to <8 x i16>
  %3065 = add <8 x i16> %.cast2990, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3066 = bitcast <8 x i16> %3065 to <2 x i64>
  %3067 = shufflevector <2 x i64> %3066, <2 x i64> undef, <1 x i32> zeroinitializer
  %3068 = bitcast <1 x i64> %3067 to <4 x i16>
  %3069 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3068) #15
  %3070 = add <8 x i16> %.cast2990, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3071 = bitcast <8 x i16> %3070 to <2 x i64>
  %3072 = shufflevector <2 x i64> %3071, <2 x i64> undef, <1 x i32> <i32 1>
  %3073 = bitcast <1 x i64> %3072 to <4 x i16>
  %3074 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3073) #15
  %3075 = shufflevector <4 x i16> %3069, <4 x i16> %3074, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3076 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t451, <8 x i16> %t451) #15
  %3077 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3076, <8 x i16> %t451) #15
  %3078 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3077) #15
  %3079 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t451, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3080 = add <8 x i16> %3079, %3078
  %3081 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3076, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3082 = add <8 x i16> %3080, %3081
  %3083 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3075, <8 x i16> %3082) #15
  %3084 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3083, <8 x i16> %3075) #15
  %3085 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3084, <8 x i16> %t458) #15
  %3086 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3085, <8 x i16> %71) #15
  %3087 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3086) #15
  %3088 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3087, <8 x i16> %77) #15
  %3089 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3088, <8 x i16> %80) #15
  %3090 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3089) #15
  %3091 = shufflevector <8 x i8> %3064, <8 x i8> %3090, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3092 = bitcast <64 x i8> %3091 to <8 x i64>
  %3093 = shufflevector <8 x i64> %3092, <8 x i64> undef, <2 x i32> <i32 4, i32 5>
  %.cast3228 = bitcast <2 x i64> %2894 to <8 x i16>
  %3094 = add <8 x i16> %.cast3228, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3095 = bitcast <8 x i16> %3094 to <2 x i64>
  %3096 = shufflevector <2 x i64> %3095, <2 x i64> undef, <1 x i32> zeroinitializer
  %3097 = bitcast <1 x i64> %3096 to <4 x i16>
  %3098 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3097) #15
  %3099 = add <8 x i16> %.cast3228, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3100 = bitcast <8 x i16> %3099 to <2 x i64>
  %3101 = shufflevector <2 x i64> %3100, <2 x i64> undef, <1 x i32> <i32 1>
  %3102 = bitcast <1 x i64> %3101 to <4 x i16>
  %3103 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3102) #15
  %3104 = shufflevector <4 x i16> %3098, <4 x i16> %3103, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3105 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t452, <8 x i16> %t452) #15
  %3106 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3105, <8 x i16> %t452) #15
  %3107 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3106) #15
  %3108 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t452, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3109 = add <8 x i16> %3108, %3107
  %3110 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3105, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3111 = add <8 x i16> %3109, %3110
  %3112 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3104, <8 x i16> %3111) #15
  %3113 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3112, <8 x i16> %3104) #15
  %3114 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3113, <8 x i16> %t458) #15
  %3115 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3114, <8 x i16> %71) #15
  %3116 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3115) #15
  %3117 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3116, <8 x i16> %77) #15
  %3118 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3117, <8 x i16> %80) #15
  %3119 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3118) #15
  %.cast3242 = bitcast <2 x i64> %2895 to <8 x i16>
  %3120 = add <8 x i16> %.cast3242, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3121 = bitcast <8 x i16> %3120 to <2 x i64>
  %3122 = shufflevector <2 x i64> %3121, <2 x i64> undef, <1 x i32> zeroinitializer
  %3123 = bitcast <1 x i64> %3122 to <4 x i16>
  %3124 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3123) #15
  %3125 = add <8 x i16> %.cast3242, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3126 = bitcast <8 x i16> %3125 to <2 x i64>
  %3127 = shufflevector <2 x i64> %3126, <2 x i64> undef, <1 x i32> <i32 1>
  %3128 = bitcast <1 x i64> %3127 to <4 x i16>
  %3129 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3128) #15
  %3130 = shufflevector <4 x i16> %3124, <4 x i16> %3129, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3131 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t453, <8 x i16> %t453) #15
  %3132 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3131, <8 x i16> %t453) #15
  %3133 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3132) #15
  %3134 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t453, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3135 = add <8 x i16> %3134, %3133
  %3136 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3131, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3137 = add <8 x i16> %3135, %3136
  %3138 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3130, <8 x i16> %3137) #15
  %3139 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3138, <8 x i16> %3130) #15
  %3140 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3139, <8 x i16> %t458) #15
  %3141 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3140, <8 x i16> %71) #15
  %3142 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3141) #15
  %3143 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3142, <8 x i16> %77) #15
  %3144 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3143, <8 x i16> %80) #15
  %3145 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3144) #15
  %3146 = shufflevector <8 x i8> %3119, <8 x i8> %3145, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3147 = shufflevector <32 x i8> %3146, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3148 = bitcast <64 x i8> %3147 to <8 x i64>
  %3149 = shufflevector <8 x i64> %3148, <8 x i64> undef, <2 x i32> <i32 6, i32 7>
  %3150 = add nsw i64 %2830, %2158
  %3151 = getelementptr inbounds i8, i8* %6, i64 %3150
  %3152 = bitcast i8* %3151 to <2 x i64>*
  store <2 x i64> %2982, <2 x i64>* %3152, align 1, !tbaa !434
  %3153 = getelementptr inbounds i8, i8* %3151, i64 16
  %3154 = bitcast i8* %3153 to <2 x i64>*
  store <2 x i64> %3038, <2 x i64>* %3154, align 1, !tbaa !434
  %3155 = getelementptr inbounds i8, i8* %3151, i64 32
  %3156 = bitcast i8* %3155 to <2 x i64>*
  store <2 x i64> %3093, <2 x i64>* %3156, align 1, !tbaa !434
  %3157 = getelementptr inbounds i8, i8* %3151, i64 48
  %3158 = bitcast i8* %3157 to <2 x i64>*
  store <2 x i64> %3149, <2 x i64>* %3158, align 1, !tbaa !434
  %indvars.iv.next4524 = add nuw nsw i64 %indvars.iv4523, 1
  %.not3255 = icmp eq i64 %indvars.iv.next4524, 2
  br i1 %.not3255, label %"for output.s0.x.xi.xi150", label %"for output.s0.x.xi.xi140"

"for output.s0.x.xi.xi150":                       ; preds = %"for output.s0.x.xi.xi140", %"for output.s0.x.xi.xi150"
  %indvars.iv4526 = phi i64 [ %indvars.iv.next4527, %"for output.s0.x.xi.xi150" ], [ 0, %"for output.s0.x.xi.xi140" ]
  %3159 = shl nsw i64 %indvars.iv4526, 6
  %3160 = add nsw i64 %3159, %2168
  %3161 = add nsw i64 %3160, %2159
  %3162 = getelementptr inbounds i8, i8* %0, i64 %3161
  %3163 = bitcast i8* %3162 to <16 x i8>*
  %3164 = load <16 x i8>, <16 x i8>* %3163, align 1, !tbaa !389
  %3165 = getelementptr inbounds i8, i8* %3162, i64 16
  %3166 = bitcast i8* %3165 to <16 x i8>*
  %3167 = load <16 x i8>, <16 x i8>* %3166, align 1, !tbaa !389
  %3168 = getelementptr inbounds i8, i8* %3162, i64 32
  %3169 = bitcast i8* %3168 to <16 x i8>*
  %3170 = load <16 x i8>, <16 x i8>* %3169, align 1, !tbaa !389
  %3171 = getelementptr inbounds i8, i8* %3162, i64 48
  %3172 = bitcast i8* %3171 to <16 x i8>*
  %3173 = load <16 x i8>, <16 x i8>* %3172, align 1, !tbaa !389
  %3174 = shufflevector <16 x i8> %3164, <16 x i8> %3167, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3175 = shufflevector <16 x i8> %3170, <16 x i8> %3173, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3176 = shufflevector <32 x i8> %3174, <32 x i8> %3175, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t474 = zext <64 x i8> %3176 to <64 x i16>
  %3177 = shl nuw nsw <64 x i16> %t474, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %3178 = bitcast <64 x i16> %3177 to <16 x i64>
  %3179 = shufflevector <16 x i64> %3178, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %3180 = bitcast <2 x i64> %3179 to <8 x i16>
  %3181 = add <8 x i16> %2163, %3180
  %3182 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3181, <8 x i16> %58) #15
  %3183 = shufflevector <16 x i64> %3178, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %3184 = bitcast <2 x i64> %3183 to <8 x i16>
  %3185 = add <8 x i16> %2163, %3184
  %3186 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3185, <8 x i16> %58) #15
  %3187 = shufflevector <16 x i64> %3178, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %3188 = bitcast <2 x i64> %3187 to <8 x i16>
  %3189 = add <8 x i16> %2163, %3188
  %3190 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3189, <8 x i16> %58) #15
  %3191 = shufflevector <16 x i64> %3178, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %3192 = bitcast <2 x i64> %3191 to <8 x i16>
  %3193 = add <8 x i16> %2163, %3192
  %3194 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3193, <8 x i16> %58) #15
  %3195 = shufflevector <16 x i64> %3178, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %3196 = bitcast <2 x i64> %3195 to <8 x i16>
  %3197 = add <8 x i16> %2163, %3196
  %3198 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3197, <8 x i16> %58) #15
  %3199 = shufflevector <16 x i64> %3178, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %3200 = bitcast <2 x i64> %3199 to <8 x i16>
  %3201 = add <8 x i16> %2163, %3200
  %3202 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3201, <8 x i16> %58) #15
  %3203 = shufflevector <16 x i64> %3178, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %3204 = bitcast <2 x i64> %3203 to <8 x i16>
  %3205 = add <8 x i16> %2163, %3204
  %3206 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3205, <8 x i16> %58) #15
  %3207 = shufflevector <16 x i64> %3178, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %3208 = bitcast <2 x i64> %3207 to <8 x i16>
  %3209 = add <8 x i16> %2163, %3208
  %3210 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3209, <8 x i16> %58) #15
  %3211 = shufflevector <8 x i16> %3182, <8 x i16> %3186, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3212 = shufflevector <8 x i16> %3190, <8 x i16> %3194, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3213 = shufflevector <8 x i16> %3198, <8 x i16> %3202, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3214 = shufflevector <8 x i16> %3206, <8 x i16> %3210, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3215 = shufflevector <16 x i16> %3211, <16 x i16> %3212, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3216 = shufflevector <16 x i16> %3213, <16 x i16> %3214, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t292154 = shufflevector <32 x i16> %3215, <32 x i16> %3216, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %t476 = shl <64 x i16> %t292154, %61
  %3217 = bitcast <64 x i16> %t476 to <16 x i64>
  %3218 = shufflevector <16 x i64> %3217, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %3219 = shufflevector <16 x i64> %3217, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %3220 = shufflevector <16 x i64> %3217, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %3221 = shufflevector <16 x i64> %3217, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %3222 = shufflevector <16 x i64> %3217, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %3223 = shufflevector <16 x i64> %3217, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %3224 = shufflevector <16 x i64> %3217, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %3225 = shufflevector <16 x i64> %3217, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %3226 = and <64 x i16> %t292154, %.not4333
  %3227 = shufflevector <64 x i16> %3226, <64 x i16> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3228 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %3227, <8 x i16> %64)
  %3229 = shufflevector <64 x i16> %3226, <64 x i16> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3230 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %3229, <8 x i16> %64)
  %3231 = shufflevector <64 x i16> %3226, <64 x i16> undef, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3232 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %3231, <8 x i16> %64)
  %3233 = shufflevector <64 x i16> %3226, <64 x i16> undef, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3234 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %3233, <8 x i16> %64)
  %3235 = shufflevector <64 x i16> %3226, <64 x i16> undef, <8 x i32> <i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39>
  %3236 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %3235, <8 x i16> %64)
  %3237 = shufflevector <64 x i16> %3226, <64 x i16> undef, <8 x i32> <i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47>
  %3238 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %3237, <8 x i16> %64)
  %3239 = shufflevector <64 x i16> %3226, <64 x i16> undef, <8 x i32> <i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %3240 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %3239, <8 x i16> %64)
  %3241 = shufflevector <64 x i16> %3226, <64 x i16> undef, <8 x i32> <i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3242 = tail call <8 x i16> @llvm.aarch64.neon.sshl.v8i16(<8 x i16> %3241, <8 x i16> %64)
  %3243 = shufflevector <8 x i16> %3228, <8 x i16> %3230, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3244 = shufflevector <8 x i16> %3232, <8 x i16> %3234, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3245 = shufflevector <8 x i16> %3236, <8 x i16> %3238, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3246 = shufflevector <8 x i16> %3240, <8 x i16> %3242, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3247 = shufflevector <16 x i16> %3243, <16 x i16> %3244, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3248 = shufflevector <16 x i16> %3245, <16 x i16> %3246, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t485 = shufflevector <32 x i16> %3247, <32 x i16> %3248, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3249 = bitcast <64 x i16> %t485 to <16 x i64>
  %3250 = shufflevector <16 x i64> %3249, <16 x i64> undef, <2 x i32> <i32 0, i32 1>
  %t486 = bitcast <2 x i64> %3250 to <8 x i16>
  %3251 = shufflevector <16 x i64> %3249, <16 x i64> undef, <2 x i32> <i32 2, i32 3>
  %t487 = bitcast <2 x i64> %3251 to <8 x i16>
  %3252 = shufflevector <16 x i64> %3249, <16 x i64> undef, <2 x i32> <i32 4, i32 5>
  %t488 = bitcast <2 x i64> %3252 to <8 x i16>
  %3253 = shufflevector <16 x i64> %3249, <16 x i64> undef, <2 x i32> <i32 6, i32 7>
  %t489 = bitcast <2 x i64> %3253 to <8 x i16>
  %3254 = shufflevector <16 x i64> %3249, <16 x i64> undef, <2 x i32> <i32 8, i32 9>
  %t490 = bitcast <2 x i64> %3254 to <8 x i16>
  %3255 = shufflevector <16 x i64> %3249, <16 x i64> undef, <2 x i32> <i32 10, i32 11>
  %t491 = bitcast <2 x i64> %3255 to <8 x i16>
  %3256 = shufflevector <16 x i64> %3249, <16 x i64> undef, <2 x i32> <i32 12, i32 13>
  %t492 = bitcast <2 x i64> %3256 to <8 x i16>
  %3257 = shufflevector <16 x i64> %3249, <16 x i64> undef, <2 x i32> <i32 14, i32 15>
  %t493 = bitcast <2 x i64> %3257 to <8 x i16>
  %.cast3402 = bitcast <2 x i64> %3218 to <8 x i16>
  %3258 = add <8 x i16> %.cast3402, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3259 = bitcast <8 x i16> %3258 to <2 x i64>
  %3260 = shufflevector <2 x i64> %3259, <2 x i64> undef, <1 x i32> zeroinitializer
  %3261 = bitcast <1 x i64> %3260 to <4 x i16>
  %3262 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3261) #15
  %3263 = add <8 x i16> %.cast3402, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3264 = bitcast <8 x i16> %3263 to <2 x i64>
  %3265 = shufflevector <2 x i64> %3264, <2 x i64> undef, <1 x i32> <i32 1>
  %3266 = bitcast <1 x i64> %3265 to <4 x i16>
  %3267 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3266) #15
  %3268 = shufflevector <4 x i16> %3262, <4 x i16> %3267, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3269 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t486, <8 x i16> %t486) #15
  %3270 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3269, <8 x i16> %t486) #15
  %3271 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3270) #15
  %3272 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t486, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3273 = add <8 x i16> %3272, %3271
  %3274 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3269, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3275 = add <8 x i16> %3273, %3274
  %3276 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3268, <8 x i16> %3275) #15
  %3277 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3276, <8 x i16> %3268) #15
  %3278 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3277, <8 x i16> %t498) #15
  %3279 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3278, <8 x i16> %71) #15
  %3280 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3279) #15
  %3281 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3280, <8 x i16> %77) #15
  %3282 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3281, <8 x i16> %80) #15
  %3283 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3282) #15
  %.cast3416 = bitcast <2 x i64> %3219 to <8 x i16>
  %3284 = add <8 x i16> %.cast3416, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3285 = bitcast <8 x i16> %3284 to <2 x i64>
  %3286 = shufflevector <2 x i64> %3285, <2 x i64> undef, <1 x i32> zeroinitializer
  %3287 = bitcast <1 x i64> %3286 to <4 x i16>
  %3288 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3287) #15
  %3289 = add <8 x i16> %.cast3416, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3290 = bitcast <8 x i16> %3289 to <2 x i64>
  %3291 = shufflevector <2 x i64> %3290, <2 x i64> undef, <1 x i32> <i32 1>
  %3292 = bitcast <1 x i64> %3291 to <4 x i16>
  %3293 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3292) #15
  %3294 = shufflevector <4 x i16> %3288, <4 x i16> %3293, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3295 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t487, <8 x i16> %t487) #15
  %3296 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3295, <8 x i16> %t487) #15
  %3297 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3296) #15
  %3298 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t487, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3299 = add <8 x i16> %3298, %3297
  %3300 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3295, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3301 = add <8 x i16> %3299, %3300
  %3302 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3294, <8 x i16> %3301) #15
  %3303 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3302, <8 x i16> %3294) #15
  %3304 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3303, <8 x i16> %t498) #15
  %3305 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3304, <8 x i16> %71) #15
  %3306 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3305) #15
  %3307 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3306, <8 x i16> %77) #15
  %3308 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3307, <8 x i16> %80) #15
  %3309 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3308) #15
  %3310 = shufflevector <8 x i8> %3283, <8 x i8> %3309, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3311 = bitcast <64 x i8> %3310 to <8 x i64>
  %3312 = shufflevector <8 x i64> %3311, <8 x i64> undef, <2 x i32> <i32 0, i32 1>
  %.cast3766 = bitcast <2 x i64> %3220 to <8 x i16>
  %3313 = add <8 x i16> %.cast3766, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3314 = bitcast <8 x i16> %3313 to <2 x i64>
  %3315 = shufflevector <2 x i64> %3314, <2 x i64> undef, <1 x i32> zeroinitializer
  %3316 = bitcast <1 x i64> %3315 to <4 x i16>
  %3317 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3316) #15
  %3318 = add <8 x i16> %.cast3766, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3319 = bitcast <8 x i16> %3318 to <2 x i64>
  %3320 = shufflevector <2 x i64> %3319, <2 x i64> undef, <1 x i32> <i32 1>
  %3321 = bitcast <1 x i64> %3320 to <4 x i16>
  %3322 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3321) #15
  %3323 = shufflevector <4 x i16> %3317, <4 x i16> %3322, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3324 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t488, <8 x i16> %t488) #15
  %3325 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3324, <8 x i16> %t488) #15
  %3326 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3325) #15
  %3327 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t488, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3328 = add <8 x i16> %3327, %3326
  %3329 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3324, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3330 = add <8 x i16> %3328, %3329
  %3331 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3323, <8 x i16> %3330) #15
  %3332 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3331, <8 x i16> %3323) #15
  %3333 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3332, <8 x i16> %t498) #15
  %3334 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3333, <8 x i16> %71) #15
  %3335 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3334) #15
  %3336 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3335, <8 x i16> %77) #15
  %3337 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3336, <8 x i16> %80) #15
  %3338 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3337) #15
  %.cast3780 = bitcast <2 x i64> %3221 to <8 x i16>
  %3339 = add <8 x i16> %.cast3780, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3340 = bitcast <8 x i16> %3339 to <2 x i64>
  %3341 = shufflevector <2 x i64> %3340, <2 x i64> undef, <1 x i32> zeroinitializer
  %3342 = bitcast <1 x i64> %3341 to <4 x i16>
  %3343 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3342) #15
  %3344 = add <8 x i16> %.cast3780, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3345 = bitcast <8 x i16> %3344 to <2 x i64>
  %3346 = shufflevector <2 x i64> %3345, <2 x i64> undef, <1 x i32> <i32 1>
  %3347 = bitcast <1 x i64> %3346 to <4 x i16>
  %3348 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3347) #15
  %3349 = shufflevector <4 x i16> %3343, <4 x i16> %3348, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3350 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t489, <8 x i16> %t489) #15
  %3351 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3350, <8 x i16> %t489) #15
  %3352 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3351) #15
  %3353 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t489, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3354 = add <8 x i16> %3353, %3352
  %3355 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3350, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3356 = add <8 x i16> %3354, %3355
  %3357 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3349, <8 x i16> %3356) #15
  %3358 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3357, <8 x i16> %3349) #15
  %3359 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3358, <8 x i16> %t498) #15
  %3360 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3359, <8 x i16> %71) #15
  %3361 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3360) #15
  %3362 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3361, <8 x i16> %77) #15
  %3363 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3362, <8 x i16> %80) #15
  %3364 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3363) #15
  %3365 = shufflevector <8 x i8> %3338, <8 x i8> %3364, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3366 = shufflevector <32 x i8> %3365, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3367 = bitcast <64 x i8> %3366 to <8 x i64>
  %3368 = shufflevector <8 x i64> %3367, <8 x i64> undef, <2 x i32> <i32 2, i32 3>
  %.cast4018 = bitcast <2 x i64> %3222 to <8 x i16>
  %3369 = add <8 x i16> %.cast4018, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3370 = bitcast <8 x i16> %3369 to <2 x i64>
  %3371 = shufflevector <2 x i64> %3370, <2 x i64> undef, <1 x i32> zeroinitializer
  %3372 = bitcast <1 x i64> %3371 to <4 x i16>
  %3373 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3372) #15
  %3374 = add <8 x i16> %.cast4018, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3375 = bitcast <8 x i16> %3374 to <2 x i64>
  %3376 = shufflevector <2 x i64> %3375, <2 x i64> undef, <1 x i32> <i32 1>
  %3377 = bitcast <1 x i64> %3376 to <4 x i16>
  %3378 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3377) #15
  %3379 = shufflevector <4 x i16> %3373, <4 x i16> %3378, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3380 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t490, <8 x i16> %t490) #15
  %3381 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3380, <8 x i16> %t490) #15
  %3382 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3381) #15
  %3383 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t490, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3384 = add <8 x i16> %3383, %3382
  %3385 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3380, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3386 = add <8 x i16> %3384, %3385
  %3387 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3379, <8 x i16> %3386) #15
  %3388 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3387, <8 x i16> %3379) #15
  %3389 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3388, <8 x i16> %t498) #15
  %3390 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3389, <8 x i16> %71) #15
  %3391 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3390) #15
  %3392 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3391, <8 x i16> %77) #15
  %3393 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3392, <8 x i16> %80) #15
  %3394 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3393) #15
  %.cast4032 = bitcast <2 x i64> %3223 to <8 x i16>
  %3395 = add <8 x i16> %.cast4032, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3396 = bitcast <8 x i16> %3395 to <2 x i64>
  %3397 = shufflevector <2 x i64> %3396, <2 x i64> undef, <1 x i32> zeroinitializer
  %3398 = bitcast <1 x i64> %3397 to <4 x i16>
  %3399 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3398) #15
  %3400 = add <8 x i16> %.cast4032, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3401 = bitcast <8 x i16> %3400 to <2 x i64>
  %3402 = shufflevector <2 x i64> %3401, <2 x i64> undef, <1 x i32> <i32 1>
  %3403 = bitcast <1 x i64> %3402 to <4 x i16>
  %3404 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3403) #15
  %3405 = shufflevector <4 x i16> %3399, <4 x i16> %3404, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3406 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t491, <8 x i16> %t491) #15
  %3407 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3406, <8 x i16> %t491) #15
  %3408 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3407) #15
  %3409 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t491, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3410 = add <8 x i16> %3409, %3408
  %3411 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3406, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3412 = add <8 x i16> %3410, %3411
  %3413 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3405, <8 x i16> %3412) #15
  %3414 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3413, <8 x i16> %3405) #15
  %3415 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3414, <8 x i16> %t498) #15
  %3416 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3415, <8 x i16> %71) #15
  %3417 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3416) #15
  %3418 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3417, <8 x i16> %77) #15
  %3419 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3418, <8 x i16> %80) #15
  %3420 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3419) #15
  %3421 = shufflevector <8 x i8> %3394, <8 x i8> %3420, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3422 = bitcast <64 x i8> %3421 to <8 x i64>
  %3423 = shufflevector <8 x i64> %3422, <8 x i64> undef, <2 x i32> <i32 4, i32 5>
  %.cast4270 = bitcast <2 x i64> %3224 to <8 x i16>
  %3424 = add <8 x i16> %.cast4270, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3425 = bitcast <8 x i16> %3424 to <2 x i64>
  %3426 = shufflevector <2 x i64> %3425, <2 x i64> undef, <1 x i32> zeroinitializer
  %3427 = bitcast <1 x i64> %3426 to <4 x i16>
  %3428 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3427) #15
  %3429 = add <8 x i16> %.cast4270, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3430 = bitcast <8 x i16> %3429 to <2 x i64>
  %3431 = shufflevector <2 x i64> %3430, <2 x i64> undef, <1 x i32> <i32 1>
  %3432 = bitcast <1 x i64> %3431 to <4 x i16>
  %3433 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3432) #15
  %3434 = shufflevector <4 x i16> %3428, <4 x i16> %3433, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3435 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t492, <8 x i16> %t492) #15
  %3436 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3435, <8 x i16> %t492) #15
  %3437 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3436) #15
  %3438 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t492, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3439 = add <8 x i16> %3438, %3437
  %3440 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3435, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3441 = add <8 x i16> %3439, %3440
  %3442 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3434, <8 x i16> %3441) #15
  %3443 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3442, <8 x i16> %3434) #15
  %3444 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3443, <8 x i16> %t498) #15
  %3445 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3444, <8 x i16> %71) #15
  %3446 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3445) #15
  %3447 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3446, <8 x i16> %77) #15
  %3448 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3447, <8 x i16> %80) #15
  %3449 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3448) #15
  %.cast4284 = bitcast <2 x i64> %3225 to <8 x i16>
  %3450 = add <8 x i16> %.cast4284, <i16 15, i16 15, i16 15, i16 15, i16 poison, i16 poison, i16 poison, i16 poison>
  %3451 = bitcast <8 x i16> %3450 to <2 x i64>
  %3452 = shufflevector <2 x i64> %3451, <2 x i64> undef, <1 x i32> zeroinitializer
  %3453 = bitcast <1 x i64> %3452 to <4 x i16>
  %3454 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3453) #15
  %3455 = add <8 x i16> %.cast4284, <i16 poison, i16 poison, i16 poison, i16 poison, i16 15, i16 15, i16 15, i16 15>
  %3456 = bitcast <8 x i16> %3455 to <2 x i64>
  %3457 = shufflevector <2 x i64> %3456, <2 x i64> undef, <1 x i32> <i32 1>
  %3458 = bitcast <1 x i64> %3457 to <4 x i16>
  %3459 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %3458) #15
  %3460 = shufflevector <4 x i16> %3454, <4 x i16> %3459, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3461 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t493, <8 x i16> %t493) #15
  %3462 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3461, <8 x i16> %t493) #15
  %3463 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %3462) #15
  %3464 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %t493, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %3465 = add <8 x i16> %3464, %3463
  %3466 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3461, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %3467 = add <8 x i16> %3465, %3466
  %3468 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3460, <8 x i16> %3467) #15
  %3469 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3468, <8 x i16> %3460) #15
  %3470 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3469, <8 x i16> %t498) #15
  %3471 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %3470, <8 x i16> %71) #15
  %3472 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %74, <8 x i16> %3471) #15
  %3473 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %3472, <8 x i16> %77) #15
  %3474 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %3473, <8 x i16> %80) #15
  %3475 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %3474) #15
  %3476 = shufflevector <8 x i8> %3449, <8 x i8> %3475, <32 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3477 = shufflevector <32 x i8> %3476, <32 x i8> poison, <64 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3478 = bitcast <64 x i8> %3477 to <8 x i64>
  %3479 = shufflevector <8 x i64> %3478, <8 x i64> undef, <2 x i32> <i32 6, i32 7>
  %3480 = add nsw i64 %3160, %2166
  %3481 = getelementptr inbounds i8, i8* %6, i64 %3480
  %3482 = bitcast i8* %3481 to <2 x i64>*
  store <2 x i64> %3312, <2 x i64>* %3482, align 1, !tbaa !434
  %3483 = getelementptr inbounds i8, i8* %3481, i64 16
  %3484 = bitcast i8* %3483 to <2 x i64>*
  store <2 x i64> %3368, <2 x i64>* %3484, align 1, !tbaa !434
  %3485 = getelementptr inbounds i8, i8* %3481, i64 32
  %3486 = bitcast i8* %3485 to <2 x i64>*
  store <2 x i64> %3423, <2 x i64>* %3486, align 1, !tbaa !434
  %3487 = getelementptr inbounds i8, i8* %3481, i64 48
  %3488 = bitcast i8* %3487 to <2 x i64>*
  store <2 x i64> %3479, <2 x i64>* %3488, align 1, !tbaa !434
  %indvars.iv.next4527 = add nuw nsw i64 %indvars.iv4526, 1
  %.not4297 = icmp eq i64 %indvars.iv.next4527, 2
  br i1 %.not4297, label %"end for output.s0.x.xi.xi151", label %"for output.s0.x.xi.xi150"

"end for output.s0.x.xi.xi151":                   ; preds = %"for output.s0.x.xi.xi150"
  %indvars.iv.next4530 = add nuw nsw i64 %indvars.iv4529, 1
  %.not4298 = icmp eq i64 %indvars.iv.next4530, %89
  br i1 %.not4298, label %"end for output.s0.x.x117", label %"for output.s0.x.x116"

destructor_block:                                 ; preds = %"end for output.s0.x.x117", %entry, %"end for output.s0.y.y"
  ret i32 0
}

; Function Attrs: nofree nounwind
define i32 @softmax_argv(i8** nocapture readonly %0) local_unnamed_addr #11 {
entry:
  %1 = bitcast i8** %0 to %struct.halide_buffer_t**
  %2 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %1, align 8
  %3 = getelementptr i8*, i8** %0, i64 1
  %4 = bitcast i8** %3 to i16**
  %5 = load i16*, i16** %4, align 8
  %6 = load i16, i16* %5, align 2
  %7 = getelementptr i8*, i8** %0, i64 2
  %8 = bitcast i8** %7 to i16**
  %9 = load i16*, i16** %8, align 8
  %10 = load i16, i16* %9, align 2
  %11 = getelementptr i8*, i8** %0, i64 3
  %12 = load i8*, i8** %11, align 8
  %13 = load i8, i8* %12, align 1
  %14 = getelementptr i8*, i8** %0, i64 4
  %15 = bitcast i8** %14 to i16**
  %16 = load i16*, i16** %15, align 8
  %17 = load i16, i16* %16, align 2
  %18 = getelementptr i8*, i8** %0, i64 5
  %19 = bitcast i8** %18 to i16**
  %20 = load i16*, i16** %19, align 8
  %21 = load i16, i16* %20, align 2
  %22 = getelementptr i8*, i8** %0, i64 6
  %23 = bitcast i8** %22 to %struct.halide_buffer_t**
  %24 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %23, align 8
  %25 = tail call i32 @softmax(%struct.halide_buffer_t* %2, i16 %6, i16 %10, i8 %13, i16 %17, i16 %21, %struct.halide_buffer_t* %24) #18
  ret i32 0
}

; Function Attrs: norecurse nounwind readnone willreturn
define nonnull %struct.halide_filter_metadata_t* @softmax_metadata() local_unnamed_addr #12 {
entry:
  ret %struct.halide_filter_metadata_t* @softmax_metadata_storage
}

; Function Attrs: nofree nosync nounwind readnone willreturn
declare i8 @llvm.vector.reduce.umax.v64i8(<64 x i8>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare i32 @llvm.vector.reduce.add.v64i32(<64 x i32>) #9

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.0(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.2(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.3(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.4(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.5(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.6(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.7(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.8(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.9(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.10(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.11(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.12(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.13(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.14(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.15(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.16(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.17(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.18(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.19(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.20(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.21(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.22(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.23(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.24(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.25(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.26(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.27(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.28(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.29(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.30(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.31(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.32(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.33(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.34(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.35(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.36(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.37(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.38(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.39(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.40(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.41(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.42(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.43(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.44(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.45(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.46(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.47(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.48(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.49(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.50(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.51(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.52(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.53(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.54(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.55(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.56(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.57(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.58(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.59(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.60(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.61(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.62(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.63(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.64(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.65(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.66(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.67(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.68(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.69(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.70(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.71(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.72(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.73(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.74(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.75(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.76(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.77(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.78(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.79(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.80(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.81(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.82(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.83(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.84(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.85(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.86(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.87(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.88(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.89(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.90(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.91(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.92(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.93(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.94(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.95(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.96(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.97(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.98(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.99(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.100(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.101(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.102(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.103(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.104(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.105(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.106(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.107(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.108(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.109(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.110(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.111(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.112(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.113(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.114(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.115(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.116(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.117(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.118(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.119(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.120(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.121(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.122(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.123(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.124(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.125(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.126(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.127(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.128(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.129(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.130(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.131(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.132(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.133(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.134(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.135(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.136(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.137(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.138(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.139(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.140(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.141(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.142(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.143(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.144(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.145(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.146(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.147(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.148(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.149(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.150(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.151(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.152(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.153(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.154(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.155(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.156(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.157(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.158(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.159(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.160(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.161(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.162(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.163(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.164(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.165(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.166(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.167(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.168(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.169(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.170(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.171(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.172(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.173(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.174(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.175(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.176(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.177(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.178(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.179(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.180(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.181(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.182(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.183(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.184(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.185(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.186(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.187(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.188(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.189(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.190(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.191(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.192(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.193(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.194(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.195(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.196(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.197(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.198(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.199(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.200(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.201(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.202(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.203(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.204(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.205(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.206(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.207(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.208(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.209(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.210(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.211(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.212(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.213(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.214(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.215(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.216(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.217(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.218(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.219(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.220(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.221(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.222(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.223(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.224(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.225(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.226(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.227(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.228(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.229(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.230(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.231(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.232(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.233(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.234(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.235(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.236(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.237(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.238(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.239(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.240(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.241(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.242(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.243(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.244(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.245(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.246(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.247(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.248(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.249(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.250(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.251(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.252(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.253(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.254(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.255(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.256(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.257(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.258(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.259(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.260(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.261(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.262(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.263(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.264(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.265(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.266(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.267(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.268(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.269(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.270(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.271(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.272(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.273(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.274(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.275(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.276(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.277(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.278(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.279(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.280(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.281(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.282(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.283(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.284(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.285(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.286(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.287(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.288(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.289(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.290(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.291(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.292(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.293(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.294(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.295(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.296(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.297(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.298(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.299(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.300(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.301(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.302(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.303(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.304(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.305(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.306(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.307(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.308(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.309(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.310(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.311(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.312(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.313(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.314(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.315(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.316(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.317(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.318(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.319(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.320(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.321(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.322(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.323(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.324(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.325(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.326(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.327(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.328(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.329(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.330(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.331(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.332(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.333(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.334(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.335(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.336(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.337(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.338(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.339(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.340(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.341(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.342(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.343(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.344(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.345(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.346(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.347(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.348(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.349(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.350(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.351(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.352(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.353(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.354(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.355(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.356(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.357(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.358(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.359(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.360(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.361(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.362(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.363(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.364(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.365(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.366(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.367(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.368(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.369(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.370(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.371(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.372(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.373(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.374(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.375(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.376(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.377(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.378(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.379(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.380(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.381(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.382(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.383(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.384(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.385(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.386(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.387(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.388(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.389(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.390(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.391(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.392(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.393(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.394(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.395(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.396(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.397(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.398(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.399(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.400(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.401(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.402(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.403(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.404(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.405(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.406(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.407(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.408(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.409(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.410(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.411(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.412(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.413(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.414(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.415(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.416(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.417(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.418(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.419(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.420(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.421(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.422(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.423(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.424(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.425(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.426(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.427(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.428(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.429(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.430(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.431(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.432(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.433(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.434(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.435(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.436(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.437(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.438(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.439(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.440(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.441(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.442(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.443(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.444(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.445(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.446(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.447(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.448(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.449(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.450(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.451(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.452(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.453(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.454(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.455(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.456(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.457(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.458(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.459(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.460(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.461(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.462(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.463(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.464(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.465(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.466(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.467(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.468(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.469(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.470(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.471(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.472(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.473(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.474(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.475(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.476(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.477(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.478(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.479(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.480(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.481(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.482(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.483(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.484(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.485(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.486(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.487(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.488(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.489(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.490(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.491(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.492(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.493(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.494(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.495(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.496(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.497(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.498(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.499(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.500(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.501(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.502(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.503(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.504(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.505(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.506(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.507(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.508(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.509(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.510(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.511(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.512(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.513(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.514(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.515(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.516(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.517(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.518(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.519(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.520(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.521(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.522(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.523(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.524(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.525(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.526(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.527(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.528(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.529(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.530(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.531(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.532(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.533(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.534(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.535(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.536(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.537(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.538(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.539(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.540(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.541(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.542(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.543(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.544(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.545(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.546(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.547(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.548(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.549(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.550(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.551(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.552(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.553(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.554(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.555(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.556(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.557(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.558(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.559(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.560(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.561(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.562(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.563(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.564(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.565(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.566(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.567(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.568(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.569(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.570(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.571(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.572(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.573(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.574(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.575(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.576(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.577(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.578(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.579(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.580(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.581(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.582(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.583(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.584(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.585(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.586(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.587(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.588(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.589(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.590(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.591(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.592(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.593(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.594(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.595(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.596(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.597(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.598(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.599(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.600(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.601(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.602(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.603(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.604(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.605(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.606(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.607(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.608(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.609(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.610(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.611(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.612(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.613(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.614(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.615(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.616(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.617(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.618(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.619(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.620(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.621(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.622(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.623(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.624(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.625(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.626(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.627(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.628(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.629(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.630(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.631(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.632(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.633(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.634(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.635(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.636(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.637(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.638(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.639(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.640(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.641(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.642(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.643(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.644(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.645(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.646(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.647(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.648(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.649(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.650(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.651(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.652(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.653(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.654(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.655(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.656(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.657(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.658(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.659(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.660(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.661(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.662(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.663(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.664(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.665(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.666(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.667(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.668(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.669(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.670(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.671(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.672(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.673(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.674(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.675(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.676(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.677(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.678(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.679(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.680(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.681(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.682(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.683(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.684(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.685(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.686(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.687(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.688(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.689(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.690(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.691(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.692(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.693(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.694(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.695(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.696(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.697(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.698(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.699(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.700(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.701(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.702(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.703(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.704(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.705(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.706(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.707(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.708(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.709(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.710(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.711(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.712(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.713(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.714(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.715(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.716(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.717(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.718(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.719(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.720(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.721(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.722(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.723(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.724(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.725(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.726(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.727(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.728(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.729(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.730(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.731(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.732(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.733(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.734(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.735(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.736(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.737(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.738(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.739(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.740(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.741(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.742(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.743(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.744(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.745(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.746(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.747(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.748(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.749(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.750(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.751(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.752(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.753(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.754(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.755(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.756(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.757(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.758(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.759(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.760(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.761(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.762(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.763(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.764(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.765(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.766(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.767(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.768(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.769(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.770(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.771(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.772(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.773(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.774(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.775(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.776(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.777(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.778(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.779(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.780(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.781(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.782(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.783(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.784(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.785(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.786(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.787(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.788(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.789(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.790(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.791(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.792(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.793(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.794(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.795(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.796(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.797(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.798(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.799(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.800(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.801(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.802(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.803(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.804(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.805(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.806(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.807(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.808(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.809(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.810(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.811(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.812(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.813(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.814(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.815(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.816(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.817(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.818(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.819(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.820(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.821(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.822(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.823(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.824(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.825(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.826(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.827(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.828(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.829(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.830(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.831(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.832(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.833(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.834(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.835(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.836(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.837(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.838(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.839(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.840(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.841(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.842(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.843(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.844(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.845(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.846(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.847(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.848(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.849(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.850(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.851(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.852(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.853(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.854(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.855(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.856(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.857(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.858(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.859(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.860(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.861(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.862(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.863(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.864(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.865(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.866(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.867(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.868(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.869(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.870(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.871(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.872(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.873(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.874(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.875(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.876(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.877(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.878(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.879(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.880(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.881(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.882(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.883(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.884(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.885(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.886(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.887(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.888(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.889(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.890(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.891(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.892(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.893(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.894(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.895(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.896(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.897(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.898(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.899(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.900(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.901(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.902(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.903(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.904(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.905(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.906(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.907(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.908(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.909(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.910(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.911(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.912(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.913(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.914(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.915(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.916(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.917(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.918(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.919(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.920(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.921(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.922(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.923(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.924(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.925(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.926(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.927(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.928(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.929(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.930(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.931(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.932(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.933(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.934(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.935(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.936(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.937(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.938(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.939(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.940(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.941(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.942(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.943(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.944(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.945(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.946(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.947(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.948(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.949(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.950(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.951(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.952(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.953(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.954(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.955(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.956(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.957(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.958(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.959(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.960(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.961(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.962(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.963(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.964(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.965(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.966(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.967(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.968(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.969(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.970(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.971(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.972(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.973(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.974(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.975(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.976(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.977(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.978(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.979(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.980(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.981(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.982(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.983(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.984(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.985(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.986(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.987(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.988(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.989(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.990(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.991(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.992(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.993(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.994(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.995(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.996(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.997(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.998(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.999(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1000(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1001(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1002(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1003(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1004(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1005(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1006(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1007(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1008(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1009(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1010(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1011(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1012(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1013(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1014(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1015(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1016(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1017(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1018(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1019(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1020(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1021(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1022(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1023(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1024(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1025(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1026(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1027(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1028(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1029(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1030(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1031(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1032(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1033(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1034(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1035(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1036(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1037(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1038(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1039(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1040(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1041(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1042(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1043(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1044(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1045(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1046(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1047(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1048(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1049(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1050(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1051(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1052(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1053(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1054(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1055(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1056(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1057(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1058(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1059(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1060(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1061(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1062(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1063(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2) local_unnamed_addr #13 {
entry:
  %0 = add <8 x i16> %arg.1, %arg
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.2) #15
  ret <8 x i16> %1
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1064(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1065(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1066(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1067(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1068(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1069(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1070(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1071(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1072(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1073(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1074(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1075(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1076(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1077(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1078(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1079(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1080(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1081(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1082(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1083(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1084(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1085(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1086(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1087(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1088(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1089(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1090(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1091(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1092(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1093(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1094(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1095(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1096(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1097(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1098(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1099(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1100(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1101(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1102(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1103(<8 x i16> %arg, <8 x i16> %arg.1) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg, <8 x i16> %arg.1) #15
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1104(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1105(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1106(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1107(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1108(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1109(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1110(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1111(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1112(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1113(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1114(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1115(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1116(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1117(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1118(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1119(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1120(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1121(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1122(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1123(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1124(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1125(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1126(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1127(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1128(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1129(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1130(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1131(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1132(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1133(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1134(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1135(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1136(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1137(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1138(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1139(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1140(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1141(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1142(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1143(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1144(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1145(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1146(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1147(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1148(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1149(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1150(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1151(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1152(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1153(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1154(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1155(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1156(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1157(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1158(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1159(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1160(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1161(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1162(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1163(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1164(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1165(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1166(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1167(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1168(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1169(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1170(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1171(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1172(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1173(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1174(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1175(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1176(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1177(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1178(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1179(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1180(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1181(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1182(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1183(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1184(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1185(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1186(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1187(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1188(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1189(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1190(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1191(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1192(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1193(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1194(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1195(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1196(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1197(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1198(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1199(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1200(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1201(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1202(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1203(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1204(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1205(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1206(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1207(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1208(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1209(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1210(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1211(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1212(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1213(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1214(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1215(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1216(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1217(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1218(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1219(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1220(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1221(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1222(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1223(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1224(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1225(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1226(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1227(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1228(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1229(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1230(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1231(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1232(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1233(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1234(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1235(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1236(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1237(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1238(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1239(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1240(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1241(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1242(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1243(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1244(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1245(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1246(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1247(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1248(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1249(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1250(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1251(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1252(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1253(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1254(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1255(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1256(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1257(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1258(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1259(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1260(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1261(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1262(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1263(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1264(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1265(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1266(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1267(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1268(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1269(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1270(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1271(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1272(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1273(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1274(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1275(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1276(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1277(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1278(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1279(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1280(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1281(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1282(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1283(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1284(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1285(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1286(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1287(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1288(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1289(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1290(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1291(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1292(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1293(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1294(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1295(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1296(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1297(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1298(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1299(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1300(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1301(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1302(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1303(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1304(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1305(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1306(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1307(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1308(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1309(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1310(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1311(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1312(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1313(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1314(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1315(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1316(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1317(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1318(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1319(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1320(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1321(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1322(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1323(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1324(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1325(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1326(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1327(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1328(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1329(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1330(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1331(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1332(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1333(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1334(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1335(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1336(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1337(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1338(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1339(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1340(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1341(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1342(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1343(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1344(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1345(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1346(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1347(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1348(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1349(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1350(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1351(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1352(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1353(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1354(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1355(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1356(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1357(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1358(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1359(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1360(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1361(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1362(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1363(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1364(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1365(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1366(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1367(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1368(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1369(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1370(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1371(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1372(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1373(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1374(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1375(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1376(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1377(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1378(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1379(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1380(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1381(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1382(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <8 x i8> @hydride.node.softmax_arm_depth3.1383(<8 x i16> %arg, <8 x i16> %arg.1, <8 x i16> %arg.2, <8 x i16> %arg.3, <8 x i16> %arg.4, <8 x i16> %arg.5, <8 x i16> %arg.6, <8 x i16> %arg.7, <8 x i16> %arg.8, <8 x i16> %arg.9, <8 x i16> %arg.10, <8 x i16> %arg.11, <8 x i16> %arg.12) local_unnamed_addr #13 {
entry:
  %0 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.5, <8 x i16> %arg.6) #15
  %1 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %0, <8 x i16> %arg.7) #15
  %2 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> <i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592, i16 2592>, <8 x i16> %1) #15
  %3 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.4, <8 x i16> <i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812, i16 22812>) #15
  %4 = add <8 x i16> %3, %2
  %5 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.2, <8 x i16> %arg.3) #15
  %6 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %5, <8 x i16> <i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363, i16 7363>) #15
  %7 = add <8 x i16> %4, %6
  %8 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %arg.1, <8 x i16> %7) #15
  %9 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %8, <8 x i16> %arg) #15
  %10 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %9, <8 x i16> %arg.8) #15
  %11 = tail call <8 x i16> @llvm.aarch64.neon.sqrdmulh.v8i16(<8 x i16> %10, <8 x i16> %arg.9) #15
  %12 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %arg.10, <8 x i16> %11) #15
  %13 = tail call <8 x i16> @llvm.aarch64.neon.ushl.v8i16(<8 x i16> %12, <8 x i16> %arg.11) #15
  %14 = tail call <8 x i16> @llvm.aarch64.neon.sqadd.v8i16(<8 x i16> %13, <8 x i16> %arg.12) #15
  %15 = tail call <8 x i8> @llvm.aarch64.neon.sqxtun.v8i8(<8 x i16> %14) #15
  ret <8 x i8> %15
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1384(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1385(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1386(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1387(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1388(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1389(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nounwind readnone willreturn
define <4 x i16> @hydride.node.softmax_arm_depth3.1390(<4 x i16> %arg) local_unnamed_addr #13 {
entry:
  %0 = tail call <4 x i16> @llvm.aarch64.neon.sqshl.v4i16(<4 x i16> <i16 1, i16 1, i16 1, i16 1>, <4 x i16> %arg) #15
  ret <4 x i16> %0
}

; Function Attrs: norecurse nounwind readnone willreturn
define <8 x i16> @hydride.node.softmax_arm_depth3.1391(<8 x i16> %arg) local_unnamed_addr #12 {
entry:
  %0 = add <8 x i16> %arg, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  ret <8 x i16> %0
}

; Function Attrs: nofree nosync nounwind readnone willreturn
declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64>) #9

; Function Attrs: nofree nosync nounwind readnone willreturn
declare i8 @llvm.vector.reduce.umax.v16i8(<16 x i8>) #9

attributes #0 = { nounwind mustprogress "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "no-builtins" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind willreturn mustprogress "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { argmemonly nofree nosync nounwind willreturn }
attributes #4 = { nounwind "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { argmemonly nofree nosync nounwind willreturn writeonly }
attributes #6 = { alwaysinline nounwind willreturn mustprogress "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nofree nosync nounwind readnone speculatable willreturn }
attributes #8 = { nounwind willreturn "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nofree nosync nounwind readnone willreturn }
attributes #10 = { nofree nounwind "reciprocal-estimates"="none" }
attributes #11 = { nofree nounwind }
attributes #12 = { norecurse nounwind readnone willreturn }
attributes #13 = { nounwind readnone willreturn }
attributes #14 = { nobuiltin nounwind "no-builtins" }
attributes #15 = { nounwind }
attributes #16 = { nobuiltin "no-builtins" }
attributes #17 = { nounwind readnone }
attributes #18 = { noinline }

!llvm.module.flags = !{!0, !1, !2, !3, !4, !5, !6, !7, !8, !9, !10, !11, !12}
!llvm.ident = !{!13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13, !13}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 2, !"halide_use_soft_float_abi", i32 0}
!3 = !{i32 2, !"halide_mcpu", !"apple-a12"}
!4 = !{i32 2, !"halide_mattrs", !"+reserve-x18"}
!5 = !{i32 2, !"halide_mabi", !""}
!6 = !{i32 2, !"halide_use_pic", i32 1}
!7 = !{i32 2, !"halide_use_large_code_model", i32 0}
!8 = !{i32 2, !"halide_per_instruction_fast_math_flags", i32 0}
!9 = !{i32 1, !"branch-target-enforcement", i32 0}
!10 = !{i32 1, !"sign-return-address", i32 0}
!11 = !{i32 1, !"sign-return-address-all", i32 0}
!12 = !{i32 1, !"sign-return-address-with-bkey", i32 0}
!13 = !{!"clang version 12.0.1 (https://github.com/llvm/llvm-project.git fed41342a82f5a3a9201819a82bf7a48313e296b)"}
!14 = !{!15, !15, i64 0}
!15 = !{!"any pointer", !16, i64 0}
!16 = !{!"omnipotent char", !17, i64 0}
!17 = !{!"Simple C++ TBAA"}
!18 = !{!16, !16, i64 0}
!19 = !{!20, !20, i64 0}
!20 = !{!"bool", !16, i64 0}
!21 = !{i8 0, i8 2}
!22 = !{!23, !23, i64 0}
!23 = !{!"long long", !16, i64 0}
!24 = !{!25, !26, i64 0}
!25 = !{!"_ZTS18mach_timebase_info", !26, i64 0, !26, i64 4}
!26 = !{!"int", !16, i64 0}
!27 = !{!25, !26, i64 4}
!28 = !{!29, !15, i64 0}
!29 = !{!"_ZTSN6Halide7Runtime8Internal4workE", !30, i64 0, !15, i64 56, !15, i64 64, !15, i64 72, !26, i64 80, !15, i64 88, !26, i64 96, !15, i64 104, !26, i64 112, !26, i64 116, !26, i64 120, !20, i64 124}
!30 = !{!"_ZTS22halide_parallel_task_t", !15, i64 0, !15, i64 8, !15, i64 16, !15, i64 24, !26, i64 32, !26, i64 36, !26, i64 40, !26, i64 44, !20, i64 48}
!31 = !{!29, !26, i64 36}
!32 = !{!29, !26, i64 40}
!33 = !{!29, !20, i64 48}
!34 = !{!29, !15, i64 24}
!35 = !{!29, !26, i64 32}
!36 = !{!29, !15, i64 8}
!37 = !{!29, !26, i64 44}
!38 = !{!29, !15, i64 16}
!39 = !{!29, !15, i64 56}
!40 = !{!29, !15, i64 104}
!41 = !{!26, !26, i64 0}
!42 = !{!29, !26, i64 120}
!43 = !{!29, !20, i64 124}
!44 = !{!29, !15, i64 72}
!45 = !{!29, !26, i64 80}
!46 = !{!29, !15, i64 88}
!47 = !{!29, !26, i64 116}
!48 = !{!49, !49, i64 0}
!49 = !{!"vtable pointer", !17, i64 0}
!50 = !{!51, !15, i64 8}
!51 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization21mutex_parking_controlE", !15, i64 8}
!52 = !{!53, !20, i64 2121}
!53 = !{!"_ZTSN6Halide7Runtime8Internal12work_queue_tE", !54, i64 0, !26, i64 8, !26, i64 12, !15, i64 16, !26, i64 24, !26, i64 28, !26, i64 32, !55, i64 40, !55, i64 48, !55, i64 56, !26, i64 64, !26, i64 68, !16, i64 72, !20, i64 2120, !20, i64 2121, !26, i64 2124}
!54 = !{!"_ZTS12halide_mutex", !16, i64 0}
!55 = !{!"_ZTS11halide_cond", !16, i64 0}
!56 = distinct !{!56, !57}
!57 = !{!"llvm.loop.mustprogress"}
!58 = !{!53, !26, i64 8}
!59 = distinct !{!59, !57}
!60 = !{!53, !26, i64 24}
!61 = !{!53, !26, i64 2124}
!62 = !{!53, !26, i64 28}
!63 = distinct !{!63, !57}
!64 = !{!29, !26, i64 112}
!65 = !{!29, !26, i64 96}
!66 = !{!53, !15, i64 16}
!67 = !{!29, !15, i64 64}
!68 = distinct !{!68, !57, !69}
!69 = !{!"llvm.loop.isvectorized", i32 1}
!70 = !{!53, !26, i64 68}
!71 = !{!53, !26, i64 32}
!72 = distinct !{!72, !57, !69}
!73 = !{!53, !20, i64 2120}
!74 = distinct !{!74, !57}
!75 = !{!76, !15, i64 0}
!76 = !{!"_ZTS26halide_semaphore_acquire_t", !15, i64 0, !26, i64 8}
!77 = !{!76, !26, i64 8}
!78 = distinct !{!78, !57}
!79 = !{!53, !26, i64 64}
!80 = distinct !{!80, !57}
!81 = distinct !{!81, !57}
!82 = !{i64 0, i64 8, !14, i64 8, i64 8, !14, i64 16, i64 8, !14, i64 24, i64 8, !14, i64 32, i64 4, !41, i64 36, i64 4, !41, i64 40, i64 4, !41, i64 44, i64 4, !41, i64 48, i64 1, !19, i64 56, i64 8, !14, i64 64, i64 8, !14, i64 72, i64 8, !14, i64 80, i64 4, !41, i64 88, i64 8, !14, i64 96, i64 4, !41, i64 104, i64 8, !14, i64 112, i64 4, !41, i64 116, i64 4, !41, i64 120, i64 4, !41, i64 124, i64 1, !19}
!83 = !{i64 0, i64 8, !14, i64 8, i64 8, !14, i64 16, i64 8, !14, i64 24, i64 4, !41, i64 28, i64 4, !41, i64 32, i64 4, !41, i64 36, i64 4, !41, i64 40, i64 1, !19, i64 48, i64 8, !14, i64 56, i64 8, !14, i64 64, i64 8, !14, i64 72, i64 4, !41, i64 80, i64 8, !14, i64 88, i64 4, !41, i64 96, i64 8, !14, i64 104, i64 4, !41, i64 108, i64 4, !41, i64 112, i64 4, !41, i64 116, i64 1, !19}
!84 = !{i64 0, i64 8, !14, i64 8, i64 8, !14, i64 16, i64 8, !14, i64 24, i64 4, !41, i64 32, i64 8, !14, i64 40, i64 4, !41, i64 48, i64 8, !14, i64 56, i64 4, !41, i64 60, i64 4, !41, i64 64, i64 4, !41, i64 68, i64 1, !19}
!85 = !{i64 0, i64 8, !14, i64 8, i64 4, !41, i64 12, i64 4, !41, i64 16, i64 4, !41, i64 20, i64 1, !19}
!86 = distinct !{!86, !57}
!87 = distinct !{!87, !57}
!88 = !{!89, !15, i64 144}
!89 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization10queue_dataE", !90, i64 0, !23, i64 136, !15, i64 144, !23, i64 152}
!90 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization13thread_parkerE", !91, i64 0, !92, i64 64, !20, i64 128}
!91 = !{!"_ZTS15pthread_mutex_t", !16, i64 0}
!92 = !{!"_ZTS14pthread_cond_t", !16, i64 0}
!93 = !{!94, !15, i64 16}
!94 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization11hash_bucketE", !95, i64 0, !15, i64 8, !15, i64 16}
!95 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization9word_lockE", !23, i64 0}
!96 = distinct !{!96, !57}
!97 = !{!89, !23, i64 152}
!98 = !{!90, !20, i64 128}
!99 = distinct !{!99, !57}
!100 = !{!101, !15, i64 152}
!101 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization20word_lock_queue_dataE", !90, i64 0, !15, i64 136, !15, i64 144, !15, i64 152}
!102 = !{!101, !15, i64 136}
!103 = !{!101, !15, i64 144}
!104 = distinct !{!104, !57}
!105 = distinct !{!105, !57}
!106 = distinct !{!106, !57}
!107 = !{!108, !15, i64 8}
!108 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization25broadcast_parking_controlE", !15, i64 8, !15, i64 16}
!109 = !{!108, !15, i64 16}
!110 = !{!111, !15, i64 8}
!111 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization20wait_parking_controlE", !15, i64 8, !15, i64 16}
!112 = !{!111, !15, i64 16}
!113 = !{!89, !23, i64 136}
!114 = !{!115, !20, i64 0}
!115 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization15validate_actionE", !20, i64 0, !23, i64 8}
!116 = !{!115, !23, i64 8}
!117 = !{!94, !15, i64 8}
!118 = !{!119, !15, i64 0}
!119 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization11bucket_pairE", !15, i64 0, !15, i64 8}
!120 = distinct !{!120, !57}
!121 = !{!119, !15, i64 8}
!122 = !{!123, !15, i64 0}
!123 = !{!"_ZTSN6Halide7Runtime8Internal14spawned_threadE", !15, i64 0, !15, i64 8, !124, i64 16}
!124 = !{!"long", !16, i64 0}
!125 = !{!123, !15, i64 8}
!126 = !{!123, !124, i64 16}
!127 = !{!30, !26, i64 40}
!128 = !{i64 0, i64 8, !14, i64 8, i64 8, !14, i64 16, i64 8, !14, i64 24, i64 8, !14, i64 32, i64 4, !41, i64 36, i64 4, !41, i64 40, i64 4, !41, i64 44, i64 4, !41, i64 48, i64 1, !19}
!129 = distinct !{!129, !57}
!130 = distinct !{!130, !57}
!131 = distinct !{!131, !57}
!132 = !{!133, !15, i64 8}
!133 = !{!"_ZTSN6Halide7Runtime8Internal15Synchronization22signal_parking_controlE", !15, i64 8, !15, i64 16}
!134 = !{!133, !15, i64 16}
!135 = !{!136, !15, i64 0}
!136 = !{!"_ZTS18halide_mutex_array", !15, i64 0}
!137 = distinct !{!137, !57}
!138 = !{!139, !142, i64 34}
!139 = !{!"_ZTS20halide_trace_event_t", !15, i64 0, !15, i64 8, !15, i64 16, !15, i64 24, !140, i64 32, !143, i64 36, !26, i64 40, !26, i64 44, !26, i64 48}
!140 = !{!"_ZTS13halide_type_t", !141, i64 0, !16, i64 1, !142, i64 2}
!141 = !{!"_ZTS18halide_type_code_t", !16, i64 0}
!142 = !{!"short", !16, i64 0}
!143 = !{!"_ZTS25halide_trace_event_code_t", !16, i64 0}
!144 = !{!140, !16, i64 1}
!145 = !{!139, !26, i64 48}
!146 = !{!139, !15, i64 0}
!147 = !{!139, !15, i64 24}
!148 = !{!149, !26, i64 0}
!149 = !{!"_ZTSN6Halide7Runtime8Internal23SharedExclusiveSpinLockE", !26, i64 0}
!150 = !{!151, !26, i64 4}
!151 = !{!"_ZTSN6Halide7Runtime8Internal11TraceBufferE", !149, i64 0, !26, i64 4, !26, i64 8, !16, i64 12}
!152 = !{!151, !26, i64 8}
!153 = distinct !{!153, !57}
!154 = !{!155, !26, i64 0}
!155 = !{!"_ZTS21halide_trace_packet_t", !26, i64 0, !26, i64 4, !140, i64 8, !143, i64 12, !26, i64 16, !26, i64 20, !26, i64 24}
!156 = !{!155, !26, i64 4}
!157 = !{!139, !15, i64 16}
!158 = !{!139, !15, i64 8}
!159 = !{!155, !26, i64 24}
!160 = !{!155, !142, i64 10}
!161 = distinct !{!161, !57}
!162 = !{!139, !143, i64 36}
!163 = !{!139, !16, i64 33}
!164 = distinct !{!164, !57}
!165 = !{!139, !26, i64 44}
!166 = distinct !{!166, !57, !167}
!167 = !{!"llvm.loop.peeled.count", i32 1}
!168 = !{!139, !141, i64 32}
!169 = !{!142, !142, i64 0}
!170 = !{!171, !171, i64 0}
!171 = !{!"float", !16, i64 0}
!172 = !{!173, !173, i64 0}
!173 = !{!"double", !16, i64 0}
!174 = distinct !{!174, !57, !167}
!175 = distinct !{!175, !57}
!176 = !{!139, !26, i64 40}
!177 = distinct !{!177, !57}
!178 = distinct !{!178, !57}
!179 = distinct !{!179, !57}
!180 = !{!181, !15, i64 16}
!181 = !{!"_ZTS15halide_buffer_t", !23, i64 0, !15, i64 8, !15, i64 16, !23, i64 24, !140, i64 32, !26, i64 36, !15, i64 40, !15, i64 48}
!182 = !{!181, !23, i64 0}
!183 = !{!181, !26, i64 36}
!184 = !{!181, !15, i64 40}
!185 = !{!186, !26, i64 8}
!186 = !{!"_ZTS18halide_dimension_t", !26, i64 0, !26, i64 4, !26, i64 8, !26, i64 12}
!187 = distinct !{!187, !57, !69}
!188 = !{i64 0, i64 4, !41, i64 4, i64 4, !41, i64 8, i64 4, !41, i64 12, i64 4, !41}
!189 = !{!186, !26, i64 4}
!190 = distinct !{!190, !57}
!191 = distinct !{!191, !57, !69}
!192 = !{!193, !142, i64 0}
!193 = !{!"_ZTSN6Halide7Runtime8Internal18halide_tiff_headerE", !142, i64 0, !142, i64 2, !26, i64 4, !142, i64 8, !16, i64 10, !26, i64 190, !16, i64 194, !16, i64 202}
!194 = !{!193, !142, i64 2}
!195 = !{!193, !26, i64 4}
!196 = !{!193, !142, i64 8}
!197 = !{!198, !142, i64 0}
!198 = !{!"_ZTSN6Halide7Runtime8Internal8tiff_tagE", !142, i64 0, !142, i64 2, !26, i64 4, !16, i64 8}
!199 = !{!198, !142, i64 2}
!200 = !{!198, !26, i64 4}
!201 = distinct !{!201, !57}
!202 = distinct !{!202, !57}
!203 = distinct !{!203, !57}
!204 = distinct !{!204, !57}
!205 = distinct !{!205, !57}
!206 = !{!207}
!207 = distinct !{!207, !208}
!208 = distinct !{!208, !"LVerDomain"}
!209 = !{!210}
!210 = distinct !{!210, !208}
!211 = distinct !{!211, !57, !69}
!212 = distinct !{!212, !57, !69}
!213 = distinct !{!213, !57, !69}
!214 = distinct !{!214, !57, !69}
!215 = distinct !{!215, !57, !216, !69}
!216 = !{!"llvm.loop.unroll.runtime.disable"}
!217 = distinct !{!217, !57, !69}
!218 = distinct !{!218, !57, !69}
!219 = distinct !{!219, !57, !69}
!220 = distinct !{!220, !57, !69}
!221 = !{!186, !26, i64 0}
!222 = distinct !{!222, !57}
!223 = distinct !{!223, !57, !69}
!224 = distinct !{!224, !57, !216, !69}
!225 = distinct !{!225, !57}
!226 = distinct !{!226, !57}
!227 = distinct !{!227, !57}
!228 = distinct !{!228, !57}
!229 = !{!230, !15, i64 0}
!230 = !{!"_ZTSN6Halide7Runtime8Internal10CacheEntryE", !15, i64 0, !15, i64 8, !15, i64 16, !15, i64 24, !124, i64 32, !15, i64 40, !26, i64 48, !26, i64 52, !26, i64 56, !26, i64 60, !15, i64 64, !15, i64 72, !23, i64 80, !20, i64 88}
!231 = distinct !{!231, !57}
!232 = !{!230, !26, i64 56}
!233 = !{!230, !15, i64 24}
!234 = !{!230, !15, i64 72}
!235 = distinct !{!235, !57}
!236 = distinct !{!236, !57}
!237 = !{!238, !23, i64 0}
!238 = !{!"_ZTSN6Halide7Runtime8Internal11device_copyE", !23, i64 0, !23, i64 8, !23, i64 16, !16, i64 24, !16, i64 152, !16, i64 280, !23, i64 408}
!239 = !{!238, !23, i64 8}
!240 = !{!238, !23, i64 408}
!241 = distinct !{!241, !57}
!242 = !{!238, !23, i64 16}
!243 = distinct !{!243, !57, !69}
!244 = distinct !{!244, !57, !216, !69}
!245 = distinct !{!245, !57}
!246 = distinct !{!246, !57}
!247 = distinct !{!247, !57}
!248 = distinct !{!248, !57}
!249 = !{i64 0, i64 8, !22, i64 8, i64 8, !22, i64 16, i64 8, !22, i64 24, i64 128, !18, i64 152, i64 128, !18, i64 280, i64 128, !18, i64 408, i64 8, !22}
!250 = distinct !{!250, !57}
!251 = !{!186, !26, i64 12}
!252 = !{!230, !15, i64 16}
!253 = !{!230, !124, i64 32}
!254 = !{!230, !26, i64 48}
!255 = !{!230, !26, i64 52}
!256 = !{!230, !26, i64 60}
!257 = !{!230, !15, i64 64}
!258 = !{!230, !15, i64 40}
!259 = distinct !{!259, !57}
!260 = distinct !{!260, !57}
!261 = distinct !{!261, !57}
!262 = !{!230, !20, i64 88}
!263 = !{!230, !23, i64 80}
!264 = !{i64 0, i64 8, !22, i64 8, i64 8, !14, i64 16, i64 8, !14, i64 24, i64 8, !22, i64 32, i64 1, !265, i64 33, i64 1, !18, i64 34, i64 2, !169, i64 36, i64 4, !41, i64 40, i64 8, !14, i64 48, i64 8, !14}
!265 = !{!141, !141, i64 0}
!266 = distinct !{!266, !57}
!267 = distinct !{!267, !57}
!268 = !{!230, !15, i64 8}
!269 = distinct !{!269, !57}
!270 = distinct !{!270, !57, !69}
!271 = distinct !{!271, !57, !69}
!272 = distinct !{!272, !57, !69}
!273 = distinct !{!273, !57, !69}
!274 = distinct !{!274, !57}
!275 = distinct !{!275, !57}
!276 = distinct !{!276, !57}
!277 = distinct !{!277, !57}
!278 = distinct !{!278, !57}
!279 = distinct !{!279, !57, !69}
!280 = distinct !{!280, !57, !69}
!281 = distinct !{!281, !57, !69}
!282 = distinct !{!282, !57, !69}
!283 = distinct !{!283, !57}
!284 = !{!285, !26, i64 8}
!285 = !{!"_ZTSN6Halide7Runtime8Internal16CacheBlockHeaderE", !15, i64 0, !26, i64 8}
!286 = !{!285, !15, i64 0}
!287 = distinct !{!287, !57}
!288 = distinct !{!288, !57}
!289 = distinct !{!289, !57}
!290 = distinct !{!290, !57}
!291 = distinct !{!291, !57, !69}
!292 = distinct !{!292, !57, !69}
!293 = distinct !{!293, !57, !69}
!294 = distinct !{!294, !57, !69}
!295 = distinct !{!295, !57}
!296 = distinct !{!296, !57}
!297 = distinct !{!297, !57}
!298 = distinct !{!298, !57}
!299 = distinct !{!299, !57}
!300 = distinct !{!300, !57}
!301 = distinct !{!301, !57}
!302 = distinct !{!302, !57}
!303 = distinct !{!303, !57}
!304 = !{!140, !141, i64 0}
!305 = !{!140, !142, i64 2}
!306 = !{!181, !15, i64 8}
!307 = !{!181, !23, i64 24}
!308 = distinct !{!308, !57}
!309 = !{!310, !15, i64 0}
!310 = !{!"_ZTS29halide_device_allocation_pool", !15, i64 0, !15, i64 8}
!311 = distinct !{!311, !57}
!312 = !{!310, !15, i64 8}
!313 = !{!314, !15, i64 120}
!314 = !{!"_ZTS25halide_device_interface_t", !15, i64 0, !15, i64 8, !15, i64 16, !15, i64 24, !15, i64 32, !15, i64 40, !15, i64 48, !15, i64 56, !15, i64 64, !15, i64 72, !15, i64 80, !15, i64 88, !15, i64 96, !15, i64 104, !15, i64 112, !15, i64 120}
!315 = !{!316, !15, i64 48}
!316 = !{!"_ZTS30halide_device_interface_impl_t", !15, i64 0, !15, i64 8, !15, i64 16, !15, i64 24, !15, i64 32, !15, i64 40, !15, i64 48, !15, i64 56, !15, i64 64, !15, i64 72, !15, i64 80, !15, i64 88, !15, i64 96, !15, i64 104, !15, i64 112, !15, i64 120}
!317 = !{!316, !15, i64 40}
!318 = !{!316, !15, i64 56}
!319 = !{!316, !15, i64 0}
!320 = !{!316, !15, i64 16}
!321 = !{!316, !15, i64 8}
!322 = !{!316, !15, i64 32}
!323 = !{!316, !15, i64 24}
!324 = !{!316, !15, i64 64}
!325 = !{!316, !15, i64 72}
!326 = distinct !{!326, !57, !69}
!327 = distinct !{!327, !57, !69}
!328 = distinct !{!328, !57, !69}
!329 = distinct !{!329, !57, !69}
!330 = !{!316, !15, i64 112}
!331 = !{!316, !15, i64 120}
!332 = !{!316, !15, i64 80}
!333 = !{!316, !15, i64 88}
!334 = !{!316, !15, i64 96}
!335 = !{!316, !15, i64 104}
!336 = !{i32 22, i32 33}
!337 = !{!338, !15, i64 40}
!338 = !{!"_ZTS21halide_profiler_state", !54, i64 0, !26, i64 8, !26, i64 12, !26, i64 16, !26, i64 20, !15, i64 24, !15, i64 32, !15, i64 40}
!339 = !{!338, !26, i64 16}
!340 = !{!341, !23, i64 0}
!341 = !{!"_ZTS30halide_profiler_pipeline_stats", !23, i64 0, !23, i64 8, !23, i64 16, !23, i64 24, !23, i64 32, !23, i64 40, !15, i64 48, !15, i64 56, !15, i64 64, !26, i64 72, !26, i64 76, !26, i64 80, !26, i64 84, !26, i64 88}
!342 = !{!341, !26, i64 80}
!343 = !{!341, !23, i64 32}
!344 = !{!341, !23, i64 40}
!345 = !{!341, !15, i64 48}
!346 = !{!341, !26, i64 84}
!347 = !{!341, !26, i64 88}
!348 = !{!341, !23, i64 16}
!349 = !{!341, !23, i64 24}
!350 = !{!341, !26, i64 72}
!351 = !{!341, !15, i64 56}
!352 = distinct !{!352, !57}
!353 = !{!354, !23, i64 32}
!354 = !{!"_ZTS26halide_profiler_func_stats", !23, i64 0, !23, i64 8, !23, i64 16, !23, i64 24, !23, i64 32, !23, i64 40, !23, i64 48, !15, i64 56, !26, i64 64}
!355 = !{!354, !23, i64 0}
!356 = !{!354, !15, i64 56}
!357 = distinct !{!357, !57}
!358 = distinct !{!358, !57}
!359 = distinct !{!359, !57}
!360 = !{!354, !23, i64 40}
!361 = !{!354, !23, i64 48}
!362 = distinct !{!362, !57}
!363 = !{!354, !23, i64 16}
!364 = distinct !{!364, !57}
!365 = !{!354, !26, i64 64}
!366 = distinct !{!366, !57}
!367 = !{!354, !23, i64 24}
!368 = distinct !{!368, !57}
!369 = distinct !{!369, !57}
!370 = !{!338, !15, i64 24}
!371 = !{!341, !15, i64 64}
!372 = distinct !{!372, !57}
!373 = !{!338, !26, i64 12}
!374 = distinct !{!374, !57}
!375 = !{!341, !26, i64 76}
!376 = distinct !{!376, !57}
!377 = distinct !{!377, !57}
!378 = !{!338, !15, i64 32}
!379 = !{!338, !26, i64 20}
!380 = !{!338, !26, i64 8}
!381 = distinct !{!381, !57}
!382 = distinct !{!382, !57}
!383 = distinct !{!383, !57}
!384 = distinct !{!384, !57}
!385 = !{!"branch_weights", i32 1073741824, i32 0}
!386 = !{!387, !387, i64 0}
!387 = !{!"max_x", !388, i64 0}
!388 = !{!"Halide buffer"}
!389 = !{!390, !390, i64 0}
!390 = !{!"input", !388, i64 0}
!391 = distinct !{!391, !69}
!392 = distinct !{!392, !216, !69}
!393 = !{!394, !394, i64 0}
!394 = !{!"sum_exp_row", !388, i64 0}
!395 = !{i32 0, i32 33}
!396 = !{!397, !397, i64 0}
!397 = !{!"inv_sum_exp_row", !388, i64 0}
!398 = !{!399, !399, i64 0}
!399 = !{!"max_x.width1.base0", !400, i64 0}
!400 = !{!"max_x.width2.base0", !401, i64 0}
!401 = !{!"max_x.width4.base0", !402, i64 0}
!402 = !{!"max_x.width8.base0", !403, i64 0}
!403 = !{!"max_x.width16.base0", !404, i64 0}
!404 = !{!"max_x.width32.base0", !405, i64 0}
!405 = !{!"max_x.width64.base0", !406, i64 0}
!406 = !{!"max_x.width128.base0", !407, i64 0}
!407 = !{!"max_x.width256.base0", !408, i64 0}
!408 = !{!"max_x.width512.base0", !409, i64 0}
!409 = !{!"max_x.width1024.base0", !387, i64 0}
!410 = !{!411, !411, i64 0}
!411 = !{!"max_x.width1.base1", !400, i64 0}
!412 = !{!413, !413, i64 0}
!413 = !{!"inv_sum_exp_row.width1.base1", !414, i64 0}
!414 = !{!"inv_sum_exp_row.width2.base0", !415, i64 0}
!415 = !{!"inv_sum_exp_row.width4.base0", !416, i64 0}
!416 = !{!"inv_sum_exp_row.width8.base0", !417, i64 0}
!417 = !{!"inv_sum_exp_row.width16.base0", !418, i64 0}
!418 = !{!"inv_sum_exp_row.width32.base0", !419, i64 0}
!419 = !{!"inv_sum_exp_row.width64.base0", !420, i64 0}
!420 = !{!"inv_sum_exp_row.width128.base0", !421, i64 0}
!421 = !{!"inv_sum_exp_row.width256.base0", !422, i64 0}
!422 = !{!"inv_sum_exp_row.width512.base0", !423, i64 0}
!423 = !{!"inv_sum_exp_row.width1024.base0", !397, i64 0}
!424 = !{!425, !425, i64 0}
!425 = !{!"max_x.width1.base2", !426, i64 0}
!426 = !{!"max_x.width2.base2", !401, i64 0}
!427 = !{!428, !428, i64 0}
!428 = !{!"inv_sum_exp_row.width1.base2", !429, i64 0}
!429 = !{!"inv_sum_exp_row.width2.base2", !415, i64 0}
!430 = !{!431, !431, i64 0}
!431 = !{!"max_x.width1.base3", !426, i64 0}
!432 = !{!433, !433, i64 0}
!433 = !{!"inv_sum_exp_row.width1.base3", !429, i64 0}
!434 = !{!435, !435, i64 0}
!435 = !{!"output", !388, i64 0}
!436 = distinct !{!436, !69}
!437 = distinct !{!437, !216, !69}

module name=matmul_256_32bit_bias_add_add, target=arm-64-osx-arm_dot_prod-arm_fp16-armv7s-armv81a-no_asserts-no_bounds_query-sve-sve2
external_plus_metadata func matmul_256_32bit_bias_add_add (A, B, add, bias, output) {
assert((uint64)reinterpret((halide_buffer_t *)output.buffer) != (uint64)0, halide_error_buffer_argument_is_null("output"))
assert((uint64)reinterpret((halide_buffer_t *)bias.buffer) != (uint64)0, halide_error_buffer_argument_is_null("bias"))
assert((uint64)reinterpret((halide_buffer_t *)add.buffer) != (uint64)0, halide_error_buffer_argument_is_null("add"))
assert((uint64)reinterpret((halide_buffer_t *)B.buffer) != (uint64)0, halide_error_buffer_argument_is_null("B"))
assert((uint64)reinterpret((halide_buffer_t *)A.buffer) != (uint64)0, halide_error_buffer_argument_is_null("A"))
let A = (void *)_halide_buffer_get_host((halide_buffer_t *)A.buffer)
let A.min.0 = _halide_buffer_get_min((halide_buffer_t *)A.buffer, 0)
let A.stride.0 = _halide_buffer_get_stride((halide_buffer_t *)A.buffer, 0)
let A.min.1 = _halide_buffer_get_min((halide_buffer_t *)A.buffer, 1)
let A.stride.1 = _halide_buffer_get_stride((halide_buffer_t *)A.buffer, 1)
let A.min.2 = _halide_buffer_get_min((halide_buffer_t *)A.buffer, 2)
let A.stride.2 = _halide_buffer_get_stride((halide_buffer_t *)A.buffer, 2)
let B = (void *)_halide_buffer_get_host((halide_buffer_t *)B.buffer)
let B.min.0 = _halide_buffer_get_min((halide_buffer_t *)B.buffer, 0)
let B.stride.0 = _halide_buffer_get_stride((halide_buffer_t *)B.buffer, 0)
let B.min.1 = _halide_buffer_get_min((halide_buffer_t *)B.buffer, 1)
let B.stride.1 = _halide_buffer_get_stride((halide_buffer_t *)B.buffer, 1)
let B.min.2 = _halide_buffer_get_min((halide_buffer_t *)B.buffer, 2)
let B.stride.2 = _halide_buffer_get_stride((halide_buffer_t *)B.buffer, 2)
let add = (void *)_halide_buffer_get_host((halide_buffer_t *)add.buffer)
let add.min.0 = _halide_buffer_get_min((halide_buffer_t *)add.buffer, 0)
let add.stride.0 = _halide_buffer_get_stride((halide_buffer_t *)add.buffer, 0)
let add.min.1 = _halide_buffer_get_min((halide_buffer_t *)add.buffer, 1)
let add.stride.1 = _halide_buffer_get_stride((halide_buffer_t *)add.buffer, 1)
let add.min.2 = _halide_buffer_get_min((halide_buffer_t *)add.buffer, 2)
let add.stride.2 = _halide_buffer_get_stride((halide_buffer_t *)add.buffer, 2)
let bias = (void *)_halide_buffer_get_host((halide_buffer_t *)bias.buffer)
let bias.min.0 = _halide_buffer_get_min((halide_buffer_t *)bias.buffer, 0)
let bias.stride.0 = _halide_buffer_get_stride((halide_buffer_t *)bias.buffer, 0)
let output = (void *)_halide_buffer_get_host((halide_buffer_t *)output.buffer)
let output.min.0 = _halide_buffer_get_min((halide_buffer_t *)output.buffer, 0)
let output.extent.0 = _halide_buffer_get_extent((halide_buffer_t *)output.buffer, 0)
let output.stride.0 = _halide_buffer_get_stride((halide_buffer_t *)output.buffer, 0)
let output.min.1 = _halide_buffer_get_min((halide_buffer_t *)output.buffer, 1)
let output.extent.1 = _halide_buffer_get_extent((halide_buffer_t *)output.buffer, 1)
let output.stride.1 = _halide_buffer_get_stride((halide_buffer_t *)output.buffer, 1)
let output.min.2 = _halide_buffer_get_min((halide_buffer_t *)output.buffer, 2)
let output.extent.2 = _halide_buffer_get_extent((halide_buffer_t *)output.buffer, 2)
let output.stride.2 = _halide_buffer_get_stride((halide_buffer_t *)output.buffer, 2)
assert(A.stride.0 == 1, 0)
assert(B.stride.0 == 1, 0)
assert(add.stride.0 == 1, 0)
assert(bias.stride.0 == 1, 0)
assert(output.stride.0 == 1, 0)
produce output {
 let t71 = (output.extent.2 + 3)/4
 let t72 = (output.extent.1 + 15)/16
 let t73 = ((output.min.0 - (add.min.2*add.stride.2)) - (add.min.1*add.stride.1)) - add.min.0
 let t74 = ((output.min.0 - (B.min.2*B.stride.2)) - (B.min.1*B.stride.1)) - B.min.0
 let t75 = ((output.min.0 - (A.min.2*A.stride.2)) - (A.min.1*A.stride.1)) - A.min.0
 let t76 = output.min.0 - bias.min.0
 let t77 = 0 - ((output.min.2*output.stride.2) + (output.min.1*output.stride.1))
 for (output.s0.c.rebased, 0, output.extent.0) {
  let t82 = output.s0.c.rebased + t77
  let t81 = output.s0.c.rebased + t76
  let t80 = output.s0.c.rebased + t75
  let t79 = output.s0.c.rebased + t74
  let t78 = output.s0.c.rebased + t73
  for (output.s0.y.y, 0, t71) {
   let output.s0.y.yi.base.s = min(output.s0.y.y*4, output.extent.2 + -4)
   let t95 = output.min.2 + output.s0.y.yi.base.s
   let t96 = t95 + 1
   let t97 = t95 + 2
   let t98 = t95 + 3
   let t94 = (output.stride.2*t98) + t82
   let t86 = (add.stride.2*t98) + t78
   let t90 = (A.stride.2*t98) + t80
   let t93 = (output.stride.2*t97) + t82
   let t85 = (add.stride.2*t97) + t78
   let t89 = (A.stride.2*t97) + t80
   let t92 = (output.stride.2*t96) + t82
   let t84 = (add.stride.2*t96) + t78
   let t88 = (A.stride.2*t96) + t80
   let t91 = (output.stride.2*t95) + t82
   let t83 = (add.stride.2*t95) + t78
   let t87 = (A.stride.2*t95) + t80
   for (output.s0.x.x, 0, t72) {
    let output.s0.x.xi.base.s = min(output.s0.x.x*16, output.extent.1 + -16)
    allocate matrix_mul[int32 * 64] in Stack
    produce matrix_mul {
     matrix_mul[ramp(0, 1, 16)] = add[ramp(((output.min.1 + output.s0.x.xi.base.s)*add.stride.1) + t83, add.stride.1, 16)]
     matrix_mul[ramp(16, 1, 16)] = add[ramp(((output.min.1 + output.s0.x.xi.base.s)*add.stride.1) + t84, add.stride.1, 16)]
     matrix_mul[ramp(32, 1, 16)] = add[ramp(((output.min.1 + output.s0.x.xi.base.s)*add.stride.1) + t85, add.stride.1, 16)]
     matrix_mul[ramp(48, 1, 16)] = add[ramp(((output.min.1 + output.s0.x.xi.base.s)*add.stride.1) + t86, add.stride.1, 16)]
     let t99 = ((output.min.1 + output.s0.x.xi.base.s)*B.stride.1) + t79
     for (matrix_mul.s1.r14$x, 0, 256) {
      matrix_mul[ramp(0, 1, 16)] = matrix_mul[ramp(0, 1, 16)] + (int32x16)widening_mul(B[ramp((B.stride.2*matrix_mul.s1.r14$x) + t99, B.stride.1, 16)], x16(A[(A.stride.1*matrix_mul.s1.r14$x) + t87]))
      matrix_mul[ramp(16, 1, 16)] = matrix_mul[ramp(16, 1, 16)] + (int32x16)widening_mul(B[ramp((B.stride.2*matrix_mul.s1.r14$x) + t99, B.stride.1, 16)], x16(A[(A.stride.1*matrix_mul.s1.r14$x) + t88]))
      matrix_mul[ramp(32, 1, 16)] = matrix_mul[ramp(32, 1, 16)] + (int32x16)widening_mul(B[ramp((B.stride.2*matrix_mul.s1.r14$x) + t99, B.stride.1, 16)], x16(A[(A.stride.1*matrix_mul.s1.r14$x) + t89]))
      matrix_mul[ramp(48, 1, 16)] = matrix_mul[ramp(48, 1, 16)] + (int32x16)widening_mul(B[ramp((B.stride.2*matrix_mul.s1.r14$x) + t99, B.stride.1, 16)], x16(A[(A.stride.1*matrix_mul.s1.r14$x) + t90]))
     }
    }
    consume matrix_mul {
     output[ramp(((output.min.1 + output.s0.x.xi.base.s)*output.stride.1) + t91, output.stride.1, 16)] = max(matrix_mul[ramp(0, 1, 16)] + x16(bias[t81]), x16(0))
     output[ramp(((output.min.1 + output.s0.x.xi.base.s)*output.stride.1) + t92, output.stride.1, 16)] = max(matrix_mul[ramp(16, 1, 16)] + x16(bias[t81]), x16(0))
     output[ramp(((output.min.1 + output.s0.x.xi.base.s)*output.stride.1) + t93, output.stride.1, 16)] = max(matrix_mul[ramp(32, 1, 16)] + x16(bias[t81]), x16(0))
     output[ramp(((output.min.1 + output.s0.x.xi.base.s)*output.stride.1) + t94, output.stride.1, 16)] = max(matrix_mul[ramp(48, 1, 16)] + x16(bias[t81]), x16(0))
     free matrix_mul
    }
   }
  }
 }
}
}


